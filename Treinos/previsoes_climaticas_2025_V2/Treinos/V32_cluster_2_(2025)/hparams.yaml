alias: null
batch_size: 32
context_size: null
dataloader_kwargs: null
decoder_hidden_size: 64
decoder_layers: 1
drop_last_loader: false
early_stop_patience_steps: -1
encoder_bias: true
encoder_dropout: 0.3
encoder_hidden_size: 64
encoder_n_layers: 3
exclude_insample_y: false
futr_exog_list:
- pr-wet-qrt_6
- pr-dry-qrt_6
- txx_9
- pr-wet-qrt_7
- tn90p_9
h: 2
h_train: 1
hist_exog_list: null
inference_input_size: null
inference_windows_batch_size: 1024
input_size: 3
learning_rate: 0.00010016088814767977
logger: !!python/object:pytorch_lightning.loggers.csv_logs.CSVLogger
  _experiment: null
  _flush_logs_every_n_steps: 100
  _fs: !!python/object/apply:fsspec.spec.make_instance
  - !!python/name:fsspec.implementations.local.LocalFileSystem ''
  - !!python/tuple []
  - {}
  _name: trial_101
  _prefix: ''
  _root_dir: Logs
  _save_dir: Logs
  _version: null
loss: !!python/object:neuralforecast.losses.pytorch.HuberLoss
  _backward_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _backward_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _buffers: {}
  _forward_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _forward_hooks_always_called: !!python/object/apply:collections.OrderedDict
  - []
  _forward_hooks_with_kwargs: !!python/object/apply:collections.OrderedDict
  - []
  _forward_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _forward_pre_hooks_with_kwargs: !!python/object/apply:collections.OrderedDict
  - []
  _is_full_backward_hook: null
  _load_state_dict_post_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _load_state_dict_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _modules: {}
  _non_persistent_buffers_set: !!set {}
  _parameters: {}
  _state_dict_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _state_dict_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  delta: 1.0
  horizon_weight: null
  is_distribution_output: false
  output_names:
  - ''
  outputsize_multiplier: 1
  training: true
lr_scheduler: !!python/name:torch.optim.lr_scheduler.StepLR ''
lr_scheduler_kwargs:
  gamma: 0.1
  step_size: 50
max_steps: 100
n_samples: 100
n_series: 1
num_lr_decays: -1
optimizer: !!python/name:torch.optim.adamw.AdamW ''
optimizer_kwargs:
  weight_decay: 0.01
random_seed: 42
recurrent: false
scaler_type: revin
start_padding_enabled: false
stat_exog_list: null
step_size: 1
val_check_steps: 100
valid_batch_size: null
valid_loss: null
windows_batch_size: 128
