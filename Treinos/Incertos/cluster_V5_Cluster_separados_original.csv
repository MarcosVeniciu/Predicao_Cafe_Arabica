treino_id,unique_id,ds,y,y_pred,diferença_%,flag,dataset,modelo,comentario,data_treino
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Abadia_dos_Dourados,2012-12-31T00:00:00,2.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Abadia_dos_Dourados,2013-12-31T00:00:00,1.97,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Abadia_dos_Dourados,2014-12-31T00:00:00,2.29,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Abadia_dos_Dourados,2015-12-31T00:00:00,1.97,2.225214958190918,12.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Abadia_dos_Dourados,2016-12-31T00:00:00,2.19,2.165462017059326,1.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Abadia_dos_Dourados,2017-12-31T00:00:00,0.83,2.0500855445861816,147.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Abadia_dos_Dourados,2018-12-31T00:00:00,1.2,1.7568615674972534,46.41,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Agua_Boa,2012-12-31T00:00:00,1.12,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Agua_Boa,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Agua_Boa,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Agua_Boa,2015-12-31T00:00:00,1.08,1.1613385677337646,7.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Agua_Boa,2016-12-31T00:00:00,1.08,1.0853763818740845,0.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Agua_Boa,2017-12-31T00:00:00,1.11,1.0237057209014893,7.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Agua_Boa,2018-12-31T00:00:00,1.2,1.1119346618652344,7.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Aguas_Vermelhas,2012-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Aguas_Vermelhas,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Aguas_Vermelhas,2014-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Aguas_Vermelhas,2015-12-31T00:00:00,1.2,1.6296582221984863,35.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Aguas_Vermelhas,2016-12-31T00:00:00,3.6,1.5317291021347046,57.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Aguas_Vermelhas,2017-12-31T00:00:00,2.6,1.8789385557174683,27.73,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Aguas_Vermelhas,2018-12-31T00:00:00,3.0,2.7351768016815186,8.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Alto_Caparao,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Alto_Caparao,2013-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Alto_Caparao,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Alto_Caparao,2015-12-31T00:00:00,1.2,1.551392674446106,29.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Alto_Caparao,2016-12-31T00:00:00,2.1,1.5467698574066162,26.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Alto_Caparao,2017-12-31T00:00:00,1.37,1.48233962059021,8.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Alto_Caparao,2018-12-31T00:00:00,1.5,2.1673660278320312,44.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Araponga,2012-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Araponga,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Araponga,2014-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Araponga,2015-12-31T00:00:00,1.26,1.303446650505066,3.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Araponga,2016-12-31T00:00:00,1.32,1.2809624671936035,2.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Araponga,2017-12-31T00:00:00,1.5,1.180795669555664,21.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Araponga,2018-12-31T00:00:00,1.38,1.5133922100067139,9.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Areado,2012-12-31T00:00:00,1.95,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Areado,2013-12-31T00:00:00,1.86,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Areado,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Areado,2015-12-31T00:00:00,1.68,1.783054232597351,6.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Areado,2016-12-31T00:00:00,2.04,1.8554866313934326,9.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Areado,2017-12-31T00:00:00,1.68,1.4736663103103638,12.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Areado,2018-12-31T00:00:00,1.5,1.7629481554031372,17.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ataleia,2012-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ataleia,2013-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ataleia,2014-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ataleia,2015-12-31T00:00:00,0.91,0.7653099894523621,15.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ataleia,2016-12-31T00:00:00,0.91,0.8738313317298889,3.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ataleia,2017-12-31T00:00:00,0.65,0.7810875177383423,20.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ataleia,2018-12-31T00:00:00,0.9,0.9723994135856628,8.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Bom_Jesus_do_Galho,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Bom_Jesus_do_Galho,2013-12-31T00:00:00,0.78,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Bom_Jesus_do_Galho,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Bom_Jesus_do_Galho,2015-12-31T00:00:00,0.96,0.9059910774230957,5.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Bom_Jesus_do_Galho,2016-12-31T00:00:00,1.8,0.9040595293045044,49.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Bom_Jesus_do_Galho,2017-12-31T00:00:00,0.82,1.1387994289398193,38.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Bom_Jesus_do_Galho,2018-12-31T00:00:00,1.2,2.112943172454834,76.08,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caiana,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caiana,2013-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caiana,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caiana,2015-12-31T00:00:00,0.96,1.1097357273101807,15.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caiana,2016-12-31T00:00:00,1.2,1.1595934629440308,3.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caiana,2017-12-31T00:00:00,1.2,1.1082786321640015,7.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caiana,2018-12-31T00:00:00,1.5,1.3957288265228271,6.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Cajuri,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Cajuri,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Cajuri,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Cajuri,2015-12-31T00:00:00,1.32,1.7812888622283936,34.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Cajuri,2016-12-31T00:00:00,1.2,1.2234054803848267,1.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Cajuri,2017-12-31T00:00:00,1.2,1.2740089893341064,6.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Cajuri,2018-12-31T00:00:00,1.8,1.2955607175827026,28.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Canaa,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Canaa,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Canaa,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Canaa,2015-12-31T00:00:00,1.02,1.2933344841003418,26.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Canaa,2016-12-31T00:00:00,1.2,1.2068477869033813,0.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Canaa,2017-12-31T00:00:00,1.5,1.116276741027832,25.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Canaa,2018-12-31T00:00:00,1.5,1.5491564273834229,3.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caparao,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caparao,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caparao,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caparao,2015-12-31T00:00:00,1.02,1.4285129308700562,40.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caparao,2016-12-31T00:00:00,1.92,1.2291135787963867,35.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caparao,2017-12-31T00:00:00,1.45,1.267555832862854,12.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caparao,2018-12-31T00:00:00,1.8,1.9903125762939453,10.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caputira,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caputira,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caputira,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caputira,2015-12-31T00:00:00,1.5,1.3658119440078735,8.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caputira,2016-12-31T00:00:00,1.26,1.4076271057128906,11.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caputira,2017-12-31T00:00:00,0.77,1.2882719039916992,67.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caputira,2018-12-31T00:00:00,1.2,1.627044677734375,35.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Carai,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Carai,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Carai,2014-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Carai,2015-12-31T00:00:00,0.96,0.9015203714370728,6.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Carai,2016-12-31T00:00:00,0.96,0.982577383518219,2.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Carai,2017-12-31T00:00:00,0.54,0.784501850605011,45.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Carai,2018-12-31T00:00:00,0.84,1.103897213935852,31.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Carangola,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Carangola,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Carangola,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Carangola,2015-12-31T00:00:00,0.9,1.0136502981185913,12.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Carangola,2016-12-31T00:00:00,1.2,4.126408100128174,243.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Carangola,2017-12-31T00:00:00,1.1,0.9742884039878845,11.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Carangola,2018-12-31T00:00:00,1.56,1.2697113752365112,18.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caratinga,2012-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caratinga,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caratinga,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caratinga,2015-12-31T00:00:00,1.08,1.1227785348892212,3.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caratinga,2016-12-31T00:00:00,1.56,1.1006306409835815,29.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caratinga,2017-12-31T00:00:00,1.46,1.1526198387145996,21.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caratinga,2018-12-31T00:00:00,1.8,1.813787579536438,0.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Central_de_Minas,2012-12-31T00:00:00,0.42,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Central_de_Minas,2013-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Central_de_Minas,2014-12-31T00:00:00,0.51,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Central_de_Minas,2015-12-31T00:00:00,0.72,0.62311851978302,13.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Central_de_Minas,2016-12-31T00:00:00,0.72,0.6928002834320068,3.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Central_de_Minas,2017-12-31T00:00:00,0.6,0.6168103218078613,2.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Central_de_Minas,2018-12-31T00:00:00,1.0,0.7495416402816772,25.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Chale,2012-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Chale,2013-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Chale,2014-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Chale,2015-12-31T00:00:00,1.38,1.6163537502288818,17.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Chale,2016-12-31T00:00:00,1.42,1.5997254848480225,12.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Chale,2017-12-31T00:00:00,0.93,1.4179017543792725,52.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Chale,2018-12-31T00:00:00,1.38,1.6867196559906006,22.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Conceicao_de_Ipanema,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Conceicao_de_Ipanema,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Conceicao_de_Ipanema,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Conceicao_de_Ipanema,2015-12-31T00:00:00,1.14,1.1538447141647339,1.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Conceicao_de_Ipanema,2016-12-31T00:00:00,1.44,1.153890609741211,19.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Conceicao_de_Ipanema,2017-12-31T00:00:00,1.44,1.1968098878860474,16.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Conceicao_de_Ipanema,2018-12-31T00:00:00,1.56,1.611042857170105,3.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Datas,2012-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Datas,2013-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Datas,2014-12-31T00:00:00,0.79,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Datas,2015-12-31T00:00:00,1.4,1.0621048212051392,24.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Datas,2016-12-31T00:00:00,1.2,1.120627999305725,6.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Datas,2017-12-31T00:00:00,1.5,1.1263080835342407,24.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Datas,2018-12-31T00:00:00,3.0,1.6231801509857178,45.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Divino,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Divino,2013-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Divino,2014-12-31T00:00:00,0.89,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Divino,2015-12-31T00:00:00,1.2,1.2965540885925293,8.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Divino,2016-12-31T00:00:00,1.2,1.3797495365142822,14.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Divino,2017-12-31T00:00:00,1.19,1.0747359991073608,9.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Divino,2018-12-31T00:00:00,1.32,1.2098156213760376,8.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Durande,2012-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Durande,2013-12-31T00:00:00,2.22,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Durande,2014-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Durande,2015-12-31T00:00:00,1.68,1.8526684045791626,10.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Durande,2016-12-31T00:00:00,1.8,1.7934978008270264,0.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Durande,2017-12-31T00:00:00,1.33,1.5794434547424316,18.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Durande,2018-12-31T00:00:00,2.1,2.128512144088745,1.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Entre_Folhas,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Entre_Folhas,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Entre_Folhas,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Entre_Folhas,2015-12-31T00:00:00,1.0,1.059966802597046,6.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Entre_Folhas,2016-12-31T00:00:00,1.2,1.086715579032898,9.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Entre_Folhas,2017-12-31T00:00:00,0.86,1.1476552486419678,33.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Entre_Folhas,2018-12-31T00:00:00,1.2,1.2110753059387207,0.92,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ervalia,2012-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ervalia,2013-12-31T00:00:00,1.92,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ervalia,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ervalia,2015-12-31T00:00:00,1.5,1.6754460334777832,11.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ervalia,2016-12-31T00:00:00,1.32,1.4392504692077637,9.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ervalia,2017-12-31T00:00:00,1.36,1.2793909311294556,5.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ervalia,2018-12-31T00:00:00,1.8,1.5274139642715454,15.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Espera_Feliz,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Espera_Feliz,2013-12-31T00:00:00,1.92,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Espera_Feliz,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Espera_Feliz,2015-12-31T00:00:00,1.38,1.3814563751220703,0.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Espera_Feliz,2016-12-31T00:00:00,1.68,1.7170300483703613,2.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Espera_Feliz,2017-12-31T00:00:00,1.21,1.3187546730041504,8.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Espera_Feliz,2018-12-31T00:00:00,1.92,1.9568867683410645,1.92,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Faria_Lemos,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Faria_Lemos,2013-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Faria_Lemos,2014-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Faria_Lemos,2015-12-31T00:00:00,1.32,1.1085608005523682,16.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Faria_Lemos,2016-12-31T00:00:00,1.38,1.266720175743103,8.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Faria_Lemos,2017-12-31T00:00:00,0.97,1.2101366519927979,24.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Faria_Lemos,2018-12-31T00:00:00,1.2,1.5269360542297363,27.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ferros,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ferros,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ferros,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ferros,2015-12-31T00:00:00,1.08,1.3148109912872314,21.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ferros,2016-12-31T00:00:00,1.2,1.3173143863677979,9.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ferros,2017-12-31T00:00:00,0.59,1.1504818201065063,95.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ferros,2018-12-31T00:00:00,0.84,1.0053489208221436,19.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Franciscopolis,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Franciscopolis,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Franciscopolis,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Franciscopolis,2015-12-31T00:00:00,1.08,3.314145565032959,206.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Franciscopolis,2016-12-31T00:00:00,1.2,1.0610787868499756,11.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Franciscopolis,2017-12-31T00:00:00,0.52,1.0020923614501953,92.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Franciscopolis,2018-12-31T00:00:00,1.8,1.3374518156051636,25.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Itanhomi,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Itanhomi,2013-12-31T00:00:00,1.35,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Itanhomi,2014-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Itanhomi,2015-12-31T00:00:00,1.2,1.3101189136505127,9.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Itanhomi,2016-12-31T00:00:00,1.14,1.2287538051605225,7.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Itanhomi,2017-12-31T00:00:00,1.0,1.0912079811096191,9.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Itanhomi,2018-12-31T00:00:00,1.62,1.2166273593902588,24.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lagoa_Formosa,2012-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lagoa_Formosa,2013-12-31T00:00:00,2.4,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lagoa_Formosa,2014-12-31T00:00:00,2.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lagoa_Formosa,2015-12-31T00:00:00,2.4,2.4532480239868164,2.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lagoa_Formosa,2016-12-31T00:00:00,1.8,2.305006742477417,28.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lagoa_Formosa,2017-12-31T00:00:00,1.92,1.9487758874893188,1.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lagoa_Formosa,2018-12-31T00:00:00,1.92,2.04522442817688,6.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lagoa_Grande,2012-12-31T00:00:00,1.43,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lagoa_Grande,2013-12-31T00:00:00,3.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lagoa_Grande,2014-12-31T00:00:00,1.79,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lagoa_Grande,2015-12-31T00:00:00,2.38,2.730877161026001,14.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lagoa_Grande,2016-12-31T00:00:00,2.1,2.4926717281341553,18.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lagoa_Grande,2017-12-31T00:00:00,2.1,1.9640157222747803,6.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lagoa_Grande,2018-12-31T00:00:00,2.1,2.162933349609375,3.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lajinha,2012-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lajinha,2013-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lajinha,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lajinha,2015-12-31T00:00:00,1.44,1.566648244857788,8.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lajinha,2016-12-31T00:00:00,1.68,1.387444019317627,17.41,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lajinha,2017-12-31T00:00:00,1.04,1.227083683013916,17.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lajinha,2018-12-31T00:00:00,1.68,1.817848563194275,8.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Luisburgo,2012-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Luisburgo,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Luisburgo,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Luisburgo,2015-12-31T00:00:00,1.5,1.3386058807373047,10.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Luisburgo,2016-12-31T00:00:00,1.32,1.483224868774414,12.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Luisburgo,2017-12-31T00:00:00,1.53,1.3542118072509766,11.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Luisburgo,2018-12-31T00:00:00,1.8,1.7324626445770264,3.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Malacacheta,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Malacacheta,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Malacacheta,2014-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Malacacheta,2015-12-31T00:00:00,1.5,1.5176060199737549,1.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Malacacheta,2016-12-31T00:00:00,1.32,1.4923043251037598,13.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Malacacheta,2017-12-31T00:00:00,1.37,1.3565986156463623,0.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Malacacheta,2018-12-31T00:00:00,1.8,1.5284124612808228,15.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Manhuacu,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Manhuacu,2013-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Manhuacu,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Manhuacu,2015-12-31T00:00:00,1.38,1.2341564893722534,10.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Manhuacu,2016-12-31T00:00:00,1.26,1.3003653287887573,3.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Manhuacu,2017-12-31T00:00:00,1.43,1.136244535446167,20.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Manhuacu,2018-12-31T00:00:00,1.44,1.4536473751068115,0.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Manhumirim,2012-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Manhumirim,2013-12-31T00:00:00,1.92,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Manhumirim,2014-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Manhumirim,2015-12-31T00:00:00,1.8,1.6110763549804688,10.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Manhumirim,2016-12-31T00:00:00,1.32,1.817826747894287,37.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Manhumirim,2017-12-31T00:00:00,1.62,1.3759125471115112,15.07,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Manhumirim,2018-12-31T00:00:00,1.56,1.7824922800064087,14.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Matipo,2012-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Matipo,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Matipo,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Matipo,2015-12-31T00:00:00,1.44,1.3336598873138428,7.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Matipo,2016-12-31T00:00:00,1.32,1.397702932357788,5.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Matipo,2017-12-31T00:00:00,0.9,1.290553092956543,43.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Matipo,2018-12-31T00:00:00,1.32,1.5263404846191406,15.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Mirai,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Mirai,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Mirai,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Mirai,2015-12-31T00:00:00,0.84,1.1099454164505005,32.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Mirai,2016-12-31T00:00:00,1.2,0.9638305902481079,19.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Mirai,2017-12-31T00:00:00,1.02,1.0080487728118896,1.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Mirai,2018-12-31T00:00:00,1.2,1.158446192741394,3.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Muriae,2012-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Muriae,2013-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Muriae,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Muriae,2015-12-31T00:00:00,1.08,1.174833059310913,8.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Muriae,2016-12-31T00:00:00,1.32,1.1292760372161865,14.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Muriae,2017-12-31T00:00:00,1.44,1.0501904487609863,27.07,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Muriae,2018-12-31T00:00:00,1.44,1.478770136833191,2.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Mutum,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Mutum,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Mutum,2014-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Mutum,2015-12-31T00:00:00,1.15,1.3807287216186523,20.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Mutum,2016-12-31T00:00:00,1.26,1.3213351964950562,4.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Mutum,2017-12-31T00:00:00,1.45,1.185356855392456,18.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Mutum,2018-12-31T00:00:00,1.5,1.5112457275390625,0.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Nova_Belem,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Nova_Belem,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Nova_Belem,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Nova_Belem,2015-12-31T00:00:00,0.9,2.5904579162597656,187.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Nova_Belem,2016-12-31T00:00:00,1.2,4.126032829284668,243.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Nova_Belem,2017-12-31T00:00:00,0.48,0.9754941463470459,103.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Nova_Belem,2018-12-31T00:00:00,1.2,1.2213550806045532,1.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Orizania,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Orizania,2013-12-31T00:00:00,1.68,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Orizania,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Orizania,2015-12-31T00:00:00,1.2,1.3107328414916992,9.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Orizania,2016-12-31T00:00:00,1.8,1.377801775932312,23.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Orizania,2017-12-31T00:00:00,1.47,1.3595480918884277,7.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Orizania,2018-12-31T00:00:00,1.56,1.8244297504425049,16.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Patis,2012-12-31T00:00:00,2.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Patis,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Patis,2014-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Patis,2015-12-31T00:00:00,2.8,1.4500970840454102,48.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Patis,2016-12-31T00:00:00,1.19,1.6394667625427246,37.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Patis,2017-12-31T00:00:00,1.8,1.7582145929336548,2.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Patis,2018-12-31T00:00:00,3.6,2.4971184730529785,30.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ponte_Nova,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ponte_Nova,2013-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ponte_Nova,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ponte_Nova,2015-12-31T00:00:00,1.26,1.222951054573059,2.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ponte_Nova,2016-12-31T00:00:00,1.2,1.1950680017471313,0.41,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ponte_Nova,2017-12-31T00:00:00,1.17,1.1680467128753662,0.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ponte_Nova,2018-12-31T00:00:00,1.5,1.3115837574005127,12.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Porto_Firme,2012-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Porto_Firme,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Porto_Firme,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Porto_Firme,2015-12-31T00:00:00,1.26,1.0958976745605469,13.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Porto_Firme,2016-12-31T00:00:00,1.2,1.2075588703155518,0.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Porto_Firme,2017-12-31T00:00:00,1.2,1.1762158870697021,1.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Porto_Firme,2018-12-31T00:00:00,1.2,1.261406660079956,5.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Raul_Soares,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Raul_Soares,2013-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Raul_Soares,2014-12-31T00:00:00,0.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Raul_Soares,2015-12-31T00:00:00,1.08,1.1106750965118408,2.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Raul_Soares,2016-12-31T00:00:00,1.08,1.0075660943984985,6.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Raul_Soares,2017-12-31T00:00:00,0.86,0.9527634978294373,10.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Raul_Soares,2018-12-31T00:00:00,1.2,1.243361234664917,3.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Reduto,2012-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Reduto,2013-12-31T00:00:00,1.62,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Reduto,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Reduto,2015-12-31T00:00:00,1.38,1.3772916793823242,0.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Reduto,2016-12-31T00:00:00,1.44,1.4297271966934204,0.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Reduto,2017-12-31T00:00:00,1.26,1.2366859912872314,1.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Reduto,2018-12-31T00:00:00,1.8,1.4734361171722412,18.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Rio_Pardo_de_Minas,2012-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Rio_Pardo_de_Minas,2013-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Rio_Pardo_de_Minas,2014-12-31T00:00:00,2.65,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Rio_Pardo_de_Minas,2015-12-31T00:00:00,2.28,2.2074339389801025,3.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Rio_Pardo_de_Minas,2016-12-31T00:00:00,2.46,2.4208760261535645,1.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Rio_Pardo_de_Minas,2017-12-31T00:00:00,2.18,2.462151050567627,12.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Rio_Pardo_de_Minas,2018-12-31T00:00:00,2.63,2.377394437789917,9.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Rosario_da_Limeira,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Rosario_da_Limeira,2013-12-31T00:00:00,1.54,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Rosario_da_Limeira,2014-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Rosario_da_Limeira,2015-12-31T00:00:00,1.14,1.4834718704223633,30.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Rosario_da_Limeira,2016-12-31T00:00:00,1.26,1.3378101587295532,6.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Rosario_da_Limeira,2017-12-31T00:00:00,0.78,1.2504829168319702,60.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Rosario_da_Limeira,2018-12-31T00:00:00,1.2,1.3400259017944336,11.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Barbara_do_Leste,2012-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Barbara_do_Leste,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Barbara_do_Leste,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Barbara_do_Leste,2015-12-31T00:00:00,1.08,1.1230040788650513,3.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Barbara_do_Leste,2016-12-31T00:00:00,1.02,1.096869945526123,7.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Barbara_do_Leste,2017-12-31T00:00:00,0.91,1.0027552843093872,10.19,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Barbara_do_Leste,2018-12-31T00:00:00,1.74,1.1595852375030518,33.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Margarida,2012-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Margarida,2013-12-31T00:00:00,1.68,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Margarida,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Margarida,2015-12-31T00:00:00,1.56,1.4551628828048706,6.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Margarida,2016-12-31T00:00:00,1.32,1.4880836009979248,12.73,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Margarida,2017-12-31T00:00:00,1.2,1.3324027061462402,11.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Margarida,2018-12-31T00:00:00,1.68,1.567725658416748,6.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Rita_de_Minas,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Rita_de_Minas,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Rita_de_Minas,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Rita_de_Minas,2015-12-31T00:00:00,1.2,1.1869263648986816,1.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Rita_de_Minas,2016-12-31T00:00:00,1.08,1.128062129020691,4.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Rita_de_Minas,2017-12-31T00:00:00,1.25,1.0419667959213257,16.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Rita_de_Minas,2018-12-31T00:00:00,1.5,1.3200931549072266,11.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santana_do_Manhuacu,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santana_do_Manhuacu,2013-12-31T00:00:00,1.62,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santana_do_Manhuacu,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santana_do_Manhuacu,2015-12-31T00:00:00,1.44,1.4862178564071655,3.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santana_do_Manhuacu,2016-12-31T00:00:00,1.32,1.4459514617919922,9.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santana_do_Manhuacu,2017-12-31T00:00:00,1.28,1.2696146965026855,0.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santana_do_Manhuacu,2018-12-31T00:00:00,1.5,1.4610545635223389,2.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Francisco_do_Gloria,2012-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Francisco_do_Gloria,2013-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Francisco_do_Gloria,2014-12-31T00:00:00,1.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Francisco_do_Gloria,2015-12-31T00:00:00,1.32,1.2728763818740845,3.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Francisco_do_Gloria,2016-12-31T00:00:00,1.5,1.2953455448150635,13.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Francisco_do_Gloria,2017-12-31T00:00:00,0.8,1.3404589891433716,67.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Francisco_do_Gloria,2018-12-31T00:00:00,1.32,1.6061776876449585,21.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Joao_do_Manhuacu,2012-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Joao_do_Manhuacu,2013-12-31T00:00:00,1.74,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Joao_do_Manhuacu,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Joao_do_Manhuacu,2015-12-31T00:00:00,1.32,1.446770429611206,9.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Joao_do_Manhuacu,2016-12-31T00:00:00,1.32,1.3859888315200806,5.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Joao_do_Manhuacu,2017-12-31T00:00:00,1.7,1.2114733457565308,28.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Joao_do_Manhuacu,2018-12-31T00:00:00,1.62,1.8096330165863037,11.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Jose_do_Mantimento,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Jose_do_Mantimento,2013-12-31T00:00:00,1.42,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Jose_do_Mantimento,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Jose_do_Mantimento,2015-12-31T00:00:00,1.44,1.3148834705352783,8.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Jose_do_Mantimento,2016-12-31T00:00:00,1.2,1.3941680192947388,16.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Jose_do_Mantimento,2017-12-31T00:00:00,1.2,1.239254117012024,3.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Jose_do_Mantimento,2018-12-31T00:00:00,1.44,1.4909708499908447,3.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sericita,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sericita,2013-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sericita,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sericita,2015-12-31T00:00:00,1.2,1.321537971496582,10.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sericita,2016-12-31T00:00:00,1.2,1.271117925643921,5.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sericita,2017-12-31T00:00:00,1.12,1.1483405828475952,2.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sericita,2018-12-31T00:00:00,1.8,1.2667157649993896,29.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Setubinha,2012-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Setubinha,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Setubinha,2014-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Setubinha,2015-12-31T00:00:00,0.9,0.8322755098342896,7.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Setubinha,2016-12-31T00:00:00,1.5,0.9366511106491089,37.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Setubinha,2017-12-31T00:00:00,0.76,0.8822212815284729,16.08,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Setubinha,2018-12-31T00:00:00,0.9,1.5163419246673584,68.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Teofilo_Otoni,2012-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Teofilo_Otoni,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Teofilo_Otoni,2014-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Teofilo_Otoni,2015-12-31T00:00:00,0.9,0.8112048506736755,9.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Teofilo_Otoni,2016-12-31T00:00:00,0.9,0.875868558883667,2.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Teofilo_Otoni,2017-12-31T00:00:00,0.67,0.7611346244812012,13.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Teofilo_Otoni,2018-12-31T00:00:00,0.91,0.9175853729248047,0.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Tombos,2012-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Tombos,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Tombos,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Tombos,2015-12-31T00:00:00,1.2,1.1055364608764648,7.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Tombos,2016-12-31T00:00:00,0.96,1.1614786386489868,20.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Tombos,2017-12-31T00:00:00,0.99,1.0481163263320923,5.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Tombos,2018-12-31T00:00:00,1.44,1.1826143264770508,17.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ubaporanga,2012-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ubaporanga,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ubaporanga,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ubaporanga,2015-12-31T00:00:00,1.2,1.3136152029037476,9.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ubaporanga,2016-12-31T00:00:00,0.96,1.2191352844238281,26.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ubaporanga,2017-12-31T00:00:00,1.03,1.021189570426941,0.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ubaporanga,2018-12-31T00:00:00,1.5,1.5194331407546997,1.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Urucuia,2012-12-31T00:00:00,2.4,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Urucuia,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Urucuia,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Urucuia,2015-12-31T00:00:00,1.8,1.8638529777526855,3.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Urucuia,2016-12-31T00:00:00,2.4,2.3690199851989746,1.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Urucuia,2017-12-31T00:00:00,1.8,1.611828088760376,10.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Urucuia,2018-12-31T00:00:00,2.4,2.181640625,9.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vermelho_Novo,2012-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vermelho_Novo,2013-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vermelho_Novo,2014-12-31T00:00:00,0.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vermelho_Novo,2015-12-31T00:00:00,1.2,0.9487432241439819,20.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vermelho_Novo,2016-12-31T00:00:00,1.2,1.0060757398605347,16.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vermelho_Novo,2017-12-31T00:00:00,1.08,1.0266176462173462,4.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vermelho_Novo,2018-12-31T00:00:00,1.32,1.2885748147964478,2.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vicosa,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vicosa,2013-12-31T00:00:00,1.62,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vicosa,2014-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vicosa,2015-12-31T00:00:00,1.44,1.5062414407730103,4.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vicosa,2016-12-31T00:00:00,1.16,1.3771830797195435,18.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vicosa,2017-12-31T00:00:00,1.49,1.3873223066329956,6.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vicosa,2018-12-31T00:00:00,1.56,1.6414177417755127,5.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vieiras,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vieiras,2013-12-31T00:00:00,1.81,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vieiras,2014-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vieiras,2015-12-31T00:00:00,1.32,1.6561667919158936,25.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vieiras,2016-12-31T00:00:00,1.2,1.6495883464813232,37.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vieiras,2017-12-31T00:00:00,1.13,1.5014126300811768,32.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vieiras,2018-12-31T00:00:00,1.26,1.3028450012207031,3.4,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Virginopolis,2012-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Virginopolis,2013-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Virginopolis,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Virginopolis,2015-12-31T00:00:00,1.32,1.2702043056488037,3.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Virginopolis,2016-12-31T00:00:00,1.0,1.2623488903045654,26.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Virginopolis,2017-12-31T00:00:00,1.37,1.1870696544647217,13.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Virginopolis,2018-12-31T00:00:00,1.5,1.477065920829773,1.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Abadia_dos_Dourados,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Agua_Boa,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Aguas_Vermelhas,2019-12-31T00:00:00,3.0,3,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Alto_Caparao,2019-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Araponga,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Areado,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ataleia,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Bom_Jesus_do_Galho,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caiana,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Cajuri,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Canaa,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caparao,2019-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caputira,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Carai,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Carangola,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caratinga,2019-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Central_de_Minas,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Chale,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Conceicao_de_Ipanema,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Datas,2019-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Divino,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Durande,2019-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Entre_Folhas,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ervalia,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Espera_Feliz,2019-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Faria_Lemos,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ferros,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Franciscopolis,2019-12-31T00:00:00,3.0,1,-66.67,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Itanhomi,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lagoa_Formosa,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lagoa_Grande,2019-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lajinha,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Luisburgo,2019-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Malacacheta,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Manhuacu,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Manhumirim,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Matipo,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Mirai,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Muriae,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Mutum,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Nova_Belem,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Orizania,2019-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Patis,2019-12-31T00:00:00,3.0,2,-33.33,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ponte_Nova,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Porto_Firme,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Raul_Soares,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Reduto,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Rio_Pardo_de_Minas,2019-12-31T00:00:00,3.0,2,-33.33,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Rosario_da_Limeira,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Barbara_do_Leste,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Margarida,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Rita_de_Minas,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santana_do_Manhuacu,2019-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Francisco_do_Gloria,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Joao_do_Manhuacu,2019-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Jose_do_Mantimento,2019-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sericita,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Setubinha,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Teofilo_Otoni,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Tombos,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ubaporanga,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Urucuia,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vermelho_Novo,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vicosa,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vieiras,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Virginopolis,2019-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Abadia_dos_Dourados,2020-12-31T00:00:00,2.584210526315789,2.2816414833068848,-11.71,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Agua_Boa,2020-12-31T00:00:00,1.33,1.2557251453399658,-5.58,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Aguas_Vermelhas,2020-12-31T00:00:00,3.6000000000000005,3.3031630516052246,-8.25,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Alto_Caparao,2020-12-31T00:00:00,1.92,1.4821417331695557,-22.81,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Araponga,2020-12-31T00:00:00,1.8000000000000005,1.5291705131530762,-15.05,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Areado,2020-12-31T00:00:00,2.078746484531941,1.9631084203720093,-5.56,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ataleia,2020-12-31T00:00:00,1.204819277108434,0.954089879989624,-20.81,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Bom_Jesus_do_Galho,2020-12-31T00:00:00,1.44,1.1491154432296753,-20.2,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caiana,2020-12-31T00:00:00,1.5,1.5291638374328613,1.94,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Cajuri,2020-12-31T00:00:00,1.8000000000000005,1.840423822402954,2.25,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Canaa,2020-12-31T00:00:00,1.8000000000000005,1.537367343902588,-14.59,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caparao,2020-12-31T00:00:00,1.9199600798403191,1.729040265083313,-9.94,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caputira,2020-12-31T00:00:00,1.8000000000000005,1.2264323234558105,-31.86,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Carai,2020-12-31T00:00:00,1.5225,1.2326676845550537,-19.04,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Carangola,2020-12-31T00:00:00,1.5,1.5252281427383423,1.68,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Caratinga,2020-12-31T00:00:00,2.040022111663903,1.747580885887146,-14.34,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Central_de_Minas,2020-12-31T00:00:00,0.6666666666666667,1.1086838245391846,66.3,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Chale,2020-12-31T00:00:00,1.71015625,1.3044267892837524,-23.72,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Conceicao_de_Ipanema,2020-12-31T00:00:00,1.500533617929563,1.4826035499572754,-1.19,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Datas,2020-12-31T00:00:00,2.0,2.2776083946228027,13.88,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Divino,2020-12-31T00:00:00,1.8000483851457605,1.320742130279541,-26.63,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Durande,2020-12-31T00:00:00,2.4,2.070668935775757,-13.72,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Entre_Folhas,2020-12-31T00:00:00,1.26046511627907,1.1342676877975464,-10.01,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ervalia,2020-12-31T00:00:00,1.7999614197530858,1.6852545738220215,-6.37,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Espera_Feliz,2020-12-31T00:00:00,2.04,2.113980531692505,3.63,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Faria_Lemos,2020-12-31T00:00:00,1.44031007751938,1.191304326057434,-17.29,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ferros,2020-12-31T00:00:00,1.2,0.9024779796600342,-24.79,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Franciscopolis,2020-12-31T00:00:00,1.8000000000000005,4.370452880859375,142.8,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Itanhomi,2020-12-31T00:00:00,1.26,1.688717246055603,34.03,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lagoa_Formosa,2020-12-31T00:00:00,2.5494505494505484,2.4490582942962646,-3.94,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lagoa_Grande,2020-12-31T00:00:00,2.4,2.453397512435913,2.22,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Lajinha,2020-12-31T00:00:00,1.9200446677833607,1.520205020904541,-20.82,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Luisburgo,2020-12-31T00:00:00,2.1,1.800461769104004,-14.26,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Malacacheta,2020-12-31T00:00:00,1.8000000000000005,1.9114978313446045,6.19,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Manhuacu,2020-12-31T00:00:00,1.6800182481751822,1.4624946117401123,-12.95,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Manhumirim,2020-12-31T00:00:00,1.68,1.6634784936904907,-0.98,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Matipo,2020-12-31T00:00:00,1.56,1.367431879043579,-12.34,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Mirai,2020-12-31T00:00:00,1.5011494252873558,1.2166728973388672,-18.95,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Muriae,2020-12-31T00:00:00,1.56,1.5452592372894287,-0.94,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Mutum,2020-12-31T00:00:00,1.65,1.4873971939086914,-9.85,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Nova_Belem,2020-12-31T00:00:00,1.1,1.1250945329666138,2.28,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Orizania,2020-12-31T00:00:00,1.679901960784314,1.5514330863952637,-7.65,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Patis,2020-12-31T00:00:00,3.6000000000000005,4.533916473388672,25.94,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ponte_Nova,2020-12-31T00:00:00,1.333333333333333,1.4146147966384888,6.1,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Porto_Firme,2020-12-31T00:00:00,1.56,1.2112298011779785,-22.36,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Raul_Soares,2020-12-31T00:00:00,1.320083682008368,1.2367041110992432,-6.32,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Reduto,2020-12-31T00:00:00,1.8000000000000005,1.7210084199905396,-4.39,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Rio_Pardo_de_Minas,2020-12-31T00:00:00,3.4487179487179493,3.3500266075134277,-2.86,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Rosario_da_Limeira,2020-12-31T00:00:00,1.5,1.2734043598175049,-15.11,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Barbara_do_Leste,2020-12-31T00:00:00,1.4400953029271608,1.5173900127410889,5.37,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Margarida,2020-12-31T00:00:00,1.8000000000000005,1.5408015251159668,-14.4,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santa_Rita_de_Minas,2020-12-31T00:00:00,1.5,1.4232134819030762,-5.12,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Santana_do_Manhuacu,2020-12-31T00:00:00,1.8000000000000005,1.5337209701538086,-14.79,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Francisco_do_Gloria,2020-12-31T00:00:00,1.679693486590038,1.2112452983856201,-27.89,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Joao_do_Manhuacu,2020-12-31T00:00:00,1.8000000000000005,1.6800107955932617,-6.67,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sao_Jose_do_Mantimento,2020-12-31T00:00:00,1.8000000000000005,1.5085577964782715,-16.19,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Sericita,2020-12-31T00:00:00,2.5200000000000005,1.7283822298049927,-31.41,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Setubinha,2020-12-31T00:00:00,1.0,0.953592836856842,-4.64,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Teofilo_Otoni,2020-12-31T00:00:00,1.09375,0.9659513235092163,-11.68,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Tombos,2020-12-31T00:00:00,1.5,1.2946093082427979,-13.69,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Ubaporanga,2020-12-31T00:00:00,1.6200873362445412,1.4106056690216064,-12.93,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Urucuia,2020-12-31T00:00:00,2.4,2.486793041229248,3.62,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vermelho_Novo,2020-12-31T00:00:00,1.320080321285141,1.2377300262451172,-6.24,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vicosa,2020-12-31T00:00:00,1.8000000000000005,1.6381959915161133,-8.99,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Vieiras,2020-12-31T00:00:00,1.8000000000000005,1.2198091745376587,-32.23,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2020),Virginopolis,2020-12-31T00:00:00,1.626666666666667,1.6433117389678955,1.02,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0019397366519644814
        encoder_hidden_size: 192
        decoder_layers: 3
        decoder_hidden_size: 128
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T10:23:08
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Abadia_dos_Dourados,2012-12-31T00:00:00,2.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Abadia_dos_Dourados,2013-12-31T00:00:00,1.97,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Abadia_dos_Dourados,2014-12-31T00:00:00,2.29,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Abadia_dos_Dourados,2015-12-31T00:00:00,1.97,2.210414171218872,12.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Abadia_dos_Dourados,2016-12-31T00:00:00,2.19,2.2054615020751953,0.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Abadia_dos_Dourados,2017-12-31T00:00:00,0.83,1.9809107780456543,138.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Abadia_dos_Dourados,2018-12-31T00:00:00,1.2,1.6948931217193604,41.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Abadia_dos_Dourados,2019-12-31T00:00:00,2.4,2.3024613857269287,4.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Agua_Boa,2012-12-31T00:00:00,1.12,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Agua_Boa,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Agua_Boa,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Agua_Boa,2015-12-31T00:00:00,1.08,1.1304311752319336,4.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Agua_Boa,2016-12-31T00:00:00,1.08,1.1052982807159424,2.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Agua_Boa,2017-12-31T00:00:00,1.11,1.0303714275360107,7.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Agua_Boa,2018-12-31T00:00:00,1.2,1.1126071214675903,7.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Agua_Boa,2019-12-31T00:00:00,1.09,1.113943338394165,2.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Aguas_Vermelhas,2012-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Aguas_Vermelhas,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Aguas_Vermelhas,2014-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Aguas_Vermelhas,2015-12-31T00:00:00,1.2,1.6316982507705688,35.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Aguas_Vermelhas,2016-12-31T00:00:00,3.6,1.526329755783081,57.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Aguas_Vermelhas,2017-12-31T00:00:00,2.6,1.7242300510406494,33.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Aguas_Vermelhas,2018-12-31T00:00:00,3.0,2.793675661087036,6.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Aguas_Vermelhas,2019-12-31T00:00:00,2.7,2.9176909923553467,8.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Alto_Caparao,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Alto_Caparao,2013-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Alto_Caparao,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Alto_Caparao,2015-12-31T00:00:00,1.2,1.520272970199585,26.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Alto_Caparao,2016-12-31T00:00:00,2.1,1.455087423324585,30.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Alto_Caparao,2017-12-31T00:00:00,1.37,1.377387285232544,0.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Alto_Caparao,2018-12-31T00:00:00,1.5,2.1759109497070312,45.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Alto_Caparao,2019-12-31T00:00:00,1.32,1.3166075944900513,0.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Araponga,2012-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Araponga,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Araponga,2014-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Araponga,2015-12-31T00:00:00,1.26,1.2579255104064941,0.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Araponga,2016-12-31T00:00:00,1.32,1.2681719064712524,3.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Araponga,2017-12-31T00:00:00,1.5,1.1621999740600586,22.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Araponga,2018-12-31T00:00:00,1.38,1.5322768688201904,11.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Araponga,2019-12-31T00:00:00,0.9,1.2895512580871582,43.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Areado,2012-12-31T00:00:00,1.95,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Areado,2013-12-31T00:00:00,1.86,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Areado,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Areado,2015-12-31T00:00:00,1.68,1.876985788345337,11.73,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Areado,2016-12-31T00:00:00,2.04,1.8508187532424927,9.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Areado,2017-12-31T00:00:00,1.68,1.4404950141906738,14.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Areado,2018-12-31T00:00:00,1.5,1.7576688528060913,17.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Areado,2019-12-31T00:00:00,1.92,1.865971326828003,2.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ataleia,2012-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ataleia,2013-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ataleia,2014-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ataleia,2015-12-31T00:00:00,0.91,0.7322309017181396,19.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ataleia,2016-12-31T00:00:00,0.91,0.8147736191749573,10.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ataleia,2017-12-31T00:00:00,0.65,0.7670782804489136,18.01,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ataleia,2018-12-31T00:00:00,0.9,0.9776772260665894,8.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ataleia,2019-12-31T00:00:00,0.9,0.8335115313529968,7.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Bom_Jesus_do_Galho,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Bom_Jesus_do_Galho,2013-12-31T00:00:00,0.78,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Bom_Jesus_do_Galho,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Bom_Jesus_do_Galho,2015-12-31T00:00:00,0.96,0.8959314823150635,6.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Bom_Jesus_do_Galho,2016-12-31T00:00:00,1.8,0.8854347467422485,50.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Bom_Jesus_do_Galho,2017-12-31T00:00:00,0.82,1.0149930715560913,23.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Bom_Jesus_do_Galho,2018-12-31T00:00:00,1.2,1.9474225044250488,62.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Bom_Jesus_do_Galho,2019-12-31T00:00:00,1.08,0.9983966946601868,7.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caiana,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caiana,2013-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caiana,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caiana,2015-12-31T00:00:00,0.96,1.1058794260025024,15.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caiana,2016-12-31T00:00:00,1.2,1.138771653175354,5.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caiana,2017-12-31T00:00:00,1.2,1.0938607454299927,8.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caiana,2018-12-31T00:00:00,1.5,1.4102134704589844,5.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caiana,2019-12-31T00:00:00,1.08,1.1656200885772705,7.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Cajuri,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Cajuri,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Cajuri,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Cajuri,2015-12-31T00:00:00,1.32,1.8647758960723877,41.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Cajuri,2016-12-31T00:00:00,1.2,1.2150342464447021,1.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Cajuri,2017-12-31T00:00:00,1.2,1.2536331415176392,4.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Cajuri,2018-12-31T00:00:00,1.8,1.2949717044830322,28.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Cajuri,2019-12-31T00:00:00,1.18,1.1901525259017944,0.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Canaa,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Canaa,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Canaa,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Canaa,2015-12-31T00:00:00,1.02,1.2874858379364014,26.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Canaa,2016-12-31T00:00:00,1.2,1.1553901433944702,3.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Canaa,2017-12-31T00:00:00,1.5,1.0948209762573242,27.01,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Canaa,2018-12-31T00:00:00,1.5,1.5600831508636475,4.01,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Canaa,2019-12-31T00:00:00,1.26,1.2703229188919067,0.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caparao,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caparao,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caparao,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caparao,2015-12-31T00:00:00,1.02,1.3294093608856201,30.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caparao,2016-12-31T00:00:00,1.92,1.1856085062026978,38.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caparao,2017-12-31T00:00:00,1.45,1.2229243516921997,15.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caparao,2018-12-31T00:00:00,1.8,2.047675848007202,13.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caparao,2019-12-31T00:00:00,1.32,1.5080581903457642,14.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caputira,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caputira,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caputira,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caputira,2015-12-31T00:00:00,1.5,1.3776624202728271,8.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caputira,2016-12-31T00:00:00,1.26,1.4076259136199951,11.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caputira,2017-12-31T00:00:00,0.77,1.2524222135543823,62.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caputira,2018-12-31T00:00:00,1.2,1.5886591672897339,32.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caputira,2019-12-31T00:00:00,1.2,0.917021632194519,23.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Carai,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Carai,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Carai,2014-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Carai,2015-12-31T00:00:00,0.96,0.8834304809570312,7.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Carai,2016-12-31T00:00:00,0.96,0.9444658756256104,1.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Carai,2017-12-31T00:00:00,0.54,0.7623795866966248,41.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Carai,2018-12-31T00:00:00,0.84,1.1312675476074219,34.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Carai,2019-12-31T00:00:00,1.2,0.9771267771720886,18.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Carangola,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Carangola,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Carangola,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Carangola,2015-12-31T00:00:00,0.9,1.0041812658309937,11.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Carangola,2016-12-31T00:00:00,1.2,3.6939241886138916,207.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Carangola,2017-12-31T00:00:00,1.1,0.9920527935028076,9.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Carangola,2018-12-31T00:00:00,1.56,1.2556071281433105,19.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Carangola,2019-12-31T00:00:00,1.26,1.076244592666626,14.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caratinga,2012-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caratinga,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caratinga,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caratinga,2015-12-31T00:00:00,1.08,1.0784330368041992,0.15,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caratinga,2016-12-31T00:00:00,1.56,1.0808366537094116,30.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caratinga,2017-12-31T00:00:00,1.46,1.0624480247497559,27.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caratinga,2018-12-31T00:00:00,1.8,1.7141231298446655,4.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caratinga,2019-12-31T00:00:00,1.0,1.535797357559204,53.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Central_de_Minas,2012-12-31T00:00:00,0.42,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Central_de_Minas,2013-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Central_de_Minas,2014-12-31T00:00:00,0.51,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Central_de_Minas,2015-12-31T00:00:00,0.72,0.6221476197242737,13.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Central_de_Minas,2016-12-31T00:00:00,0.72,0.6767792701721191,6.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Central_de_Minas,2017-12-31T00:00:00,0.6,0.5944615602493286,0.92,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Central_de_Minas,2018-12-31T00:00:00,1.0,0.7529367804527283,24.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Central_de_Minas,2019-12-31T00:00:00,1.0,0.7459253668785095,25.41,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Chale,2012-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Chale,2013-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Chale,2014-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Chale,2015-12-31T00:00:00,1.38,1.6327412128448486,18.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Chale,2016-12-31T00:00:00,1.42,1.5664310455322266,10.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Chale,2017-12-31T00:00:00,0.93,1.4057484865188599,51.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Chale,2018-12-31T00:00:00,1.38,1.5996627807617188,15.92,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Chale,2019-12-31T00:00:00,1.2,1.123642086982727,6.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Conceicao_de_Ipanema,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Conceicao_de_Ipanema,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Conceicao_de_Ipanema,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Conceicao_de_Ipanema,2015-12-31T00:00:00,1.14,1.1504948139190674,0.92,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Conceicao_de_Ipanema,2016-12-31T00:00:00,1.44,1.1474941968917847,20.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Conceicao_de_Ipanema,2017-12-31T00:00:00,1.44,1.201844573020935,16.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Conceicao_de_Ipanema,2018-12-31T00:00:00,1.56,1.5754245519638062,0.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Conceicao_de_Ipanema,2019-12-31T00:00:00,1.19,1.4694510698318481,23.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Datas,2012-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Datas,2013-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Datas,2014-12-31T00:00:00,0.79,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Datas,2015-12-31T00:00:00,1.4,1.036630392074585,25.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Datas,2016-12-31T00:00:00,1.2,1.1662166118621826,2.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Datas,2017-12-31T00:00:00,1.5,1.0885086059570312,27.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Datas,2018-12-31T00:00:00,3.0,1.5884544849395752,47.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Datas,2019-12-31T00:00:00,2.0,1.3645247220993042,31.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Divino,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Divino,2013-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Divino,2014-12-31T00:00:00,0.89,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Divino,2015-12-31T00:00:00,1.2,1.2810826301574707,6.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Divino,2016-12-31T00:00:00,1.2,1.351182222366333,12.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Divino,2017-12-31T00:00:00,1.19,1.0444717407226562,12.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Divino,2018-12-31T00:00:00,1.32,1.2108701467514038,8.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Divino,2019-12-31T00:00:00,1.08,1.1584362983703613,7.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Durande,2012-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Durande,2013-12-31T00:00:00,2.22,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Durande,2014-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Durande,2015-12-31T00:00:00,1.68,1.9162840843200684,14.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Durande,2016-12-31T00:00:00,1.8,1.7536811828613281,2.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Durande,2017-12-31T00:00:00,1.33,1.5354682207107544,15.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Durande,2018-12-31T00:00:00,2.1,2.123328685760498,1.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Durande,2019-12-31T00:00:00,1.32,1.5082693099975586,14.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Entre_Folhas,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Entre_Folhas,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Entre_Folhas,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Entre_Folhas,2015-12-31T00:00:00,1.0,1.042960286140442,4.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Entre_Folhas,2016-12-31T00:00:00,1.2,1.0892187356948853,9.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Entre_Folhas,2017-12-31T00:00:00,0.86,1.0733425617218018,24.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Entre_Folhas,2018-12-31T00:00:00,1.2,1.2446422576904297,3.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Entre_Folhas,2019-12-31T00:00:00,0.84,0.8874778151512146,5.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ervalia,2012-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ervalia,2013-12-31T00:00:00,1.92,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ervalia,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ervalia,2015-12-31T00:00:00,1.5,1.5863072872161865,5.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ervalia,2016-12-31T00:00:00,1.32,1.2905628681182861,2.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ervalia,2017-12-31T00:00:00,1.36,1.2688666582107544,6.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ervalia,2018-12-31T00:00:00,1.8,1.5441815853118896,14.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ervalia,2019-12-31T00:00:00,1.2,1.1360605955123901,5.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Espera_Feliz,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Espera_Feliz,2013-12-31T00:00:00,1.92,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Espera_Feliz,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Espera_Feliz,2015-12-31T00:00:00,1.38,1.3568458557128906,1.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Espera_Feliz,2016-12-31T00:00:00,1.68,1.6351115703582764,2.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Espera_Feliz,2017-12-31T00:00:00,1.21,1.3124630451202393,8.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Espera_Feliz,2018-12-31T00:00:00,1.92,1.9557538032531738,1.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Espera_Feliz,2019-12-31T00:00:00,0.9,1.3405961990356445,48.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Faria_Lemos,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Faria_Lemos,2013-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Faria_Lemos,2014-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Faria_Lemos,2015-12-31T00:00:00,1.32,1.1030468940734863,16.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Faria_Lemos,2016-12-31T00:00:00,1.38,1.2550697326660156,9.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Faria_Lemos,2017-12-31T00:00:00,0.97,1.231364130973816,26.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Faria_Lemos,2018-12-31T00:00:00,1.2,1.5073109865188599,25.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Faria_Lemos,2019-12-31T00:00:00,1.08,1.0017340183258057,7.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ferros,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ferros,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ferros,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ferros,2015-12-31T00:00:00,1.08,1.3186309337615967,22.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ferros,2016-12-31T00:00:00,1.2,1.2763152122497559,6.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ferros,2017-12-31T00:00:00,0.59,1.139753818511963,93.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ferros,2018-12-31T00:00:00,0.84,0.9966560006141663,18.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ferros,2019-12-31T00:00:00,0.84,0.8870405554771423,5.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Franciscopolis,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Franciscopolis,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Franciscopolis,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Franciscopolis,2015-12-31T00:00:00,1.08,2.105841636657715,94.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Franciscopolis,2016-12-31T00:00:00,1.2,1.0584017038345337,11.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Franciscopolis,2017-12-31T00:00:00,0.52,1.0049231052398682,93.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Franciscopolis,2018-12-31T00:00:00,1.8,1.3968937397003174,22.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Franciscopolis,2019-12-31T00:00:00,3.0,1.2599098682403564,58.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Itanhomi,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Itanhomi,2013-12-31T00:00:00,1.35,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Itanhomi,2014-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Itanhomi,2015-12-31T00:00:00,1.2,1.2999744415283203,8.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Itanhomi,2016-12-31T00:00:00,1.14,1.2135937213897705,6.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Itanhomi,2017-12-31T00:00:00,1.0,1.1063203811645508,10.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Itanhomi,2018-12-31T00:00:00,1.62,1.2137571573257446,25.08,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Itanhomi,2019-12-31T00:00:00,0.96,1.1493927240371704,19.73,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lagoa_Formosa,2012-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lagoa_Formosa,2013-12-31T00:00:00,2.4,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lagoa_Formosa,2014-12-31T00:00:00,2.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lagoa_Formosa,2015-12-31T00:00:00,2.4,2.3870797157287598,0.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lagoa_Formosa,2016-12-31T00:00:00,1.8,2.3045895099639893,28.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lagoa_Formosa,2017-12-31T00:00:00,1.92,1.8788658380508423,2.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lagoa_Formosa,2018-12-31T00:00:00,1.92,2.085763931274414,8.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lagoa_Formosa,2019-12-31T00:00:00,2.25,1.929744005203247,14.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lagoa_Grande,2012-12-31T00:00:00,1.43,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lagoa_Grande,2013-12-31T00:00:00,3.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lagoa_Grande,2014-12-31T00:00:00,1.79,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lagoa_Grande,2015-12-31T00:00:00,2.38,2.5370583534240723,6.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lagoa_Grande,2016-12-31T00:00:00,2.1,2.3368518352508545,11.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lagoa_Grande,2017-12-31T00:00:00,2.1,1.9208039045333862,8.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lagoa_Grande,2018-12-31T00:00:00,2.1,2.188326120376587,4.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lagoa_Grande,2019-12-31T00:00:00,1.2,2.100306510925293,75.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lajinha,2012-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lajinha,2013-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lajinha,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lajinha,2015-12-31T00:00:00,1.44,1.6141841411590576,12.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lajinha,2016-12-31T00:00:00,1.68,1.3561887741088867,19.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lajinha,2017-12-31T00:00:00,1.04,1.1412571668624878,9.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lajinha,2018-12-31T00:00:00,1.68,1.7872848510742188,6.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lajinha,2019-12-31T00:00:00,1.06,1.2215256690979004,15.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Luisburgo,2012-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Luisburgo,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Luisburgo,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Luisburgo,2015-12-31T00:00:00,1.5,1.3374379873275757,10.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Luisburgo,2016-12-31T00:00:00,1.32,1.4514484405517578,9.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Luisburgo,2017-12-31T00:00:00,1.53,1.3251458406448364,13.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Luisburgo,2018-12-31T00:00:00,1.8,1.734867811203003,3.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Luisburgo,2019-12-31T00:00:00,1.64,1.2966622114181519,20.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Malacacheta,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Malacacheta,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Malacacheta,2014-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Malacacheta,2015-12-31T00:00:00,1.5,1.4843189716339111,1.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Malacacheta,2016-12-31T00:00:00,1.32,1.3735246658325195,4.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Malacacheta,2017-12-31T00:00:00,1.37,1.3775638341903687,0.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Malacacheta,2018-12-31T00:00:00,1.8,1.5369709730148315,14.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Malacacheta,2019-12-31T00:00:00,1.5,1.505273461341858,0.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Manhuacu,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Manhuacu,2013-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Manhuacu,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Manhuacu,2015-12-31T00:00:00,1.38,1.2512738704681396,9.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Manhuacu,2016-12-31T00:00:00,1.26,1.28041672706604,1.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Manhuacu,2017-12-31T00:00:00,1.43,1.1402627229690552,20.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Manhuacu,2018-12-31T00:00:00,1.44,1.4619289636611938,1.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Manhuacu,2019-12-31T00:00:00,1.02,1.3014990091323853,27.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Manhumirim,2012-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Manhumirim,2013-12-31T00:00:00,1.92,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Manhumirim,2014-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Manhumirim,2015-12-31T00:00:00,1.8,1.5968303680419922,11.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Manhumirim,2016-12-31T00:00:00,1.32,1.7986159324645996,36.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Manhumirim,2017-12-31T00:00:00,1.62,1.3776979446411133,14.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Manhumirim,2018-12-31T00:00:00,1.56,1.7680600881576538,13.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Manhumirim,2019-12-31T00:00:00,1.2,1.3685190677642822,14.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Matipo,2012-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Matipo,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Matipo,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Matipo,2015-12-31T00:00:00,1.44,1.3211376667022705,8.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Matipo,2016-12-31T00:00:00,1.32,1.407914400100708,6.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Matipo,2017-12-31T00:00:00,0.9,1.2694371938705444,41.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Matipo,2018-12-31T00:00:00,1.32,1.4951324462890625,13.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Matipo,2019-12-31T00:00:00,1.32,1.0796198844909668,18.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Mirai,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Mirai,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Mirai,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Mirai,2015-12-31T00:00:00,0.84,1.0898387432098389,29.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Mirai,2016-12-31T00:00:00,1.2,0.9060376882553101,24.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Mirai,2017-12-31T00:00:00,1.02,1.00802743434906,1.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Mirai,2018-12-31T00:00:00,1.2,1.1221660375595093,6.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Mirai,2019-12-31T00:00:00,1.2,1.090057134628296,9.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Muriae,2012-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Muriae,2013-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Muriae,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Muriae,2015-12-31T00:00:00,1.08,1.1900298595428467,10.19,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Muriae,2016-12-31T00:00:00,1.32,1.1190733909606934,15.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Muriae,2017-12-31T00:00:00,1.44,0.9975376129150391,30.73,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Muriae,2018-12-31T00:00:00,1.44,1.5243263244628906,5.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Muriae,2019-12-31T00:00:00,1.02,1.358486533164978,33.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Mutum,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Mutum,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Mutum,2014-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Mutum,2015-12-31T00:00:00,1.15,1.3816112279891968,20.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Mutum,2016-12-31T00:00:00,1.26,1.2968543767929077,2.92,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Mutum,2017-12-31T00:00:00,1.45,1.1901440620422363,17.92,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Mutum,2018-12-31T00:00:00,1.5,1.4753458499908447,1.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Mutum,2019-12-31T00:00:00,1.44,1.3493155241012573,6.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Nova_Belem,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Nova_Belem,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Nova_Belem,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Nova_Belem,2015-12-31T00:00:00,0.9,1.8989129066467285,110.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Nova_Belem,2016-12-31T00:00:00,1.2,2.1032862663269043,75.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Nova_Belem,2017-12-31T00:00:00,0.48,0.960406482219696,100.08,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Nova_Belem,2018-12-31T00:00:00,1.2,1.2383760213851929,3.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Nova_Belem,2019-12-31T00:00:00,0.9,0.8884437680244446,1.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Orizania,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Orizania,2013-12-31T00:00:00,1.68,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Orizania,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Orizania,2015-12-31T00:00:00,1.2,1.301604986190796,8.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Orizania,2016-12-31T00:00:00,1.8,1.342421531677246,25.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Orizania,2017-12-31T00:00:00,1.47,1.3338501453399658,9.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Orizania,2018-12-31T00:00:00,1.56,1.7820839881896973,14.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Orizania,2019-12-31T00:00:00,1.38,1.39990234375,1.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Patis,2012-12-31T00:00:00,2.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Patis,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Patis,2014-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Patis,2015-12-31T00:00:00,2.8,1.3865138292312622,50.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Patis,2016-12-31T00:00:00,1.19,1.3295663595199585,11.73,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Patis,2017-12-31T00:00:00,1.8,1.8186864852905273,1.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Patis,2018-12-31T00:00:00,3.6,2.4633498191833496,31.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Patis,2019-12-31T00:00:00,3.0,2.1426515579223633,28.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ponte_Nova,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ponte_Nova,2013-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ponte_Nova,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ponte_Nova,2015-12-31T00:00:00,1.26,1.2132006883621216,3.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ponte_Nova,2016-12-31T00:00:00,1.2,1.2024898529052734,0.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ponte_Nova,2017-12-31T00:00:00,1.17,1.1451326608657837,2.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ponte_Nova,2018-12-31T00:00:00,1.5,1.3044884204864502,13.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ponte_Nova,2019-12-31T00:00:00,1.17,1.2942830324172974,10.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Porto_Firme,2012-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Porto_Firme,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Porto_Firme,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Porto_Firme,2015-12-31T00:00:00,1.26,1.0965718030929565,12.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Porto_Firme,2016-12-31T00:00:00,1.2,1.1955766677856445,0.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Porto_Firme,2017-12-31T00:00:00,1.2,1.1605744361877441,3.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Porto_Firme,2018-12-31T00:00:00,1.2,1.268193244934082,5.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Porto_Firme,2019-12-31T00:00:00,1.12,-0.06561852991580963,105.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Raul_Soares,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Raul_Soares,2013-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Raul_Soares,2014-12-31T00:00:00,0.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Raul_Soares,2015-12-31T00:00:00,1.08,1.0845704078674316,0.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Raul_Soares,2016-12-31T00:00:00,1.08,1.0072115659713745,6.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Raul_Soares,2017-12-31T00:00:00,0.86,0.8767043948173523,1.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Raul_Soares,2018-12-31T00:00:00,1.2,1.1631797552108765,3.07,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Raul_Soares,2019-12-31T00:00:00,1.2,1.0513447523117065,12.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Reduto,2012-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Reduto,2013-12-31T00:00:00,1.62,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Reduto,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Reduto,2015-12-31T00:00:00,1.38,1.3967734575271606,1.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Reduto,2016-12-31T00:00:00,1.44,1.4033091068267822,2.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Reduto,2017-12-31T00:00:00,1.26,1.1975812911987305,4.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Reduto,2018-12-31T00:00:00,1.8,1.4738843441009521,18.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Reduto,2019-12-31T00:00:00,1.26,1.3130645751953125,4.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Rio_Pardo_de_Minas,2012-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Rio_Pardo_de_Minas,2013-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Rio_Pardo_de_Minas,2014-12-31T00:00:00,2.65,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Rio_Pardo_de_Minas,2015-12-31T00:00:00,2.28,2.063476800918579,9.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Rio_Pardo_de_Minas,2016-12-31T00:00:00,2.46,2.342555522918701,4.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Rio_Pardo_de_Minas,2017-12-31T00:00:00,2.18,2.5055830478668213,14.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Rio_Pardo_de_Minas,2018-12-31T00:00:00,2.63,2.365743637084961,10.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Rio_Pardo_de_Minas,2019-12-31T00:00:00,2.75,2.4605512619018555,10.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Rosario_da_Limeira,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Rosario_da_Limeira,2013-12-31T00:00:00,1.54,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Rosario_da_Limeira,2014-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Rosario_da_Limeira,2015-12-31T00:00:00,1.14,1.4565441608428955,27.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Rosario_da_Limeira,2016-12-31T00:00:00,1.26,1.2596478462219238,0.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Rosario_da_Limeira,2017-12-31T00:00:00,0.78,1.2287392616271973,57.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Rosario_da_Limeira,2018-12-31T00:00:00,1.2,1.3268975019454956,10.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Rosario_da_Limeira,2019-12-31T00:00:00,1.2,0.8647804260253906,27.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Barbara_do_Leste,2012-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Barbara_do_Leste,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Barbara_do_Leste,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Barbara_do_Leste,2015-12-31T00:00:00,1.08,1.0967015027999878,1.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Barbara_do_Leste,2016-12-31T00:00:00,1.02,1.0708907842636108,4.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Barbara_do_Leste,2017-12-31T00:00:00,0.91,0.9921380281448364,9.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Barbara_do_Leste,2018-12-31T00:00:00,1.74,1.1537781953811646,33.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Barbara_do_Leste,2019-12-31T00:00:00,1.14,0.9873796105384827,13.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Margarida,2012-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Margarida,2013-12-31T00:00:00,1.68,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Margarida,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Margarida,2015-12-31T00:00:00,1.56,1.4528119564056396,6.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Margarida,2016-12-31T00:00:00,1.32,1.4703408479690552,11.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Margarida,2017-12-31T00:00:00,1.2,1.291770100593567,7.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Margarida,2018-12-31T00:00:00,1.68,1.5843901634216309,5.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Margarida,2019-12-31T00:00:00,1.2,1.16204833984375,3.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Rita_de_Minas,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Rita_de_Minas,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Rita_de_Minas,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Rita_de_Minas,2015-12-31T00:00:00,1.2,1.1139601469039917,7.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Rita_de_Minas,2016-12-31T00:00:00,1.08,1.089268445968628,0.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Rita_de_Minas,2017-12-31T00:00:00,1.25,1.0035629272460938,19.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Rita_de_Minas,2018-12-31T00:00:00,1.5,1.3053889274597168,12.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Rita_de_Minas,2019-12-31T00:00:00,1.26,1.1762863397598267,6.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santana_do_Manhuacu,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santana_do_Manhuacu,2013-12-31T00:00:00,1.62,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santana_do_Manhuacu,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santana_do_Manhuacu,2015-12-31T00:00:00,1.44,1.5029356479644775,4.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santana_do_Manhuacu,2016-12-31T00:00:00,1.32,1.4250731468200684,7.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santana_do_Manhuacu,2017-12-31T00:00:00,1.28,1.2448911666870117,2.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santana_do_Manhuacu,2018-12-31T00:00:00,1.5,1.4591169357299805,2.73,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santana_do_Manhuacu,2019-12-31T00:00:00,1.5,1.3171820640563965,12.19,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Francisco_do_Gloria,2012-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Francisco_do_Gloria,2013-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Francisco_do_Gloria,2014-12-31T00:00:00,1.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Francisco_do_Gloria,2015-12-31T00:00:00,1.32,1.2661820650100708,4.08,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Francisco_do_Gloria,2016-12-31T00:00:00,1.5,1.2753223180770874,14.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Francisco_do_Gloria,2017-12-31T00:00:00,0.8,1.30265474319458,62.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Francisco_do_Gloria,2018-12-31T00:00:00,1.32,1.5787808895111084,19.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Francisco_do_Gloria,2019-12-31T00:00:00,0.9,0.7564152479171753,15.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Joao_do_Manhuacu,2012-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Joao_do_Manhuacu,2013-12-31T00:00:00,1.74,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Joao_do_Manhuacu,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Joao_do_Manhuacu,2015-12-31T00:00:00,1.32,1.4411511421203613,9.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Joao_do_Manhuacu,2016-12-31T00:00:00,1.32,1.3610931634902954,3.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Joao_do_Manhuacu,2017-12-31T00:00:00,1.7,1.1928120851516724,29.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Joao_do_Manhuacu,2018-12-31T00:00:00,1.62,1.745285153388977,7.73,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Joao_do_Manhuacu,2019-12-31T00:00:00,1.32,1.359442114830017,2.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Jose_do_Mantimento,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Jose_do_Mantimento,2013-12-31T00:00:00,1.42,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Jose_do_Mantimento,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Jose_do_Mantimento,2015-12-31T00:00:00,1.44,1.335111379623413,7.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Jose_do_Mantimento,2016-12-31T00:00:00,1.2,1.369901418685913,14.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Jose_do_Mantimento,2017-12-31T00:00:00,1.2,1.2225017547607422,1.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Jose_do_Mantimento,2018-12-31T00:00:00,1.44,1.4721424579620361,2.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Jose_do_Mantimento,2019-12-31T00:00:00,1.56,1.2713419198989868,18.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sericita,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sericita,2013-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sericita,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sericita,2015-12-31T00:00:00,1.2,1.32551109790802,10.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sericita,2016-12-31T00:00:00,1.2,1.2360552549362183,3.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sericita,2017-12-31T00:00:00,1.12,1.139216661453247,1.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sericita,2018-12-31T00:00:00,1.8,1.2728149890899658,29.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sericita,2019-12-31T00:00:00,0.9,1.1049431562423706,22.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Setubinha,2012-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Setubinha,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Setubinha,2014-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Setubinha,2015-12-31T00:00:00,0.9,0.8004181385040283,11.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Setubinha,2016-12-31T00:00:00,1.5,0.792270302772522,47.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Setubinha,2017-12-31T00:00:00,0.76,1.0703754425048828,40.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Setubinha,2018-12-31T00:00:00,0.9,1.5925599336624146,76.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Setubinha,2019-12-31T00:00:00,0.9,1.016910433769226,12.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Teofilo_Otoni,2012-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Teofilo_Otoni,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Teofilo_Otoni,2014-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Teofilo_Otoni,2015-12-31T00:00:00,0.9,0.793329119682312,11.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Teofilo_Otoni,2016-12-31T00:00:00,0.9,0.8814610242843628,2.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Teofilo_Otoni,2017-12-31T00:00:00,0.67,0.7249929904937744,8.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Teofilo_Otoni,2018-12-31T00:00:00,0.91,0.9263465404510498,1.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Teofilo_Otoni,2019-12-31T00:00:00,0.91,0.8176149725914001,10.15,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Tombos,2012-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Tombos,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Tombos,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Tombos,2015-12-31T00:00:00,1.2,1.1082366704940796,7.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Tombos,2016-12-31T00:00:00,0.96,1.155529499053955,20.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Tombos,2017-12-31T00:00:00,0.99,1.0200854539871216,3.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Tombos,2018-12-31T00:00:00,1.44,1.1915202140808105,17.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Tombos,2019-12-31T00:00:00,0.96,0.8981359004974365,6.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ubaporanga,2012-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ubaporanga,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ubaporanga,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ubaporanga,2015-12-31T00:00:00,1.2,1.260060429573059,5.01,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ubaporanga,2016-12-31T00:00:00,0.96,1.1308434009552002,17.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ubaporanga,2017-12-31T00:00:00,1.03,1.0144050121307373,1.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ubaporanga,2018-12-31T00:00:00,1.5,1.466526985168457,2.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ubaporanga,2019-12-31T00:00:00,1.32,1.0913070440292358,17.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Urucuia,2012-12-31T00:00:00,2.4,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Urucuia,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Urucuia,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Urucuia,2015-12-31T00:00:00,1.8,1.7753751277923584,1.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Urucuia,2016-12-31T00:00:00,2.4,2.1983189582824707,8.4,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Urucuia,2017-12-31T00:00:00,1.8,1.6060638427734375,10.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Urucuia,2018-12-31T00:00:00,2.4,2.1765029430389404,9.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Urucuia,2019-12-31T00:00:00,2.4,2.408108711242676,0.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vermelho_Novo,2012-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vermelho_Novo,2013-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vermelho_Novo,2014-12-31T00:00:00,0.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vermelho_Novo,2015-12-31T00:00:00,1.2,0.935210108757019,22.07,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vermelho_Novo,2016-12-31T00:00:00,1.2,0.9919711947441101,17.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vermelho_Novo,2017-12-31T00:00:00,1.08,0.9487047791481018,12.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vermelho_Novo,2018-12-31T00:00:00,1.32,1.2750158309936523,3.41,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vermelho_Novo,2019-12-31T00:00:00,1.08,1.1776202917099,9.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vicosa,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vicosa,2013-12-31T00:00:00,1.62,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vicosa,2014-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vicosa,2015-12-31T00:00:00,1.44,1.5080713033676147,4.73,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vicosa,2016-12-31T00:00:00,1.16,1.328223466873169,14.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vicosa,2017-12-31T00:00:00,1.49,1.344101071357727,9.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vicosa,2018-12-31T00:00:00,1.56,1.635927438735962,4.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vicosa,2019-12-31T00:00:00,0.84,1.2022368907928467,43.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vieiras,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vieiras,2013-12-31T00:00:00,1.81,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vieiras,2014-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vieiras,2015-12-31T00:00:00,1.32,1.649221658706665,24.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vieiras,2016-12-31T00:00:00,1.2,1.6040012836456299,33.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vieiras,2017-12-31T00:00:00,1.13,1.4107013940811157,24.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vieiras,2018-12-31T00:00:00,1.26,1.3218940496444702,4.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vieiras,2019-12-31T00:00:00,1.02,1.137521505355835,11.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Virginopolis,2012-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Virginopolis,2013-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Virginopolis,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Virginopolis,2015-12-31T00:00:00,1.32,1.2574777603149414,4.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Virginopolis,2016-12-31T00:00:00,1.0,1.242846131324768,24.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Virginopolis,2017-12-31T00:00:00,1.37,1.1567976474761963,15.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Virginopolis,2018-12-31T00:00:00,1.5,1.4532431364059448,3.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Virginopolis,2019-12-31T00:00:00,1.51,1.249135971069336,17.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Abadia_dos_Dourados,2020-12-31T00:00:00,3.0,2,-33.33,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Agua_Boa,2020-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Aguas_Vermelhas,2020-12-31T00:00:00,4.0,3,-25.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Alto_Caparao,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Araponga,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Areado,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ataleia,2020-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Bom_Jesus_do_Galho,2020-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caiana,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Cajuri,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Canaa,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caparao,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caputira,2020-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Carai,2020-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Carangola,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caratinga,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Central_de_Minas,2020-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Chale,2020-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Conceicao_de_Ipanema,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Datas,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Divino,2020-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Durande,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Entre_Folhas,2020-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ervalia,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Espera_Feliz,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Faria_Lemos,2020-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ferros,2020-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Franciscopolis,2020-12-31T00:00:00,2.0,4,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Itanhomi,2020-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lagoa_Formosa,2020-12-31T00:00:00,3.0,2,-33.33,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lagoa_Grande,2020-12-31T00:00:00,2.0,3,50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lajinha,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Luisburgo,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Malacacheta,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Manhuacu,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Manhumirim,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Matipo,2020-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Mirai,2020-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Muriae,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Mutum,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Nova_Belem,2020-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Orizania,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Patis,2020-12-31T00:00:00,4.0,5,25.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ponte_Nova,2020-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Porto_Firme,2020-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Raul_Soares,2020-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Reduto,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Rio_Pardo_de_Minas,2020-12-31T00:00:00,3.0,3,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Rosario_da_Limeira,2020-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Barbara_do_Leste,2020-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Margarida,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Rita_de_Minas,2020-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santana_do_Manhuacu,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Francisco_do_Gloria,2020-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Joao_do_Manhuacu,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Jose_do_Mantimento,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sericita,2020-12-31T00:00:00,3.0,2,-33.33,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Setubinha,2020-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Teofilo_Otoni,2020-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Tombos,2020-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ubaporanga,2020-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Urucuia,2020-12-31T00:00:00,2.0,3,50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vermelho_Novo,2020-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vicosa,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vieiras,2020-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Virginopolis,2020-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Abadia_dos_Dourados,2021-12-31T00:00:00,1.8000000000000005,1.7327407598495483,-3.74,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Agua_Boa,2021-12-31T00:00:00,0.6171428571428572,1.1450023651123047,85.53,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Aguas_Vermelhas,2021-12-31T00:00:00,3.0,2.868281126022339,-4.39,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Alto_Caparao,2021-12-31T00:00:00,1.08,1.4735037088394165,36.44,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Araponga,2021-12-31T00:00:00,1.2,1.2284706830978394,2.37,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Areado,2021-12-31T00:00:00,1.5228426395939092,1.7798230648040771,16.88,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ataleia,2021-12-31T00:00:00,0.6266666666666667,0.8500828742980957,35.65,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Bom_Jesus_do_Galho,2021-12-31T00:00:00,1.079802955665025,1.0726332664489746,-0.66,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caiana,2021-12-31T00:00:00,0.9,1.1834684610366821,31.5,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Cajuri,2021-12-31T00:00:00,1.2602564102564102,1.5779473781585693,25.21,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Canaa,2021-12-31T00:00:00,1.2,1.4538202285766602,21.15,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caparao,2021-12-31T00:00:00,0.9,1.5433777570724487,71.49,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caputira,2021-12-31T00:00:00,1.38008658008658,1.2847247123718262,-6.91,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Carai,2021-12-31T00:00:00,1.218,1.0543348789215088,-13.44,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Carangola,2021-12-31T00:00:00,1.02,1.3369139432907104,31.07,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Caratinga,2021-12-31T00:00:00,1.26,0.9713234305381775,-22.91,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Central_de_Minas,2021-12-31T00:00:00,0.8333333333333335,0.6996874809265137,-16.04,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Chale,2021-12-31T00:00:00,1.26016713091922,1.1438241004943848,-9.23,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Conceicao_de_Ipanema,2021-12-31T00:00:00,1.29,1.1914737224578857,-7.64,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Datas,2021-12-31T00:00:00,1.0,2.085689067840576,108.57,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Divino,2021-12-31T00:00:00,1.08,1.225293755531311,13.45,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Durande,2021-12-31T00:00:00,1.32,1.4788105487823486,12.03,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Entre_Folhas,2021-12-31T00:00:00,0.8400000000000001,1.046213150024414,24.55,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ervalia,2021-12-31T00:00:00,1.08,1.4709774255752563,36.2,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Espera_Feliz,2021-12-31T00:00:00,0.78,1.2838307619094849,64.59,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Faria_Lemos,2021-12-31T00:00:00,0.7199999999999999,1.1220214366912842,55.84,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ferros,2021-12-31T00:00:00,1.205128205128205,0.8929577469825745,-25.9,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Franciscopolis,2021-12-31T00:00:00,1.2,1.876381516456604,56.37,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Itanhomi,2021-12-31T00:00:00,0.9606060606060604,0.9834924340248108,2.38,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lagoa_Formosa,2021-12-31T00:00:00,1.4830188679245278,2.360393524169922,59.16,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lagoa_Grande,2021-12-31T00:00:00,0.6000000000000001,1.4680372476577759,144.67,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Lajinha,2021-12-31T00:00:00,1.260014255167498,1.154085397720337,-8.41,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Luisburgo,2021-12-31T00:00:00,1.3799999999999997,1.8361464738845825,33.05,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Malacacheta,2021-12-31T00:00:00,1.8000000000000005,1.580771565437317,-12.18,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Manhuacu,2021-12-31T00:00:00,0.9,1.174935221672058,30.55,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Manhumirim,2021-12-31T00:00:00,1.2,1.3796982765197754,14.97,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Matipo,2021-12-31T00:00:00,1.07995337995338,1.3397129774093628,24.05,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Mirai,2021-12-31T00:00:00,1.019512195121951,1.1943583488464355,17.15,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Muriae,2021-12-31T00:00:00,0.9,1.1078524589538574,23.09,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Mutum,2021-12-31T00:00:00,1.319934249850568,1.4819670915603638,12.28,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Nova_Belem,2021-12-31T00:00:00,1.0,0.9719367027282715,-2.81,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Orizania,2021-12-31T00:00:00,1.08,1.4988899230957031,38.79,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Patis,2021-12-31T00:00:00,2.111111111111112,3.0848937034606934,46.13,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ponte_Nova,2021-12-31T00:00:00,1.2,1.2434462308883667,3.62,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Porto_Firme,2021-12-31T00:00:00,1.319607843137255,1.2654480934143066,-4.1,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Raul_Soares,2021-12-31T00:00:00,1.320079522862823,1.1720964908599854,-11.21,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Reduto,2021-12-31T00:00:00,1.2,1.3328220844268799,11.07,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Rio_Pardo_de_Minas,2021-12-31T00:00:00,2.764006791171477,2.780405282974243,0.59,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Rosario_da_Limeira,2021-12-31T00:00:00,0.9,1.2135175466537476,34.84,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Barbara_do_Leste,2021-12-31T00:00:00,1.319917440660475,1.1736663579940796,-11.08,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Margarida,2021-12-31T00:00:00,0.9,1.434849739074707,59.43,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santa_Rita_de_Minas,2021-12-31T00:00:00,1.2,1.2942099571228027,7.85,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Santana_do_Manhuacu,2021-12-31T00:00:00,1.32,1.4231958389282227,7.82,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Francisco_do_Gloria,2021-12-31T00:00:00,0.78,1.0246798992156982,31.37,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Joao_do_Manhuacu,2021-12-31T00:00:00,0.9,1.5214391946792603,69.05,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sao_Jose_do_Mantimento,2021-12-31T00:00:00,1.500917431192661,1.3861531019210815,-7.65,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Sericita,2021-12-31T00:00:00,0.9,1.3738892078399658,52.65,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Setubinha,2021-12-31T00:00:00,0.9329787234042556,0.9070239067077637,-2.78,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Teofilo_Otoni,2021-12-31T00:00:00,0.6800000000000002,0.866667628288269,27.45,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Tombos,2021-12-31T00:00:00,0.8497959183673469,1.032121181488037,21.46,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Ubaporanga,2021-12-31T00:00:00,1.319867549668874,1.2302100658416748,-6.79,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Urucuia,2021-12-31T00:00:00,1.799276672694394,2.4001851081848145,33.4,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vermelho_Novo,2021-12-31T00:00:00,0.96,1.1477340459823608,19.56,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vicosa,2021-12-31T00:00:00,0.9006711409395973,1.271610975265503,41.18,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Vieiras,2021-12-31T00:00:00,0.78,1.1634820699691772,49.16,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2021),Virginopolis,2021-12-31T00:00:00,1.202380952380952,1.5129444599151611,25.83,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2021)
        Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 5
        learning_rate: 0.0001099127376613816
        encoder_hidden_size: 256
        decoder_layers: 1
        decoder_hidden_size: 256
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 900
        ",2025-09-17T10:42:06
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Abadia_dos_Dourados,2012-12-31T00:00:00,2.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Abadia_dos_Dourados,2013-12-31T00:00:00,1.97,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Abadia_dos_Dourados,2014-12-31T00:00:00,2.29,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Abadia_dos_Dourados,2015-12-31T00:00:00,1.97,2.1975250244140625,11.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Abadia_dos_Dourados,2016-12-31T00:00:00,2.19,2.1661946773529053,1.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Abadia_dos_Dourados,2017-12-31T00:00:00,0.83,1.8812774419784546,126.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Abadia_dos_Dourados,2018-12-31T00:00:00,1.2,1.3137052059173584,9.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Abadia_dos_Dourados,2019-12-31T00:00:00,2.4,2.8777265548706055,19.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Abadia_dos_Dourados,2020-12-31T00:00:00,2.58,2.8393287658691406,10.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Agua_Boa,2012-12-31T00:00:00,1.12,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Agua_Boa,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Agua_Boa,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Agua_Boa,2015-12-31T00:00:00,1.08,1.1329853534698486,4.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Agua_Boa,2016-12-31T00:00:00,1.08,1.0910279750823975,1.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Agua_Boa,2017-12-31T00:00:00,1.11,1.1149210929870605,0.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Agua_Boa,2018-12-31T00:00:00,1.2,1.1106644868850708,7.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Agua_Boa,2019-12-31T00:00:00,1.09,1.1358455419540405,4.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Agua_Boa,2020-12-31T00:00:00,1.33,1.2903251647949219,2.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Aguas_Vermelhas,2012-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Aguas_Vermelhas,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Aguas_Vermelhas,2014-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Aguas_Vermelhas,2015-12-31T00:00:00,1.2,1.5893700122833252,32.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Aguas_Vermelhas,2016-12-31T00:00:00,3.6,1.6379482746124268,54.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Aguas_Vermelhas,2017-12-31T00:00:00,2.6,1.918698787689209,26.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Aguas_Vermelhas,2018-12-31T00:00:00,3.0,2.510714530944824,16.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Aguas_Vermelhas,2019-12-31T00:00:00,2.7,2.87886381149292,6.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Aguas_Vermelhas,2020-12-31T00:00:00,3.6,3.5991270542144775,0.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Alto_Caparao,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Alto_Caparao,2013-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Alto_Caparao,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Alto_Caparao,2015-12-31T00:00:00,1.2,1.3870725631713867,15.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Alto_Caparao,2016-12-31T00:00:00,2.1,1.3635987043380737,35.07,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Alto_Caparao,2017-12-31T00:00:00,1.37,1.6981722116470337,23.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Alto_Caparao,2018-12-31T00:00:00,1.5,1.8308568000793457,22.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Alto_Caparao,2019-12-31T00:00:00,1.32,1.302368402481079,1.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Alto_Caparao,2020-12-31T00:00:00,1.92,1.5912244319915771,17.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Araponga,2012-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Araponga,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Araponga,2014-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Araponga,2015-12-31T00:00:00,1.26,1.2066541910171509,4.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Araponga,2016-12-31T00:00:00,1.32,1.2396223545074463,6.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Araponga,2017-12-31T00:00:00,1.5,1.0608607530593872,29.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Araponga,2018-12-31T00:00:00,1.38,1.4892041683197021,7.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Araponga,2019-12-31T00:00:00,0.9,1.3203400373458862,46.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Araponga,2020-12-31T00:00:00,1.8,1.7214045524597168,4.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Areado,2012-12-31T00:00:00,1.95,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Areado,2013-12-31T00:00:00,1.86,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Areado,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Areado,2015-12-31T00:00:00,1.68,1.6462197303771973,2.01,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Areado,2016-12-31T00:00:00,2.04,2.2510972023010254,10.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Areado,2017-12-31T00:00:00,1.68,1.5506569147109985,7.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Areado,2018-12-31T00:00:00,1.5,1.6735496520996094,11.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Areado,2019-12-31T00:00:00,1.92,1.8869434595108032,1.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Areado,2020-12-31T00:00:00,2.08,2.0654335021972656,0.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ataleia,2012-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ataleia,2013-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ataleia,2014-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ataleia,2015-12-31T00:00:00,0.91,0.7694292068481445,15.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ataleia,2016-12-31T00:00:00,0.91,0.8060383200645447,11.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ataleia,2017-12-31T00:00:00,0.65,0.6980023384094238,7.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ataleia,2018-12-31T00:00:00,0.9,0.9156430959701538,1.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ataleia,2019-12-31T00:00:00,0.9,0.8386423587799072,6.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ataleia,2020-12-31T00:00:00,1.2,1.128673791885376,5.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Bom_Jesus_do_Galho,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Bom_Jesus_do_Galho,2013-12-31T00:00:00,0.78,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Bom_Jesus_do_Galho,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Bom_Jesus_do_Galho,2015-12-31T00:00:00,0.96,0.8884239792823792,7.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Bom_Jesus_do_Galho,2016-12-31T00:00:00,1.8,0.8626096248626709,52.08,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Bom_Jesus_do_Galho,2017-12-31T00:00:00,0.82,1.2992167472839355,58.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Bom_Jesus_do_Galho,2018-12-31T00:00:00,1.2,2.342099666595459,95.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Bom_Jesus_do_Galho,2019-12-31T00:00:00,1.08,0.8476423025131226,21.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Bom_Jesus_do_Galho,2020-12-31T00:00:00,1.44,1.207899570465088,16.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caiana,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caiana,2013-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caiana,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caiana,2015-12-31T00:00:00,0.96,1.0749568939208984,11.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caiana,2016-12-31T00:00:00,1.2,1.1666549444198608,2.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caiana,2017-12-31T00:00:00,1.2,1.1794040203094482,1.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caiana,2018-12-31T00:00:00,1.5,1.4773423671722412,1.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caiana,2019-12-31T00:00:00,1.08,1.1865779161453247,9.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caiana,2020-12-31T00:00:00,1.5,1.627457618713379,8.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Cajuri,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Cajuri,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Cajuri,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Cajuri,2015-12-31T00:00:00,1.32,0.6414792537689209,51.4,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Cajuri,2016-12-31T00:00:00,1.2,1.2190077304840088,1.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Cajuri,2017-12-31T00:00:00,1.2,1.2929913997650146,7.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Cajuri,2018-12-31T00:00:00,1.8,1.2792822122573853,28.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Cajuri,2019-12-31T00:00:00,1.18,1.2164971828460693,3.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Cajuri,2020-12-31T00:00:00,1.8,1.9437934160232544,7.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Canaa,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Canaa,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Canaa,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Canaa,2015-12-31T00:00:00,1.02,1.1918134689331055,16.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Canaa,2016-12-31T00:00:00,1.2,1.1468565464019775,4.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Canaa,2017-12-31T00:00:00,1.5,1.1545264720916748,23.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Canaa,2018-12-31T00:00:00,1.5,1.453883409500122,3.07,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Canaa,2019-12-31T00:00:00,1.26,1.2590014934539795,0.08,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Canaa,2020-12-31T00:00:00,1.8,1.5999341011047363,11.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caparao,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caparao,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caparao,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caparao,2015-12-31T00:00:00,1.02,0.46307212114334106,54.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caparao,2016-12-31T00:00:00,1.92,1.2785838842391968,33.41,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caparao,2017-12-31T00:00:00,1.45,1.4989497661590576,3.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caparao,2018-12-31T00:00:00,1.8,1.7612123489379883,2.15,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caparao,2019-12-31T00:00:00,1.32,1.541924238204956,16.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caparao,2020-12-31T00:00:00,1.92,1.9070197343826294,0.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caputira,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caputira,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caputira,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caputira,2015-12-31T00:00:00,1.5,1.3306102752685547,11.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caputira,2016-12-31T00:00:00,1.26,1.37770676612854,9.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caputira,2017-12-31T00:00:00,0.77,1.2394201755523682,60.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caputira,2018-12-31T00:00:00,1.2,1.4531712532043457,21.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caputira,2019-12-31T00:00:00,1.2,0.9011034369468689,24.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caputira,2020-12-31T00:00:00,1.8,1.5553724765777588,13.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Carai,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Carai,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Carai,2014-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Carai,2015-12-31T00:00:00,0.96,0.8909887671470642,7.19,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Carai,2016-12-31T00:00:00,0.96,1.147479772567749,19.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Carai,2017-12-31T00:00:00,0.54,0.8778700232505798,62.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Carai,2018-12-31T00:00:00,0.84,1.3354620933532715,58.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Carai,2019-12-31T00:00:00,1.2,1.142439603805542,4.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Carai,2020-12-31T00:00:00,1.52,1.2336337566375732,18.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Carangola,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Carangola,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Carangola,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Carangola,2015-12-31T00:00:00,0.9,0.9435400366783142,4.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Carangola,2016-12-31T00:00:00,1.2,3.667144298553467,205.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Carangola,2017-12-31T00:00:00,1.1,1.0724941492080688,2.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Carangola,2018-12-31T00:00:00,1.56,1.3831874132156372,11.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Carangola,2019-12-31T00:00:00,1.26,1.1890897750854492,5.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Carangola,2020-12-31T00:00:00,1.5,1.802750587463379,20.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caratinga,2012-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caratinga,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caratinga,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caratinga,2015-12-31T00:00:00,1.08,1.0778642892837524,0.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caratinga,2016-12-31T00:00:00,1.56,1.067817211151123,31.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caratinga,2017-12-31T00:00:00,1.46,1.418831467628479,2.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caratinga,2018-12-31T00:00:00,1.8,1.824672818183899,1.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caratinga,2019-12-31T00:00:00,1.0,1.433730959892273,43.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caratinga,2020-12-31T00:00:00,2.04,2.119204521179199,3.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Central_de_Minas,2012-12-31T00:00:00,0.42,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Central_de_Minas,2013-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Central_de_Minas,2014-12-31T00:00:00,0.51,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Central_de_Minas,2015-12-31T00:00:00,0.72,0.6827340722084045,5.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Central_de_Minas,2016-12-31T00:00:00,0.72,0.7899356484413147,9.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Central_de_Minas,2017-12-31T00:00:00,0.6,0.5482510328292847,8.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Central_de_Minas,2018-12-31T00:00:00,1.0,0.7537824511528015,24.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Central_de_Minas,2019-12-31T00:00:00,1.0,0.7994781136512756,20.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Central_de_Minas,2020-12-31T00:00:00,0.67,1.1638790369033813,73.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Chale,2012-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Chale,2013-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Chale,2014-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Chale,2015-12-31T00:00:00,1.38,1.5963895320892334,15.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Chale,2016-12-31T00:00:00,1.42,1.5204123258590698,7.07,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Chale,2017-12-31T00:00:00,0.93,1.3817706108093262,48.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Chale,2018-12-31T00:00:00,1.38,1.5119023323059082,9.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Chale,2019-12-31T00:00:00,1.2,1.1014900207519531,8.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Chale,2020-12-31T00:00:00,1.71,1.7814134359359741,4.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Conceicao_de_Ipanema,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Conceicao_de_Ipanema,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Conceicao_de_Ipanema,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Conceicao_de_Ipanema,2015-12-31T00:00:00,1.14,1.1414353847503662,0.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Conceicao_de_Ipanema,2016-12-31T00:00:00,1.44,1.136160969734192,21.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Conceicao_de_Ipanema,2017-12-31T00:00:00,1.44,1.3385694026947021,7.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Conceicao_de_Ipanema,2018-12-31T00:00:00,1.56,1.6275877952575684,4.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Conceicao_de_Ipanema,2019-12-31T00:00:00,1.19,1.4577168226242065,22.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Conceicao_de_Ipanema,2020-12-31T00:00:00,1.5,1.572713851928711,4.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Datas,2012-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Datas,2013-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Datas,2014-12-31T00:00:00,0.79,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Datas,2015-12-31T00:00:00,1.4,1.0187650918960571,27.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Datas,2016-12-31T00:00:00,1.2,1.1054728031158447,7.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Datas,2017-12-31T00:00:00,1.5,1.3067313432693481,12.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Datas,2018-12-31T00:00:00,3.0,1.6260178089141846,45.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Datas,2019-12-31T00:00:00,2.0,0.8125534057617188,59.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Datas,2020-12-31T00:00:00,2.0,1.912943720817566,4.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Divino,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Divino,2013-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Divino,2014-12-31T00:00:00,0.89,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Divino,2015-12-31T00:00:00,1.2,1.1604634523391724,3.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Divino,2016-12-31T00:00:00,1.2,1.7035374641418457,41.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Divino,2017-12-31T00:00:00,1.19,1.0445960760116577,12.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Divino,2018-12-31T00:00:00,1.32,1.2152351140975952,7.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Divino,2019-12-31T00:00:00,1.08,1.1751515865325928,8.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Divino,2020-12-31T00:00:00,1.8,1.3454416990280151,25.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Durande,2012-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Durande,2013-12-31T00:00:00,2.22,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Durande,2014-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Durande,2015-12-31T00:00:00,1.68,1.78020179271698,5.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Durande,2016-12-31T00:00:00,1.8,1.6746715307235718,6.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Durande,2017-12-31T00:00:00,1.33,1.4904124736785889,12.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Durande,2018-12-31T00:00:00,2.1,2.2669484615325928,7.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Durande,2019-12-31T00:00:00,1.32,1.5205399990081787,15.19,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Durande,2020-12-31T00:00:00,2.4,2.7526140213012695,14.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Entre_Folhas,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Entre_Folhas,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Entre_Folhas,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Entre_Folhas,2015-12-31T00:00:00,1.0,1.0185680389404297,1.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Entre_Folhas,2016-12-31T00:00:00,1.2,1.0733226537704468,10.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Entre_Folhas,2017-12-31T00:00:00,0.86,1.0018839836120605,16.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Entre_Folhas,2018-12-31T00:00:00,1.2,1.183319091796875,1.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Entre_Folhas,2019-12-31T00:00:00,0.84,0.9367108345031738,11.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Entre_Folhas,2020-12-31T00:00:00,1.26,1.177603006362915,6.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ervalia,2012-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ervalia,2013-12-31T00:00:00,1.92,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ervalia,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ervalia,2015-12-31T00:00:00,1.5,1.3855220079421997,7.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ervalia,2016-12-31T00:00:00,1.32,1.2733619213104248,3.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ervalia,2017-12-31T00:00:00,1.36,1.1734631061553955,13.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ervalia,2018-12-31T00:00:00,1.8,1.5165879726409912,15.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ervalia,2019-12-31T00:00:00,1.2,1.2959046363830566,7.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ervalia,2020-12-31T00:00:00,1.8,1.7847075462341309,0.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Espera_Feliz,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Espera_Feliz,2013-12-31T00:00:00,1.92,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Espera_Feliz,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Espera_Feliz,2015-12-31T00:00:00,1.38,1.2215576171875,11.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Espera_Feliz,2016-12-31T00:00:00,1.68,1.6928303241729736,0.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Espera_Feliz,2017-12-31T00:00:00,1.21,1.397582769393921,15.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Espera_Feliz,2018-12-31T00:00:00,1.92,2.0310802459716797,5.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Espera_Feliz,2019-12-31T00:00:00,0.9,1.3836336135864258,53.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Espera_Feliz,2020-12-31T00:00:00,2.04,2.664886474609375,30.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Faria_Lemos,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Faria_Lemos,2013-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Faria_Lemos,2014-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Faria_Lemos,2015-12-31T00:00:00,1.32,1.0705374479293823,18.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Faria_Lemos,2016-12-31T00:00:00,1.38,1.2561999559402466,8.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Faria_Lemos,2017-12-31T00:00:00,0.97,1.3223216533660889,36.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Faria_Lemos,2018-12-31T00:00:00,1.2,1.6791093349456787,39.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Faria_Lemos,2019-12-31T00:00:00,1.08,1.094320297241211,1.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Faria_Lemos,2020-12-31T00:00:00,1.44,1.3213905096054077,8.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ferros,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ferros,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ferros,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ferros,2015-12-31T00:00:00,1.08,1.2702032327651978,17.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ferros,2016-12-31T00:00:00,1.2,1.2928510904312134,7.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ferros,2017-12-31T00:00:00,0.59,1.1026959419250488,86.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ferros,2018-12-31T00:00:00,0.84,1.0115418434143066,20.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ferros,2019-12-31T00:00:00,0.84,0.8041272759437561,4.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ferros,2020-12-31T00:00:00,1.2,0.959409773349762,20.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Franciscopolis,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Franciscopolis,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Franciscopolis,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Franciscopolis,2015-12-31T00:00:00,1.08,2.4185845851898193,123.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Franciscopolis,2016-12-31T00:00:00,1.2,1.0964045524597168,8.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Franciscopolis,2017-12-31T00:00:00,0.52,0.948166012763977,82.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Franciscopolis,2018-12-31T00:00:00,1.8,1.5401334762573242,14.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Franciscopolis,2019-12-31T00:00:00,3.0,1.5752582550048828,47.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Franciscopolis,2020-12-31T00:00:00,1.8,4.925312042236328,173.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Itanhomi,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Itanhomi,2013-12-31T00:00:00,1.35,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Itanhomi,2014-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Itanhomi,2015-12-31T00:00:00,1.2,1.3072153329849243,8.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Itanhomi,2016-12-31T00:00:00,1.14,1.184024691581726,3.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Itanhomi,2017-12-31T00:00:00,1.0,1.0383310317993164,3.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Itanhomi,2018-12-31T00:00:00,1.62,1.246506690979004,23.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Itanhomi,2019-12-31T00:00:00,0.96,1.0513935089111328,9.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Itanhomi,2020-12-31T00:00:00,1.26,1.6205153465270996,28.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lagoa_Formosa,2012-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lagoa_Formosa,2013-12-31T00:00:00,2.4,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lagoa_Formosa,2014-12-31T00:00:00,2.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lagoa_Formosa,2015-12-31T00:00:00,2.4,2.3642959594726562,1.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lagoa_Formosa,2016-12-31T00:00:00,1.8,2.248161792755127,24.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lagoa_Formosa,2017-12-31T00:00:00,1.92,1.8405054807662964,4.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lagoa_Formosa,2018-12-31T00:00:00,1.92,1.9306375980377197,0.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lagoa_Formosa,2019-12-31T00:00:00,2.25,1.979286551475525,12.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lagoa_Formosa,2020-12-31T00:00:00,2.55,2.588046073913574,1.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lagoa_Grande,2012-12-31T00:00:00,1.43,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lagoa_Grande,2013-12-31T00:00:00,3.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lagoa_Grande,2014-12-31T00:00:00,1.79,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lagoa_Grande,2015-12-31T00:00:00,2.38,2.477647304534912,4.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lagoa_Grande,2016-12-31T00:00:00,2.1,2.245035171508789,6.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lagoa_Grande,2017-12-31T00:00:00,2.1,1.8117878437042236,13.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lagoa_Grande,2018-12-31T00:00:00,2.1,2.0681395530700684,1.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lagoa_Grande,2019-12-31T00:00:00,1.2,2.0996956825256348,74.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lagoa_Grande,2020-12-31T00:00:00,2.4,2.4718527793884277,2.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lajinha,2012-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lajinha,2013-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lajinha,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lajinha,2015-12-31T00:00:00,1.44,1.501474142074585,4.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lajinha,2016-12-31T00:00:00,1.68,1.268068552017212,24.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lajinha,2017-12-31T00:00:00,1.04,1.0231122970581055,1.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lajinha,2018-12-31T00:00:00,1.68,1.8057701587677002,7.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lajinha,2019-12-31T00:00:00,1.06,1.2616060972213745,19.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lajinha,2020-12-31T00:00:00,1.92,2.2854673862457275,19.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Luisburgo,2012-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Luisburgo,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Luisburgo,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Luisburgo,2015-12-31T00:00:00,1.5,1.3370246887207031,10.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Luisburgo,2016-12-31T00:00:00,1.32,1.4262279272079468,8.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Luisburgo,2017-12-31T00:00:00,1.53,1.4751125574111938,3.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Luisburgo,2018-12-31T00:00:00,1.8,1.7916312217712402,0.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Luisburgo,2019-12-31T00:00:00,1.64,1.3173880577087402,19.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Luisburgo,2020-12-31T00:00:00,2.1,1.8655481338500977,11.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Malacacheta,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Malacacheta,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Malacacheta,2014-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Malacacheta,2015-12-31T00:00:00,1.5,1.4876782894134521,0.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Malacacheta,2016-12-31T00:00:00,1.32,1.4072614908218384,6.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Malacacheta,2017-12-31T00:00:00,1.37,1.3433475494384766,1.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Malacacheta,2018-12-31T00:00:00,1.8,1.587778091430664,11.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Malacacheta,2019-12-31T00:00:00,1.5,1.560293197631836,4.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Malacacheta,2020-12-31T00:00:00,1.8,1.8469804525375366,2.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Manhuacu,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Manhuacu,2013-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Manhuacu,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Manhuacu,2015-12-31T00:00:00,1.38,1.21735417842865,11.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Manhuacu,2016-12-31T00:00:00,1.26,1.2528005838394165,0.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Manhuacu,2017-12-31T00:00:00,1.43,1.2319755554199219,13.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Manhuacu,2018-12-31T00:00:00,1.44,1.49648916721344,3.92,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Manhuacu,2019-12-31T00:00:00,1.02,1.3058966398239136,28.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Manhuacu,2020-12-31T00:00:00,1.68,1.557051658630371,7.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Manhumirim,2012-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Manhumirim,2013-12-31T00:00:00,1.92,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Manhumirim,2014-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Manhumirim,2015-12-31T00:00:00,1.8,1.9285180568695068,7.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Manhumirim,2016-12-31T00:00:00,1.32,1.7338773012161255,31.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Manhumirim,2017-12-31T00:00:00,1.62,1.4662683010101318,9.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Manhumirim,2018-12-31T00:00:00,1.56,1.6976228952407837,8.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Manhumirim,2019-12-31T00:00:00,1.2,1.376179814338684,14.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Manhumirim,2020-12-31T00:00:00,1.68,1.8212120532989502,8.41,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Matipo,2012-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Matipo,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Matipo,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Matipo,2015-12-31T00:00:00,1.44,1.2613445520401,12.41,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Matipo,2016-12-31T00:00:00,1.32,1.3819290399551392,4.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Matipo,2017-12-31T00:00:00,0.9,1.2590138912200928,39.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Matipo,2018-12-31T00:00:00,1.32,1.3631935119628906,3.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Matipo,2019-12-31T00:00:00,1.32,1.032540202140808,21.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Matipo,2020-12-31T00:00:00,1.56,1.7116096019744873,9.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Mirai,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Mirai,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Mirai,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Mirai,2015-12-31T00:00:00,0.84,1.042147159576416,24.07,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Mirai,2016-12-31T00:00:00,1.2,1.0366063117980957,13.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Mirai,2017-12-31T00:00:00,1.02,0.9137572646141052,10.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Mirai,2018-12-31T00:00:00,1.2,1.0845489501953125,9.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Mirai,2019-12-31T00:00:00,1.2,1.1568907499313354,3.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Mirai,2020-12-31T00:00:00,1.5,1.368844747543335,8.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Muriae,2012-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Muriae,2013-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Muriae,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Muriae,2015-12-31T00:00:00,1.08,1.0851656198501587,0.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Muriae,2016-12-31T00:00:00,1.32,1.4020538330078125,6.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Muriae,2017-12-31T00:00:00,1.44,0.8948768377304077,37.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Muriae,2018-12-31T00:00:00,1.44,1.4996296167373657,4.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Muriae,2019-12-31T00:00:00,1.02,1.3870576620101929,35.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Muriae,2020-12-31T00:00:00,1.56,1.8093922138214111,15.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Mutum,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Mutum,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Mutum,2014-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Mutum,2015-12-31T00:00:00,1.15,1.3417115211486816,16.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Mutum,2016-12-31T00:00:00,1.26,1.2627791166305542,0.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Mutum,2017-12-31T00:00:00,1.45,1.2459571361541748,14.07,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Mutum,2018-12-31T00:00:00,1.5,1.5846043825149536,5.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Mutum,2019-12-31T00:00:00,1.44,1.324544072151184,8.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Mutum,2020-12-31T00:00:00,1.65,1.5345667600631714,7.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Nova_Belem,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Nova_Belem,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Nova_Belem,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Nova_Belem,2015-12-31T00:00:00,0.9,5.533517837524414,514.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Nova_Belem,2016-12-31T00:00:00,1.2,1.601818323135376,33.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Nova_Belem,2017-12-31T00:00:00,0.48,0.867184579372406,80.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Nova_Belem,2018-12-31T00:00:00,1.2,1.088080883026123,9.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Nova_Belem,2019-12-31T00:00:00,0.9,0.7595897912979126,15.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Nova_Belem,2020-12-31T00:00:00,1.1,1.1603102684020996,5.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Orizania,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Orizania,2013-12-31T00:00:00,1.68,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Orizania,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Orizania,2015-12-31T00:00:00,1.2,1.2240350246429443,2.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Orizania,2016-12-31T00:00:00,1.8,1.306878924369812,27.4,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Orizania,2017-12-31T00:00:00,1.47,1.5669162273406982,6.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Orizania,2018-12-31T00:00:00,1.56,1.6743005514144897,7.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Orizania,2019-12-31T00:00:00,1.38,1.4502536058425903,5.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Orizania,2020-12-31T00:00:00,1.68,1.6003360748291016,4.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Patis,2012-12-31T00:00:00,2.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Patis,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Patis,2014-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Patis,2015-12-31T00:00:00,2.8,1.1652318239212036,58.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Patis,2016-12-31T00:00:00,1.19,1.1788676977157593,0.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Patis,2017-12-31T00:00:00,1.8,1.55574631690979,13.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Patis,2018-12-31T00:00:00,3.6,3.512127161026001,2.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Patis,2019-12-31T00:00:00,3.0,2.210415840148926,26.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Patis,2020-12-31T00:00:00,3.6,4.017971992492676,11.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ponte_Nova,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ponte_Nova,2013-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ponte_Nova,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ponte_Nova,2015-12-31T00:00:00,1.26,1.1905320882797241,5.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ponte_Nova,2016-12-31T00:00:00,1.2,1.1864557266235352,1.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ponte_Nova,2017-12-31T00:00:00,1.17,1.1999083757400513,2.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ponte_Nova,2018-12-31T00:00:00,1.5,1.3384290933609009,10.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ponte_Nova,2019-12-31T00:00:00,1.17,1.2654974460601807,8.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ponte_Nova,2020-12-31T00:00:00,1.33,1.3016984462738037,2.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Porto_Firme,2012-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Porto_Firme,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Porto_Firme,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Porto_Firme,2015-12-31T00:00:00,1.26,1.0491290092468262,16.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Porto_Firme,2016-12-31T00:00:00,1.2,1.18210768699646,1.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Porto_Firme,2017-12-31T00:00:00,1.2,1.153814435005188,3.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Porto_Firme,2018-12-31T00:00:00,1.2,1.2441802024841309,3.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Porto_Firme,2019-12-31T00:00:00,1.12,-0.18140748143196106,116.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Porto_Firme,2020-12-31T00:00:00,1.56,1.2281830310821533,21.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Raul_Soares,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Raul_Soares,2013-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Raul_Soares,2014-12-31T00:00:00,0.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Raul_Soares,2015-12-31T00:00:00,1.08,1.0748698711395264,0.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Raul_Soares,2016-12-31T00:00:00,1.08,0.9808430075645447,9.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Raul_Soares,2017-12-31T00:00:00,0.86,0.9727433323860168,13.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Raul_Soares,2018-12-31T00:00:00,1.2,1.1423842906951904,4.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Raul_Soares,2019-12-31T00:00:00,1.2,1.002182126045227,16.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Raul_Soares,2020-12-31T00:00:00,1.32,1.5498988628387451,17.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Reduto,2012-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Reduto,2013-12-31T00:00:00,1.62,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Reduto,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Reduto,2015-12-31T00:00:00,1.38,1.3221266269683838,4.19,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Reduto,2016-12-31T00:00:00,1.44,1.3650219440460205,5.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Reduto,2017-12-31T00:00:00,1.26,1.3614298105239868,8.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Reduto,2018-12-31T00:00:00,1.8,1.5210927724838257,15.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Reduto,2019-12-31T00:00:00,1.26,1.3092960119247437,3.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Reduto,2020-12-31T00:00:00,1.8,1.9119889736175537,6.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Rio_Pardo_de_Minas,2012-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Rio_Pardo_de_Minas,2013-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Rio_Pardo_de_Minas,2014-12-31T00:00:00,2.65,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Rio_Pardo_de_Minas,2015-12-31T00:00:00,2.28,2.0497190952301025,10.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Rio_Pardo_de_Minas,2016-12-31T00:00:00,2.46,2.2402710914611816,8.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Rio_Pardo_de_Minas,2017-12-31T00:00:00,2.18,2.4512062072753906,12.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Rio_Pardo_de_Minas,2018-12-31T00:00:00,2.63,2.4845399856567383,5.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Rio_Pardo_de_Minas,2019-12-31T00:00:00,2.75,2.631549835205078,4.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Rio_Pardo_de_Minas,2020-12-31T00:00:00,3.45,3.4197826385498047,0.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Rosario_da_Limeira,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Rosario_da_Limeira,2013-12-31T00:00:00,1.54,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Rosario_da_Limeira,2014-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Rosario_da_Limeira,2015-12-31T00:00:00,1.14,1.3505810499191284,18.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Rosario_da_Limeira,2016-12-31T00:00:00,1.26,1.366679072380066,8.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Rosario_da_Limeira,2017-12-31T00:00:00,0.78,1.1358214616775513,45.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Rosario_da_Limeira,2018-12-31T00:00:00,1.2,1.2521880865097046,4.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Rosario_da_Limeira,2019-12-31T00:00:00,1.2,1.0272282361984253,14.4,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Rosario_da_Limeira,2020-12-31T00:00:00,1.5,1.498962163925171,0.07,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Barbara_do_Leste,2012-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Barbara_do_Leste,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Barbara_do_Leste,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Barbara_do_Leste,2015-12-31T00:00:00,1.08,1.0933794975280762,1.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Barbara_do_Leste,2016-12-31T00:00:00,1.02,1.0491125583648682,2.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Barbara_do_Leste,2017-12-31T00:00:00,0.91,1.0014641284942627,10.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Barbara_do_Leste,2018-12-31T00:00:00,1.74,1.2024344205856323,30.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Barbara_do_Leste,2019-12-31T00:00:00,1.14,0.8329505324363708,26.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Barbara_do_Leste,2020-12-31T00:00:00,1.44,1.5962061882019043,10.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Margarida,2012-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Margarida,2013-12-31T00:00:00,1.68,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Margarida,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Margarida,2015-12-31T00:00:00,1.56,1.4104136228561401,9.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Margarida,2016-12-31T00:00:00,1.32,1.4448057413101196,9.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Margarida,2017-12-31T00:00:00,1.2,1.270058512687683,5.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Margarida,2018-12-31T00:00:00,1.68,1.5962432622909546,4.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Margarida,2019-12-31T00:00:00,1.2,1.1854335069656372,1.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Margarida,2020-12-31T00:00:00,1.8,1.6785165071487427,6.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Rita_de_Minas,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Rita_de_Minas,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Rita_de_Minas,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Rita_de_Minas,2015-12-31T00:00:00,1.2,1.099079966545105,8.41,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Rita_de_Minas,2016-12-31T00:00:00,1.08,1.0536035299301147,2.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Rita_de_Minas,2017-12-31T00:00:00,1.25,1.1018712520599365,11.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Rita_de_Minas,2018-12-31T00:00:00,1.5,1.3527065515518188,9.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Rita_de_Minas,2019-12-31T00:00:00,1.26,1.0513880252838135,16.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Rita_de_Minas,2020-12-31T00:00:00,1.5,1.4779727458953857,1.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santana_do_Manhuacu,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santana_do_Manhuacu,2013-12-31T00:00:00,1.62,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santana_do_Manhuacu,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santana_do_Manhuacu,2015-12-31T00:00:00,1.44,1.4594612121582031,1.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santana_do_Manhuacu,2016-12-31T00:00:00,1.32,1.4037671089172363,6.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santana_do_Manhuacu,2017-12-31T00:00:00,1.28,1.325637936592102,3.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santana_do_Manhuacu,2018-12-31T00:00:00,1.5,1.4920556545257568,0.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santana_do_Manhuacu,2019-12-31T00:00:00,1.5,1.314362645149231,12.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santana_do_Manhuacu,2020-12-31T00:00:00,1.8,1.6253299713134766,9.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Francisco_do_Gloria,2012-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Francisco_do_Gloria,2013-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Francisco_do_Gloria,2014-12-31T00:00:00,1.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Francisco_do_Gloria,2015-12-31T00:00:00,1.32,1.2177635431289673,7.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Francisco_do_Gloria,2016-12-31T00:00:00,1.5,1.3104873895645142,12.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Francisco_do_Gloria,2017-12-31T00:00:00,0.8,1.1671088933944702,45.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Francisco_do_Gloria,2018-12-31T00:00:00,1.32,1.512876272201538,14.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Francisco_do_Gloria,2019-12-31T00:00:00,0.9,0.8595995903015137,4.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Francisco_do_Gloria,2020-12-31T00:00:00,1.68,1.621522307395935,3.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Joao_do_Manhuacu,2012-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Joao_do_Manhuacu,2013-12-31T00:00:00,1.74,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Joao_do_Manhuacu,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Joao_do_Manhuacu,2015-12-31T00:00:00,1.32,1.6688565015792847,26.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Joao_do_Manhuacu,2016-12-31T00:00:00,1.32,1.338221549987793,1.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Joao_do_Manhuacu,2017-12-31T00:00:00,1.7,1.2313170433044434,27.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Joao_do_Manhuacu,2018-12-31T00:00:00,1.62,1.7097892761230469,5.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Joao_do_Manhuacu,2019-12-31T00:00:00,1.32,1.3759561777114868,4.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Joao_do_Manhuacu,2020-12-31T00:00:00,1.8,1.7300482988357544,3.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Jose_do_Mantimento,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Jose_do_Mantimento,2013-12-31T00:00:00,1.42,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Jose_do_Mantimento,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Jose_do_Mantimento,2015-12-31T00:00:00,1.44,1.3050068616867065,9.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Jose_do_Mantimento,2016-12-31T00:00:00,1.2,1.345327377319336,12.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Jose_do_Mantimento,2017-12-31T00:00:00,1.2,1.2838225364685059,6.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Jose_do_Mantimento,2018-12-31T00:00:00,1.44,1.4578934907913208,1.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Jose_do_Mantimento,2019-12-31T00:00:00,1.56,1.2419726848602295,20.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Jose_do_Mantimento,2020-12-31T00:00:00,1.8,1.8313850164413452,1.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sericita,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sericita,2013-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sericita,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sericita,2015-12-31T00:00:00,1.2,1.2774205207824707,6.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sericita,2016-12-31T00:00:00,1.2,1.1739330291748047,2.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sericita,2017-12-31T00:00:00,1.12,1.2014013528823853,7.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sericita,2018-12-31T00:00:00,1.8,1.2752127647399902,29.15,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sericita,2019-12-31T00:00:00,0.9,1.1908588409423828,32.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sericita,2020-12-31T00:00:00,2.52,2.338541269302368,7.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Setubinha,2012-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Setubinha,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Setubinha,2014-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Setubinha,2015-12-31T00:00:00,0.9,0.8128730058670044,9.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Setubinha,2016-12-31T00:00:00,1.5,0.8755893707275391,41.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Setubinha,2017-12-31T00:00:00,0.76,0.9800752401351929,28.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Setubinha,2018-12-31T00:00:00,0.9,1.7292513847351074,92.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Setubinha,2019-12-31T00:00:00,0.9,1.1324207782745361,25.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Setubinha,2020-12-31T00:00:00,1.0,0.9676932096481323,3.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Teofilo_Otoni,2012-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Teofilo_Otoni,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Teofilo_Otoni,2014-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Teofilo_Otoni,2015-12-31T00:00:00,0.9,0.8298620581626892,7.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Teofilo_Otoni,2016-12-31T00:00:00,0.9,0.9735915064811707,8.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Teofilo_Otoni,2017-12-31T00:00:00,0.67,0.6559892892837524,2.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Teofilo_Otoni,2018-12-31T00:00:00,0.91,0.8652268648147583,4.92,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Teofilo_Otoni,2019-12-31T00:00:00,0.91,0.850905179977417,6.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Teofilo_Otoni,2020-12-31T00:00:00,1.09,1.1059322357177734,1.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Tombos,2012-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Tombos,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Tombos,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Tombos,2015-12-31T00:00:00,1.2,1.0792982578277588,10.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Tombos,2016-12-31T00:00:00,0.96,1.1299840211868286,17.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Tombos,2017-12-31T00:00:00,0.99,0.963309109210968,2.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Tombos,2018-12-31T00:00:00,1.44,1.1775521039962769,18.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Tombos,2019-12-31T00:00:00,0.96,0.9580803513526917,0.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Tombos,2020-12-31T00:00:00,1.5,1.6976373195648193,13.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ubaporanga,2012-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ubaporanga,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ubaporanga,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ubaporanga,2015-12-31T00:00:00,1.2,1.2452048063278198,3.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ubaporanga,2016-12-31T00:00:00,0.96,1.1059627532958984,15.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ubaporanga,2017-12-31T00:00:00,1.03,0.9424384832382202,8.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ubaporanga,2018-12-31T00:00:00,1.5,1.5278892517089844,1.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ubaporanga,2019-12-31T00:00:00,1.32,1.0067996978759766,23.73,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ubaporanga,2020-12-31T00:00:00,1.62,1.61826753616333,0.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Urucuia,2012-12-31T00:00:00,2.4,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Urucuia,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Urucuia,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Urucuia,2015-12-31T00:00:00,1.8,1.5620293617248535,13.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Urucuia,2016-12-31T00:00:00,2.4,2.3325281143188477,2.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Urucuia,2017-12-31T00:00:00,1.8,2.084817886352539,15.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Urucuia,2018-12-31T00:00:00,2.4,2.3458588123321533,2.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Urucuia,2019-12-31T00:00:00,2.4,2.5620522499084473,6.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Urucuia,2020-12-31T00:00:00,2.4,2.3618664741516113,1.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vermelho_Novo,2012-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vermelho_Novo,2013-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vermelho_Novo,2014-12-31T00:00:00,0.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vermelho_Novo,2015-12-31T00:00:00,1.2,0.9243241548538208,22.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vermelho_Novo,2016-12-31T00:00:00,1.2,0.9607440829277039,19.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vermelho_Novo,2017-12-31T00:00:00,1.08,1.0737524032592773,0.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vermelho_Novo,2018-12-31T00:00:00,1.32,1.324714183807373,0.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vermelho_Novo,2019-12-31T00:00:00,1.08,1.0950980186462402,1.4,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vermelho_Novo,2020-12-31T00:00:00,1.32,1.3532596826553345,2.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vicosa,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vicosa,2013-12-31T00:00:00,1.62,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vicosa,2014-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vicosa,2015-12-31T00:00:00,1.44,1.4320088624954224,0.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vicosa,2016-12-31T00:00:00,1.16,1.3031965494155884,12.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vicosa,2017-12-31T00:00:00,1.49,1.3770053386688232,7.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vicosa,2018-12-31T00:00:00,1.56,1.5668814182281494,0.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vicosa,2019-12-31T00:00:00,0.84,1.206347942352295,43.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vicosa,2020-12-31T00:00:00,1.8,1.681485891342163,6.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vieiras,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vieiras,2013-12-31T00:00:00,1.81,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vieiras,2014-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vieiras,2015-12-31T00:00:00,1.32,1.642045021057129,24.4,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vieiras,2016-12-31T00:00:00,1.2,1.502220630645752,25.19,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vieiras,2017-12-31T00:00:00,1.13,1.2132227420806885,7.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vieiras,2018-12-31T00:00:00,1.26,1.3019347190856934,3.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vieiras,2019-12-31T00:00:00,1.02,1.1617501974105835,13.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vieiras,2020-12-31T00:00:00,1.8,1.390872836112976,22.73,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Virginopolis,2012-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Virginopolis,2013-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Virginopolis,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Virginopolis,2015-12-31T00:00:00,1.32,1.2558730840682983,4.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Virginopolis,2016-12-31T00:00:00,1.0,1.2225561141967773,22.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Virginopolis,2017-12-31T00:00:00,1.37,1.321560263633728,3.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Virginopolis,2018-12-31T00:00:00,1.5,1.555240511894226,3.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Virginopolis,2019-12-31T00:00:00,1.51,1.1282685995101929,25.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Virginopolis,2020-12-31T00:00:00,1.63,1.6176247596740723,0.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Abadia_dos_Dourados,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Agua_Boa,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Aguas_Vermelhas,2021-12-31T00:00:00,3.0,3,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Alto_Caparao,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Araponga,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Areado,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ataleia,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Bom_Jesus_do_Galho,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caiana,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Cajuri,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Canaa,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caparao,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caputira,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Carai,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Carangola,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caratinga,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Central_de_Minas,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Chale,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Conceicao_de_Ipanema,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Datas,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Divino,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Durande,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Entre_Folhas,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ervalia,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Espera_Feliz,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Faria_Lemos,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ferros,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Franciscopolis,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Itanhomi,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lagoa_Formosa,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lagoa_Grande,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lajinha,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Luisburgo,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Malacacheta,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Manhuacu,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Manhumirim,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Matipo,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Mirai,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Muriae,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Mutum,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Nova_Belem,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Orizania,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Patis,2021-12-31T00:00:00,2.0,3,50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ponte_Nova,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Porto_Firme,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Raul_Soares,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Reduto,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Rio_Pardo_de_Minas,2021-12-31T00:00:00,3.0,3,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Rosario_da_Limeira,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Barbara_do_Leste,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Margarida,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Rita_de_Minas,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santana_do_Manhuacu,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Francisco_do_Gloria,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Joao_do_Manhuacu,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Jose_do_Mantimento,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sericita,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Setubinha,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Teofilo_Otoni,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Tombos,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ubaporanga,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Urucuia,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vermelho_Novo,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vicosa,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vieiras,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Virginopolis,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Abadia_dos_Dourados,2022-12-31T00:00:00,2.0384615384615383,2.3358166217803955,14.59,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Agua_Boa,2022-12-31T00:00:00,0.9136363636363636,0.7530568242073059,-17.58,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Aguas_Vermelhas,2022-12-31T00:00:00,3.0,2.7549543380737305,-8.17,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Alto_Caparao,2022-12-31T00:00:00,1.5,1.4466986656188965,-3.55,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Araponga,2022-12-31T00:00:00,1.260041407867495,1.077622890472412,-14.48,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Areado,2022-12-31T00:00:00,0.9076923076923076,1.5413360595703125,69.81,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ataleia,2022-12-31T00:00:00,0.7142857142857143,0.7341963052749634,2.79,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Bom_Jesus_do_Galho,2022-12-31T00:00:00,0.7801587301587303,0.9980781078338623,27.93,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caiana,2022-12-31T00:00:00,0.9,1.1057827472686768,22.86,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Cajuri,2022-12-31T00:00:00,1.050602409638554,1.3599743843078613,29.45,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Canaa,2022-12-31T00:00:00,1.320338983050847,1.4011235237121582,6.12,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caparao,2022-12-31T00:00:00,1.32,1.299442172050476,-1.56,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caputira,2022-12-31T00:00:00,1.440044247787611,1.3156824111938477,-8.64,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Carai,2022-12-31T00:00:00,1.2,1.2271034717559814,2.26,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Carangola,2022-12-31T00:00:00,1.02,1.180640697479248,15.75,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Caratinga,2022-12-31T00:00:00,1.620022123893805,0.9052375555038452,-44.12,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Central_de_Minas,2022-12-31T00:00:00,0.8333333333333335,0.6412134766578674,-23.05,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Chale,2022-12-31T00:00:00,1.44,1.2723987102508545,-11.64,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Conceicao_de_Ipanema,2022-12-31T00:00:00,1.5,1.2403788566589355,-17.31,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Datas,2022-12-31T00:00:00,0.75,1.4794825315475464,97.26,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Divino,2022-12-31T00:00:00,1.08,1.2214670181274414,13.1,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Durande,2022-12-31T00:00:00,1.5,1.3207345008850098,-11.95,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Entre_Folhas,2022-12-31T00:00:00,1.2,0.8458975553512573,-29.51,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ervalia,2022-12-31T00:00:00,1.2,1.2895011901855469,7.46,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Espera_Feliz,2022-12-31T00:00:00,1.2,0.9938878417015076,-17.18,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Faria_Lemos,2022-12-31T00:00:00,1.200305810397553,0.9536376595497131,-20.55,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ferros,2022-12-31T00:00:00,1.230769230769231,1.0018056631088257,-18.6,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Franciscopolis,2022-12-31T00:00:00,1.255555555555556,1.170576572418213,-6.77,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Itanhomi,2022-12-31T00:00:00,1.081818181818182,1.102707028388977,1.93,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lagoa_Formosa,2022-12-31T00:00:00,2.088607594936709,1.7009077072143555,-18.56,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lagoa_Grande,2022-12-31T00:00:00,2.4,0.7819716930389404,-67.42,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Lajinha,2022-12-31T00:00:00,1.419975786924939,1.026865005493164,-27.68,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Luisburgo,2022-12-31T00:00:00,1.5,1.6713976860046387,11.43,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Malacacheta,2022-12-31T00:00:00,1.5595238095238098,1.5012147426605225,-3.74,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Manhuacu,2022-12-31T00:00:00,1.44,1.1638611555099487,-19.18,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Manhumirim,2022-12-31T00:00:00,1.3799999999999997,1.4016599655151367,1.57,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Matipo,2022-12-31T00:00:00,1.26,1.1281380653381348,-10.47,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Mirai,2022-12-31T00:00:00,1.2,1.2519965171813965,4.33,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Muriae,2022-12-31T00:00:00,0.9897142857142858,0.9216796159744263,-6.87,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Mutum,2022-12-31T00:00:00,1.379940564635958,1.278438687324524,-7.36,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Nova_Belem,2022-12-31T00:00:00,0.96,0.9279284477233887,-3.34,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Orizania,2022-12-31T00:00:00,1.5,1.3393889665603638,-10.71,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Patis,2022-12-31T00:00:00,2.044444444444444,1.9389301538467407,-5.16,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ponte_Nova,2022-12-31T00:00:00,1.25,1.2445343732833862,-0.44,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Porto_Firme,2022-12-31T00:00:00,1.32,1.318464994430542,-0.12,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Raul_Soares,2022-12-31T00:00:00,0.8399548532731377,1.211377501487732,44.22,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Reduto,2022-12-31T00:00:00,1.260059171597633,1.432377576828003,13.68,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Rio_Pardo_de_Minas,2022-12-31T00:00:00,2.515254237288135,2.568232536315918,2.11,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Rosario_da_Limeira,2022-12-31T00:00:00,1.02,0.9376444816589355,-8.07,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Barbara_do_Leste,2022-12-31T00:00:00,1.05015873015873,1.1453940868377686,9.07,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Margarida,2022-12-31T00:00:00,1.3799999999999997,1.2804253101348877,-7.22,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santa_Rita_de_Minas,2022-12-31T00:00:00,1.019909502262443,1.1545414924621582,13.2,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Santana_do_Manhuacu,2022-12-31T00:00:00,1.26,1.3791534900665283,9.46,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Francisco_do_Gloria,2022-12-31T00:00:00,0.9601476014760146,0.9606304168701172,0.05,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Joao_do_Manhuacu,2022-12-31T00:00:00,1.2,1.3058191537857056,8.82,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sao_Jose_do_Mantimento,2022-12-31T00:00:00,1.499236641221374,1.5378562211990356,2.58,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Sericita,2022-12-31T00:00:00,1.3799999999999997,1.2125320434570312,-12.14,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Setubinha,2022-12-31T00:00:00,1.079761904761905,0.8773379921913147,-18.75,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Teofilo_Otoni,2022-12-31T00:00:00,0.8181818181818183,0.7722484469413757,-5.61,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Tombos,2022-12-31T00:00:00,1.2,0.8775702714920044,-26.87,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Ubaporanga,2022-12-31T00:00:00,1.2,1.2518234252929688,4.32,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Urucuia,2022-12-31T00:00:00,1.9193245778611627,1.8783984184265137,-2.13,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vermelho_Novo,2022-12-31T00:00:00,0.9598214285714286,0.9757023453712463,1.65,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vicosa,2022-12-31T00:00:00,1.079768786127168,1.2146615982055664,12.49,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Vieiras,2022-12-31T00:00:00,1.32,0.8690993785858154,-34.16,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2022),Virginopolis,2022-12-31T00:00:00,1.314606741573034,1.2944681644439697,-1.53,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 6
        learning_rate: 0.0009055528877980373
        encoder_hidden_size: 128
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 1e-05
        steps: 400
        ",2025-09-17T10:59:15
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Abadia_dos_Dourados,2012-12-31T00:00:00,2.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Abadia_dos_Dourados,2013-12-31T00:00:00,1.97,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Abadia_dos_Dourados,2014-12-31T00:00:00,2.29,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Abadia_dos_Dourados,2015-12-31T00:00:00,1.97,2.123298168182373,7.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Abadia_dos_Dourados,2016-12-31T00:00:00,2.19,2.122274875640869,3.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Abadia_dos_Dourados,2017-12-31T00:00:00,0.83,2.0707366466522217,149.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Abadia_dos_Dourados,2018-12-31T00:00:00,1.2,1.5740032196044922,31.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Abadia_dos_Dourados,2019-12-31T00:00:00,2.4,1.4347126483917236,40.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Abadia_dos_Dourados,2020-12-31T00:00:00,2.58,2.0299627780914307,21.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Abadia_dos_Dourados,2021-12-31T00:00:00,1.8,1.7618008852005005,2.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Agua_Boa,2012-12-31T00:00:00,1.12,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Agua_Boa,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Agua_Boa,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Agua_Boa,2015-12-31T00:00:00,1.08,1.0841361284255981,0.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Agua_Boa,2016-12-31T00:00:00,1.08,1.0497117042541504,2.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Agua_Boa,2017-12-31T00:00:00,1.11,1.0419608354568481,6.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Agua_Boa,2018-12-31T00:00:00,1.2,1.0917400121688843,9.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Agua_Boa,2019-12-31T00:00:00,1.09,1.1272132396697998,3.41,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Agua_Boa,2020-12-31T00:00:00,1.33,1.1954758167266846,10.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Agua_Boa,2021-12-31T00:00:00,0.62,1.1821790933609009,90.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Aguas_Vermelhas,2012-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Aguas_Vermelhas,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Aguas_Vermelhas,2014-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Aguas_Vermelhas,2015-12-31T00:00:00,1.2,1.6696958541870117,39.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Aguas_Vermelhas,2016-12-31T00:00:00,3.6,1.4442335367202759,59.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Aguas_Vermelhas,2017-12-31T00:00:00,2.6,1.8938642740249634,27.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Aguas_Vermelhas,2018-12-31T00:00:00,3.0,2.444827079772949,18.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Aguas_Vermelhas,2019-12-31T00:00:00,2.7,2.9703760147094727,10.01,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Aguas_Vermelhas,2020-12-31T00:00:00,3.6,3.0847713947296143,14.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Aguas_Vermelhas,2021-12-31T00:00:00,3.0,2.934375047683716,2.19,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Alto_Caparao,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Alto_Caparao,2013-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Alto_Caparao,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Alto_Caparao,2015-12-31T00:00:00,1.2,1.4396437406539917,19.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Alto_Caparao,2016-12-31T00:00:00,2.1,1.4648938179016113,30.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Alto_Caparao,2017-12-31T00:00:00,1.37,1.5913887023925781,16.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Alto_Caparao,2018-12-31T00:00:00,1.5,2.0020899772644043,33.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Alto_Caparao,2019-12-31T00:00:00,1.32,1.5251027345657349,15.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Alto_Caparao,2020-12-31T00:00:00,1.92,1.4380829334259033,25.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Alto_Caparao,2021-12-31T00:00:00,1.08,1.4836432933807373,37.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Araponga,2012-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Araponga,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Araponga,2014-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Araponga,2015-12-31T00:00:00,1.26,1.194847822189331,5.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Araponga,2016-12-31T00:00:00,1.32,1.3165544271469116,0.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Araponga,2017-12-31T00:00:00,1.5,1.2116022109985352,19.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Araponga,2018-12-31T00:00:00,1.38,1.4352293014526367,4.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Araponga,2019-12-31T00:00:00,0.9,1.3773179054260254,53.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Araponga,2020-12-31T00:00:00,1.8,1.4335969686508179,20.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Araponga,2021-12-31T00:00:00,1.2,1.2632615566253662,5.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Areado,2012-12-31T00:00:00,1.95,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Areado,2013-12-31T00:00:00,1.86,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Areado,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Areado,2015-12-31T00:00:00,1.68,1.7096744775772095,1.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Areado,2016-12-31T00:00:00,2.04,1.7563564777374268,13.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Areado,2017-12-31T00:00:00,1.68,1.5619988441467285,7.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Areado,2018-12-31T00:00:00,1.5,1.7496848106384277,16.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Areado,2019-12-31T00:00:00,1.92,1.7826030254364014,7.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Areado,2020-12-31T00:00:00,2.08,1.8114389181137085,12.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Areado,2021-12-31T00:00:00,1.52,1.7827794551849365,17.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ataleia,2012-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ataleia,2013-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ataleia,2014-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ataleia,2015-12-31T00:00:00,0.91,0.6864633560180664,24.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ataleia,2016-12-31T00:00:00,0.91,0.7677342295646667,15.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ataleia,2017-12-31T00:00:00,0.65,0.8072723150253296,24.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ataleia,2018-12-31T00:00:00,0.9,0.8592612743377686,4.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ataleia,2019-12-31T00:00:00,0.9,0.7955063581466675,11.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ataleia,2020-12-31T00:00:00,1.2,0.9486755728721619,20.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ataleia,2021-12-31T00:00:00,0.63,0.9583734273910522,52.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Bom_Jesus_do_Galho,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Bom_Jesus_do_Galho,2013-12-31T00:00:00,0.78,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Bom_Jesus_do_Galho,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Bom_Jesus_do_Galho,2015-12-31T00:00:00,0.96,0.8554674386978149,10.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Bom_Jesus_do_Galho,2016-12-31T00:00:00,1.8,0.8995711207389832,50.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Bom_Jesus_do_Galho,2017-12-31T00:00:00,0.82,1.182431697845459,44.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Bom_Jesus_do_Galho,2018-12-31T00:00:00,1.2,1.539628505706787,28.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Bom_Jesus_do_Galho,2019-12-31T00:00:00,1.08,1.0815443992614746,0.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Bom_Jesus_do_Galho,2020-12-31T00:00:00,1.44,1.1694952249526978,18.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Bom_Jesus_do_Galho,2021-12-31T00:00:00,1.08,1.1700639724731445,8.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caiana,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caiana,2013-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caiana,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caiana,2015-12-31T00:00:00,0.96,1.1061819791793823,15.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caiana,2016-12-31T00:00:00,1.2,1.1175892353057861,6.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caiana,2017-12-31T00:00:00,1.2,1.1412298679351807,4.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caiana,2018-12-31T00:00:00,1.5,1.2971653938293457,13.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caiana,2019-12-31T00:00:00,1.08,1.2770612239837646,18.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caiana,2020-12-31T00:00:00,1.5,1.3917410373687744,7.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caiana,2021-12-31T00:00:00,0.9,1.2573274374008179,39.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Cajuri,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Cajuri,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Cajuri,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Cajuri,2015-12-31T00:00:00,1.32,1.6965882778167725,28.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Cajuri,2016-12-31T00:00:00,1.2,1.2630622386932373,5.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Cajuri,2017-12-31T00:00:00,1.2,1.2333201169967651,2.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Cajuri,2018-12-31T00:00:00,1.8,1.268007755279541,29.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Cajuri,2019-12-31T00:00:00,1.18,1.4308724403381348,21.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Cajuri,2020-12-31T00:00:00,1.8,1.7869731187820435,0.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Cajuri,2021-12-31T00:00:00,1.26,1.56187105178833,23.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Canaa,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Canaa,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Canaa,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Canaa,2015-12-31T00:00:00,1.02,1.2775840759277344,25.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Canaa,2016-12-31T00:00:00,1.2,1.2859346866607666,7.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Canaa,2017-12-31T00:00:00,1.5,1.0864088535308838,27.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Canaa,2018-12-31T00:00:00,1.5,1.3685028553009033,8.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Canaa,2019-12-31T00:00:00,1.26,1.4053001403808594,11.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Canaa,2020-12-31T00:00:00,1.8,1.5520567893981934,13.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Canaa,2021-12-31T00:00:00,1.2,1.4702577590942383,22.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caparao,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caparao,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caparao,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caparao,2015-12-31T00:00:00,1.02,0.6404788494110107,37.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caparao,2016-12-31T00:00:00,1.92,1.1726888418197632,38.92,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caparao,2017-12-31T00:00:00,1.45,1.4070005416870117,2.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caparao,2018-12-31T00:00:00,1.8,2.226090431213379,23.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caparao,2019-12-31T00:00:00,1.32,1.6733222007751465,26.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caparao,2020-12-31T00:00:00,1.92,1.6514278650283813,13.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caparao,2021-12-31T00:00:00,0.9,1.5560404062271118,72.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caputira,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caputira,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caputira,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caputira,2015-12-31T00:00:00,1.5,1.2863476276397705,14.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caputira,2016-12-31T00:00:00,1.26,1.4005194902420044,11.15,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caputira,2017-12-31T00:00:00,0.77,1.3254339694976807,72.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caputira,2018-12-31T00:00:00,1.2,1.5870935916900635,32.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caputira,2019-12-31T00:00:00,1.2,0.982329785823822,18.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caputira,2020-12-31T00:00:00,1.8,1.1640033721923828,35.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caputira,2021-12-31T00:00:00,1.38,1.3561993837356567,1.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Carai,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Carai,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Carai,2014-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Carai,2015-12-31T00:00:00,0.96,0.8504421710968018,11.41,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Carai,2016-12-31T00:00:00,0.96,0.8963627219200134,6.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Carai,2017-12-31T00:00:00,0.54,0.8286900520324707,53.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Carai,2018-12-31T00:00:00,0.84,0.9234328866004944,9.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Carai,2019-12-31T00:00:00,1.2,0.7729367017745972,35.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Carai,2020-12-31T00:00:00,1.52,1.1168087720870972,26.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Carai,2021-12-31T00:00:00,1.22,1.1969603300094604,1.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Carangola,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Carangola,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Carangola,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Carangola,2015-12-31T00:00:00,0.9,0.9402240514755249,4.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Carangola,2016-12-31T00:00:00,1.2,0.901214063167572,24.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Carangola,2017-12-31T00:00:00,1.1,1.068416953086853,2.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Carangola,2018-12-31T00:00:00,1.56,1.2181479930877686,21.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Carangola,2019-12-31T00:00:00,1.26,1.2125120162963867,3.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Carangola,2020-12-31T00:00:00,1.5,1.4222941398620605,5.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Carangola,2021-12-31T00:00:00,1.02,1.385360598564148,35.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caratinga,2012-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caratinga,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caratinga,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caratinga,2015-12-31T00:00:00,1.08,1.0125880241394043,6.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caratinga,2016-12-31T00:00:00,1.56,1.113535761833191,28.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caratinga,2017-12-31T00:00:00,1.46,1.1823424100875854,19.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caratinga,2018-12-31T00:00:00,1.8,1.5424162149429321,14.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caratinga,2019-12-31T00:00:00,1.0,1.5395326614379883,53.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caratinga,2020-12-31T00:00:00,2.04,1.6609827280044556,18.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caratinga,2021-12-31T00:00:00,1.26,1.40305495262146,11.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Central_de_Minas,2012-12-31T00:00:00,0.42,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Central_de_Minas,2013-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Central_de_Minas,2014-12-31T00:00:00,0.51,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Central_de_Minas,2015-12-31T00:00:00,0.72,0.5466384887695312,24.08,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Central_de_Minas,2016-12-31T00:00:00,0.72,0.6433463096618652,10.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Central_de_Minas,2017-12-31T00:00:00,0.6,0.6229593753814697,3.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Central_de_Minas,2018-12-31T00:00:00,1.0,0.7015352249145508,29.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Central_de_Minas,2019-12-31T00:00:00,1.0,0.7383655309677124,26.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Central_de_Minas,2020-12-31T00:00:00,0.67,1.0291109085083008,53.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Central_de_Minas,2021-12-31T00:00:00,0.83,0.8421469926834106,1.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Chale,2012-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Chale,2013-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Chale,2014-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Chale,2015-12-31T00:00:00,1.38,1.5152873992919922,9.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Chale,2016-12-31T00:00:00,1.42,1.5741264820098877,10.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Chale,2017-12-31T00:00:00,0.93,1.4423569440841675,55.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Chale,2018-12-31T00:00:00,1.38,1.4889155626296997,7.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Chale,2019-12-31T00:00:00,1.2,1.1862890720367432,1.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Chale,2020-12-31T00:00:00,1.71,1.205780029296875,29.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Chale,2021-12-31T00:00:00,1.26,1.33809232711792,6.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Conceicao_de_Ipanema,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Conceicao_de_Ipanema,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Conceicao_de_Ipanema,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Conceicao_de_Ipanema,2015-12-31T00:00:00,1.14,1.1293034553527832,0.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Conceicao_de_Ipanema,2016-12-31T00:00:00,1.44,1.1484469175338745,20.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Conceicao_de_Ipanema,2017-12-31T00:00:00,1.44,1.2396584749221802,13.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Conceicao_de_Ipanema,2018-12-31T00:00:00,1.56,1.485152006149292,4.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Conceicao_de_Ipanema,2019-12-31T00:00:00,1.19,1.476125717163086,24.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Conceicao_de_Ipanema,2020-12-31T00:00:00,1.5,1.5014357566833496,0.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Conceicao_de_Ipanema,2021-12-31T00:00:00,1.29,1.3397836685180664,3.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Datas,2012-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Datas,2013-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Datas,2014-12-31T00:00:00,0.79,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Datas,2015-12-31T00:00:00,1.4,0.9410416483879089,32.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Datas,2016-12-31T00:00:00,1.2,1.0819296836853027,9.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Datas,2017-12-31T00:00:00,1.5,1.109984040260315,26.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Datas,2018-12-31T00:00:00,3.0,1.4752955436706543,50.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Datas,2019-12-31T00:00:00,2.0,1.6083893775939941,19.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Datas,2020-12-31T00:00:00,2.0,2.987870931625366,49.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Datas,2021-12-31T00:00:00,1.0,2.1271328926086426,112.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Divino,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Divino,2013-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Divino,2014-12-31T00:00:00,0.89,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Divino,2015-12-31T00:00:00,1.2,1.121305227279663,6.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Divino,2016-12-31T00:00:00,1.2,1.2667515277862549,5.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Divino,2017-12-31T00:00:00,1.19,1.1402419805526733,4.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Divino,2018-12-31T00:00:00,1.32,1.2048673629760742,8.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Divino,2019-12-31T00:00:00,1.08,1.2228400707244873,13.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Divino,2020-12-31T00:00:00,1.8,1.3035650253295898,27.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Divino,2021-12-31T00:00:00,1.08,1.2533149719238281,16.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Durande,2012-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Durande,2013-12-31T00:00:00,2.22,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Durande,2014-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Durande,2015-12-31T00:00:00,1.68,1.7209477424621582,2.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Durande,2016-12-31T00:00:00,1.8,1.776986837387085,1.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Durande,2017-12-31T00:00:00,1.33,1.6688991785049438,25.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Durande,2018-12-31T00:00:00,2.1,1.7826333045959473,15.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Durande,2019-12-31T00:00:00,1.32,1.6504302024841309,25.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Durande,2020-12-31T00:00:00,2.4,1.6505839824676514,31.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Durande,2021-12-31T00:00:00,1.32,1.6864428520202637,27.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Entre_Folhas,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Entre_Folhas,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Entre_Folhas,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Entre_Folhas,2015-12-31T00:00:00,1.0,1.006670355796814,0.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Entre_Folhas,2016-12-31T00:00:00,1.2,1.0847150087356567,9.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Entre_Folhas,2017-12-31T00:00:00,0.86,1.09815514087677,27.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Entre_Folhas,2018-12-31T00:00:00,1.2,1.1291033029556274,5.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Entre_Folhas,2019-12-31T00:00:00,0.84,1.060256004333496,26.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Entre_Folhas,2020-12-31T00:00:00,1.26,1.0887681245803833,13.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Entre_Folhas,2021-12-31T00:00:00,0.84,1.041939377784729,24.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ervalia,2012-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ervalia,2013-12-31T00:00:00,1.92,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ervalia,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ervalia,2015-12-31T00:00:00,1.5,1.5091276168823242,0.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ervalia,2016-12-31T00:00:00,1.32,1.585615634918213,20.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ervalia,2017-12-31T00:00:00,1.36,1.2805759906768799,5.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ervalia,2018-12-31T00:00:00,1.8,1.4431400299072266,19.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ervalia,2019-12-31T00:00:00,1.2,1.4326776266098022,19.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ervalia,2020-12-31T00:00:00,1.8,1.591484785079956,11.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ervalia,2021-12-31T00:00:00,1.08,1.4895100593566895,37.92,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Espera_Feliz,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Espera_Feliz,2013-12-31T00:00:00,1.92,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Espera_Feliz,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Espera_Feliz,2015-12-31T00:00:00,1.38,1.304964542388916,5.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Espera_Feliz,2016-12-31T00:00:00,1.68,1.6242899894714355,3.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Espera_Feliz,2017-12-31T00:00:00,1.21,1.435280442237854,18.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Espera_Feliz,2018-12-31T00:00:00,1.92,1.7611448764801025,8.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Espera_Feliz,2019-12-31T00:00:00,0.9,1.5888454914093018,76.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Espera_Feliz,2020-12-31T00:00:00,2.04,1.7091717720031738,16.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Espera_Feliz,2021-12-31T00:00:00,0.78,1.3050482273101807,67.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Faria_Lemos,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Faria_Lemos,2013-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Faria_Lemos,2014-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Faria_Lemos,2015-12-31T00:00:00,1.32,1.0687508583068848,19.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Faria_Lemos,2016-12-31T00:00:00,1.38,1.1363308429718018,17.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Faria_Lemos,2017-12-31T00:00:00,0.97,1.3201696872711182,36.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Faria_Lemos,2018-12-31T00:00:00,1.2,1.448876142501831,20.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Faria_Lemos,2019-12-31T00:00:00,1.08,1.1209843158721924,3.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Faria_Lemos,2020-12-31T00:00:00,1.44,1.142256259918213,20.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Faria_Lemos,2021-12-31T00:00:00,0.72,1.177722454071045,63.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ferros,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ferros,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ferros,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ferros,2015-12-31T00:00:00,1.08,1.3351079225540161,23.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ferros,2016-12-31T00:00:00,1.2,1.2475485801696777,3.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ferros,2017-12-31T00:00:00,0.59,1.1469227075576782,94.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ferros,2018-12-31T00:00:00,0.84,1.139514684677124,35.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ferros,2019-12-31T00:00:00,0.84,0.9412122964859009,12.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ferros,2020-12-31T00:00:00,1.2,0.7799606323242188,35.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ferros,2021-12-31T00:00:00,1.21,0.8260859847068787,31.73,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Franciscopolis,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Franciscopolis,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Franciscopolis,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Franciscopolis,2015-12-31T00:00:00,1.08,1.0799922943115234,0.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Franciscopolis,2016-12-31T00:00:00,1.2,0.9682500958442688,19.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Franciscopolis,2017-12-31T00:00:00,0.52,1.0554802417755127,102.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Franciscopolis,2018-12-31T00:00:00,1.8,1.0936341285705566,39.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Franciscopolis,2019-12-31T00:00:00,3.0,1.1754478216171265,60.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Franciscopolis,2020-12-31T00:00:00,1.8,3.008017063140869,67.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Franciscopolis,2021-12-31T00:00:00,1.2,2.119607925415039,76.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Itanhomi,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Itanhomi,2013-12-31T00:00:00,1.35,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Itanhomi,2014-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Itanhomi,2015-12-31T00:00:00,1.2,1.1821459531784058,1.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Itanhomi,2016-12-31T00:00:00,1.14,1.1905320882797241,4.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Itanhomi,2017-12-31T00:00:00,1.0,1.1254411935806274,12.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Itanhomi,2018-12-31T00:00:00,1.62,1.2184659242630005,24.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Itanhomi,2019-12-31T00:00:00,0.96,1.2031867504119873,25.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Itanhomi,2020-12-31T00:00:00,1.26,1.6683528423309326,32.41,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Itanhomi,2021-12-31T00:00:00,0.96,1.164765477180481,21.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lagoa_Formosa,2012-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lagoa_Formosa,2013-12-31T00:00:00,2.4,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lagoa_Formosa,2014-12-31T00:00:00,2.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lagoa_Formosa,2015-12-31T00:00:00,2.4,2.230034351348877,7.08,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lagoa_Formosa,2016-12-31T00:00:00,1.8,2.298057794570923,27.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lagoa_Formosa,2017-12-31T00:00:00,1.92,2.028555393218994,5.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lagoa_Formosa,2018-12-31T00:00:00,1.92,2.059049129486084,7.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lagoa_Formosa,2019-12-31T00:00:00,2.25,1.8858757019042969,16.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lagoa_Formosa,2020-12-31T00:00:00,2.55,2.3093786239624023,9.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lagoa_Formosa,2021-12-31T00:00:00,1.48,2.2017898559570312,48.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lagoa_Grande,2012-12-31T00:00:00,1.43,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lagoa_Grande,2013-12-31T00:00:00,3.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lagoa_Grande,2014-12-31T00:00:00,1.79,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lagoa_Grande,2015-12-31T00:00:00,2.38,2.624789237976074,10.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lagoa_Grande,2016-12-31T00:00:00,2.1,2.497093677520752,18.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lagoa_Grande,2017-12-31T00:00:00,2.1,1.9244548082351685,8.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lagoa_Grande,2018-12-31T00:00:00,2.1,2.1831417083740234,3.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lagoa_Grande,2019-12-31T00:00:00,1.2,2.101254463195801,75.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lagoa_Grande,2020-12-31T00:00:00,2.4,2.054241180419922,14.41,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lagoa_Grande,2021-12-31T00:00:00,0.6,1.634069561958313,172.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lajinha,2012-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lajinha,2013-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lajinha,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lajinha,2015-12-31T00:00:00,1.44,1.336823582649231,7.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lajinha,2016-12-31T00:00:00,1.68,1.3564128875732422,19.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lajinha,2017-12-31T00:00:00,1.04,1.4085593223571777,35.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lajinha,2018-12-31T00:00:00,1.68,1.7195179462432861,2.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lajinha,2019-12-31T00:00:00,1.06,1.3769398927688599,29.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lajinha,2020-12-31T00:00:00,1.92,1.3583756685256958,29.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lajinha,2021-12-31T00:00:00,1.26,1.4054718017578125,11.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Luisburgo,2012-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Luisburgo,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Luisburgo,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Luisburgo,2015-12-31T00:00:00,1.5,1.2816816568374634,14.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Luisburgo,2016-12-31T00:00:00,1.32,1.4453275203704834,9.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Luisburgo,2017-12-31T00:00:00,1.53,1.380138874053955,9.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Luisburgo,2018-12-31T00:00:00,1.8,1.5717853307724,12.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Luisburgo,2019-12-31T00:00:00,1.64,1.4840078353881836,9.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Luisburgo,2020-12-31T00:00:00,2.1,1.7137432098388672,18.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Luisburgo,2021-12-31T00:00:00,1.38,1.7922532558441162,29.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Malacacheta,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Malacacheta,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Malacacheta,2014-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Malacacheta,2015-12-31T00:00:00,1.5,1.4518135786056519,3.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Malacacheta,2016-12-31T00:00:00,1.32,1.4205780029296875,7.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Malacacheta,2017-12-31T00:00:00,1.37,1.4002838134765625,2.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Malacacheta,2018-12-31T00:00:00,1.8,1.400217056274414,22.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Malacacheta,2019-12-31T00:00:00,1.5,1.4917937517166138,0.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Malacacheta,2020-12-31T00:00:00,1.8,1.7983816862106323,0.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Malacacheta,2021-12-31T00:00:00,1.8,1.6786441802978516,6.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Manhuacu,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Manhuacu,2013-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Manhuacu,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Manhuacu,2015-12-31T00:00:00,1.38,1.1670023202896118,15.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Manhuacu,2016-12-31T00:00:00,1.26,1.2808144092559814,1.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Manhuacu,2017-12-31T00:00:00,1.43,1.2070002555847168,15.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Manhuacu,2018-12-31T00:00:00,1.44,1.4238677024841309,1.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Manhuacu,2019-12-31T00:00:00,1.02,1.3422026634216309,31.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Manhuacu,2020-12-31T00:00:00,1.68,1.3834640979766846,17.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Manhuacu,2021-12-31T00:00:00,0.9,1.2697558403015137,41.08,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Manhumirim,2012-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Manhumirim,2013-12-31T00:00:00,1.92,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Manhumirim,2014-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Manhumirim,2015-12-31T00:00:00,1.8,1.5618829727172852,13.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Manhumirim,2016-12-31T00:00:00,1.32,1.733459234237671,31.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Manhumirim,2017-12-31T00:00:00,1.62,1.4517087936401367,10.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Manhumirim,2018-12-31T00:00:00,1.56,1.8045463562011719,15.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Manhumirim,2019-12-31T00:00:00,1.2,1.4473930597305298,20.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Manhumirim,2020-12-31T00:00:00,1.68,1.523684024810791,9.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Manhumirim,2021-12-31T00:00:00,1.2,1.4020969867706299,16.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Matipo,2012-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Matipo,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Matipo,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Matipo,2015-12-31T00:00:00,1.44,1.2593393325805664,12.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Matipo,2016-12-31T00:00:00,1.32,1.3772706985473633,4.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Matipo,2017-12-31T00:00:00,0.9,1.3253083229064941,47.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Matipo,2018-12-31T00:00:00,1.32,1.5130388736724854,14.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Matipo,2019-12-31T00:00:00,1.32,1.0968409776687622,16.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Matipo,2020-12-31T00:00:00,1.56,1.2880439758300781,17.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Matipo,2021-12-31T00:00:00,1.08,1.3799493312835693,27.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Mirai,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Mirai,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Mirai,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Mirai,2015-12-31T00:00:00,0.84,1.0884480476379395,29.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Mirai,2016-12-31T00:00:00,1.2,0.9987924098968506,16.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Mirai,2017-12-31T00:00:00,1.02,1.0289649963378906,0.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Mirai,2018-12-31T00:00:00,1.2,1.2090457677841187,0.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Mirai,2019-12-31T00:00:00,1.2,1.147701621055603,4.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Mirai,2020-12-31T00:00:00,1.5,1.1747925281524658,21.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Mirai,2021-12-31T00:00:00,1.02,1.242150068283081,21.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Muriae,2012-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Muriae,2013-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Muriae,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Muriae,2015-12-31T00:00:00,1.08,1.1949434280395508,10.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Muriae,2016-12-31T00:00:00,1.32,1.1190029382705688,15.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Muriae,2017-12-31T00:00:00,1.44,1.096616268157959,23.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Muriae,2018-12-31T00:00:00,1.44,1.5780916213989258,9.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Muriae,2019-12-31T00:00:00,1.02,1.395987629890442,36.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Muriae,2020-12-31T00:00:00,1.56,1.3668444156646729,12.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Muriae,2021-12-31T00:00:00,0.9,1.241121768951416,37.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Mutum,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Mutum,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Mutum,2014-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Mutum,2015-12-31T00:00:00,1.15,1.2894521951675415,12.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Mutum,2016-12-31T00:00:00,1.26,1.293607473373413,2.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Mutum,2017-12-31T00:00:00,1.45,1.1838213205337524,18.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Mutum,2018-12-31T00:00:00,1.5,1.3934295177459717,7.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Mutum,2019-12-31T00:00:00,1.44,1.3880882263183594,3.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Mutum,2020-12-31T00:00:00,1.65,1.4705787897109985,10.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Mutum,2021-12-31T00:00:00,1.32,1.5073537826538086,14.19,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Nova_Belem,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Nova_Belem,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Nova_Belem,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Nova_Belem,2015-12-31T00:00:00,0.9,0.4690462350845337,47.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Nova_Belem,2016-12-31T00:00:00,1.2,1.0596336126327515,11.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Nova_Belem,2017-12-31T00:00:00,0.48,0.9770380854606628,103.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Nova_Belem,2018-12-31T00:00:00,1.2,0.9950833320617676,17.08,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Nova_Belem,2019-12-31T00:00:00,0.9,0.8266740441322327,8.15,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Nova_Belem,2020-12-31T00:00:00,1.1,1.1036456823349,0.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Nova_Belem,2021-12-31T00:00:00,1.0,1.046220064163208,4.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Orizania,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Orizania,2013-12-31T00:00:00,1.68,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Orizania,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Orizania,2015-12-31T00:00:00,1.2,1.2233853340148926,1.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Orizania,2016-12-31T00:00:00,1.8,1.3380720615386963,25.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Orizania,2017-12-31T00:00:00,1.47,1.4453883171081543,1.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Orizania,2018-12-31T00:00:00,1.56,1.839501976966858,17.92,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Orizania,2019-12-31T00:00:00,1.38,1.5742870569229126,14.08,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Orizania,2020-12-31T00:00:00,1.68,1.534847617149353,8.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Orizania,2021-12-31T00:00:00,1.08,1.496212363243103,38.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Patis,2012-12-31T00:00:00,2.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Patis,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Patis,2014-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Patis,2015-12-31T00:00:00,2.8,1.2974581718444824,53.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Patis,2016-12-31T00:00:00,1.19,1.9171457290649414,61.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Patis,2017-12-31T00:00:00,1.8,1.8198926448822021,1.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Patis,2018-12-31T00:00:00,3.6,2.228989362716675,38.08,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Patis,2019-12-31T00:00:00,3.0,1.763670563697815,41.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Patis,2020-12-31T00:00:00,3.6,3.708110809326172,3.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Patis,2021-12-31T00:00:00,2.11,3.304326057434082,56.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ponte_Nova,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ponte_Nova,2013-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ponte_Nova,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ponte_Nova,2015-12-31T00:00:00,1.26,1.1930254697799683,5.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ponte_Nova,2016-12-31T00:00:00,1.2,1.227864146232605,2.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ponte_Nova,2017-12-31T00:00:00,1.17,1.1741808652877808,0.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ponte_Nova,2018-12-31T00:00:00,1.5,1.2617151737213135,15.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ponte_Nova,2019-12-31T00:00:00,1.17,1.3019057512283325,11.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ponte_Nova,2020-12-31T00:00:00,1.33,1.492034912109375,12.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ponte_Nova,2021-12-31T00:00:00,1.2,1.2972166538238525,8.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Porto_Firme,2012-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Porto_Firme,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Porto_Firme,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Porto_Firme,2015-12-31T00:00:00,1.26,1.097520112991333,12.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Porto_Firme,2016-12-31T00:00:00,1.2,1.18722403049469,1.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Porto_Firme,2017-12-31T00:00:00,1.2,1.1633360385894775,3.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Porto_Firme,2018-12-31T00:00:00,1.2,1.2336478233337402,2.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Porto_Firme,2019-12-31T00:00:00,1.12,1.6224051713943481,44.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Porto_Firme,2020-12-31T00:00:00,1.56,1.2140603065490723,22.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Porto_Firme,2021-12-31T00:00:00,1.32,1.274340033531189,3.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Raul_Soares,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Raul_Soares,2013-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Raul_Soares,2014-12-31T00:00:00,0.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Raul_Soares,2015-12-31T00:00:00,1.08,0.9921706914901733,8.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Raul_Soares,2016-12-31T00:00:00,1.08,0.9888483285903931,8.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Raul_Soares,2017-12-31T00:00:00,0.86,1.0021777153015137,16.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Raul_Soares,2018-12-31T00:00:00,1.2,1.1425235271453857,4.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Raul_Soares,2019-12-31T00:00:00,1.2,1.012883186340332,15.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Raul_Soares,2020-12-31T00:00:00,1.32,1.1881338357925415,9.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Raul_Soares,2021-12-31T00:00:00,1.32,1.2122207880020142,8.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Reduto,2012-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Reduto,2013-12-31T00:00:00,1.62,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Reduto,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Reduto,2015-12-31T00:00:00,1.38,1.297832727432251,5.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Reduto,2016-12-31T00:00:00,1.44,1.3973878622055054,2.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Reduto,2017-12-31T00:00:00,1.26,1.3290109634399414,5.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Reduto,2018-12-31T00:00:00,1.8,1.4361345767974854,20.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Reduto,2019-12-31T00:00:00,1.26,1.4139955043792725,12.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Reduto,2020-12-31T00:00:00,1.8,1.5489243268966675,13.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Reduto,2021-12-31T00:00:00,1.2,1.5000975131988525,25.01,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Rio_Pardo_de_Minas,2012-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Rio_Pardo_de_Minas,2013-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Rio_Pardo_de_Minas,2014-12-31T00:00:00,2.65,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Rio_Pardo_de_Minas,2015-12-31T00:00:00,2.28,2.0290753841400146,11.01,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Rio_Pardo_de_Minas,2016-12-31T00:00:00,2.46,2.500440835952759,1.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Rio_Pardo_de_Minas,2017-12-31T00:00:00,2.18,2.45465087890625,12.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Rio_Pardo_de_Minas,2018-12-31T00:00:00,2.63,2.3765482902526855,9.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Rio_Pardo_de_Minas,2019-12-31T00:00:00,2.75,2.4223623275756836,11.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Rio_Pardo_de_Minas,2020-12-31T00:00:00,3.45,2.8308029174804688,17.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Rio_Pardo_de_Minas,2021-12-31T00:00:00,2.76,2.841219186782837,2.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Rosario_da_Limeira,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Rosario_da_Limeira,2013-12-31T00:00:00,1.54,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Rosario_da_Limeira,2014-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Rosario_da_Limeira,2015-12-31T00:00:00,1.14,1.3860342502593994,21.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Rosario_da_Limeira,2016-12-31T00:00:00,1.26,1.3650181293487549,8.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Rosario_da_Limeira,2017-12-31T00:00:00,0.78,1.282175898551941,64.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Rosario_da_Limeira,2018-12-31T00:00:00,1.2,1.2527886629104614,4.4,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Rosario_da_Limeira,2019-12-31T00:00:00,1.2,1.0646469593048096,11.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Rosario_da_Limeira,2020-12-31T00:00:00,1.5,1.1429760456085205,23.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Rosario_da_Limeira,2021-12-31T00:00:00,0.9,1.223042607307434,35.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Barbara_do_Leste,2012-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Barbara_do_Leste,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Barbara_do_Leste,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Barbara_do_Leste,2015-12-31T00:00:00,1.08,1.0474591255187988,3.01,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Barbara_do_Leste,2016-12-31T00:00:00,1.02,1.107073426246643,8.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Barbara_do_Leste,2017-12-31T00:00:00,0.91,1.0214848518371582,12.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Barbara_do_Leste,2018-12-31T00:00:00,1.74,1.076761245727539,38.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Barbara_do_Leste,2019-12-31T00:00:00,1.14,0.9987865686416626,12.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Barbara_do_Leste,2020-12-31T00:00:00,1.44,1.4618600606918335,1.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Barbara_do_Leste,2021-12-31T00:00:00,1.32,1.3437443971633911,1.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Margarida,2012-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Margarida,2013-12-31T00:00:00,1.68,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Margarida,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Margarida,2015-12-31T00:00:00,1.56,1.3825938701629639,11.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Margarida,2016-12-31T00:00:00,1.32,1.4629946947097778,10.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Margarida,2017-12-31T00:00:00,1.2,1.3926289081573486,16.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Margarida,2018-12-31T00:00:00,1.68,1.5066707134246826,10.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Margarida,2019-12-31T00:00:00,1.2,1.3111413717269897,9.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Margarida,2020-12-31T00:00:00,1.8,1.511702060699463,16.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Margarida,2021-12-31T00:00:00,0.9,1.5280613899230957,69.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Rita_de_Minas,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Rita_de_Minas,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Rita_de_Minas,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Rita_de_Minas,2015-12-31T00:00:00,1.2,1.0021830797195435,16.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Rita_de_Minas,2016-12-31T00:00:00,1.08,1.1404482126235962,5.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Rita_de_Minas,2017-12-31T00:00:00,1.25,1.0525736808776855,15.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Rita_de_Minas,2018-12-31T00:00:00,1.5,1.2415521144866943,17.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Rita_de_Minas,2019-12-31T00:00:00,1.26,1.1717911958694458,7.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Rita_de_Minas,2020-12-31T00:00:00,1.5,1.4253069162368774,4.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Rita_de_Minas,2021-12-31T00:00:00,1.2,1.3694627285003662,14.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santana_do_Manhuacu,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santana_do_Manhuacu,2013-12-31T00:00:00,1.62,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santana_do_Manhuacu,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santana_do_Manhuacu,2015-12-31T00:00:00,1.44,1.422018051147461,1.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santana_do_Manhuacu,2016-12-31T00:00:00,1.32,1.4415923357009888,9.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santana_do_Manhuacu,2017-12-31T00:00:00,1.28,1.3359169960021973,4.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santana_do_Manhuacu,2018-12-31T00:00:00,1.5,1.4226332902908325,5.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santana_do_Manhuacu,2019-12-31T00:00:00,1.5,1.3383822441101074,10.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santana_do_Manhuacu,2020-12-31T00:00:00,1.8,1.4819557666778564,17.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santana_do_Manhuacu,2021-12-31T00:00:00,1.32,1.5393531322479248,16.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Francisco_do_Gloria,2012-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Francisco_do_Gloria,2013-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Francisco_do_Gloria,2014-12-31T00:00:00,1.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Francisco_do_Gloria,2015-12-31T00:00:00,1.32,1.1794400215148926,10.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Francisco_do_Gloria,2016-12-31T00:00:00,1.5,1.2323031425476074,17.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Francisco_do_Gloria,2017-12-31T00:00:00,0.8,1.3993122577667236,74.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Francisco_do_Gloria,2018-12-31T00:00:00,1.32,1.6145710945129395,22.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Francisco_do_Gloria,2019-12-31T00:00:00,0.9,1.1102495193481445,23.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Francisco_do_Gloria,2020-12-31T00:00:00,1.68,1.1600626707077026,30.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Francisco_do_Gloria,2021-12-31T00:00:00,0.78,1.1240953207015991,44.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Joao_do_Manhuacu,2012-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Joao_do_Manhuacu,2013-12-31T00:00:00,1.74,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Joao_do_Manhuacu,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Joao_do_Manhuacu,2015-12-31T00:00:00,1.32,1.310314416885376,0.73,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Joao_do_Manhuacu,2016-12-31T00:00:00,1.32,1.3597819805145264,3.01,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Joao_do_Manhuacu,2017-12-31T00:00:00,1.7,1.2669312953948975,25.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Joao_do_Manhuacu,2018-12-31T00:00:00,1.62,1.7017450332641602,5.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Joao_do_Manhuacu,2019-12-31T00:00:00,1.32,1.4760979413986206,11.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Joao_do_Manhuacu,2020-12-31T00:00:00,1.8,1.6123831272125244,10.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Joao_do_Manhuacu,2021-12-31T00:00:00,0.9,1.5622810125350952,73.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Jose_do_Mantimento,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Jose_do_Mantimento,2013-12-31T00:00:00,1.42,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Jose_do_Mantimento,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Jose_do_Mantimento,2015-12-31T00:00:00,1.44,1.2762528657913208,11.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Jose_do_Mantimento,2016-12-31T00:00:00,1.2,1.3732478618621826,14.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Jose_do_Mantimento,2017-12-31T00:00:00,1.2,1.3189412355422974,9.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Jose_do_Mantimento,2018-12-31T00:00:00,1.44,1.4013352394104004,2.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Jose_do_Mantimento,2019-12-31T00:00:00,1.56,1.261838436126709,19.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Jose_do_Mantimento,2020-12-31T00:00:00,1.8,1.4284985065460205,20.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Jose_do_Mantimento,2021-12-31T00:00:00,1.5,1.5976694822311401,6.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sericita,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sericita,2013-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sericita,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sericita,2015-12-31T00:00:00,1.2,1.237534999847412,3.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sericita,2016-12-31T00:00:00,1.2,1.2620532512664795,5.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sericita,2017-12-31T00:00:00,1.12,1.1672868728637695,4.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sericita,2018-12-31T00:00:00,1.8,1.244162678718567,30.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sericita,2019-12-31T00:00:00,0.9,1.2904108762741089,43.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sericita,2020-12-31T00:00:00,2.52,1.7667454481124878,29.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sericita,2021-12-31T00:00:00,0.9,1.741572618484497,93.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Setubinha,2012-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Setubinha,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Setubinha,2014-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Setubinha,2015-12-31T00:00:00,0.9,0.7585249543190002,15.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Setubinha,2016-12-31T00:00:00,1.5,0.8100047707557678,46.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Setubinha,2017-12-31T00:00:00,0.76,1.0919368267059326,43.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Setubinha,2018-12-31T00:00:00,0.9,1.1030247211456299,22.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Setubinha,2019-12-31T00:00:00,0.9,1.0978598594665527,21.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Setubinha,2020-12-31T00:00:00,1.0,0.9079166650772095,9.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Setubinha,2021-12-31T00:00:00,0.93,0.9231441617012024,0.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Teofilo_Otoni,2012-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Teofilo_Otoni,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Teofilo_Otoni,2014-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Teofilo_Otoni,2015-12-31T00:00:00,0.9,0.6662179231643677,25.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Teofilo_Otoni,2016-12-31T00:00:00,0.9,0.7503228783607483,16.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Teofilo_Otoni,2017-12-31T00:00:00,0.67,0.7768339514732361,15.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Teofilo_Otoni,2018-12-31T00:00:00,0.91,0.8594020009040833,5.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Teofilo_Otoni,2019-12-31T00:00:00,0.91,0.8130322694778442,10.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Teofilo_Otoni,2020-12-31T00:00:00,1.09,0.9525220990180969,12.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Teofilo_Otoni,2021-12-31T00:00:00,0.68,0.939017653465271,38.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Tombos,2012-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Tombos,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Tombos,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Tombos,2015-12-31T00:00:00,1.2,1.0937355756759644,8.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Tombos,2016-12-31T00:00:00,0.96,1.1596927642822266,20.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Tombos,2017-12-31T00:00:00,0.99,1.1488323211669922,16.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Tombos,2018-12-31T00:00:00,1.44,1.174555778503418,18.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Tombos,2019-12-31T00:00:00,0.96,1.0591602325439453,10.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Tombos,2020-12-31T00:00:00,1.5,1.2156964540481567,18.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Tombos,2021-12-31T00:00:00,0.85,1.1618398427963257,36.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ubaporanga,2012-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ubaporanga,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ubaporanga,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ubaporanga,2015-12-31T00:00:00,1.2,1.0696377754211426,10.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ubaporanga,2016-12-31T00:00:00,0.96,1.2417778968811035,29.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ubaporanga,2017-12-31T00:00:00,1.03,1.0360292196273804,0.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ubaporanga,2018-12-31T00:00:00,1.5,1.1734575033187866,21.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ubaporanga,2019-12-31T00:00:00,1.32,1.0800502300262451,18.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ubaporanga,2020-12-31T00:00:00,1.62,1.4018521308898926,13.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ubaporanga,2021-12-31T00:00:00,1.32,1.4150314331054688,7.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Urucuia,2012-12-31T00:00:00,2.4,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Urucuia,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Urucuia,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Urucuia,2015-12-31T00:00:00,1.8,1.6179029941558838,10.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Urucuia,2016-12-31T00:00:00,2.4,1.7790961265563965,25.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Urucuia,2017-12-31T00:00:00,1.8,1.718252420425415,4.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Urucuia,2018-12-31T00:00:00,2.4,2.0340633392333984,15.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Urucuia,2019-12-31T00:00:00,2.4,2.3148293495178223,3.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Urucuia,2020-12-31T00:00:00,2.4,2.4207754135131836,0.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Urucuia,2021-12-31T00:00:00,1.8,2.400212287902832,33.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vermelho_Novo,2012-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vermelho_Novo,2013-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vermelho_Novo,2014-12-31T00:00:00,0.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vermelho_Novo,2015-12-31T00:00:00,1.2,0.9011738300323486,24.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vermelho_Novo,2016-12-31T00:00:00,1.2,1.0205684900283813,14.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vermelho_Novo,2017-12-31T00:00:00,1.08,1.0679267644882202,1.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vermelho_Novo,2018-12-31T00:00:00,1.32,1.242252230644226,5.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vermelho_Novo,2019-12-31T00:00:00,1.08,1.1561387777328491,7.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vermelho_Novo,2020-12-31T00:00:00,1.32,1.2181824445724487,7.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vermelho_Novo,2021-12-31T00:00:00,0.96,1.1914170980453491,24.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vicosa,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vicosa,2013-12-31T00:00:00,1.62,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vicosa,2014-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vicosa,2015-12-31T00:00:00,1.44,1.4879425764083862,3.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vicosa,2016-12-31T00:00:00,1.16,1.4244778156280518,22.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vicosa,2017-12-31T00:00:00,1.49,1.274444341659546,14.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vicosa,2018-12-31T00:00:00,1.56,1.4919699430465698,4.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vicosa,2019-12-31T00:00:00,0.84,1.4127745628356934,68.19,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vicosa,2020-12-31T00:00:00,1.8,1.6648054122924805,7.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vicosa,2021-12-31T00:00:00,0.9,1.3051860332489014,45.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vieiras,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vieiras,2013-12-31T00:00:00,1.81,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vieiras,2014-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vieiras,2015-12-31T00:00:00,1.32,1.4561539888381958,10.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vieiras,2016-12-31T00:00:00,1.2,1.5970399379730225,33.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vieiras,2017-12-31T00:00:00,1.13,1.5590298175811768,37.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vieiras,2018-12-31T00:00:00,1.26,1.3089886903762817,3.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vieiras,2019-12-31T00:00:00,1.02,1.1905666589736938,16.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vieiras,2020-12-31T00:00:00,1.8,1.1855759620666504,34.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vieiras,2021-12-31T00:00:00,0.78,1.2130924463272095,55.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Virginopolis,2012-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Virginopolis,2013-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Virginopolis,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Virginopolis,2015-12-31T00:00:00,1.32,1.2212132215499878,7.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Virginopolis,2016-12-31T00:00:00,1.0,1.2679107189178467,26.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Virginopolis,2017-12-31T00:00:00,1.37,1.1644465923309326,15.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Virginopolis,2018-12-31T00:00:00,1.5,1.3526620864868164,9.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Virginopolis,2019-12-31T00:00:00,1.51,1.2905895709991455,14.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Virginopolis,2020-12-31T00:00:00,1.63,1.5251314640045166,6.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Virginopolis,2021-12-31T00:00:00,1.2,1.5085989236831665,25.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Abadia_dos_Dourados,2022-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Agua_Boa,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Aguas_Vermelhas,2022-12-31T00:00:00,3.0,3,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Alto_Caparao,2022-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Araponga,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Areado,2022-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ataleia,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Bom_Jesus_do_Galho,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caiana,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Cajuri,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Canaa,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caparao,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caputira,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Carai,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Carangola,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caratinga,2022-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Central_de_Minas,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Chale,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Conceicao_de_Ipanema,2022-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Datas,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Divino,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Durande,2022-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Entre_Folhas,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ervalia,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Espera_Feliz,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Faria_Lemos,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ferros,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Franciscopolis,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Itanhomi,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lagoa_Formosa,2022-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lagoa_Grande,2022-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lajinha,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Luisburgo,2022-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Malacacheta,2022-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Manhuacu,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Manhumirim,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Matipo,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Mirai,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Muriae,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Mutum,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Nova_Belem,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Orizania,2022-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Patis,2022-12-31T00:00:00,2.0,3,50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ponte_Nova,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Porto_Firme,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Raul_Soares,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Reduto,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Rio_Pardo_de_Minas,2022-12-31T00:00:00,3.0,3,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Rosario_da_Limeira,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Barbara_do_Leste,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Margarida,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Rita_de_Minas,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santana_do_Manhuacu,2022-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Francisco_do_Gloria,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Joao_do_Manhuacu,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Jose_do_Mantimento,2022-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sericita,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Setubinha,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Teofilo_Otoni,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Tombos,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ubaporanga,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Urucuia,2022-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vermelho_Novo,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vicosa,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vieiras,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Virginopolis,2022-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Abadia_dos_Dourados,2023-12-31T00:00:00,2.103030303030303,2.1189417839050293,0.76,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Agua_Boa,2023-12-31T00:00:00,1.213636363636364,0.7344823479652405,-39.48,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Aguas_Vermelhas,2023-12-31T00:00:00,3.0,3.117417335510254,3.91,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Alto_Caparao,2023-12-31T00:00:00,1.32,1.3567677736282349,2.79,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Araponga,2023-12-31T00:00:00,1.5,1.344387412071228,-10.37,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Areado,2023-12-31T00:00:00,1.590034364261168,1.659938097000122,4.4,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ataleia,2023-12-31T00:00:00,0.6833333333333333,0.7446507215499878,8.97,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Bom_Jesus_do_Galho,2023-12-31T00:00:00,1.2003192338387871,0.9852505326271057,-17.92,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caiana,2023-12-31T00:00:00,1.08,0.9800719618797302,-9.25,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Cajuri,2023-12-31T00:00:00,0.8200000000000001,1.2889586687088013,57.19,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Canaa,2023-12-31T00:00:00,1.560135135135135,1.3995541334152222,-10.29,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caparao,2023-12-31T00:00:00,1.32,1.2244280576705933,-7.24,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caputira,2023-12-31T00:00:00,1.380065005417118,1.457371473312378,5.6,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Carai,2023-12-31T00:00:00,1.2,1.2460585832595825,3.84,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Carangola,2023-12-31T00:00:00,1.140118343195266,1.1330056190490723,-0.62,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Caratinga,2023-12-31T00:00:00,1.3799999999999997,1.487014651298523,7.75,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Central_de_Minas,2023-12-31T00:00:00,0.8333333333333335,0.7498183250427246,-10.02,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Chale,2023-12-31T00:00:00,1.3799999999999997,1.4189033508300781,2.82,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Conceicao_de_Ipanema,2023-12-31T00:00:00,1.5,1.3845564126968384,-7.7,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Datas,2023-12-31T00:00:00,0.6666666666666667,1.0686347484588623,60.3,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Divino,2023-12-31T00:00:00,1.02,1.2203038930892944,19.64,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Durande,2023-12-31T00:00:00,1.3799999999999997,1.600773572921753,16.0,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Entre_Folhas,2023-12-31T00:00:00,1.3210526315789468,1.0416823625564575,-21.15,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ervalia,2023-12-31T00:00:00,1.380044843049327,1.3045058250427246,-5.47,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Espera_Feliz,2023-12-31T00:00:00,1.08,1.1111347675323486,2.88,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Faria_Lemos,2023-12-31T00:00:00,1.380152671755725,1.0477421283721924,-24.09,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ferros,2023-12-31T00:00:00,1.17948717948718,1.2068945169448853,2.32,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Franciscopolis,2023-12-31T00:00:00,1.2,1.2964251041412354,8.04,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Itanhomi,2023-12-31T00:00:00,1.078787878787879,1.0637974739074707,-1.39,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lagoa_Formosa,2023-12-31T00:00:00,1.978723404255319,1.9393627643585205,-1.99,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lagoa_Grande,2023-12-31T00:00:00,2.4,1.1196508407592773,-53.35,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Lajinha,2023-12-31T00:00:00,1.4399536768963517,1.3929258584976196,-3.27,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Luisburgo,2023-12-31T00:00:00,1.44,1.525774359703064,5.96,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Malacacheta,2023-12-31T00:00:00,1.619230769230769,1.6419570446014404,1.4,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Manhuacu,2023-12-31T00:00:00,1.2,1.1517635583877563,-4.02,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Manhumirim,2023-12-31T00:00:00,1.44,1.3003807067871094,-9.7,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Matipo,2023-12-31T00:00:00,1.25990675990676,1.2094025611877441,-4.01,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Mirai,2023-12-31T00:00:00,1.08,1.1172236204147339,3.45,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Muriae,2023-12-31T00:00:00,1.057297297297297,1.0947682857513428,3.54,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Mutum,2023-12-31T00:00:00,1.019985196150999,1.2920093536376953,26.67,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Nova_Belem,2023-12-31T00:00:00,0.96,0.9856499433517456,2.67,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Orizania,2023-12-31T00:00:00,1.2,1.2907134294509888,7.56,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Patis,2023-12-31T00:00:00,1.2,2.297328472137451,91.44,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ponte_Nova,2023-12-31T00:00:00,1.333333333333333,1.2447395324707031,-6.64,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Porto_Firme,2023-12-31T00:00:00,1.200764818355641,1.3836677074432373,15.23,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Raul_Soares,2023-12-31T00:00:00,1.5,1.0757591724395752,-28.28,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Reduto,2023-12-31T00:00:00,0.9,1.2812190055847168,42.36,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Rio_Pardo_de_Minas,2023-12-31T00:00:00,2.568224299065421,2.7670822143554688,7.74,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Rosario_da_Limeira,2023-12-31T00:00:00,1.2,1.1025234460830688,-8.12,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Barbara_do_Leste,2023-12-31T00:00:00,1.08,1.1850478649139404,9.73,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Margarida,2023-12-31T00:00:00,1.32,1.1858090162277222,-10.17,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santa_Rita_de_Minas,2023-12-31T00:00:00,1.019930675909879,1.138870120048523,11.66,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Santana_do_Manhuacu,2023-12-31T00:00:00,1.32,1.3255680799484253,0.42,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Francisco_do_Gloria,2023-12-31T00:00:00,1.08,1.033927083015442,-4.27,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Joao_do_Manhuacu,2023-12-31T00:00:00,1.2,1.1410877704620361,-4.91,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sao_Jose_do_Mantimento,2023-12-31T00:00:00,1.5,1.5740382671356201,4.94,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Sericita,2023-12-31T00:00:00,1.26,1.2308298349380493,-2.32,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Setubinha,2023-12-31T00:00:00,1.2,0.9644705057144165,-19.63,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Teofilo_Otoni,2023-12-31T00:00:00,1.2,0.7944514751434326,-33.8,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Tombos,2023-12-31T00:00:00,1.32,1.13027822971344,-14.37,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Ubaporanga,2023-12-31T00:00:00,1.5,1.279886245727539,-14.67,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Urucuia,2023-12-31T00:00:00,2.0994575045207946,1.9251514673233032,-8.3,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vermelho_Novo,2023-12-31T00:00:00,1.5,0.9958831667900085,-33.61,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vicosa,2023-12-31T00:00:00,1.5004329004329,1.1876637935638428,-20.85,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Vieiras,2023-12-31T00:00:00,1.5,1.1852316856384277,-20.98,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 0 (2023),Virginopolis,2023-12-31T00:00:00,1.3258426966292132,1.3590576648712158,2.51,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 0 (2023)
        Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 8
        learning_rate: 0.00011978805707210645
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 64
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 100
        ",2025-09-17T11:14:07
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Abre_Campo,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Abre_Campo,2013-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Abre_Campo,2014-12-31T00:00:00,0.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Abre_Campo,2015-12-31T00:00:00,1.2,0.9611400961875916,19.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Abre_Campo,2016-12-31T00:00:00,1.2,1.055895209312439,12.01,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Abre_Campo,2017-12-31T00:00:00,0.96,1.1382468938827515,18.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Abre_Campo,2018-12-31T00:00:00,1.2,1.2586705684661865,4.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Aimores,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Aimores,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Aimores,2014-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Aimores,2015-12-31T00:00:00,1.08,1.230672836303711,13.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Aimores,2016-12-31T00:00:00,1.2,1.184632658958435,1.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Aimores,2017-12-31T00:00:00,1.23,1.2038969993591309,2.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Aimores,2018-12-31T00:00:00,1.2,1.229393482208252,2.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Alvarenga,2012-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Alvarenga,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Alvarenga,2014-12-31T00:00:00,0.84,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Alvarenga,2015-12-31T00:00:00,0.78,0.8914027214050293,14.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Alvarenga,2016-12-31T00:00:00,0.74,0.8504246473312378,14.92,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Alvarenga,2017-12-31T00:00:00,0.63,0.792937159538269,25.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Alvarenga,2018-12-31T00:00:00,0.72,0.7917912602424622,9.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Amparo_do_Serra,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Amparo_do_Serra,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Amparo_do_Serra,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Amparo_do_Serra,2015-12-31T00:00:00,1.08,0.9662278890609741,10.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Amparo_do_Serra,2016-12-31T00:00:00,1.2,1.072541356086731,10.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Amparo_do_Serra,2017-12-31T00:00:00,1.29,1.0998831987380981,14.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Amparo_do_Serra,2018-12-31T00:00:00,1.5,1.3217504024505615,11.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Angelandia,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Angelandia,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Angelandia,2014-12-31T00:00:00,1.15,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Angelandia,2015-12-31T00:00:00,0.96,1.1459412574768066,19.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Angelandia,2016-12-31T00:00:00,0.96,1.1400116682052612,18.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Angelandia,2017-12-31T00:00:00,0.94,1.0217599868774414,8.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Angelandia,2018-12-31T00:00:00,1.68,0.956246554851532,43.08,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Antonio_Dias,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Antonio_Dias,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Antonio_Dias,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Antonio_Dias,2015-12-31T00:00:00,1.08,1.0937767028808594,1.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Antonio_Dias,2016-12-31T00:00:00,0.9,1.0884078741073608,20.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Antonio_Dias,2017-12-31T00:00:00,1.0,0.9559752345085144,4.4,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Antonio_Dias,2018-12-31T00:00:00,0.8,1.105984091758728,38.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Antonio_Prado_de_Minas,2012-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Antonio_Prado_de_Minas,2013-12-31T00:00:00,0.69,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Antonio_Prado_de_Minas,2014-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Antonio_Prado_de_Minas,2015-12-31T00:00:00,1.08,0.7060739994049072,34.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Antonio_Prado_de_Minas,2016-12-31T00:00:00,0.9,0.8554638624191284,4.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Antonio_Prado_de_Minas,2017-12-31T00:00:00,0.85,0.9156187772750854,7.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Antonio_Prado_de_Minas,2018-12-31T00:00:00,1.2,1.0718961954116821,10.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Aricanduva,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Aricanduva,2013-12-31T00:00:00,0.87,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Aricanduva,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Aricanduva,2015-12-31T00:00:00,1.2,0.8901443481445312,25.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Aricanduva,2016-12-31T00:00:00,1.08,1.0355918407440186,4.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Aricanduva,2017-12-31T00:00:00,0.87,1.0459202527999878,20.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Aricanduva,2018-12-31T00:00:00,0.96,1.118457317352295,16.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bandeira,2012-12-31T00:00:00,0.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bandeira,2013-12-31T00:00:00,0.84,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bandeira,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bandeira,2015-12-31T00:00:00,0.96,0.9393787980079651,2.15,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bandeira,2016-12-31T00:00:00,0.9,1.0223394632339478,13.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bandeira,2017-12-31T00:00:00,0.9,1.0310097932815552,14.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bandeira,2018-12-31T00:00:00,0.9,0.9493612051010132,5.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Berilo,2012-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Berilo,2013-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Berilo,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Berilo,2015-12-31T00:00:00,0.9,0.9403433203697205,4.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Berilo,2016-12-31T00:00:00,0.6,0.9215922355651855,53.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Berilo,2017-12-31T00:00:00,1.0,0.8131765723228455,18.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Berilo,2018-12-31T00:00:00,0.71,0.9063354730606079,27.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Berizal,2012-12-31T00:00:00,0.62,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Berizal,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Berizal,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Berizal,2015-12-31T00:00:00,1.08,0.7771137952804565,28.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Berizal,2016-12-31T00:00:00,3.0,1.005441427230835,66.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Berizal,2017-12-31T00:00:00,0.55,1.3587355613708496,147.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Berizal,2018-12-31T00:00:00,1.2,1.609684705734253,34.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bocaiuva,2012-12-31T00:00:00,2.7,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bocaiuva,2013-12-31T00:00:00,2.7,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bocaiuva,2014-12-31T00:00:00,2.7,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bocaiuva,2015-12-31T00:00:00,1.8,2.6161763668060303,45.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bocaiuva,2016-12-31T00:00:00,1.8,2.7404279708862305,52.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bocaiuva,2017-12-31T00:00:00,1.62,2.088085889816284,28.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bocaiuva,2018-12-31T00:00:00,1.8,1.7933549880981445,0.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bom_Jesus_do_Amparo,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bom_Jesus_do_Amparo,2013-12-31T00:00:00,0.78,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bom_Jesus_do_Amparo,2014-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bom_Jesus_do_Amparo,2015-12-31T00:00:00,0.9,0.864160418510437,3.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bom_Jesus_do_Amparo,2016-12-31T00:00:00,1.2,0.7978547811508179,33.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bom_Jesus_do_Amparo,2017-12-31T00:00:00,1.0,0.9410953521728516,5.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bom_Jesus_do_Amparo,2018-12-31T00:00:00,2.2,1.3004193305969238,40.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Capela_Nova,2012-12-31T00:00:00,1.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Capela_Nova,2013-12-31T00:00:00,1.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Capela_Nova,2014-12-31T00:00:00,2.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Capela_Nova,2015-12-31T00:00:00,1.5,1.7763069868087769,18.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Capela_Nova,2016-12-31T00:00:00,2.04,1.8638163805007935,8.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Capela_Nova,2017-12-31T00:00:00,1.84,1.862041711807251,1.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Capela_Nova,2018-12-31T00:00:00,2.1,2.0601792335510254,1.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Capelinha,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Capelinha,2013-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Capelinha,2014-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Capelinha,2015-12-31T00:00:00,0.9,1.4148235321044922,57.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Capelinha,2016-12-31T00:00:00,1.08,1.4629707336425781,35.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Capelinha,2017-12-31T00:00:00,1.16,1.0671590566635132,8.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Capelinha,2018-12-31T00:00:00,1.26,1.0876438617706299,13.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Caranaiba,2012-12-31T00:00:00,0.33,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Caranaiba,2013-12-31T00:00:00,0.33,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Caranaiba,2014-12-31T00:00:00,0.33,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Caranaiba,2015-12-31T00:00:00,2.47,0.028418822214007378,98.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Caranaiba,2016-12-31T00:00:00,2.47,1.1668376922607422,52.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Caranaiba,2017-12-31T00:00:00,0.45,1.5296838283538818,239.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Caranaiba,2018-12-31T00:00:00,0.61,2.871809959411621,370.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Carmo_da_Mata,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Carmo_da_Mata,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Carmo_da_Mata,2014-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Carmo_da_Mata,2015-12-31T00:00:00,1.2,1.4451712369918823,20.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Carmo_da_Mata,2016-12-31T00:00:00,1.2,1.4155173301696777,17.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Carmo_da_Mata,2017-12-31T00:00:00,1.23,1.2913165092468262,4.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Carmo_da_Mata,2018-12-31T00:00:00,1.5,1.2265923023223877,18.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Carrancas,2012-12-31T00:00:00,1.68,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Carrancas,2013-12-31T00:00:00,1.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Carrancas,2014-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Carrancas,2015-12-31T00:00:00,0.7,1.3554009199142456,93.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Carrancas,2016-12-31T00:00:00,1.2,1.282020092010498,6.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Carrancas,2017-12-31T00:00:00,1.96,1.0229697227478027,47.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Carrancas,2018-12-31T00:00:00,1.5,1.7942428588867188,19.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Casa_Grande,2012-12-31T00:00:00,1.23,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Casa_Grande,2013-12-31T00:00:00,1.23,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Casa_Grande,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Casa_Grande,2015-12-31T00:00:00,1.32,1.2169843912124634,7.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Casa_Grande,2016-12-31T00:00:00,1.51,1.2877795696258545,14.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Casa_Grande,2017-12-31T00:00:00,0.71,1.3484703302383423,89.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Casa_Grande,2018-12-31T00:00:00,1.21,1.612291932106018,33.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cataguases,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cataguases,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cataguases,2014-12-31T00:00:00,0.87,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cataguases,2015-12-31T00:00:00,0.62,0.8837583065032959,42.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cataguases,2016-12-31T00:00:00,0.67,0.8340108394622803,24.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cataguases,2017-12-31T00:00:00,2.0,0.7430918216705322,62.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cataguases,2018-12-31T00:00:00,0.5,1.6354484558105469,227.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Catas_Altas_da_Noruega,2012-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Catas_Altas_da_Noruega,2013-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Catas_Altas_da_Noruega,2014-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Catas_Altas_da_Noruega,2015-12-31T00:00:00,1.0,0.6714324951171875,32.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Catas_Altas_da_Noruega,2016-12-31T00:00:00,1.2,1.8107659816741943,50.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Catas_Altas_da_Noruega,2017-12-31T00:00:00,0.87,1.0842384099960327,24.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Catas_Altas_da_Noruega,2018-12-31T00:00:00,0.62,1.1918222904205322,92.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Catuji,2012-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Catuji,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Catuji,2014-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Catuji,2015-12-31T00:00:00,0.9,0.730493426322937,18.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Catuji,2016-12-31T00:00:00,1.2,0.8581010103225708,28.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Catuji,2017-12-31T00:00:00,0.47,0.9303091168403625,97.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Catuji,2018-12-31T00:00:00,0.9,1.1114981174468994,23.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Caxambu,2012-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Caxambu,2013-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Caxambu,2014-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Caxambu,2015-12-31T00:00:00,1.2,1.272337555885315,6.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Caxambu,2016-12-31T00:00:00,1.5,1.2736992835998535,15.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Caxambu,2017-12-31T00:00:00,0.59,1.3479316234588623,128.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Caxambu,2018-12-31T00:00:00,0.9,1.3858442306518555,53.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Claudio,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Claudio,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Claudio,2014-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Claudio,2015-12-31T00:00:00,0.9,1.441178798675537,60.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Claudio,2016-12-31T00:00:00,1.2,1.3318969011306763,10.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Claudio,2017-12-31T00:00:00,1.42,1.2236425876617432,13.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Claudio,2018-12-31T00:00:00,1.5,1.36849844455719,8.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Coimbra,2012-12-31T00:00:00,1.53,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Coimbra,2013-12-31T00:00:00,1.53,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Coimbra,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Coimbra,2015-12-31T00:00:00,1.5,1.386125087738037,7.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Coimbra,2016-12-31T00:00:00,1.32,1.4216049909591675,7.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Coimbra,2017-12-31T00:00:00,1.86,1.353562355041504,27.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Coimbra,2018-12-31T00:00:00,1.8,1.9848272800445557,10.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Conselheiro_Pena,2012-12-31T00:00:00,1.48,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Conselheiro_Pena,2013-12-31T00:00:00,1.3,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Conselheiro_Pena,2014-12-31T00:00:00,1.3,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Conselheiro_Pena,2015-12-31T00:00:00,1.06,1.3531826734542847,27.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Conselheiro_Pena,2016-12-31T00:00:00,1.18,1.2276930809020996,4.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Conselheiro_Pena,2017-12-31T00:00:00,1.29,1.2119218111038208,6.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Conselheiro_Pena,2018-12-31T00:00:00,1.62,1.2756314277648926,21.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Coroaci,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Coroaci,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Coroaci,2014-12-31T00:00:00,1.04,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Coroaci,2015-12-31T00:00:00,1.32,0.9395368099212646,28.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Coroaci,2016-12-31T00:00:00,1.74,1.1374342441558838,34.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Coroaci,2017-12-31T00:00:00,1.73,1.270097017288208,26.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Coroaci,2018-12-31T00:00:00,1.56,1.8138493299484253,16.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Corrego_Novo,2012-12-31T00:00:00,1.17,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Corrego_Novo,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Corrego_Novo,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Corrego_Novo,2015-12-31T00:00:00,1.2,1.1425867080688477,4.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Corrego_Novo,2016-12-31T00:00:00,0.96,1.1689287424087524,21.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Corrego_Novo,2017-12-31T00:00:00,0.5,1.1048030853271484,120.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Corrego_Novo,2018-12-31T00:00:00,0.66,1.3223148584365845,100.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cruzilia,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cruzilia,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cruzilia,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cruzilia,2015-12-31T00:00:00,1.12,0.6645022630691528,40.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cruzilia,2016-12-31T00:00:00,1.5,1.1886008977890015,20.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cruzilia,2017-12-31T00:00:00,0.9,1.2947803735733032,43.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cruzilia,2018-12-31T00:00:00,1.2,1.3734071254730225,14.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cuparaque,2012-12-31T00:00:00,1.06,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cuparaque,2013-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cuparaque,2014-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cuparaque,2015-12-31T00:00:00,0.84,1.0520325899124146,25.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cuparaque,2016-12-31T00:00:00,1.02,0.9855288863182068,3.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cuparaque,2017-12-31T00:00:00,0.74,0.964825451374054,30.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cuparaque,2018-12-31T00:00:00,1.02,1.0227206945419312,0.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Diamantina,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Diamantina,2013-12-31T00:00:00,1.31,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Diamantina,2014-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Diamantina,2015-12-31T00:00:00,1.87,1.422093391418457,23.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Diamantina,2016-12-31T00:00:00,1.8,1.60341215133667,10.92,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Diamantina,2017-12-31T00:00:00,1.42,1.724348545074463,21.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Diamantina,2018-12-31T00:00:00,2.0,1.897444248199463,5.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Divisopolis,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Divisopolis,2013-12-31T00:00:00,1.74,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Divisopolis,2014-12-31T00:00:00,1.68,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Divisopolis,2015-12-31T00:00:00,0.66,1.575510025024414,138.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Divisopolis,2016-12-31T00:00:00,0.72,1.3905998468399048,93.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Divisopolis,2017-12-31T00:00:00,1.08,0.9839320778846741,8.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Divisopolis,2018-12-31T00:00:00,1.2,0.9180598855018616,23.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Dores_do_Turvo,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Dores_do_Turvo,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Dores_do_Turvo,2014-12-31T00:00:00,1.3,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Dores_do_Turvo,2015-12-31T00:00:00,1.32,1.3124626874923706,0.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Dores_do_Turvo,2016-12-31T00:00:00,1.32,1.3164632320404053,0.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Dores_do_Turvo,2017-12-31T00:00:00,0.6,1.3144128322601318,119.07,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Dores_do_Turvo,2018-12-31T00:00:00,0.89,1.603764533996582,80.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Esmeraldas,2012-12-31T00:00:00,2.41,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Esmeraldas,2013-12-31T00:00:00,1.51,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Esmeraldas,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Esmeraldas,2015-12-31T00:00:00,1.5,1.6011676788330078,6.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Esmeraldas,2016-12-31T00:00:00,1.5,1.4538377523422241,3.08,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Esmeraldas,2017-12-31T00:00:00,2.27,1.4631564617156982,35.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Esmeraldas,2018-12-31T00:00:00,2.1,2.1750311851501465,3.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Espirito_Santo_do_Dourado,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Espirito_Santo_do_Dourado,2013-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Espirito_Santo_do_Dourado,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Espirito_Santo_do_Dourado,2015-12-31T00:00:00,1.02,1.0860005617141724,6.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Espirito_Santo_do_Dourado,2016-12-31T00:00:00,1.14,1.0083017349243164,11.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Espirito_Santo_do_Dourado,2017-12-31T00:00:00,1.44,1.0498968362808228,27.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Espirito_Santo_do_Dourado,2018-12-31T00:00:00,1.8,1.3821460008621216,23.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Eugenopolis,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Eugenopolis,2013-12-31T00:00:00,1.71,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Eugenopolis,2014-12-31T00:00:00,1.71,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Eugenopolis,2015-12-31T00:00:00,1.5,1.411085844039917,5.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Eugenopolis,2016-12-31T00:00:00,1.2,1.6531651020050049,37.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Eugenopolis,2017-12-31T00:00:00,1.02,1.5033031702041626,47.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Eugenopolis,2018-12-31T00:00:00,1.2,1.4473708868026733,20.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Felicio_dos_Santos,2012-12-31T00:00:00,1.68,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Felicio_dos_Santos,2013-12-31T00:00:00,1.68,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Felicio_dos_Santos,2014-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Felicio_dos_Santos,2015-12-31T00:00:00,1.81,1.6135858297348022,10.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Felicio_dos_Santos,2016-12-31T00:00:00,1.8,1.6960387229919434,5.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Felicio_dos_Santos,2017-12-31T00:00:00,1.25,1.7021987438201904,36.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Felicio_dos_Santos,2018-12-31T00:00:00,1.3,1.902821660041809,46.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Fervedouro,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Fervedouro,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Fervedouro,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Fervedouro,2015-12-31T00:00:00,1.08,1.2738771438598633,17.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Fervedouro,2016-12-31T00:00:00,1.14,1.2141821384429932,6.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Fervedouro,2017-12-31T00:00:00,1.06,1.1606760025024414,9.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Fervedouro,2018-12-31T00:00:00,1.32,1.1327800750732422,14.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Formiga,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Formiga,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Formiga,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Formiga,2015-12-31T00:00:00,1.2,1.1999386548995972,0.01,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Formiga,2016-12-31T00:00:00,1.5,1.1999315023422241,20.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Formiga,2017-12-31T00:00:00,1.8,1.3638027906417847,24.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Formiga,2018-12-31T00:00:00,2.4,1.7269189357757568,28.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Formoso,2012-12-31T00:00:00,2.4,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Formoso,2013-12-31T00:00:00,2.4,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Formoso,2014-12-31T00:00:00,2.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Formoso,2015-12-31T00:00:00,1.8,2.504380941390991,39.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Formoso,2016-12-31T00:00:00,3.0,2.36279296875,21.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Formoso,2017-12-31T00:00:00,2.45,2.419201612472534,1.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Formoso,2018-12-31T00:00:00,2.7,2.89156436920166,7.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Fortaleza_de_Minas,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Fortaleza_de_Minas,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Fortaleza_de_Minas,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Fortaleza_de_Minas,2015-12-31T00:00:00,0.9,1.2208280563354492,35.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Fortaleza_de_Minas,2016-12-31T00:00:00,1.0,1.1663415431976318,16.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Fortaleza_de_Minas,2017-12-31T00:00:00,1.28,1.0000951290130615,21.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Fortaleza_de_Minas,2018-12-31T00:00:00,1.8,1.1532528400421143,35.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Guaraciaba,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Guaraciaba,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Guaraciaba,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Guaraciaba,2015-12-31T00:00:00,1.2,1.0211758613586426,14.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Guaraciaba,2016-12-31T00:00:00,1.2,1.1564350128173828,3.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Guaraciaba,2017-12-31T00:00:00,1.14,1.1019483804702759,3.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Guaraciaba,2018-12-31T00:00:00,1.2,1.2094746828079224,0.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Guiricema,2012-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Guiricema,2013-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Guiricema,2014-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Guiricema,2015-12-31T00:00:00,1.5,1.3348388671875,11.01,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Guiricema,2016-12-31T00:00:00,1.5,1.734763264656067,15.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Guiricema,2017-12-31T00:00:00,1.9,1.6198186874389648,14.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Guiricema,2018-12-31T00:00:00,1.8,1.8578747510910034,3.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Iapu,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Iapu,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Iapu,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Iapu,2015-12-31T00:00:00,1.2,0.5936141014099121,50.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Iapu,2016-12-31T00:00:00,1.2,1.0358891487121582,13.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Iapu,2017-12-31T00:00:00,1.28,1.1479345560073853,10.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Iapu,2018-12-31T00:00:00,1.5,1.2709659337997437,15.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Imbe_de_Minas,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Imbe_de_Minas,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Imbe_de_Minas,2014-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Imbe_de_Minas,2015-12-31T00:00:00,1.2,1.0862306356430054,9.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Imbe_de_Minas,2016-12-31T00:00:00,0.9,1.1510766744613647,27.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Imbe_de_Minas,2017-12-31T00:00:00,1.29,1.0765691995620728,16.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Imbe_de_Minas,2018-12-31T00:00:00,1.5,1.3258191347122192,11.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Inhapim,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Inhapim,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Inhapim,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Inhapim,2015-12-31T00:00:00,1.21,1.370260238647461,13.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Inhapim,2016-12-31T00:00:00,1.5,1.3212336301803589,11.92,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Inhapim,2017-12-31T00:00:00,1.12,1.3481779098510742,20.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Inhapim,2018-12-31T00:00:00,1.5,1.4744653701782227,1.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Irai_de_Minas,2012-12-31T00:00:00,2.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Irai_de_Minas,2013-12-31T00:00:00,2.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Irai_de_Minas,2014-12-31T00:00:00,2.4,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Irai_de_Minas,2015-12-31T00:00:00,1.2,2.1243464946746826,77.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Irai_de_Minas,2016-12-31T00:00:00,1.8,2.0512261390686035,13.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Irai_de_Minas,2017-12-31T00:00:00,0.87,1.8602499961853027,113.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Irai_de_Minas,2018-12-31T00:00:00,1.8,1.8233070373535156,1.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itaipe,2012-12-31T00:00:00,0.84,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itaipe,2013-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itaipe,2014-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itaipe,2015-12-31T00:00:00,0.84,0.813926637172699,3.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itaipe,2016-12-31T00:00:00,0.72,0.8587172031402588,19.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itaipe,2017-12-31T00:00:00,0.69,0.7421178221702576,7.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itaipe,2018-12-31T00:00:00,0.96,0.8000746965408325,16.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itamarandiba,2012-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itamarandiba,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itamarandiba,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itamarandiba,2015-12-31T00:00:00,1.2,1.003966212272644,16.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itamarandiba,2016-12-31T00:00:00,1.2,1.1833770275115967,1.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itamarandiba,2017-12-31T00:00:00,1.64,1.1043171882629395,32.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itamarandiba,2018-12-31T00:00:00,1.8,1.5073199272155762,16.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itamarati_de_Minas,2012-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itamarati_de_Minas,2013-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itamarati_de_Minas,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itamarati_de_Minas,2015-12-31T00:00:00,0.9,0.9503006339073181,5.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itamarati_de_Minas,2016-12-31T00:00:00,0.9,0.9515144228935242,5.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itamarati_de_Minas,2017-12-31T00:00:00,0.74,2.513535499572754,239.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itamarati_de_Minas,2018-12-31T00:00:00,0.9,0.8982388377189636,0.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jequeri,2012-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jequeri,2013-12-31T00:00:00,1.86,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jequeri,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jequeri,2015-12-31T00:00:00,1.26,1.55191969871521,23.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jequeri,2016-12-31T00:00:00,1.2,1.4588074684143066,21.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jequeri,2017-12-31T00:00:00,1.28,1.2280298471450806,4.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jequeri,2018-12-31T00:00:00,1.5,1.298572063446045,13.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jequitinhonha,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jequitinhonha,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jequitinhonha,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jequitinhonha,2015-12-31T00:00:00,0.9,0.9857578873634338,9.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jequitinhonha,2016-12-31T00:00:00,1.1,1.2088278532028198,9.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jequitinhonha,2017-12-31T00:00:00,1.44,0.9681925177574158,32.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jequitinhonha,2018-12-31T00:00:00,2.4,1.337949275970459,44.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jose_Goncalves_de_Minas,2012-12-31T00:00:00,0.84,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jose_Goncalves_de_Minas,2013-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jose_Goncalves_de_Minas,2014-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jose_Goncalves_de_Minas,2015-12-31T00:00:00,0.9,0.6825786828994751,24.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jose_Goncalves_de_Minas,2016-12-31T00:00:00,1.2,0.7282701730728149,39.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jose_Goncalves_de_Minas,2017-12-31T00:00:00,0.6,0.8774802088737488,46.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jose_Goncalves_de_Minas,2018-12-31T00:00:00,1.2,0.9856894612312317,17.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Lamim,2012-12-31T00:00:00,1.05,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Lamim,2013-12-31T00:00:00,1.05,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Lamim,2014-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Lamim,2015-12-31T00:00:00,1.8,1.223642110824585,32.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Lamim,2016-12-31T00:00:00,1.05,1.6201496124267578,54.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Lamim,2017-12-31T00:00:00,1.2,1.5725271701812744,31.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Lamim,2018-12-31T00:00:00,1.19,1.7431995868682861,46.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mantena,2012-12-31T00:00:00,0.42,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mantena,2013-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mantena,2014-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mantena,2015-12-31T00:00:00,1.01,0.568451464176178,43.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mantena,2016-12-31T00:00:00,0.6,0.7779797315597534,29.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mantena,2017-12-31T00:00:00,0.64,0.7427428960800171,16.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mantena,2018-12-31T00:00:00,0.9,1.0671517848968506,18.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mar_de_Espanha,2012-12-31T00:00:00,2.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mar_de_Espanha,2013-12-31T00:00:00,2.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mar_de_Espanha,2014-12-31T00:00:00,2.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mar_de_Espanha,2015-12-31T00:00:00,1.26,0.6589211225509644,47.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mar_de_Espanha,2016-12-31T00:00:00,1.2,1.6829745769500732,40.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mar_de_Espanha,2017-12-31T00:00:00,2.19,1.6207301616668701,25.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mar_de_Espanha,2018-12-31T00:00:00,1.8,1.7606823444366455,2.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mata_Verde,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mata_Verde,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mata_Verde,2014-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mata_Verde,2015-12-31T00:00:00,1.44,1.280887246131897,11.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mata_Verde,2016-12-31T00:00:00,0.96,1.3412716388702393,39.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mata_Verde,2017-12-31T00:00:00,0.6,1.2594664096832275,109.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mata_Verde,2018-12-31T00:00:00,1.5,1.2698304653167725,15.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Matutina,2012-12-31T00:00:00,1.92,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Matutina,2013-12-31T00:00:00,1.92,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Matutina,2014-12-31T00:00:00,1.53,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Matutina,2015-12-31T00:00:00,1.5,1.7029025554656982,13.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Matutina,2016-12-31T00:00:00,1.5,1.600294828414917,6.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Matutina,2017-12-31T00:00:00,1.75,1.512494683265686,13.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Matutina,2018-12-31T00:00:00,2.1,1.7064186334609985,18.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Minas_Novas,2012-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Minas_Novas,2013-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Minas_Novas,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Minas_Novas,2015-12-31T00:00:00,1.2,0.9403393864631653,21.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Minas_Novas,2016-12-31T00:00:00,1.2,1.0611246824264526,11.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Minas_Novas,2017-12-31T00:00:00,0.69,1.0863947868347168,57.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Minas_Novas,2018-12-31T00:00:00,0.9,1.1208925247192383,24.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Monte_Santo_de_Minas,2012-12-31T00:00:00,1.89,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Monte_Santo_de_Minas,2013-12-31T00:00:00,1.62,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Monte_Santo_de_Minas,2014-12-31T00:00:00,1.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Monte_Santo_de_Minas,2015-12-31T00:00:00,1.35,1.609204888343811,19.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Monte_Santo_de_Minas,2016-12-31T00:00:00,2.04,1.5646851062774658,23.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Monte_Santo_de_Minas,2017-12-31T00:00:00,1.08,1.6755746603012085,55.15,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Monte_Santo_de_Minas,2018-12-31T00:00:00,1.88,2.0576953887939453,9.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Nova_Ponte,2012-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Nova_Ponte,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Nova_Ponte,2014-12-31T00:00:00,1.68,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Nova_Ponte,2015-12-31T00:00:00,1.2,1.5562336444854736,29.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Nova_Ponte,2016-12-31T00:00:00,1.8,1.51462984085083,15.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Nova_Ponte,2017-12-31T00:00:00,1.07,1.5838361978530884,48.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Nova_Ponte,2018-12-31T00:00:00,1.8,1.6682257652282715,7.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Novo_Cruzeiro,2012-12-31T00:00:00,0.84,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Novo_Cruzeiro,2013-12-31T00:00:00,0.84,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Novo_Cruzeiro,2014-12-31T00:00:00,0.84,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Novo_Cruzeiro,2015-12-31T00:00:00,0.9,0.7100282311439514,21.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Novo_Cruzeiro,2016-12-31T00:00:00,0.84,0.8681855201721191,3.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Novo_Cruzeiro,2017-12-31T00:00:00,1.05,0.8679507970809937,17.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Novo_Cruzeiro,2018-12-31T00:00:00,1.14,1.0422496795654297,8.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Novorizonte,2012-12-31T00:00:00,1.48,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Novorizonte,2013-12-31T00:00:00,0.93,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Novorizonte,2014-12-31T00:00:00,0.91,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Novorizonte,2015-12-31T00:00:00,0.87,1.0647717714309692,22.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Novorizonte,2016-12-31T00:00:00,1.2,0.9280542135238647,22.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Novorizonte,2017-12-31T00:00:00,0.71,0.9875051975250244,39.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Novorizonte,2018-12-31T00:00:00,0.91,0.9741201400756836,7.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ouro_Verde_de_Minas,2012-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ouro_Verde_de_Minas,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ouro_Verde_de_Minas,2014-12-31T00:00:00,0.73,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ouro_Verde_de_Minas,2015-12-31T00:00:00,0.9,0.7771319150924683,13.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ouro_Verde_de_Minas,2016-12-31T00:00:00,1.2,0.8662727475166321,27.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ouro_Verde_de_Minas,2017-12-31T00:00:00,0.86,1.002708077430725,16.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ouro_Verde_de_Minas,2018-12-31T00:00:00,1.2,1.1505827903747559,4.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Passos,2012-12-31T00:00:00,2.16,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Passos,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Passos,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Passos,2015-12-31T00:00:00,0.9,1.213712453842163,34.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Passos,2016-12-31T00:00:00,1.68,1.1603305339813232,30.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Passos,2017-12-31T00:00:00,1.92,1.277002215385437,33.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Passos,2018-12-31T00:00:00,2.1,1.9153025150299072,8.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Paula_Candido,2012-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Paula_Candido,2013-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Paula_Candido,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Paula_Candido,2015-12-31T00:00:00,1.32,1.3287032842636108,0.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Paula_Candido,2016-12-31T00:00:00,1.26,1.3318407535552979,5.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Paula_Candido,2017-12-31T00:00:00,1.37,1.270027995109558,7.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Paula_Candido,2018-12-31T00:00:00,1.5,1.3895723819732666,7.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pecanha,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pecanha,2013-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pecanha,2014-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pecanha,2015-12-31T00:00:00,0.91,0.6868466138839722,24.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pecanha,2016-12-31T00:00:00,0.91,0.768460750579834,15.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pecanha,2017-12-31T00:00:00,1.33,0.794173538684845,40.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pecanha,2018-12-31T00:00:00,1.44,1.2640354633331299,12.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Azul,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Azul,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Azul,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Azul,2015-12-31T00:00:00,0.9,0.6812580227851868,24.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Azul,2016-12-31T00:00:00,0.9,1.228253722190857,36.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Azul,2017-12-31T00:00:00,1.5,1.0242968797683716,31.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Azul,2018-12-31T00:00:00,1.2,1.1671396493911743,2.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Bonita,2012-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Bonita,2013-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Bonita,2014-12-31T00:00:00,0.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Bonita,2015-12-31T00:00:00,0.6,0.9276471734046936,54.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Bonita,2016-12-31T00:00:00,1.32,0.8301184177398682,37.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Bonita,2017-12-31T00:00:00,0.86,1.0024075508117676,16.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Bonita,2018-12-31T00:00:00,1.2,1.3723411560058594,14.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Dourada,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Dourada,2013-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Dourada,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Dourada,2015-12-31T00:00:00,0.96,0.9902412295341492,3.15,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Dourada,2016-12-31T00:00:00,0.96,1.3157449960708618,37.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Dourada,2017-12-31T00:00:00,1.34,1.457782506942749,8.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Dourada,2018-12-31T00:00:00,1.2,1.3366279602050781,11.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_do_Anta,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_do_Anta,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_do_Anta,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_do_Anta,2015-12-31T00:00:00,1.26,1.1473653316497803,8.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_do_Anta,2016-12-31T00:00:00,1.2,1.1888296604156494,0.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_do_Anta,2017-12-31T00:00:00,1.18,1.205293893814087,2.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_do_Anta,2018-12-31T00:00:00,1.2,1.263535976409912,5.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Piedade_de_Caratinga,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Piedade_de_Caratinga,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Piedade_de_Caratinga,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Piedade_de_Caratinga,2015-12-31T00:00:00,1.2,1.1514546871185303,4.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Piedade_de_Caratinga,2016-12-31T00:00:00,1.2,1.1715306043624878,2.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Piedade_de_Caratinga,2017-12-31T00:00:00,1.59,1.176241397857666,26.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Piedade_de_Caratinga,2018-12-31T00:00:00,1.68,1.5104190111160278,10.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pocrane,2012-12-31T00:00:00,1.21,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pocrane,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pocrane,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pocrane,2015-12-31T00:00:00,1.08,1.1542280912399292,6.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pocrane,2016-12-31T00:00:00,1.09,1.1328169107437134,3.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pocrane,2017-12-31T00:00:00,1.32,1.0838090181350708,17.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pocrane,2018-12-31T00:00:00,1.32,1.2761433124542236,3.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ponto_dos_Volantes,2012-12-31T00:00:00,0.7,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ponto_dos_Volantes,2013-12-31T00:00:00,0.3,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ponto_dos_Volantes,2014-12-31T00:00:00,0.7,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ponto_dos_Volantes,2015-12-31T00:00:00,0.6,0.520957887172699,13.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ponto_dos_Volantes,2016-12-31T00:00:00,0.6,0.5276287198066711,12.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ponto_dos_Volantes,2017-12-31T00:00:00,0.38,0.637171745300293,67.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ponto_dos_Volantes,2018-12-31T00:00:00,0.6,0.6403208374977112,6.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pote,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pote,2013-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pote,2014-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pote,2015-12-31T00:00:00,0.9,0.6851295232772827,23.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pote,2016-12-31T00:00:00,0.9,0.732779860496521,18.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pote,2017-12-31T00:00:00,0.6,0.8389392495155334,39.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pote,2018-12-31T00:00:00,0.73,0.9409206509590149,28.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pratinha,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pratinha,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pratinha,2014-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pratinha,2015-12-31T00:00:00,1.5,1.5047013759613037,0.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pratinha,2016-12-31T00:00:00,1.5,1.5794909000396729,5.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pratinha,2017-12-31T00:00:00,1.72,1.6158976554870605,6.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pratinha,2018-12-31T00:00:00,1.8,1.677852749824524,6.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Quartel_Geral,2012-12-31T00:00:00,4.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Quartel_Geral,2013-12-31T00:00:00,3.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Quartel_Geral,2014-12-31T00:00:00,2.4,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Quartel_Geral,2015-12-31T00:00:00,1.8,3.1437816619873047,74.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Quartel_Geral,2016-12-31T00:00:00,2.7,2.634190559387207,2.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Quartel_Geral,2017-12-31T00:00:00,4.12,2.3715579509735107,42.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Quartel_Geral,2018-12-31T00:00:00,4.5,4.084417819976807,9.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ritapolis,2012-12-31T00:00:00,1.68,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ritapolis,2013-12-31T00:00:00,1.85,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ritapolis,2014-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ritapolis,2015-12-31T00:00:00,1.5,1.755648136138916,17.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ritapolis,2016-12-31T00:00:00,1.8,1.7461328506469727,2.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ritapolis,2017-12-31T00:00:00,1.81,1.6923235654830933,6.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ritapolis,2018-12-31T00:00:00,1.8,1.9022939205169678,5.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sabinopolis,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sabinopolis,2013-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sabinopolis,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sabinopolis,2015-12-31T00:00:00,1.5,0.7846187353134155,47.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sabinopolis,2016-12-31T00:00:00,0.6,1.168470859527588,94.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sabinopolis,2017-12-31T00:00:00,1.25,0.9507360458374023,23.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sabinopolis,2018-12-31T00:00:00,1.2,1.5930399894714355,32.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Barbara,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Barbara,2013-12-31T00:00:00,0.98,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Barbara,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Barbara,2015-12-31T00:00:00,1.2,0.9938701391220093,17.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Barbara,2016-12-31T00:00:00,0.91,1.0341875553131104,13.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Barbara,2017-12-31T00:00:00,1.17,1.0200705528259277,12.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Barbara,2018-12-31T00:00:00,1.21,1.333070158958435,10.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Maria_do_Suacui,2012-12-31T00:00:00,0.91,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Maria_do_Suacui,2013-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Maria_do_Suacui,2014-12-31T00:00:00,0.66,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Maria_do_Suacui,2015-12-31T00:00:00,0.9,0.7129808068275452,20.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Maria_do_Suacui,2016-12-31T00:00:00,0.83,0.7869538068771362,5.19,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Maria_do_Suacui,2017-12-31T00:00:00,0.67,0.772026777267456,15.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Maria_do_Suacui,2018-12-31T00:00:00,0.8,0.8712828755378723,8.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Rita_de_Caldas,2012-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Rita_de_Caldas,2013-12-31T00:00:00,1.68,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Rita_de_Caldas,2014-12-31T00:00:00,1.68,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Rita_de_Caldas,2015-12-31T00:00:00,1.5,1.6938750743865967,12.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Rita_de_Caldas,2016-12-31T00:00:00,1.8,1.6464728116989136,8.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Rita_de_Caldas,2017-12-31T00:00:00,2.18,1.6935153007507324,22.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Rita_de_Caldas,2018-12-31T00:00:00,1.8,1.9792346954345703,9.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Rita_do_Itueto,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Rita_do_Itueto,2013-12-31T00:00:00,1.17,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Rita_do_Itueto,2014-12-31T00:00:00,1.11,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Rita_do_Itueto,2015-12-31T00:00:00,0.92,1.1605123281478882,26.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Rita_do_Itueto,2016-12-31T00:00:00,1.2,1.065824270248413,11.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Rita_do_Itueto,2017-12-31T00:00:00,1.32,1.0982799530029297,16.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Rita_do_Itueto,2018-12-31T00:00:00,1.35,1.3144336938858032,2.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santo_Antonio_do_Retiro,2012-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santo_Antonio_do_Retiro,2013-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santo_Antonio_do_Retiro,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santo_Antonio_do_Retiro,2015-12-31T00:00:00,1.2,0.9847539663314819,17.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santo_Antonio_do_Retiro,2016-12-31T00:00:00,0.9,1.1405813694000244,26.73,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santo_Antonio_do_Retiro,2017-12-31T00:00:00,0.93,1.084316372871399,16.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santo_Antonio_do_Retiro,2018-12-31T00:00:00,1.08,1.04793119430542,2.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Domingos_do_Prata,2012-12-31T00:00:00,0.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Domingos_do_Prata,2013-12-31T00:00:00,0.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Domingos_do_Prata,2014-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Domingos_do_Prata,2015-12-31T00:00:00,0.9,0.7262336015701294,19.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Domingos_do_Prata,2016-12-31T00:00:00,0.84,0.7700380682945251,8.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Domingos_do_Prata,2017-12-31T00:00:00,0.7,0.779629647731781,11.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Domingos_do_Prata,2018-12-31T00:00:00,1.2,0.9646438360214233,19.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Francisco_de_Paula,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Francisco_de_Paula,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Francisco_de_Paula,2014-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Francisco_de_Paula,2015-12-31T00:00:00,0.9,1.1137371063232422,23.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Francisco_de_Paula,2016-12-31T00:00:00,1.56,1.0856624841690063,30.41,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Francisco_de_Paula,2017-12-31T00:00:00,1.56,1.2531205415725708,19.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Francisco_de_Paula,2018-12-31T00:00:00,1.8,1.6944055557250977,5.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Geraldo,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Geraldo,2013-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Geraldo,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Geraldo,2015-12-31T00:00:00,0.75,1.0799994468688965,44.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Geraldo,2016-12-31T00:00:00,0.75,0.9946643114089966,32.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Geraldo,2017-12-31T00:00:00,0.59,0.9062217473983765,53.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Geraldo,2018-12-31T00:00:00,1.2,0.8110598921775818,32.41,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Goncalo_do_Rio_Preto,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Goncalo_do_Rio_Preto,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Goncalo_do_Rio_Preto,2014-12-31T00:00:00,1.25,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Goncalo_do_Rio_Preto,2015-12-31T00:00:00,1.3,1.2144074440002441,6.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Goncalo_do_Rio_Preto,2016-12-31T00:00:00,1.25,1.2597157955169678,0.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Goncalo_do_Rio_Preto,2017-12-31T00:00:00,4.77,1.2659094333648682,73.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Goncalo_do_Rio_Preto,2018-12-31T00:00:00,1.79,3.6538753509521484,104.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Joao_do_Manteninha,2012-12-31T00:00:00,0.48,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Joao_do_Manteninha,2013-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Joao_do_Manteninha,2014-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Joao_do_Manteninha,2015-12-31T00:00:00,0.6,0.8037896752357483,33.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Joao_do_Manteninha,2016-12-31T00:00:00,0.6,0.9427798986434937,57.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Joao_do_Manteninha,2017-12-31T00:00:00,0.65,0.8896433711051941,36.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Joao_do_Manteninha,2018-12-31T00:00:00,0.6,0.6566482782363892,9.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Joao_do_Paraiso,2012-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Joao_do_Paraiso,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Joao_do_Paraiso,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Joao_do_Paraiso,2015-12-31T00:00:00,1.32,1.216726541519165,7.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Joao_do_Paraiso,2016-12-31T00:00:00,2.1,1.299553394317627,38.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Joao_do_Paraiso,2017-12-31T00:00:00,0.59,1.5171926021575928,157.15,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Joao_do_Paraiso,2018-12-31T00:00:00,2.96,1.4582324028015137,50.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Jose_da_Barra,2012-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Jose_da_Barra,2013-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Jose_da_Barra,2014-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Jose_da_Barra,2015-12-31T00:00:00,1.2,1.480607271194458,23.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Jose_da_Barra,2016-12-31T00:00:00,1.2,1.4546103477478027,21.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Jose_da_Barra,2017-12-31T00:00:00,1.91,1.299757719039917,31.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Jose_da_Barra,2018-12-31T00:00:00,2.1,1.6871428489685059,19.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Jose_do_Alegre,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Jose_do_Alegre,2013-12-31T00:00:00,1.09,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Jose_do_Alegre,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Jose_do_Alegre,2015-12-31T00:00:00,1.2,1.1629366874694824,3.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Jose_do_Alegre,2016-12-31T00:00:00,1.51,1.1786694526672363,21.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Jose_do_Alegre,2017-12-31T00:00:00,1.1,1.2648727893829346,14.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Jose_do_Alegre,2018-12-31T00:00:00,1.5,1.3648433685302734,9.01,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Miguel_do_Anta,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Miguel_do_Anta,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Miguel_do_Anta,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Miguel_do_Anta,2015-12-31T00:00:00,1.32,1.1068594455718994,16.15,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Miguel_do_Anta,2016-12-31T00:00:00,1.2,1.210219144821167,0.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Miguel_do_Anta,2017-12-31T00:00:00,1.02,1.2126643657684326,18.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Miguel_do_Anta,2018-12-31T00:00:00,1.44,1.4018603563308716,2.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_da_Vargem_Alegre,2012-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_da_Vargem_Alegre,2013-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_da_Vargem_Alegre,2014-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_da_Vargem_Alegre,2015-12-31T00:00:00,1.02,0.6844193935394287,32.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_da_Vargem_Alegre,2016-12-31T00:00:00,1.02,1.6369519233703613,60.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_da_Vargem_Alegre,2017-12-31T00:00:00,1.27,1.3946850299835205,9.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_da_Vargem_Alegre,2018-12-31T00:00:00,1.02,1.243999719619751,21.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_do_Anta,2012-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_do_Anta,2013-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_do_Anta,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_do_Anta,2015-12-31T00:00:00,1.2,1.299431324005127,8.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_do_Anta,2016-12-31T00:00:00,1.2,1.2745869159698486,6.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_do_Anta,2017-12-31T00:00:00,1.78,1.9985573291778564,12.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_do_Anta,2018-12-31T00:00:00,1.64,1.6824417114257812,2.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_do_Maranhao,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_do_Maranhao,2013-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_do_Maranhao,2014-12-31T00:00:00,0.66,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_do_Maranhao,2015-12-31T00:00:00,0.9,0.7115988731384277,20.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_do_Maranhao,2016-12-31T00:00:00,0.9,0.7675896883010864,14.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_do_Maranhao,2017-12-31T00:00:00,0.88,0.7912953495979309,10.08,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_do_Maranhao,2018-12-31T00:00:00,0.9,0.9004154205322266,0.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Senador_Modestino_Goncalves,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Senador_Modestino_Goncalves,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Senador_Modestino_Goncalves,2014-12-31T00:00:00,1.55,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Senador_Modestino_Goncalves,2015-12-31T00:00:00,1.8,1.1795514822006226,34.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Senador_Modestino_Goncalves,2016-12-31T00:00:00,1.8,1.4768568277359009,17.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Senador_Modestino_Goncalves,2017-12-31T00:00:00,1.14,1.702617883682251,49.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Senador_Modestino_Goncalves,2018-12-31T00:00:00,1.5,1.9199203252792358,27.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Senhora_dos_Remedios,2012-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Senhora_dos_Remedios,2013-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Senhora_dos_Remedios,2014-12-31T00:00:00,1.51,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Senhora_dos_Remedios,2015-12-31T00:00:00,1.32,1.6425029039382935,24.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Senhora_dos_Remedios,2016-12-31T00:00:00,1.2,1.6368999481201172,36.41,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Senhora_dos_Remedios,2017-12-31T00:00:00,1.07,1.344395637512207,25.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Senhora_dos_Remedios,2018-12-31T00:00:00,1.5,1.3116742372512817,12.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Simonesia,2012-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Simonesia,2013-12-31T00:00:00,1.62,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Simonesia,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Simonesia,2015-12-31T00:00:00,1.44,1.4332382678985596,0.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Simonesia,2016-12-31T00:00:00,1.32,1.4338796138763428,8.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Simonesia,2017-12-31T00:00:00,1.14,1.360633373260498,19.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Simonesia,2018-12-31T00:00:00,1.2,1.4577703475952148,21.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Taiobeiras,2012-12-31T00:00:00,3.3,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Taiobeiras,2013-12-31T00:00:00,3.3,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Taiobeiras,2014-12-31T00:00:00,3.3,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Taiobeiras,2015-12-31T00:00:00,3.3,3.3005313873291016,0.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Taiobeiras,2016-12-31T00:00:00,1.08,3.3005855083465576,205.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Taiobeiras,2017-12-31T00:00:00,1.45,2.4172146320343018,66.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Taiobeiras,2018-12-31T00:00:00,2.22,2.2401206493377686,0.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tapira,2012-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tapira,2013-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tapira,2014-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tapira,2015-12-31T00:00:00,1.5,1.7980587482452393,19.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tapira,2016-12-31T00:00:00,1.5,1.6738405227661133,11.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tapira,2017-12-31T00:00:00,2.7,1.6043243408203125,40.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tapira,2018-12-31T00:00:00,1.8,2.483187198638916,37.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Teixeiras,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Teixeiras,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Teixeiras,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Teixeiras,2015-12-31T00:00:00,1.26,1.1057854890823364,12.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Teixeiras,2016-12-31T00:00:00,1.2,1.1895699501037598,0.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Teixeiras,2017-12-31T00:00:00,0.86,1.1912055015563965,38.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Teixeiras,2018-12-31T00:00:00,1.32,1.4389212131500244,9.01,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tocos_do_Moji,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tocos_do_Moji,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tocos_do_Moji,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tocos_do_Moji,2015-12-31T00:00:00,1.2,1.317129373550415,9.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tocos_do_Moji,2016-12-31T00:00:00,1.08,1.300683856010437,20.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tocos_do_Moji,2017-12-31T00:00:00,1.74,1.128295660018921,35.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tocos_do_Moji,2018-12-31T00:00:00,1.8,1.5234136581420898,15.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tupaciguara,2012-12-31T00:00:00,2.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tupaciguara,2013-12-31T00:00:00,2.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tupaciguara,2014-12-31T00:00:00,2.28,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tupaciguara,2015-12-31T00:00:00,2.1,2.1177287101745605,0.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tupaciguara,2016-12-31T00:00:00,2.1,2.14628529548645,2.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tupaciguara,2017-12-31T00:00:00,2.1,2.2121973037719727,5.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tupaciguara,2018-12-31T00:00:00,2.4,2.10080623626709,12.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Uberaba,2012-12-31T00:00:00,2.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Uberaba,2013-12-31T00:00:00,2.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Uberaba,2014-12-31T00:00:00,2.12,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Uberaba,2015-12-31T00:00:00,1.86,2.102475881576538,13.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Uberaba,2016-12-31T00:00:00,1.08,2.0643792152404785,91.15,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Uberaba,2017-12-31T00:00:00,1.99,1.7159826755523682,13.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Uberaba,2018-12-31T00:00:00,2.48,1.9218990802764893,22.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Vargem_Grande_do_Rio_Pardo,2012-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Vargem_Grande_do_Rio_Pardo,2013-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Vargem_Grande_do_Rio_Pardo,2014-12-31T00:00:00,0.7,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Vargem_Grande_do_Rio_Pardo,2015-12-31T00:00:00,1.22,0.7160834074020386,41.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Vargem_Grande_do_Rio_Pardo,2016-12-31T00:00:00,1.2,1.0572471618652344,11.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Vargem_Grande_do_Rio_Pardo,2017-12-31T00:00:00,1.57,1.0768171548843384,31.41,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Vargem_Grande_do_Rio_Pardo,2018-12-31T00:00:00,1.8,1.3814518451690674,23.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Visconde_do_Rio_Branco,2012-12-31T00:00:00,0.78,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Visconde_do_Rio_Branco,2013-12-31T00:00:00,0.78,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Visconde_do_Rio_Branco,2014-12-31T00:00:00,1.54,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Visconde_do_Rio_Branco,2015-12-31T00:00:00,0.83,0.9199705123901367,10.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Visconde_do_Rio_Branco,2016-12-31T00:00:00,0.83,1.1402883529663086,37.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Visconde_do_Rio_Branco,2017-12-31T00:00:00,1.17,1.0803685188293457,7.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Visconde_do_Rio_Branco,2018-12-31T00:00:00,0.83,1.1278260946273804,35.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Abre_Campo,2019-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Aimores,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Alvarenga,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Amparo_do_Serra,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Angelandia,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Antonio_Dias,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Antonio_Prado_de_Minas,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Aricanduva,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bandeira,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Berilo,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Berizal,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bocaiuva,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bom_Jesus_do_Amparo,2019-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Capela_Nova,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Capelinha,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Caranaiba,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Carmo_da_Mata,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Carrancas,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Casa_Grande,2019-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cataguases,2019-12-31T00:00:00,0.0,1,inf,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Catas_Altas_da_Noruega,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Catuji,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Caxambu,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Claudio,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Coimbra,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Conselheiro_Pena,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Coroaci,2019-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Corrego_Novo,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cruzilia,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cuparaque,2019-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Diamantina,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Divisopolis,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Dores_do_Turvo,2019-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Esmeraldas,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Espirito_Santo_do_Dourado,2019-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Eugenopolis,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Felicio_dos_Santos,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Fervedouro,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Formiga,2019-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Formoso,2019-12-31T00:00:00,3.0,3,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Fortaleza_de_Minas,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Guaraciaba,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Guiricema,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Iapu,2019-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Imbe_de_Minas,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Inhapim,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Irai_de_Minas,2019-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itaipe,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itamarandiba,2019-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itamarati_de_Minas,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jequeri,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jequitinhonha,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jose_Goncalves_de_Minas,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Lamim,2019-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mantena,2019-12-31T00:00:00,0.0,1,inf,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mar_de_Espanha,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mata_Verde,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Matutina,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Minas_Novas,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Monte_Santo_de_Minas,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Nova_Ponte,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Novo_Cruzeiro,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Novorizonte,2019-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ouro_Verde_de_Minas,2019-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Passos,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Paula_Candido,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pecanha,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Azul,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Bonita,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Dourada,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_do_Anta,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Piedade_de_Caratinga,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pocrane,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ponto_dos_Volantes,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pote,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pratinha,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Quartel_Geral,2019-12-31T00:00:00,3.0,4,33.33,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ritapolis,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sabinopolis,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Barbara,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Maria_do_Suacui,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Rita_de_Caldas,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Rita_do_Itueto,2019-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santo_Antonio_do_Retiro,2019-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Domingos_do_Prata,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Francisco_de_Paula,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Geraldo,2019-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Goncalo_do_Rio_Preto,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Joao_do_Manteninha,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Joao_do_Paraiso,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Jose_da_Barra,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Jose_do_Alegre,2019-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Miguel_do_Anta,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_da_Vargem_Alegre,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_do_Anta,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_do_Maranhao,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Senador_Modestino_Goncalves,2019-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Senhora_dos_Remedios,2019-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Simonesia,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Taiobeiras,2019-12-31T00:00:00,3.0,2,-33.33,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tapira,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Teixeiras,2019-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tocos_do_Moji,2019-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tupaciguara,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Uberaba,2019-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Vargem_Grande_do_Rio_Pardo,2019-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Visconde_do_Rio_Branco,2019-12-31T00:00:00,0.0,1,inf,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Abre_Campo,2020-12-31T00:00:00,1.5,1.365723967552185,-8.95,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Aimores,2020-12-31T00:00:00,2.063157894736842,1.4005769491195679,-32.11,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Alvarenga,2020-12-31T00:00:00,0.9,0.6984772682189941,-22.39,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Amparo_do_Serra,2020-12-31T00:00:00,1.4392156862745098,1.4482805728912354,0.63,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Angelandia,2020-12-31T00:00:00,1.8400349650349652,1.6236157417297363,-11.76,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Antonio_Dias,2020-12-31T00:00:00,1.333333333333333,0.9969721436500549,-25.23,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Antonio_Prado_de_Minas,2020-12-31T00:00:00,1.5,1.111948013305664,-25.87,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Aricanduva,2020-12-31T00:00:00,1.3196428571428571,0.9660979509353638,-26.79,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bandeira,2020-12-31T00:00:00,1.083333333333333,1.9346551895141602,78.58,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Berilo,2020-12-31T00:00:00,0.8428571428571429,0.8662306070327759,2.77,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Berizal,2020-12-31T00:00:00,3.340236686390532,1.1516813039779663,-65.52,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bocaiuva,2020-12-31T00:00:00,1.622950819672131,1.723193645477295,6.18,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Bom_Jesus_do_Amparo,2020-12-31T00:00:00,1.5,1.9923855066299438,32.83,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Capela_Nova,2020-12-31T00:00:00,1.8000000000000003,2.016017436981201,12.0,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Capelinha,2020-12-31T00:00:00,1.434123222748815,1.2240262031555176,-14.65,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Caranaiba,2020-12-31T00:00:00,1.645161290322581,1.0381741523742676,-36.9,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Carmo_da_Mata,2020-12-31T00:00:00,1.68,1.4055123329162598,-16.34,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Carrancas,2020-12-31T00:00:00,1.785714285714286,2.2123310565948486,23.89,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Casa_Grande,2020-12-31T00:00:00,1.553846153846154,1.272629976272583,-18.1,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cataguases,2020-12-31T00:00:00,1.25,1.6483638286590576,31.87,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Catas_Altas_da_Noruega,2020-12-31T00:00:00,1.0,0.7965986728668213,-20.34,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Catuji,2020-12-31T00:00:00,1.197183098591549,1.1059448719024658,-7.62,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Caxambu,2020-12-31T00:00:00,1.3265306122448983,0.8704732656478882,-34.38,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Claudio,2020-12-31T00:00:00,2.76,1.4862169027328491,-46.15,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Coimbra,2020-12-31T00:00:00,1.8000000000000003,1.8552772998809814,3.07,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Conselheiro_Pena,2020-12-31T00:00:00,1.55981308411215,1.5363068580627441,-1.51,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Coroaci,2020-12-31T00:00:00,1.8000000000000003,1.6726808547973633,-7.07,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Corrego_Novo,2020-12-31T00:00:00,1.2545454545454553,0.9971774816513062,-20.51,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cruzilia,2020-12-31T00:00:00,1.2,1.1825041770935059,-1.46,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Cuparaque,2020-12-31T00:00:00,1.018518518518519,1.3632497787475586,33.85,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Diamantina,2020-12-31T00:00:00,2.3453815261044184,1.9429471492767334,-17.16,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Divisopolis,2020-12-31T00:00:00,1.34029484029484,1.1492153406143188,-14.26,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Dores_do_Turvo,2020-12-31T00:00:00,1.625,1.2705044746398926,-21.82,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Esmeraldas,2020-12-31T00:00:00,2.096153846153846,2.2428019046783447,7.0,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Espirito_Santo_do_Dourado,2020-12-31T00:00:00,1.619148936170213,1.5999070405960083,-1.19,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Eugenopolis,2020-12-31T00:00:00,1.8000000000000003,1.1717067956924438,-34.91,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Felicio_dos_Santos,2020-12-31T00:00:00,3.548821548821549,1.6986942291259766,-52.13,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Fervedouro,2020-12-31T00:00:00,1.5,1.2496813535690308,-16.69,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Formiga,2020-12-31T00:00:00,1.441791044776119,2.188431739807129,51.79,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Formoso,2020-12-31T00:00:00,3.0,2.880894422531128,-3.97,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Fortaleza_de_Minas,2020-12-31T00:00:00,1.68,1.5824346542358398,-5.81,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Guaraciaba,2020-12-31T00:00:00,1.2,1.2007423639297485,0.06,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Guiricema,2020-12-31T00:00:00,2.4,1.8570753335952759,-22.62,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Iapu,2020-12-31T00:00:00,1.0,1.5471444129943848,54.71,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Imbe_de_Minas,2020-12-31T00:00:00,1.439877300613497,1.4220643043518066,-1.24,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Inhapim,2020-12-31T00:00:00,1.8000000000000003,1.4427894353866577,-19.85,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Irai_de_Minas,2020-12-31T00:00:00,3.3595092024539883,1.8221626281738281,-45.76,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itaipe,2020-12-31T00:00:00,0.9594594594594595,0.9954173564910889,3.75,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itamarandiba,2020-12-31T00:00:00,1.7196261682242993,1.752730369567871,1.93,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Itamarati_de_Minas,2020-12-31T00:00:00,1.2,0.917269229888916,-23.56,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jequeri,2020-12-31T00:00:00,2.1,1.4538941383361816,-30.77,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jequitinhonha,2020-12-31T00:00:00,2.4,2.049777030944824,-14.59,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Jose_Goncalves_de_Minas,2020-12-31T00:00:00,1.5,1.0578970909118652,-29.47,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Lamim,2020-12-31T00:00:00,2.387096774193548,1.379240870475769,-42.22,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mantena,2020-12-31T00:00:00,0.7,0.8515823483467102,21.65,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mar_de_Espanha,2020-12-31T00:00:00,1.8000000000000003,2.088406562805176,16.02,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Mata_Verde,2020-12-31T00:00:00,1.319688109161793,1.2443902492523193,-5.71,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Matutina,2020-12-31T00:00:00,1.8299595141700402,1.9835184812545776,8.39,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Minas_Novas,2020-12-31T00:00:00,1.0,0.8899378180503845,-11.01,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Monte_Santo_de_Minas,2020-12-31T00:00:00,2.123987903619159,1.7977535724639893,-15.36,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Nova_Ponte,2020-12-31T00:00:00,1.8591549295774648,1.7750664949417114,-4.52,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Novo_Cruzeiro,2020-12-31T00:00:00,1.19727047146402,1.1244162321090698,-6.09,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Novorizonte,2020-12-31T00:00:00,1.235294117647059,1.2611507177352905,2.09,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ouro_Verde_de_Minas,2020-12-31T00:00:00,1.2,1.440423846244812,20.04,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Passos,2020-12-31T00:00:00,1.62,1.9701392650604248,21.61,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Paula_Candido,2020-12-31T00:00:00,1.62,1.4621182680130005,-9.75,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pecanha,2020-12-31T00:00:00,1.9999999999999996,1.4379006624221802,-28.1,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Azul,2020-12-31T00:00:00,1.0,1.3473408222198486,34.73,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Bonita,2020-12-31T00:00:00,1.7400000000000002,1.2087414264678955,-30.53,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_Dourada,2020-12-31T00:00:00,1.44,1.2835813760757446,-10.86,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pedra_do_Anta,2020-12-31T00:00:00,1.5,1.2896804809570312,-14.02,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Piedade_de_Caratinga,2020-12-31T00:00:00,1.8000000000000003,1.6705033779144287,-7.19,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pocrane,2020-12-31T00:00:00,1.258064516129032,1.3396962881088257,6.49,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ponto_dos_Volantes,2020-12-31T00:00:00,0.631578947368421,0.5974147319793701,-5.41,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pote,2020-12-31T00:00:00,0.6571428571428573,0.7352495193481445,11.89,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Pratinha,2020-12-31T00:00:00,2.1,1.7818876504898071,-15.15,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Quartel_Geral,2020-12-31T00:00:00,3.6000000000000005,4.286304950714111,19.06,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Ritapolis,2020-12-31T00:00:00,2.101769911504425,1.813417911529541,-13.72,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sabinopolis,2020-12-31T00:00:00,1.0,1.236415147781372,23.64,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Barbara,2020-12-31T00:00:00,1.142857142857143,1.1781102418899536,3.08,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Maria_do_Suacui,2020-12-31T00:00:00,0.8,0.8159784078598022,2.0,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Rita_de_Caldas,2020-12-31T00:00:00,1.8000000000000003,2.138274669647217,18.79,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santa_Rita_do_Itueto,2020-12-31T00:00:00,1.77,1.589919090270996,-10.17,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Santo_Antonio_do_Retiro,2020-12-31T00:00:00,0.9749999999999999,1.65891432762146,70.15,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Domingos_do_Prata,2020-12-31T00:00:00,0.8846153846153846,1.0699846744537354,20.95,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Francisco_de_Paula,2020-12-31T00:00:00,1.62,1.7234523296356201,6.39,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Geraldo,2020-12-31T00:00:00,1.8000000000000003,2.48530912399292,38.07,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Goncalo_do_Rio_Preto,2020-12-31T00:00:00,3.6000000000000005,3.8790087699890137,7.75,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Joao_do_Manteninha,2020-12-31T00:00:00,0.9166666666666665,0.8627398610115051,-5.88,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Joao_do_Paraiso,2020-12-31T00:00:00,3.146938775510204,1.9430404901504517,-38.26,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Jose_da_Barra,2020-12-31T00:00:00,2.537024221453287,2.002861738204956,-21.05,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Jose_do_Alegre,2020-12-31T00:00:00,1.359090909090909,1.469357967376709,8.11,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Miguel_do_Anta,2020-12-31T00:00:00,1.5,1.4400054216384888,-4.0,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_da_Vargem_Alegre,2020-12-31T00:00:00,1.8000000000000003,1.1862950325012207,-34.09,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_do_Anta,2020-12-31T00:00:00,1.8000000000000003,1.732420563697815,-3.75,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Sao_Sebastiao_do_Maranhao,2020-12-31T00:00:00,0.8148148148148149,0.919619083404541,12.86,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Senador_Modestino_Goncalves,2020-12-31T00:00:00,3.6000000000000005,1.7017242908477783,-52.73,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Senhora_dos_Remedios,2020-12-31T00:00:00,1.8000000000000003,1.6982121467590332,-5.65,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Simonesia,2020-12-31T00:00:00,1.8000000000000003,1.2699577808380127,-29.45,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Taiobeiras,2020-12-31T00:00:00,3.240083507306889,2.330843210220337,-28.06,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tapira,2020-12-31T00:00:00,2.1013698630136997,2.624279499053955,24.88,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Teixeiras,2020-12-31T00:00:00,1.5,1.2334705591201782,-17.77,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tocos_do_Moji,2020-12-31T00:00:00,1.441340782122905,1.7305800914764404,20.07,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Tupaciguara,2020-12-31T00:00:00,2.1,2.3736181259155273,13.03,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Uberaba,2020-12-31T00:00:00,2.5325581395348844,2.4942712783813477,-1.51,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Vargem_Grande_do_Rio_Pardo,2020-12-31T00:00:00,1.8000000000000003,1.9489063024520874,8.27,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
IBGE - Cluster V5 Metodo 1 Cluster 1 (2020),Visconde_do_Rio_Branco,2020-12-31T00:00:00,1.0,1.0374802350997925,3.75,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Metodo 1 Cluster 1 (2020)
        Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Neste teste os cluster foram usados como features do tipo true/false.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 7
        learning_rate: 0.00021750706321645716
        encoder_hidden_size: 192
        decoder_layers: 1
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.01
        steps: 100
        ",2025-09-17T11:28:32
