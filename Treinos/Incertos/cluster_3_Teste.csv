treino_id,unique_id,ds,y,y_pred,diferença_%,flag,dataset,modelo,comentario,data_treino
IBGE - Cluster V5 Cluster 3 Teste (2022),Aguanil,2012-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Aguanil,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Aguanil,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Aguanil,2015-12-31T00:00:00,0.9,1.126393437385559,25.15,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Aguanil,2016-12-31T00:00:00,1.8,1.8185113668441772,1.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Aguanil,2017-12-31T00:00:00,1.85,1.5574119091033936,15.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Aguanil,2018-12-31T00:00:00,2.1,2.0167953968048096,3.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Aguanil,2019-12-31T00:00:00,1.8,1.7853360176086426,0.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Aguanil,2020-12-31T00:00:00,2.16,2.178560733795166,0.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Aiuruoca,2012-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Aiuruoca,2013-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Aiuruoca,2014-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Aiuruoca,2015-12-31T00:00:00,1.09,1.3395884037017822,22.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Aiuruoca,2016-12-31T00:00:00,1.19,1.1738426685333252,1.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Aiuruoca,2017-12-31T00:00:00,1.5,1.286688208580017,14.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Aiuruoca,2018-12-31T00:00:00,1.77,1.7043986320495605,3.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Aiuruoca,2019-12-31T00:00:00,1.54,1.5178041458129883,1.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Aiuruoca,2020-12-31T00:00:00,1.8,1.7727771997451782,1.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Albertina,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Albertina,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Albertina,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Albertina,2015-12-31T00:00:00,1.08,1.0572668313980103,2.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Albertina,2016-12-31T00:00:00,1.2,1.1804651021957397,1.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Albertina,2017-12-31T00:00:00,1.83,1.2083337306976318,33.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Albertina,2018-12-31T00:00:00,1.56,1.8544076681137085,18.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Albertina,2019-12-31T00:00:00,1.56,1.3520430326461792,13.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Albertina,2020-12-31T00:00:00,1.68,1.6784675121307373,0.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Alfenas,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Alfenas,2013-12-31T00:00:00,1.98,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Alfenas,2014-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Alfenas,2015-12-31T00:00:00,1.38,1.4076669216156006,2.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Alfenas,2016-12-31T00:00:00,2.25,2.273171901702881,1.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Alfenas,2017-12-31T00:00:00,1.68,1.694514513015747,0.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Alfenas,2018-12-31T00:00:00,2.34,2.265702247619629,3.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Alfenas,2019-12-31T00:00:00,1.76,1.839930534362793,4.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Alfenas,2020-12-31T00:00:00,2.36,2.5685181617736816,8.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Alterosa,2012-12-31T00:00:00,1.59,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Alterosa,2013-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Alterosa,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Alterosa,2015-12-31T00:00:00,1.08,1.1449506282806396,6.01,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Alterosa,2016-12-31T00:00:00,1.92,1.911529779434204,0.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Alterosa,2017-12-31T00:00:00,1.8,2.040369987487793,13.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Alterosa,2018-12-31T00:00:00,1.96,1.9030728340148926,2.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Alterosa,2019-12-31T00:00:00,1.74,1.728324294090271,0.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Alterosa,2020-12-31T00:00:00,1.98,1.9327319860458374,2.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Andradas,2012-12-31T00:00:00,1.98,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Andradas,2013-12-31T00:00:00,1.59,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Andradas,2014-12-31T00:00:00,1.21,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Andradas,2015-12-31T00:00:00,1.89,1.9360765218734741,2.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Andradas,2016-12-31T00:00:00,1.8,1.784386157989502,0.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Andradas,2017-12-31T00:00:00,1.34,1.6195204257965088,20.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Andradas,2018-12-31T00:00:00,1.73,1.748262643814087,1.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Andradas,2019-12-31T00:00:00,1.62,1.5387027263641357,5.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Andradas,2020-12-31T00:00:00,2.57,2.579953193664551,0.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Andrelandia,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Andrelandia,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Andrelandia,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Andrelandia,2015-12-31T00:00:00,1.2,0.9024451971054077,24.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Andrelandia,2016-12-31T00:00:00,1.5,1.5123846530914307,0.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Andrelandia,2017-12-31T00:00:00,1.4,1.469572901725769,4.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Andrelandia,2018-12-31T00:00:00,1.5,1.5073386430740356,0.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Andrelandia,2019-12-31T00:00:00,1.5,1.4843182563781738,1.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Andrelandia,2020-12-31T00:00:00,1.8,1.800459384918213,0.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Arceburgo,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Arceburgo,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Arceburgo,2014-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Arceburgo,2015-12-31T00:00:00,1.32,1.263343095779419,4.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Arceburgo,2016-12-31T00:00:00,1.8,1.749886393547058,2.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Arceburgo,2017-12-31T00:00:00,1.02,1.222806453704834,19.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Arceburgo,2018-12-31T00:00:00,1.72,1.7584545612335205,2.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Arceburgo,2019-12-31T00:00:00,1.5,1.4324111938476562,4.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Arceburgo,2020-12-31T00:00:00,1.84,1.7707738876342773,3.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Baependi,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Baependi,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Baependi,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Baependi,2015-12-31T00:00:00,0.84,1.0688031911849976,27.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Baependi,2016-12-31T00:00:00,1.8,1.6738616228103638,7.01,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Baependi,2017-12-31T00:00:00,1.56,1.8481991291046143,18.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Baependi,2018-12-31T00:00:00,1.56,2.3602499961853027,51.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Baependi,2019-12-31T00:00:00,1.44,1.5299662351608276,6.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Baependi,2020-12-31T00:00:00,1.68,1.709030270576477,1.73,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bandeira_do_Sul,2012-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bandeira_do_Sul,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bandeira_do_Sul,2014-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bandeira_do_Sul,2015-12-31T00:00:00,1.26,1.353456735610962,7.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bandeira_do_Sul,2016-12-31T00:00:00,1.5,1.4864447116851807,0.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bandeira_do_Sul,2017-12-31T00:00:00,1.76,1.6280832290649414,7.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bandeira_do_Sul,2018-12-31T00:00:00,1.8,1.5937882661819458,11.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bandeira_do_Sul,2019-12-31T00:00:00,1.5,1.5514271259307861,3.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bandeira_do_Sul,2020-12-31T00:00:00,1.5,1.502932071685791,0.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Boa_Esperanca,2012-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Boa_Esperanca,2013-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Boa_Esperanca,2014-12-31T00:00:00,1.15,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Boa_Esperanca,2015-12-31T00:00:00,1.26,1.2896065711975098,2.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Boa_Esperanca,2016-12-31T00:00:00,1.92,1.914124608039856,0.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Boa_Esperanca,2017-12-31T00:00:00,2.53,2.048102855682373,19.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Boa_Esperanca,2018-12-31T00:00:00,1.8,2.1167550086975098,17.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Boa_Esperanca,2019-12-31T00:00:00,1.92,1.608019471168518,16.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Boa_Esperanca,2020-12-31T00:00:00,2.06,2.4031407833099365,16.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bom_Sucesso,2012-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bom_Sucesso,2013-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bom_Sucesso,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bom_Sucesso,2015-12-31T00:00:00,1.14,1.2158679962158203,6.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bom_Sucesso,2016-12-31T00:00:00,1.92,1.9792730808258057,3.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bom_Sucesso,2017-12-31T00:00:00,1.48,1.698544979095459,14.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bom_Sucesso,2018-12-31T00:00:00,1.7,1.7382152080535889,2.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bom_Sucesso,2019-12-31T00:00:00,1.5,1.5327339172363281,2.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bom_Sucesso,2020-12-31T00:00:00,2.1,2.109360694885254,0.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Borda_da_Mata,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Borda_da_Mata,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Borda_da_Mata,2014-12-31T00:00:00,0.78,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Borda_da_Mata,2015-12-31T00:00:00,1.2,1.1795347929000854,1.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Borda_da_Mata,2016-12-31T00:00:00,1.8,1.7343642711639404,3.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Borda_da_Mata,2017-12-31T00:00:00,1.67,1.4841914176940918,11.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Borda_da_Mata,2018-12-31T00:00:00,1.8,1.758188247680664,2.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Borda_da_Mata,2019-12-31T00:00:00,1.56,1.5987656116485596,2.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Borda_da_Mata,2020-12-31T00:00:00,1.62,1.726149082183838,6.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Brazopolis,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Brazopolis,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Brazopolis,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Brazopolis,2015-12-31T00:00:00,1.08,1.1453897953033447,6.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Brazopolis,2016-12-31T00:00:00,1.44,1.4109947681427002,2.01,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Brazopolis,2017-12-31T00:00:00,0.63,1.3022198677062988,106.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Brazopolis,2018-12-31T00:00:00,1.56,1.4272468090057373,8.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Brazopolis,2019-12-31T00:00:00,1.56,1.5137765407562256,2.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Brazopolis,2020-12-31T00:00:00,1.68,1.6130719184875488,3.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bueno_Brandao,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bueno_Brandao,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bueno_Brandao,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bueno_Brandao,2015-12-31T00:00:00,1.26,1.2605946063995361,0.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bueno_Brandao,2016-12-31T00:00:00,2.1,2.073871374130249,1.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bueno_Brandao,2017-12-31T00:00:00,1.2,1.084763765335083,9.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bueno_Brandao,2018-12-31T00:00:00,1.8,2.055253505706787,14.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bueno_Brandao,2019-12-31T00:00:00,1.56,1.5115649700164795,3.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bueno_Brandao,2020-12-31T00:00:00,1.8,1.6241081953048706,9.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cachoeira_de_Minas,2012-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cachoeira_de_Minas,2013-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cachoeira_de_Minas,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cachoeira_de_Minas,2015-12-31T00:00:00,1.02,1.1756480932235718,15.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cachoeira_de_Minas,2016-12-31T00:00:00,1.56,1.5480884313583374,0.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cachoeira_de_Minas,2017-12-31T00:00:00,2.28,1.898269534111023,16.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cachoeira_de_Minas,2018-12-31T00:00:00,2.2,2.1775195598602295,1.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cachoeira_de_Minas,2019-12-31T00:00:00,1.68,1.7202436923980713,2.4,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cachoeira_de_Minas,2020-12-31T00:00:00,1.86,1.8761223554611206,0.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Caete,2012-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Caete,2013-12-31T00:00:00,0.93,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Caete,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Caete,2015-12-31T00:00:00,1.08,1.0782467126846313,0.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Caete,2016-12-31T00:00:00,1.2,1.217474102973938,1.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Caete,2017-12-31T00:00:00,1.53,1.5209884643554688,0.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Caete,2018-12-31T00:00:00,1.5,1.4948649406433105,0.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Caete,2019-12-31T00:00:00,1.31,1.2886394262313843,1.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Caete,2020-12-31T00:00:00,1.2,1.1927967071533203,0.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Camacho,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Camacho,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Camacho,2014-12-31T00:00:00,0.67,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Camacho,2015-12-31T00:00:00,1.02,1.0835469961166382,6.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Camacho,2016-12-31T00:00:00,1.5,1.5331718921661377,2.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Camacho,2017-12-31T00:00:00,1.73,1.3260893821716309,23.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Camacho,2018-12-31T00:00:00,1.8,1.8671314716339111,3.73,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Camacho,2019-12-31T00:00:00,1.5,1.4430168867111206,3.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Camacho,2020-12-31T00:00:00,2.1,2.054327964782715,2.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cambuquira,2012-12-31T00:00:00,1.15,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cambuquira,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cambuquira,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cambuquira,2015-12-31T00:00:00,1.08,1.0496588945388794,2.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cambuquira,2016-12-31T00:00:00,1.68,1.6798237562179565,0.01,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cambuquira,2017-12-31T00:00:00,1.82,1.8473259210586548,1.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cambuquira,2018-12-31T00:00:00,1.74,1.8099424839019775,4.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cambuquira,2019-12-31T00:00:00,1.68,1.6724704504013062,0.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cambuquira,2020-12-31T00:00:00,1.8,1.7543561458587646,2.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campanha,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campanha,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campanha,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campanha,2015-12-31T00:00:00,1.02,1.0805156230926514,5.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campanha,2016-12-31T00:00:00,1.5,1.4955006837844849,0.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campanha,2017-12-31T00:00:00,1.88,1.6371111869812012,12.92,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campanha,2018-12-31T00:00:00,1.8,1.7902402877807617,0.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campanha,2019-12-31T00:00:00,1.51,1.4562304019927979,3.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campanha,2020-12-31T00:00:00,1.68,1.7181012630462646,2.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campestre,2012-12-31T00:00:00,1.35,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campestre,2013-12-31T00:00:00,1.31,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campestre,2014-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campestre,2015-12-31T00:00:00,1.91,1.5064771175384521,21.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campestre,2016-12-31T00:00:00,1.85,2.7601733207702637,49.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campestre,2017-12-31T00:00:00,2.11,2.225820302963257,5.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campestre,2018-12-31T00:00:00,1.54,1.9312217235565186,25.4,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campestre,2019-12-31T00:00:00,1.55,1.6184792518615723,4.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campestre,2020-12-31T00:00:00,2.14,2.0810985565185547,2.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campo_Belo,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campo_Belo,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campo_Belo,2014-12-31T00:00:00,0.63,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campo_Belo,2015-12-31T00:00:00,0.84,0.8211667537689209,2.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campo_Belo,2016-12-31T00:00:00,1.62,1.588972568511963,1.92,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campo_Belo,2017-12-31T00:00:00,1.32,1.5025696754455566,13.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campo_Belo,2018-12-31T00:00:00,1.26,1.460540533065796,15.92,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campo_Belo,2019-12-31T00:00:00,1.26,1.2082725763320923,4.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campo_Belo,2020-12-31T00:00:00,1.8,1.3817040920257568,23.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campo_do_Meio,2012-12-31T00:00:00,1.17,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campo_do_Meio,2013-12-31T00:00:00,1.17,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campo_do_Meio,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campo_do_Meio,2015-12-31T00:00:00,0.9,0.8565513491630554,4.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campo_do_Meio,2016-12-31T00:00:00,1.8,1.8054357767105103,0.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campo_do_Meio,2017-12-31T00:00:00,2.08,1.7980027198791504,13.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campo_do_Meio,2018-12-31T00:00:00,1.82,1.953467845916748,7.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campo_do_Meio,2019-12-31T00:00:00,1.62,1.6117018461227417,0.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campo_do_Meio,2020-12-31T00:00:00,2.4,2.074086904525757,13.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campos_Gerais,2012-12-31T00:00:00,1.65,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campos_Gerais,2013-12-31T00:00:00,1.22,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campos_Gerais,2014-12-31T00:00:00,1.15,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campos_Gerais,2015-12-31T00:00:00,1.32,1.4051659107208252,6.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campos_Gerais,2016-12-31T00:00:00,2.5,2.577728271484375,3.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campos_Gerais,2017-12-31T00:00:00,1.81,2.443883180618286,35.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campos_Gerais,2018-12-31T00:00:00,2.21,2.1551008224487305,2.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campos_Gerais,2019-12-31T00:00:00,1.59,1.6349917650222778,2.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campos_Gerais,2020-12-31T00:00:00,2.69,2.2443103790283203,16.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Candeias,2012-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Candeias,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Candeias,2014-12-31T00:00:00,0.99,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Candeias,2015-12-31T00:00:00,1.2,1.1673603057861328,2.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Candeias,2016-12-31T00:00:00,2.28,2.263291597366333,0.73,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Candeias,2017-12-31T00:00:00,1.38,2.332890748977661,69.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Candeias,2018-12-31T00:00:00,2.04,2.0322117805480957,0.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Candeias,2019-12-31T00:00:00,1.5,1.5412391424179077,2.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Candeias,2020-12-31T00:00:00,1.86,1.7451794147491455,6.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Capetinga,2012-12-31T00:00:00,1.81,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Capetinga,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Capetinga,2014-12-31T00:00:00,1.59,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Capetinga,2015-12-31T00:00:00,1.2,1.344696044921875,12.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Capetinga,2016-12-31T00:00:00,1.93,2.0189566612243652,4.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Capetinga,2017-12-31T00:00:00,2.09,2.064763307571411,1.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Capetinga,2018-12-31T00:00:00,2.7,2.655355453491211,1.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Capetinga,2019-12-31T00:00:00,2.04,1.9944812059402466,2.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Capetinga,2020-12-31T00:00:00,2.21,2.1980466842651367,0.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Capitolio,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Capitolio,2013-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Capitolio,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Capitolio,2015-12-31T00:00:00,1.2,1.1594808101654053,3.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Capitolio,2016-12-31T00:00:00,1.32,1.3478591442108154,2.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Capitolio,2017-12-31T00:00:00,1.47,1.344056248664856,8.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Capitolio,2018-12-31T00:00:00,1.8,1.8185449838638306,1.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Capitolio,2019-12-31T00:00:00,1.5,1.4428696632385254,3.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Capitolio,2020-12-31T00:00:00,2.1,2.043941020965576,2.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_da_Cachoeira,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_da_Cachoeira,2013-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_da_Cachoeira,2014-12-31T00:00:00,1.15,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_da_Cachoeira,2015-12-31T00:00:00,1.26,1.218221664428711,3.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_da_Cachoeira,2016-12-31T00:00:00,1.44,1.5076446533203125,4.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_da_Cachoeira,2017-12-31T00:00:00,1.73,1.518888235092163,12.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_da_Cachoeira,2018-12-31T00:00:00,1.98,1.7004674673080444,14.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_da_Cachoeira,2019-12-31T00:00:00,1.62,1.6341171264648438,0.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_da_Cachoeira,2020-12-31T00:00:00,1.8,1.9285781383514404,7.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_de_Minas,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_de_Minas,2013-12-31T00:00:00,1.74,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_de_Minas,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_de_Minas,2015-12-31T00:00:00,1.32,1.4533734321594238,10.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_de_Minas,2016-12-31T00:00:00,1.5,1.3740787506103516,8.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_de_Minas,2017-12-31T00:00:00,1.38,1.5155961513519287,9.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_de_Minas,2018-12-31T00:00:00,1.56,1.4913239479064941,4.4,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_de_Minas,2019-12-31T00:00:00,1.5,1.5074912309646606,0.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_de_Minas,2020-12-31T00:00:00,1.74,1.7540587186813354,0.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_do_Rio_Claro,2012-12-31T00:00:00,1.66,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_do_Rio_Claro,2013-12-31T00:00:00,1.94,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_do_Rio_Claro,2014-12-31T00:00:00,1.65,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_do_Rio_Claro,2015-12-31T00:00:00,1.53,1.552680492401123,1.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_do_Rio_Claro,2016-12-31T00:00:00,2.37,2.3445420265197754,1.07,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_do_Rio_Claro,2017-12-31T00:00:00,1.82,2.0533275604248047,12.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_do_Rio_Claro,2018-12-31T00:00:00,2.22,2.4012553691864014,8.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_do_Rio_Claro,2019-12-31T00:00:00,1.94,1.9195064306259155,1.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_do_Rio_Claro,2020-12-31T00:00:00,2.78,2.766645669937134,0.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carvalhopolis,2012-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carvalhopolis,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carvalhopolis,2014-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carvalhopolis,2015-12-31T00:00:00,1.44,1.4887630939483643,3.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carvalhopolis,2016-12-31T00:00:00,1.8,1.8021996021270752,0.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carvalhopolis,2017-12-31T00:00:00,1.44,1.5414718389511108,7.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carvalhopolis,2018-12-31T00:00:00,1.56,1.7179110050201416,10.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carvalhopolis,2019-12-31T00:00:00,1.56,1.484819769859314,4.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carvalhopolis,2020-12-31T00:00:00,1.68,1.6995179653167725,1.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cassia,2012-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cassia,2013-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cassia,2014-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cassia,2015-12-31T00:00:00,1.14,1.1511542797088623,0.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cassia,2016-12-31T00:00:00,1.56,1.5154261589050293,2.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cassia,2017-12-31T00:00:00,1.6,1.582983136177063,1.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cassia,2018-12-31T00:00:00,2.1,2.1509594917297363,2.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cassia,2019-12-31T00:00:00,1.56,1.5186069011688232,2.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cassia,2020-12-31T00:00:00,2.17,2.2024831771850586,1.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_da_Barra_de_Minas,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_da_Barra_de_Minas,2013-12-31T00:00:00,1.46,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_da_Barra_de_Minas,2014-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_da_Barra_de_Minas,2015-12-31T00:00:00,1.2,1.5295166969299316,27.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_da_Barra_de_Minas,2016-12-31T00:00:00,2.1,2.0996294021606445,0.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_da_Barra_de_Minas,2017-12-31T00:00:00,2.63,2.4252305030822754,7.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_da_Barra_de_Minas,2018-12-31T00:00:00,2.08,2.302903175354004,10.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_da_Barra_de_Minas,2019-12-31T00:00:00,1.67,1.792647123336792,7.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_da_Barra_de_Minas,2020-12-31T00:00:00,1.91,1.9637973308563232,2.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_das_Pedras,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_das_Pedras,2013-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_das_Pedras,2014-12-31T00:00:00,1.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_das_Pedras,2015-12-31T00:00:00,1.26,1.234419345855713,2.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_das_Pedras,2016-12-31T00:00:00,1.44,1.3724374771118164,4.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_das_Pedras,2017-12-31T00:00:00,1.47,1.3095656633377075,10.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_das_Pedras,2018-12-31T00:00:00,1.56,1.5453662872314453,0.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_das_Pedras,2019-12-31T00:00:00,1.68,1.4844985008239746,11.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_das_Pedras,2020-12-31T00:00:00,1.74,1.765197992324829,1.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_do_Rio_Verde,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_do_Rio_Verde,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_do_Rio_Verde,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_do_Rio_Verde,2015-12-31T00:00:00,1.62,1.192626953125,26.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_do_Rio_Verde,2016-12-31T00:00:00,1.62,1.7652950286865234,8.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_do_Rio_Verde,2017-12-31T00:00:00,2.04,2.0887508392333984,2.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_do_Rio_Verde,2018-12-31T00:00:00,1.98,2.016972303390503,1.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_do_Rio_Verde,2019-12-31T00:00:00,1.8,1.7063031196594238,5.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_do_Rio_Verde,2020-12-31T00:00:00,1.8,1.8649394512176514,3.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_dos_Ouros,2012-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_dos_Ouros,2013-12-31T00:00:00,1.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_dos_Ouros,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_dos_Ouros,2015-12-31T00:00:00,1.32,1.3074071407318115,0.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_dos_Ouros,2016-12-31T00:00:00,1.5,1.5032029151916504,0.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_dos_Ouros,2017-12-31T00:00:00,1.52,1.5465846061706543,1.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_dos_Ouros,2018-12-31T00:00:00,1.5,1.5144667625427246,0.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_dos_Ouros,2019-12-31T00:00:00,1.5,1.5044353008270264,0.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_dos_Ouros,2020-12-31T00:00:00,1.5,1.5062487125396729,0.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Coqueiral,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Coqueiral,2013-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Coqueiral,2014-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Coqueiral,2015-12-31T00:00:00,1.26,1.1490046977996826,8.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Coqueiral,2016-12-31T00:00:00,1.68,1.759671926498413,4.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Coqueiral,2017-12-31T00:00:00,1.75,1.7117698192596436,2.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Coqueiral,2018-12-31T00:00:00,1.8,1.6728827953338623,7.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Coqueiral,2019-12-31T00:00:00,1.5,1.632660150527954,8.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Coqueiral,2020-12-31T00:00:00,2.16,1.791497826576233,17.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cordislandia,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cordislandia,2013-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cordislandia,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cordislandia,2015-12-31T00:00:00,1.26,1.1047663688659668,12.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cordislandia,2016-12-31T00:00:00,1.62,1.6032862663269043,1.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cordislandia,2017-12-31T00:00:00,2.1,1.7952643632888794,14.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cordislandia,2018-12-31T00:00:00,1.86,1.9807875156402588,6.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cordislandia,2019-12-31T00:00:00,1.5,1.4061062335968018,6.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cordislandia,2020-12-31T00:00:00,1.62,1.8525681495666504,14.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Corrego_Danta,2012-12-31T00:00:00,1.25,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Corrego_Danta,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Corrego_Danta,2014-12-31T00:00:00,1.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Corrego_Danta,2015-12-31T00:00:00,1.32,1.3089135885238647,0.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Corrego_Danta,2016-12-31T00:00:00,1.5,1.4683517217636108,2.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Corrego_Danta,2017-12-31T00:00:00,1.44,1.4795517921447754,2.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Corrego_Danta,2018-12-31T00:00:00,1.8,1.800339937210083,0.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Corrego_Danta,2019-12-31T00:00:00,1.5,1.5296143293380737,1.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Corrego_Danta,2020-12-31T00:00:00,1.8,1.7671184539794922,1.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cristais,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cristais,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cristais,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cristais,2015-12-31T00:00:00,1.2,1.2401188611984253,3.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cristais,2016-12-31T00:00:00,1.92,1.8880259990692139,1.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cristais,2017-12-31T00:00:00,2.4,2.076936721801758,13.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cristais,2018-12-31T00:00:00,1.92,2.0822598934173584,8.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cristais,2019-12-31T00:00:00,1.74,1.8000404834747314,3.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cristais,2020-12-31T00:00:00,1.92,1.9961658716201782,3.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cristina,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cristina,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cristina,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cristina,2015-12-31T00:00:00,1.08,1.092525839805603,1.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cristina,2016-12-31T00:00:00,1.44,1.4243699312210083,1.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cristina,2017-12-31T00:00:00,1.62,1.6067754030227661,0.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cristina,2018-12-31T00:00:00,1.56,1.555633783340454,0.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cristina,2019-12-31T00:00:00,1.5,1.5016939640045166,0.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cristina,2020-12-31T00:00:00,2.1,1.7641509771347046,15.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Delfinopolis,2012-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Delfinopolis,2013-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Delfinopolis,2014-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Delfinopolis,2015-12-31T00:00:00,1.32,1.2784452438354492,3.15,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Delfinopolis,2016-12-31T00:00:00,1.5,1.5266669988632202,1.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Delfinopolis,2017-12-31T00:00:00,1.24,1.3035051822662354,5.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Delfinopolis,2018-12-31T00:00:00,1.8,1.8242311477661133,1.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Delfinopolis,2019-12-31T00:00:00,1.56,1.5131242275238037,3.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Delfinopolis,2020-12-31T00:00:00,1.8,1.8687483072280884,3.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Desterro_de_Entre_Rios,2012-12-31T00:00:00,0.57,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Desterro_de_Entre_Rios,2013-12-31T00:00:00,0.57,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Desterro_de_Entre_Rios,2014-12-31T00:00:00,3.28,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Desterro_de_Entre_Rios,2015-12-31T00:00:00,1.51,1.4941978454589844,1.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Desterro_de_Entre_Rios,2016-12-31T00:00:00,2.28,2.060781955718994,9.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Desterro_de_Entre_Rios,2017-12-31T00:00:00,2.08,2.0062034130096436,3.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Desterro_de_Entre_Rios,2018-12-31T00:00:00,2.1,2.1249639987945557,1.19,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Desterro_de_Entre_Rios,2019-12-31T00:00:00,1.8,1.771649956703186,1.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Desterro_de_Entre_Rios,2020-12-31T00:00:00,2.4,2.372910261154175,1.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Divinesia,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Divinesia,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Divinesia,2014-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Divinesia,2015-12-31T00:00:00,1.5,1.3796474933624268,8.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Divinesia,2016-12-31T00:00:00,1.8,1.8092100620269775,0.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Divinesia,2017-12-31T00:00:00,2.04,2.027653217315674,0.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Divinesia,2018-12-31T00:00:00,4.0,3.4138410091400146,14.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Divinesia,2019-12-31T00:00:00,2.0,2.2518415451049805,12.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Divinesia,2020-12-31T00:00:00,2.1,1.9753661155700684,5.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Divisa_Nova,2012-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Divisa_Nova,2013-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Divisa_Nova,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Divisa_Nova,2015-12-31T00:00:00,1.08,1.1528542041778564,6.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Divisa_Nova,2016-12-31T00:00:00,1.68,1.6052100658416748,4.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Divisa_Nova,2017-12-31T00:00:00,2.28,2.019662857055664,11.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Divisa_Nova,2018-12-31T00:00:00,1.8,2.0183424949645996,12.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Divisa_Nova,2019-12-31T00:00:00,1.8,1.6372723579406738,9.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Divisa_Nova,2020-12-31T00:00:00,1.8,1.7913806438446045,0.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Dom_Vicoso,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Dom_Vicoso,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Dom_Vicoso,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Dom_Vicoso,2015-12-31T00:00:00,1.32,1.2036426067352295,8.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Dom_Vicoso,2016-12-31T00:00:00,1.5,1.4888365268707275,0.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Dom_Vicoso,2017-12-31T00:00:00,1.16,1.5008888244628906,29.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Dom_Vicoso,2018-12-31T00:00:00,1.5,1.5223315954208374,1.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Dom_Vicoso,2019-12-31T00:00:00,1.65,1.5888912677764893,3.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Dom_Vicoso,2020-12-31T00:00:00,1.43,1.4303202629089355,0.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Doresopolis,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Doresopolis,2013-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Doresopolis,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Doresopolis,2015-12-31T00:00:00,1.2,1.205399513244629,0.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Doresopolis,2016-12-31T00:00:00,1.26,1.2673451900482178,0.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Doresopolis,2017-12-31T00:00:00,1.43,1.440500259399414,0.73,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Doresopolis,2018-12-31T00:00:00,1.8,1.8962135314941406,5.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Doresopolis,2019-12-31T00:00:00,1.74,1.6709582805633545,3.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Doresopolis,2020-12-31T00:00:00,1.8,1.7646162509918213,1.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Eloi_Mendes,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Eloi_Mendes,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Eloi_Mendes,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Eloi_Mendes,2015-12-31T00:00:00,1.26,1.2366609573364258,1.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Eloi_Mendes,2016-12-31T00:00:00,1.74,1.7141711711883545,1.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Eloi_Mendes,2017-12-31T00:00:00,1.83,2.0925068855285645,14.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Eloi_Mendes,2018-12-31T00:00:00,1.72,1.8199249505996704,5.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Eloi_Mendes,2019-12-31T00:00:00,1.5,1.6456210613250732,9.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Eloi_Mendes,2020-12-31T00:00:00,2.11,1.8249156475067139,13.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Entre_Rios_de_Minas,2012-12-31T00:00:00,1.58,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Entre_Rios_de_Minas,2013-12-31T00:00:00,1.58,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Entre_Rios_de_Minas,2014-12-31T00:00:00,1.58,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Entre_Rios_de_Minas,2015-12-31T00:00:00,1.63,1.5806834697723389,3.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Entre_Rios_de_Minas,2016-12-31T00:00:00,2.4,2.0625693798065186,14.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Entre_Rios_de_Minas,2017-12-31T00:00:00,2.28,2.2557930946350098,1.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Entre_Rios_de_Minas,2018-12-31T00:00:00,2.1,2.201794147491455,4.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Entre_Rios_de_Minas,2019-12-31T00:00:00,1.92,1.904496669769287,0.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Entre_Rios_de_Minas,2020-12-31T00:00:00,1.8,1.8132057189941406,0.73,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Fama,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Fama,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Fama,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Fama,2015-12-31T00:00:00,1.08,1.1601883172988892,7.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Fama,2016-12-31T00:00:00,1.68,1.263162612915039,24.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Fama,2017-12-31T00:00:00,1.32,1.850978136062622,40.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Fama,2018-12-31T00:00:00,1.51,1.6574853658676147,9.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Fama,2019-12-31T00:00:00,1.62,1.5003535747528076,7.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Fama,2020-12-31T00:00:00,1.8,1.7608236074447632,2.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Grao_Mogol,2012-12-31T00:00:00,0.3,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Grao_Mogol,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Grao_Mogol,2014-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Grao_Mogol,2015-12-31T00:00:00,0.9,0.9318410158157349,3.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Grao_Mogol,2016-12-31T00:00:00,0.6,0.5555824637413025,7.4,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Grao_Mogol,2017-12-31T00:00:00,3.5,3.4353959560394287,1.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Grao_Mogol,2018-12-31T00:00:00,1.0,0.9878864288330078,1.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Grao_Mogol,2019-12-31T00:00:00,0.73,0.6750698089599609,7.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Grao_Mogol,2020-12-31T00:00:00,0.77,0.6611941456794739,14.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Guape,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Guape,2013-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Guape,2014-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Guape,2015-12-31T00:00:00,1.8,1.5701966285705566,12.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Guape,2016-12-31T00:00:00,1.92,1.8680387735366821,2.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Guape,2017-12-31T00:00:00,1.92,1.5269814729690552,20.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Guape,2018-12-31T00:00:00,2.1,2.0173325538635254,3.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Guape,2019-12-31T00:00:00,1.62,1.6702505350112915,3.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Guape,2020-12-31T00:00:00,1.85,2.1251349449157715,14.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Heliodora,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Heliodora,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Heliodora,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Heliodora,2015-12-31T00:00:00,1.2,1.0890488624572754,9.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Heliodora,2016-12-31T00:00:00,1.5,1.540331244468689,2.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Heliodora,2017-12-31T00:00:00,1.57,1.3917725086212158,11.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Heliodora,2018-12-31T00:00:00,1.8,1.7839796543121338,0.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Heliodora,2019-12-31T00:00:00,1.56,1.5898396968841553,1.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Heliodora,2020-12-31T00:00:00,1.8,1.8637425899505615,3.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ibituruna,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ibituruna,2013-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ibituruna,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ibituruna,2015-12-31T00:00:00,1.2,1.1396442651748657,5.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ibituruna,2016-12-31T00:00:00,1.74,1.7802077531814575,2.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ibituruna,2017-12-31T00:00:00,1.62,1.48868727684021,8.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ibituruna,2018-12-31T00:00:00,1.66,1.7136754989624023,3.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ibituruna,2019-12-31T00:00:00,1.66,1.652944564819336,0.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ibituruna,2020-12-31T00:00:00,1.8,1.80424165725708,0.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ijaci,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ijaci,2013-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ijaci,2014-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ijaci,2015-12-31T00:00:00,0.84,0.915867030620575,9.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ijaci,2016-12-31T00:00:00,1.8,1.8380539417266846,2.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ijaci,2017-12-31T00:00:00,1.25,1.390913724899292,11.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ijaci,2018-12-31T00:00:00,2.0,1.8964227437973022,5.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ijaci,2019-12-31T00:00:00,1.42,1.3949439525604248,1.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ijaci,2020-12-31T00:00:00,2.46,2.267709970474243,7.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ilicinea,2012-12-31T00:00:00,1.69,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ilicinea,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ilicinea,2014-12-31T00:00:00,1.35,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ilicinea,2015-12-31T00:00:00,1.5,1.5208892822265625,1.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ilicinea,2016-12-31T00:00:00,2.46,2.4491355419158936,0.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ilicinea,2017-12-31T00:00:00,1.92,2.3361706733703613,21.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ilicinea,2018-12-31T00:00:00,2.46,2.200718641281128,10.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ilicinea,2019-12-31T00:00:00,1.86,1.5820646286010742,14.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ilicinea,2020-12-31T00:00:00,2.1,2.4790658950805664,18.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Inconfidentes,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Inconfidentes,2013-12-31T00:00:00,1.4,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Inconfidentes,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Inconfidentes,2015-12-31T00:00:00,1.2,1.1259416341781616,6.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Inconfidentes,2016-12-31T00:00:00,2.1,2.0682930946350098,1.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Inconfidentes,2017-12-31T00:00:00,1.3,0.9964470267295837,23.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Inconfidentes,2018-12-31T00:00:00,2.88,2.277509927749634,20.92,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Inconfidentes,2019-12-31T00:00:00,1.5,1.606284737586975,7.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Inconfidentes,2020-12-31T00:00:00,2.46,3.102086305618286,26.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ingai,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ingai,2013-12-31T00:00:00,1.68,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ingai,2014-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ingai,2015-12-31T00:00:00,1.2,1.1669929027557373,2.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ingai,2016-12-31T00:00:00,1.74,1.8600788116455078,6.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ingai,2017-12-31T00:00:00,2.22,1.8742481470108032,15.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ingai,2018-12-31T00:00:00,1.8,2.020658493041992,12.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ingai,2019-12-31T00:00:00,1.5,1.570397138595581,4.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ingai,2020-12-31T00:00:00,1.68,1.6583564281463623,1.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itajuba,2012-12-31T00:00:00,0.91,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itajuba,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itajuba,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itajuba,2015-12-31T00:00:00,1.5,1.5658860206604004,4.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itajuba,2016-12-31T00:00:00,1.8,1.8210391998291016,1.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itajuba,2017-12-31T00:00:00,2.33,2.2145752906799316,4.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itajuba,2018-12-31T00:00:00,1.82,2.0536632537841797,12.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itajuba,2019-12-31T00:00:00,1.82,1.7428207397460938,4.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itajuba,2020-12-31T00:00:00,1.59,1.764763355255127,10.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itamogi,2012-12-31T00:00:00,1.95,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itamogi,2013-12-31T00:00:00,1.17,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itamogi,2014-12-31T00:00:00,1.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itamogi,2015-12-31T00:00:00,1.58,1.4440326690673828,8.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itamogi,2016-12-31T00:00:00,1.95,1.9312262535095215,0.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itamogi,2017-12-31T00:00:00,1.42,1.4186798334121704,0.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itamogi,2018-12-31T00:00:00,2.1,2.1690826416015625,3.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itamogi,2019-12-31T00:00:00,1.85,1.83119535446167,1.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itamogi,2020-12-31T00:00:00,2.4,2.369917392730713,1.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itapecerica,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itapecerica,2013-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itapecerica,2014-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itapecerica,2015-12-31T00:00:00,1.2,1.2782611846923828,6.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itapecerica,2016-12-31T00:00:00,1.5,1.4606966972351074,2.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itapecerica,2017-12-31T00:00:00,1.56,1.338392734527588,14.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itapecerica,2018-12-31T00:00:00,1.8,1.7922463417053223,0.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itapecerica,2019-12-31T00:00:00,1.2,1.3007378578186035,8.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itapecerica,2020-12-31T00:00:00,1.8,1.76029634475708,2.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itumirim,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itumirim,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itumirim,2014-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itumirim,2015-12-31T00:00:00,1.08,1.0757912397384644,0.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itumirim,2016-12-31T00:00:00,1.62,1.622851848602295,0.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itumirim,2017-12-31T00:00:00,1.32,1.5111117362976074,14.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itumirim,2018-12-31T00:00:00,1.8,1.5575119256973267,13.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itumirim,2019-12-31T00:00:00,1.6,1.6023025512695312,0.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itumirim,2020-12-31T00:00:00,2.05,1.9822287559509277,3.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itutinga,2012-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itutinga,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itutinga,2014-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itutinga,2015-12-31T00:00:00,1.26,1.2469451427459717,1.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itutinga,2016-12-31T00:00:00,1.68,1.4038385152816772,16.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itutinga,2017-12-31T00:00:00,1.49,1.5465617179870605,3.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itutinga,2018-12-31T00:00:00,1.52,1.5554981231689453,2.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itutinga,2019-12-31T00:00:00,1.52,1.5078012943267822,0.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itutinga,2020-12-31T00:00:00,1.8,1.66428804397583,7.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Jacutinga,2012-12-31T00:00:00,1.68,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Jacutinga,2013-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Jacutinga,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Jacutinga,2015-12-31T00:00:00,1.32,1.4497511386871338,9.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Jacutinga,2016-12-31T00:00:00,1.5,1.4947010278701782,0.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Jacutinga,2017-12-31T00:00:00,1.37,1.3978853225708008,2.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Jacutinga,2018-12-31T00:00:00,1.74,1.6957893371582031,2.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Jacutinga,2019-12-31T00:00:00,1.68,1.7068219184875488,1.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Jacutinga,2020-12-31T00:00:00,1.8,1.7899971008300781,0.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Jesuania,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Jesuania,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Jesuania,2014-12-31T00:00:00,1.05,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Jesuania,2015-12-31T00:00:00,0.96,1.061001181602478,10.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Jesuania,2016-12-31T00:00:00,1.56,1.4581804275512695,6.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Jesuania,2017-12-31T00:00:00,1.52,1.5353654623031616,1.01,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Jesuania,2018-12-31T00:00:00,1.68,1.6893913745880127,0.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Jesuania,2019-12-31T00:00:00,1.5,1.5915892124176025,6.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Jesuania,2020-12-31T00:00:00,1.5,1.4684631824493408,2.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Lambari,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Lambari,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Lambari,2014-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Lambari,2015-12-31T00:00:00,1.08,1.0689594745635986,1.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Lambari,2016-12-31T00:00:00,1.5,1.4922484159469604,0.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Lambari,2017-12-31T00:00:00,1.44,1.6196095943450928,12.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Lambari,2018-12-31T00:00:00,1.56,1.5807087421417236,1.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Lambari,2019-12-31T00:00:00,1.56,1.489306092262268,4.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Lambari,2020-12-31T00:00:00,1.8,1.7992959022521973,0.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Lavras,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Lavras,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Lavras,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Lavras,2015-12-31T00:00:00,0.84,0.8066900372505188,3.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Lavras,2016-12-31T00:00:00,1.68,1.6293472051620483,3.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Lavras,2017-12-31T00:00:00,2.25,1.4725656509399414,34.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Lavras,2018-12-31T00:00:00,1.92,2.1833271980285645,13.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Lavras,2019-12-31T00:00:00,1.5,1.5335339307785034,2.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Lavras,2020-12-31T00:00:00,1.8,1.8859411478042603,4.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Luminarias,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Luminarias,2013-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Luminarias,2014-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Luminarias,2015-12-31T00:00:00,0.84,0.971121072769165,15.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Luminarias,2016-12-31T00:00:00,1.86,1.480279803276062,20.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Luminarias,2017-12-31T00:00:00,2.33,1.9019767045974731,18.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Luminarias,2018-12-31T00:00:00,2.0,2.4137375354766846,20.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Luminarias,2019-12-31T00:00:00,1.72,1.6701183319091797,2.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Luminarias,2020-12-31T00:00:00,1.86,1.8786784410476685,1.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Machado,2012-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Machado,2013-12-31T00:00:00,1.62,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Machado,2014-12-31T00:00:00,1.15,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Machado,2015-12-31T00:00:00,1.32,1.3556066751480103,2.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Machado,2016-12-31T00:00:00,1.86,1.8317006826400757,1.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Machado,2017-12-31T00:00:00,1.51,1.399346113204956,7.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Machado,2018-12-31T00:00:00,1.98,1.9868539571762085,0.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Machado,2019-12-31T00:00:00,1.53,1.5626710653305054,2.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Machado,2020-12-31T00:00:00,2.21,2.069190502166748,6.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Maria_da_Fe,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Maria_da_Fe,2013-12-31T00:00:00,0.89,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Maria_da_Fe,2014-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Maria_da_Fe,2015-12-31T00:00:00,1.51,1.2767351865768433,15.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Maria_da_Fe,2016-12-31T00:00:00,1.91,1.9619430303573608,2.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Maria_da_Fe,2017-12-31T00:00:00,1.51,1.6919076442718506,12.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Maria_da_Fe,2018-12-31T00:00:00,1.5,1.624682903289795,8.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Maria_da_Fe,2019-12-31T00:00:00,1.5,1.5184738636016846,1.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Maria_da_Fe,2020-12-31T00:00:00,1.73,1.5076875686645508,12.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Moeda,2012-12-31T00:00:00,0.77,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Moeda,2013-12-31T00:00:00,0.77,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Moeda,2014-12-31T00:00:00,0.69,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Moeda,2015-12-31T00:00:00,0.94,0.9015531539916992,4.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Moeda,2016-12-31T00:00:00,0.94,0.9416287541389465,0.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Moeda,2017-12-31T00:00:00,2.0,2.0008387565612793,0.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Moeda,2018-12-31T00:00:00,1.2,1.3510959148406982,12.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Moeda,2019-12-31T00:00:00,1.0,0.9854772686958313,1.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Moeda,2020-12-31T00:00:00,1.2,1.4765928983688354,23.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monsenhor_Paulo,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monsenhor_Paulo,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monsenhor_Paulo,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monsenhor_Paulo,2015-12-31T00:00:00,1.26,1.1926311254501343,5.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monsenhor_Paulo,2016-12-31T00:00:00,1.62,1.607298731803894,0.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monsenhor_Paulo,2017-12-31T00:00:00,1.72,1.7752702236175537,3.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monsenhor_Paulo,2018-12-31T00:00:00,1.8,1.71949303150177,4.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monsenhor_Paulo,2019-12-31T00:00:00,1.5,1.536309838294983,2.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monsenhor_Paulo,2020-12-31T00:00:00,2.1,1.8141840696334839,13.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Alegre_de_Minas,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Alegre_de_Minas,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Alegre_de_Minas,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Alegre_de_Minas,2015-12-31T00:00:00,1.2,0.4652816951274872,61.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Alegre_de_Minas,2016-12-31T00:00:00,1.5,1.5372185707092285,2.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Alegre_de_Minas,2017-12-31T00:00:00,3.27,3.2831099033355713,0.4,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Alegre_de_Minas,2018-12-31T00:00:00,1.8,1.829726219177246,1.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Alegre_de_Minas,2019-12-31T00:00:00,1.8,2.135587453842163,18.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Alegre_de_Minas,2020-12-31T00:00:00,3.0,2.930349588394165,2.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Formoso,2012-12-31T00:00:00,0.45,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Formoso,2013-12-31T00:00:00,0.45,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Formoso,2014-12-31T00:00:00,0.42,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Formoso,2015-12-31T00:00:00,0.42,0.4163435101509094,0.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Formoso,2016-12-31T00:00:00,0.42,0.41621559858322144,0.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Formoso,2017-12-31T00:00:00,1.33,1.1354960203170776,14.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Formoso,2018-12-31T00:00:00,1.2,1.202796220779419,0.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Formoso,2019-12-31T00:00:00,1.2,1.1996738910675049,0.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Formoso,2020-12-31T00:00:00,0.6,0.6948646903038025,15.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Siao,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Siao,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Siao,2014-12-31T00:00:00,0.66,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Siao,2015-12-31T00:00:00,1.2,1.0696396827697754,10.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Siao,2016-12-31T00:00:00,1.62,1.6219446659088135,0.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Siao,2017-12-31T00:00:00,1.2,1.4760279655456543,23.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Siao,2018-12-31T00:00:00,1.8,1.8048748970031738,0.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Siao,2019-12-31T00:00:00,1.56,1.547105073928833,0.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Siao,2020-12-31T00:00:00,1.8,1.8062076568603516,0.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Muzambinho,2012-12-31T00:00:00,1.74,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Muzambinho,2013-12-31T00:00:00,1.35,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Muzambinho,2014-12-31T00:00:00,1.35,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Muzambinho,2015-12-31T00:00:00,1.48,1.497767448425293,1.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Muzambinho,2016-12-31T00:00:00,1.98,2.009338617324829,1.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Muzambinho,2017-12-31T00:00:00,1.62,1.6011501550674438,1.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Muzambinho,2018-12-31T00:00:00,1.3,1.7602035999298096,35.4,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Muzambinho,2019-12-31T00:00:00,2.1,1.2624911069869995,39.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Muzambinho,2020-12-31T00:00:00,1.76,1.6607930660247803,5.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Natercia,2012-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Natercia,2013-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Natercia,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Natercia,2015-12-31T00:00:00,1.38,1.2066043615341187,12.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Natercia,2016-12-31T00:00:00,1.56,1.5651917457580566,0.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Natercia,2017-12-31T00:00:00,1.6,1.437257170677185,10.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Natercia,2018-12-31T00:00:00,1.8,1.7412140369415283,3.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Natercia,2019-12-31T00:00:00,1.44,1.606208086013794,11.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Natercia,2020-12-31T00:00:00,1.44,1.5334112644195557,6.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Nazareno,2012-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Nazareno,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Nazareno,2014-12-31T00:00:00,1.3,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Nazareno,2015-12-31T00:00:00,1.8,1.9996914863586426,11.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Nazareno,2016-12-31T00:00:00,1.92,1.9646520614624023,2.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Nazareno,2017-12-31T00:00:00,1.59,1.7986499071121216,13.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Nazareno,2018-12-31T00:00:00,1.8,1.8421871662139893,2.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Nazareno,2019-12-31T00:00:00,1.68,1.6863348484039307,0.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Nazareno,2020-12-31T00:00:00,2.1,2.1796305179595947,3.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Nepomuceno,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Nepomuceno,2013-12-31T00:00:00,1.68,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Nepomuceno,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Nepomuceno,2015-12-31T00:00:00,1.26,1.223685383796692,2.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Nepomuceno,2016-12-31T00:00:00,1.74,1.7123565673828125,1.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Nepomuceno,2017-12-31T00:00:00,1.69,1.7532317638397217,3.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Nepomuceno,2018-12-31T00:00:00,1.74,1.6773297786712646,3.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Nepomuceno,2019-12-31T00:00:00,1.5,1.6531741619110107,10.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Nepomuceno,2020-12-31T00:00:00,1.92,1.7551512718200684,8.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Olimpio_Noronha,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Olimpio_Noronha,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Olimpio_Noronha,2014-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Olimpio_Noronha,2015-12-31T00:00:00,1.2,0.6974995732307434,41.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Olimpio_Noronha,2016-12-31T00:00:00,1.5,1.5845580101013184,5.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Olimpio_Noronha,2017-12-31T00:00:00,1.23,1.5782387256622314,28.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Olimpio_Noronha,2018-12-31T00:00:00,1.5,1.4744703769683838,1.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Olimpio_Noronha,2019-12-31T00:00:00,1.5,1.4481451511383057,3.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Olimpio_Noronha,2020-12-31T00:00:00,1.56,1.5214364528656006,2.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Oliveira,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Oliveira,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Oliveira,2014-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Oliveira,2015-12-31T00:00:00,1.32,1.3089637756347656,0.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Oliveira,2016-12-31T00:00:00,1.74,1.7138159275054932,1.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Oliveira,2017-12-31T00:00:00,1.4,1.4335240125656128,2.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Oliveira,2018-12-31T00:00:00,2.1,2.0681581497192383,1.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Oliveira,2019-12-31T00:00:00,1.56,1.5043272972106934,3.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Oliveira,2020-12-31T00:00:00,1.95,1.9901899099349976,2.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ouro_Fino,2012-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ouro_Fino,2013-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ouro_Fino,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ouro_Fino,2015-12-31T00:00:00,1.29,1.3227360248565674,2.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ouro_Fino,2016-12-31T00:00:00,1.44,1.3321187496185303,7.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ouro_Fino,2017-12-31T00:00:00,1.42,1.3345134258270264,6.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ouro_Fino,2018-12-31T00:00:00,1.69,1.5150004625320435,10.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ouro_Fino,2019-12-31T00:00:00,1.44,1.4033372402191162,2.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ouro_Fino,2020-12-31T00:00:00,2.1,1.9015530347824097,9.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Paraguacu,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Paraguacu,2013-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Paraguacu,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Paraguacu,2015-12-31T00:00:00,1.2,1.1943539381027222,0.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Paraguacu,2016-12-31T00:00:00,1.98,1.9998712539672852,1.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Paraguacu,2017-12-31T00:00:00,1.56,1.6709980964660645,7.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Paraguacu,2018-12-31T00:00:00,1.98,1.9705982208251953,0.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Paraguacu,2019-12-31T00:00:00,1.56,1.6401240825653076,5.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Paraguacu,2020-12-31T00:00:00,2.34,2.1235833168029785,9.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Paraisopolis,2012-12-31T00:00:00,1.06,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Paraisopolis,2013-12-31T00:00:00,1.06,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Paraisopolis,2014-12-31T00:00:00,1.11,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Paraisopolis,2015-12-31T00:00:00,1.2,1.222710132598877,1.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Paraisopolis,2016-12-31T00:00:00,1.5,1.5063810348510742,0.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Paraisopolis,2017-12-31T00:00:00,2.1,1.432541847229004,31.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Paraisopolis,2018-12-31T00:00:00,1.8,1.8222514390945435,1.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Paraisopolis,2019-12-31T00:00:00,1.2,1.395395040512085,16.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Paraisopolis,2020-12-31T00:00:00,2.4,2.191380023956299,8.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pedralva,2012-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pedralva,2013-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pedralva,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pedralva,2015-12-31T00:00:00,0.96,1.4094104766845703,46.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pedralva,2016-12-31T00:00:00,2.28,2.263519763946533,0.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pedralva,2017-12-31T00:00:00,1.43,1.5133591890335083,5.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pedralva,2018-12-31T00:00:00,1.8,1.9068756103515625,5.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pedralva,2019-12-31T00:00:00,1.5,1.737597107887268,15.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pedralva,2020-12-31T00:00:00,1.68,1.6904127597808838,0.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Perdoes,2012-12-31T00:00:00,1.68,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Perdoes,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Perdoes,2014-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Perdoes,2015-12-31T00:00:00,1.14,1.0378183126449585,8.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Perdoes,2016-12-31T00:00:00,1.68,1.6271495819091797,3.15,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Perdoes,2017-12-31T00:00:00,1.84,1.6649826765060425,9.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Perdoes,2018-12-31T00:00:00,1.8,1.959308385848999,8.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Perdoes,2019-12-31T00:00:00,1.74,1.7068064212799072,1.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Perdoes,2020-12-31T00:00:00,1.92,1.9058289527893066,0.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Piranga,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Piranga,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Piranga,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Piranga,2015-12-31T00:00:00,1.32,1.278635025024414,3.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Piranga,2016-12-31T00:00:00,1.5,1.4885505437850952,0.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Piranga,2017-12-31T00:00:00,2.5,2.88999080657959,15.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Piranga,2018-12-31T00:00:00,1.8,1.8024685382843018,0.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Piranga,2019-12-31T00:00:00,2.1,2.0276551246643066,3.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Piranga,2020-12-31T00:00:00,2.4,2.377872943878174,0.92,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pirangucu,2012-12-31T00:00:00,1.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pirangucu,2013-12-31T00:00:00,1.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pirangucu,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pirangucu,2015-12-31T00:00:00,1.32,1.3542468547821045,2.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pirangucu,2016-12-31T00:00:00,1.5,1.4874460697174072,0.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pirangucu,2017-12-31T00:00:00,1.2,1.3054345846176147,8.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pirangucu,2018-12-31T00:00:00,1.17,1.1547294855117798,1.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pirangucu,2019-12-31T00:00:00,1.17,1.1398993730545044,2.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pirangucu,2020-12-31T00:00:00,1.33,1.1987992525100708,9.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Piranguinho,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Piranguinho,2013-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Piranguinho,2014-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Piranguinho,2015-12-31T00:00:00,1.26,1.1837437152862549,6.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Piranguinho,2016-12-31T00:00:00,1.5,1.4874767065048218,0.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Piranguinho,2017-12-31T00:00:00,1.41,1.450340986251831,2.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Piranguinho,2018-12-31T00:00:00,1.5,1.4578862190246582,2.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Piranguinho,2019-12-31T00:00:00,1.5,1.4689915180206299,2.07,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Piranguinho,2020-12-31T00:00:00,1.46,1.4648542404174805,0.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Poco_Fundo,2012-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Poco_Fundo,2013-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Poco_Fundo,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Poco_Fundo,2015-12-31T00:00:00,1.2,0.9736524820327759,18.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Poco_Fundo,2016-12-31T00:00:00,1.41,1.4199734926223755,0.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Poco_Fundo,2017-12-31T00:00:00,1.2,1.171709418296814,2.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Poco_Fundo,2018-12-31T00:00:00,1.8,1.4530140161514282,19.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Poco_Fundo,2019-12-31T00:00:00,1.2,1.2783350944519043,6.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Poco_Fundo,2020-12-31T00:00:00,1.74,1.7537927627563477,0.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pocos_de_Caldas,2012-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pocos_de_Caldas,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pocos_de_Caldas,2014-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pocos_de_Caldas,2015-12-31T00:00:00,1.5,1.5114808082580566,0.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pocos_de_Caldas,2016-12-31T00:00:00,1.56,1.563842535018921,0.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pocos_de_Caldas,2017-12-31T00:00:00,1.77,1.686185359954834,4.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pocos_de_Caldas,2018-12-31T00:00:00,1.8,1.7345095872879028,3.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pocos_de_Caldas,2019-12-31T00:00:00,1.08,1.386587142944336,28.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pocos_de_Caldas,2020-12-31T00:00:00,1.8,1.7469733953475952,2.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pouso_Alegre,2012-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pouso_Alegre,2013-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pouso_Alegre,2014-12-31T00:00:00,0.78,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pouso_Alegre,2015-12-31T00:00:00,0.72,0.8965259790420532,24.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pouso_Alegre,2016-12-31T00:00:00,1.49,1.5929429531097412,6.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pouso_Alegre,2017-12-31T00:00:00,1.41,1.3983131647109985,0.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pouso_Alegre,2018-12-31T00:00:00,1.51,1.6587178707122803,9.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pouso_Alegre,2019-12-31T00:00:00,1.5,1.50076162815094,0.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pouso_Alegre,2020-12-31T00:00:00,1.64,1.6432708501815796,0.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pouso_Alto,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pouso_Alto,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pouso_Alto,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pouso_Alto,2015-12-31T00:00:00,1.32,2.1626758575439453,63.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pouso_Alto,2016-12-31T00:00:00,1.5,1.4811701774597168,1.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pouso_Alto,2017-12-31T00:00:00,1.5,1.465268611907959,2.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pouso_Alto,2018-12-31T00:00:00,1.65,1.5941005945205688,3.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pouso_Alto,2019-12-31T00:00:00,1.65,1.643760085105896,0.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pouso_Alto,2020-12-31T00:00:00,1.45,1.8368207216262817,26.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Presidente_Bernardes,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Presidente_Bernardes,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Presidente_Bernardes,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Presidente_Bernardes,2015-12-31T00:00:00,1.26,1.2772083282470703,1.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Presidente_Bernardes,2016-12-31T00:00:00,1.5,1.4992471933364868,0.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Presidente_Bernardes,2017-12-31T00:00:00,1.2,1.197806715965271,0.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Presidente_Bernardes,2018-12-31T00:00:00,1.5,1.5638973712921143,4.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Presidente_Bernardes,2019-12-31T00:00:00,1.26,1.2641080617904663,0.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Presidente_Bernardes,2020-12-31T00:00:00,1.5,1.4430134296417236,3.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ribeirao_Vermelho,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ribeirao_Vermelho,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ribeirao_Vermelho,2014-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ribeirao_Vermelho,2015-12-31T00:00:00,1.14,1.1352195739746094,0.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ribeirao_Vermelho,2016-12-31T00:00:00,1.62,1.6460559368133545,1.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ribeirao_Vermelho,2017-12-31T00:00:00,1.51,1.4159821271896362,6.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ribeirao_Vermelho,2018-12-31T00:00:00,1.8,1.6880083084106445,6.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ribeirao_Vermelho,2019-12-31T00:00:00,1.5,1.543181300163269,2.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ribeirao_Vermelho,2020-12-31T00:00:00,1.92,1.8996798992156982,1.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santa_Barbara_do_Monte_Verde,2012-12-31T00:00:00,0.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santa_Barbara_do_Monte_Verde,2013-12-31T00:00:00,0.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santa_Barbara_do_Monte_Verde,2014-12-31T00:00:00,0.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santa_Barbara_do_Monte_Verde,2015-12-31T00:00:00,1.33,0.8316968679428101,37.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santa_Barbara_do_Monte_Verde,2016-12-31T00:00:00,3.0,3.0899734497070312,3.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santa_Barbara_do_Monte_Verde,2017-12-31T00:00:00,0.67,0.6061890125274658,9.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santa_Barbara_do_Monte_Verde,2018-12-31T00:00:00,1.0,1.1722172498703003,17.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santa_Barbara_do_Monte_Verde,2019-12-31T00:00:00,0.67,0.5597195625305176,16.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santa_Barbara_do_Monte_Verde,2020-12-31T00:00:00,1.6,1.6397299766540527,2.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santa_Rita_do_Sapucai,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santa_Rita_do_Sapucai,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santa_Rita_do_Sapucai,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santa_Rita_do_Sapucai,2015-12-31T00:00:00,1.2,1.1657142639160156,2.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santa_Rita_do_Sapucai,2016-12-31T00:00:00,1.68,1.6913111209869385,0.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santa_Rita_do_Sapucai,2017-12-31T00:00:00,1.79,1.627913236618042,9.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santa_Rita_do_Sapucai,2018-12-31T00:00:00,1.8,1.7877370119094849,0.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santa_Rita_do_Sapucai,2019-12-31T00:00:00,1.5,1.6810688972473145,12.07,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santa_Rita_do_Sapucai,2020-12-31T00:00:00,1.68,1.751307487487793,4.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santana_da_Vargem,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santana_da_Vargem,2013-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santana_da_Vargem,2014-12-31T00:00:00,1.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santana_da_Vargem,2015-12-31T00:00:00,1.14,1.1897132396697998,4.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santana_da_Vargem,2016-12-31T00:00:00,1.74,1.7147362232208252,1.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santana_da_Vargem,2017-12-31T00:00:00,2.09,1.8132362365722656,13.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santana_da_Vargem,2018-12-31T00:00:00,1.8,1.9552488327026367,8.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santana_da_Vargem,2019-12-31T00:00:00,1.8,1.7121893167495728,4.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santana_da_Vargem,2020-12-31T00:00:00,2.22,1.9887142181396484,10.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santana_do_Jacare,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santana_do_Jacare,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santana_do_Jacare,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santana_do_Jacare,2015-12-31T00:00:00,1.68,0.993105411529541,40.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santana_do_Jacare,2016-12-31T00:00:00,1.56,1.6984410285949707,8.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santana_do_Jacare,2017-12-31T00:00:00,1.2,1.7514885663986206,45.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santana_do_Jacare,2018-12-31T00:00:00,1.8,1.7876516580581665,0.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santana_do_Jacare,2019-12-31T00:00:00,1.2,1.37864089012146,14.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santana_do_Jacare,2020-12-31T00:00:00,1.8,1.991109013557434,10.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santo_Antonio_do_Amparo,2012-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santo_Antonio_do_Amparo,2013-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santo_Antonio_do_Amparo,2014-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santo_Antonio_do_Amparo,2015-12-31T00:00:00,1.2,1.3021750450134277,8.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santo_Antonio_do_Amparo,2016-12-31T00:00:00,1.8,1.8316625356674194,1.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santo_Antonio_do_Amparo,2017-12-31T00:00:00,1.34,1.7921408414840698,33.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santo_Antonio_do_Amparo,2018-12-31T00:00:00,2.16,1.9796900749206543,8.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santo_Antonio_do_Amparo,2019-12-31T00:00:00,1.64,1.4301059246063232,12.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santo_Antonio_do_Amparo,2020-12-31T00:00:00,2.1,1.992249608039856,5.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santo_Antonio_do_Grama,2012-12-31T00:00:00,0.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santo_Antonio_do_Grama,2013-12-31T00:00:00,0.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santo_Antonio_do_Grama,2014-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santo_Antonio_do_Grama,2015-12-31T00:00:00,0.9,0.9610207676887512,6.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santo_Antonio_do_Grama,2016-12-31T00:00:00,0.9,0.9122260808944702,1.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santo_Antonio_do_Grama,2017-12-31T00:00:00,3.33,3.3761239051818848,1.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santo_Antonio_do_Grama,2018-12-31T00:00:00,1.8,1.9460848569869995,8.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santo_Antonio_do_Grama,2019-12-31T00:00:00,1.2,1.3880038261413574,15.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santo_Antonio_do_Grama,2020-12-31T00:00:00,1.7,1.7588975429534912,3.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Bento_Abade,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Bento_Abade,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Bento_Abade,2014-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Bento_Abade,2015-12-31T00:00:00,1.08,1.0572540760040283,2.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Bento_Abade,2016-12-31T00:00:00,1.62,1.6261072158813477,0.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Bento_Abade,2017-12-31T00:00:00,2.41,1.714866280555725,28.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Bento_Abade,2018-12-31T00:00:00,2.4,2.115797519683838,11.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Bento_Abade,2019-12-31T00:00:00,1.44,1.3894293308258057,3.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Bento_Abade,2020-12-31T00:00:00,1.8,1.6826133728027344,6.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Goncalo_do_Sapucai,2012-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Goncalo_do_Sapucai,2013-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Goncalo_do_Sapucai,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Goncalo_do_Sapucai,2015-12-31T00:00:00,1.26,1.29134202003479,2.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Goncalo_do_Sapucai,2016-12-31T00:00:00,1.5,1.470848798751831,1.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Goncalo_do_Sapucai,2017-12-31T00:00:00,2.04,1.7966759204864502,11.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Goncalo_do_Sapucai,2018-12-31T00:00:00,2.22,2.0979409217834473,5.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Goncalo_do_Sapucai,2019-12-31T00:00:00,1.5,1.5069341659545898,0.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Goncalo_do_Sapucai,2020-12-31T00:00:00,2.4,2.070913076400757,13.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Joao_del_Rei,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Joao_del_Rei,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Joao_del_Rei,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Joao_del_Rei,2015-12-31T00:00:00,1.62,1.632781982421875,0.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Joao_del_Rei,2016-12-31T00:00:00,1.5,1.8112566471099854,20.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Joao_del_Rei,2017-12-31T00:00:00,1.75,1.7657746076583862,0.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Joao_del_Rei,2018-12-31T00:00:00,1.8,1.7867107391357422,0.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Joao_del_Rei,2019-12-31T00:00:00,1.98,1.9281299114227295,2.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Joao_del_Rei,2020-12-31T00:00:00,1.97,1.9554105997085571,0.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Lourenco,2012-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Lourenco,2013-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Lourenco,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Lourenco,2015-12-31T00:00:00,1.32,1.3284542560577393,0.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Lourenco,2016-12-31T00:00:00,1.6,1.6014704704284668,0.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Lourenco,2017-12-31T00:00:00,1.77,1.6495964527130127,6.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Lourenco,2018-12-31T00:00:00,1.6,1.7094533443450928,6.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Lourenco,2019-12-31T00:00:00,1.6,1.6318010091781616,1.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Lourenco,2020-12-31T00:00:00,3.39,1.944320559501648,42.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Roque_de_Minas,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Roque_de_Minas,2013-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Roque_de_Minas,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Roque_de_Minas,2015-12-31T00:00:00,1.08,1.0757627487182617,0.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Roque_de_Minas,2016-12-31T00:00:00,1.32,1.3277511596679688,0.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Roque_de_Minas,2017-12-31T00:00:00,1.46,1.5163578987121582,3.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Roque_de_Minas,2018-12-31T00:00:00,1.62,1.700934648513794,5.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Roque_de_Minas,2019-12-31T00:00:00,1.5,1.4634017944335938,2.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Roque_de_Minas,2020-12-31T00:00:00,1.8,1.7614295482635498,2.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Sebastiao_da_Bela_Vista,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Sebastiao_da_Bela_Vista,2013-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Sebastiao_da_Bela_Vista,2014-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Sebastiao_da_Bela_Vista,2015-12-31T00:00:00,1.02,1.0559666156768799,3.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Sebastiao_da_Bela_Vista,2016-12-31T00:00:00,1.56,1.5446783304214478,0.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Sebastiao_da_Bela_Vista,2017-12-31T00:00:00,1.58,1.5571928024291992,1.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Sebastiao_da_Bela_Vista,2018-12-31T00:00:00,1.32,1.3373208045959473,1.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Sebastiao_da_Bela_Vista,2019-12-31T00:00:00,1.44,1.3618234395980835,5.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Sebastiao_da_Bela_Vista,2020-12-31T00:00:00,1.5,1.4837039709091187,1.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Sebastiao_do_Paraiso,2012-12-31T00:00:00,1.62,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Sebastiao_do_Paraiso,2013-12-31T00:00:00,1.71,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Sebastiao_do_Paraiso,2014-12-31T00:00:00,1.42,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Sebastiao_do_Paraiso,2015-12-31T00:00:00,1.38,1.3519494533538818,2.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Sebastiao_do_Paraiso,2016-12-31T00:00:00,1.7,1.7689769268035889,4.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Sebastiao_do_Paraiso,2017-12-31T00:00:00,1.54,1.569394588470459,1.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Sebastiao_do_Paraiso,2018-12-31T00:00:00,1.89,1.860357403755188,1.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Sebastiao_do_Paraiso,2019-12-31T00:00:00,1.47,1.511655330657959,2.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Sebastiao_do_Paraiso,2020-12-31T00:00:00,1.93,1.924237608909607,0.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tiago,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tiago,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tiago,2014-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tiago,2015-12-31T00:00:00,1.62,1.5022783279418945,7.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tiago,2016-12-31T00:00:00,1.62,1.6413706541061401,1.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tiago,2017-12-31T00:00:00,2.17,2.176124095916748,0.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tiago,2018-12-31T00:00:00,2.7,2.2903082370758057,15.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tiago,2019-12-31T00:00:00,1.68,1.6791948080062866,0.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tiago,2020-12-31T00:00:00,2.7,2.7975471019744873,3.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tomas_de_Aquino,2012-12-31T00:00:00,1.75,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tomas_de_Aquino,2013-12-31T00:00:00,1.05,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tomas_de_Aquino,2014-12-31T00:00:00,1.35,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tomas_de_Aquino,2015-12-31T00:00:00,0.96,0.8680107593536377,9.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tomas_de_Aquino,2016-12-31T00:00:00,1.8,1.7750661373138428,1.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tomas_de_Aquino,2017-12-31T00:00:00,1.5,1.4570891857147217,2.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tomas_de_Aquino,2018-12-31T00:00:00,2.1,2.0135657787323,4.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tomas_de_Aquino,2019-12-31T00:00:00,1.56,1.5096168518066406,3.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tomas_de_Aquino,2020-12-31T00:00:00,2.1,1.9452972412109375,7.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tome_das_Letras,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tome_das_Letras,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tome_das_Letras,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tome_das_Letras,2015-12-31T00:00:00,1.02,1.028320074081421,0.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tome_das_Letras,2016-12-31T00:00:00,1.62,1.618980884552002,0.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tome_das_Letras,2017-12-31T00:00:00,1.05,1.712341547012329,63.08,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tome_das_Letras,2018-12-31T00:00:00,1.5,1.5459644794464111,3.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tome_das_Letras,2019-12-31T00:00:00,1.44,1.478243350982666,2.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tome_das_Letras,2020-12-31T00:00:00,2.13,2.098987579345703,1.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Senador_Jose_Bento,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Senador_Jose_Bento,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Senador_Jose_Bento,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Senador_Jose_Bento,2015-12-31T00:00:00,1.5,1.3736411333084106,8.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Senador_Jose_Bento,2016-12-31T00:00:00,1.38,1.437737226486206,4.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Senador_Jose_Bento,2017-12-31T00:00:00,1.15,1.4285857677459717,24.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Senador_Jose_Bento,2018-12-31T00:00:00,1.32,1.3958468437194824,5.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Senador_Jose_Bento,2019-12-31T00:00:00,1.2,1.1850755214691162,1.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Senador_Jose_Bento,2020-12-31T00:00:00,1.62,1.313136339187622,18.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Senhora_de_Oliveira,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Senhora_de_Oliveira,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Senhora_de_Oliveira,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Senhora_de_Oliveira,2015-12-31T00:00:00,1.26,1.2450482845306396,1.19,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Senhora_de_Oliveira,2016-12-31T00:00:00,1.2,1.1813610792160034,1.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Senhora_de_Oliveira,2017-12-31T00:00:00,2.0,1.5228865146636963,23.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Senhora_de_Oliveira,2018-12-31T00:00:00,1.8,1.671149730682373,7.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Senhora_de_Oliveira,2019-12-31T00:00:00,1.66,1.6348345279693604,1.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Senhora_de_Oliveira,2020-12-31T00:00:00,1.8,1.7677254676818848,1.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Serrania,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Serrania,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Serrania,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Serrania,2015-12-31T00:00:00,0.9,1.0310920476913452,14.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Serrania,2016-12-31T00:00:00,1.56,1.529315710067749,1.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Serrania,2017-12-31T00:00:00,1.5,1.4833370447158813,1.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Serrania,2018-12-31T00:00:00,1.8,1.701780080795288,5.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Serrania,2019-12-31T00:00:00,1.68,1.5014042854309082,10.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Serrania,2020-12-31T00:00:00,1.8,1.862386703491211,3.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Silvianopolis,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Silvianopolis,2013-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Silvianopolis,2014-12-31T00:00:00,0.78,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Silvianopolis,2015-12-31T00:00:00,0.9,0.8515801429748535,5.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Silvianopolis,2016-12-31T00:00:00,1.5,1.468085765838623,2.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Silvianopolis,2017-12-31T00:00:00,1.07,1.4197843074798584,32.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Silvianopolis,2018-12-31T00:00:00,1.2,1.194527268409729,0.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Silvianopolis,2019-12-31T00:00:00,1.2,1.095651626586914,8.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Silvianopolis,2020-12-31T00:00:00,1.5,1.460578203201294,2.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Soledade_de_Minas,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Soledade_de_Minas,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Soledade_de_Minas,2014-12-31T00:00:00,1.06,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Soledade_de_Minas,2015-12-31T00:00:00,1.71,1.3294786214828491,22.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Soledade_de_Minas,2016-12-31T00:00:00,1.6,1.5621229410171509,2.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Soledade_de_Minas,2017-12-31T00:00:00,1.6,1.8378276824951172,14.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Soledade_de_Minas,2018-12-31T00:00:00,1.8,1.7402710914611816,3.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Soledade_de_Minas,2019-12-31T00:00:00,1.8,1.7974741458892822,0.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Soledade_de_Minas,2020-12-31T00:00:00,3.2,2.8327019214630127,11.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Tres_Coracoes,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Tres_Coracoes,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Tres_Coracoes,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Tres_Coracoes,2015-12-31T00:00:00,0.96,0.9942495226860046,3.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Tres_Coracoes,2016-12-31T00:00:00,1.68,1.715255618095398,2.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Tres_Coracoes,2017-12-31T00:00:00,2.67,1.9950759410858154,25.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Tres_Coracoes,2018-12-31T00:00:00,2.1,2.356196641921997,12.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Tres_Coracoes,2019-12-31T00:00:00,1.56,1.6240445375442505,4.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Tres_Coracoes,2020-12-31T00:00:00,2.1,2.1114308834075928,0.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Tres_Pontas,2012-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Tres_Pontas,2013-12-31T00:00:00,1.53,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Tres_Pontas,2014-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Tres_Pontas,2015-12-31T00:00:00,1.14,1.249280333518982,9.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Tres_Pontas,2016-12-31T00:00:00,1.86,1.8450818061828613,0.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Tres_Pontas,2017-12-31T00:00:00,1.88,2.171877145767212,15.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Tres_Pontas,2018-12-31T00:00:00,2.22,1.9335631132125854,12.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Tres_Pontas,2019-12-31T00:00:00,1.74,1.6838595867156982,3.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Tres_Pontas,2020-12-31T00:00:00,2.26,2.2010433673858643,2.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Turvolandia,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Turvolandia,2013-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Turvolandia,2014-12-31T00:00:00,0.84,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Turvolandia,2015-12-31T00:00:00,1.08,1.0934065580368042,1.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Turvolandia,2016-12-31T00:00:00,1.5,1.4966342449188232,0.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Turvolandia,2017-12-31T00:00:00,1.8,1.5756741762161255,12.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Turvolandia,2018-12-31T00:00:00,2.29,2.229414463043213,2.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Turvolandia,2019-12-31T00:00:00,2.1,1.9988737106323242,4.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Turvolandia,2020-12-31T00:00:00,1.62,2.100006580352783,29.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Uberlandia,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Uberlandia,2013-12-31T00:00:00,2.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Uberlandia,2014-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Uberlandia,2015-12-31T00:00:00,1.32,1.2915900945663452,2.15,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Uberlandia,2016-12-31T00:00:00,1.62,1.6184632778167725,0.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Uberlandia,2017-12-31T00:00:00,3.15,3.187833786010742,1.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Uberlandia,2018-12-31T00:00:00,2.64,2.4917962551116943,5.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Uberlandia,2019-12-31T00:00:00,2.02,1.9978114366531372,1.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Uberlandia,2020-12-31T00:00:00,1.92,2.536451578140259,32.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Vargem_Bonita,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Vargem_Bonita,2013-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Vargem_Bonita,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Vargem_Bonita,2015-12-31T00:00:00,1.08,1.1162508726119995,3.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Vargem_Bonita,2016-12-31T00:00:00,1.32,1.3223414421081543,0.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Vargem_Bonita,2017-12-31T00:00:00,1.67,1.5865869522094727,4.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Vargem_Bonita,2018-12-31T00:00:00,2.4,2.247720241546631,6.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Vargem_Bonita,2019-12-31T00:00:00,2.1,1.9849716424942017,5.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Vargem_Bonita,2020-12-31T00:00:00,1.8,2.1666603088378906,20.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Varginha,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Varginha,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Varginha,2014-12-31T00:00:00,1.03,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Varginha,2015-12-31T00:00:00,1.2,1.1630258560180664,3.08,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Varginha,2016-12-31T00:00:00,1.74,1.870396375656128,7.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Varginha,2017-12-31T00:00:00,2.12,2.0466177463531494,3.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Varginha,2018-12-31T00:00:00,2.1,2.0045418739318848,4.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Varginha,2019-12-31T00:00:00,1.56,1.629918098449707,4.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Varginha,2020-12-31T00:00:00,1.9,2.0707459449768066,8.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Virginia,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Virginia,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Virginia,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Virginia,2015-12-31T00:00:00,1.5,1.7702665328979492,18.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Virginia,2016-12-31T00:00:00,1.6,1.6115210056304932,0.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Virginia,2017-12-31T00:00:00,1.4,1.5111322402954102,7.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Virginia,2018-12-31T00:00:00,1.8,1.7974144220352173,0.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Virginia,2019-12-31T00:00:00,1.36,1.3791743516921997,1.41,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Virginia,2020-12-31T00:00:00,1.53,1.6126198768615723,5.4,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Aguanil,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Aiuruoca,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Albertina,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Alfenas,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Alterosa,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Andradas,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Andrelandia,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Arceburgo,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Baependi,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bandeira_do_Sul,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Boa_Esperanca,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bom_Sucesso,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Borda_da_Mata,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Brazopolis,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bueno_Brandao,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cachoeira_de_Minas,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Caete,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Camacho,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cambuquira,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campanha,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campestre,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campo_Belo,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campo_do_Meio,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campos_Gerais,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Candeias,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Capetinga,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Capitolio,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_da_Cachoeira,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_de_Minas,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_do_Rio_Claro,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carvalhopolis,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cassia,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_da_Barra_de_Minas,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_das_Pedras,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_do_Rio_Verde,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_dos_Ouros,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Coqueiral,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cordislandia,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Corrego_Danta,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cristais,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cristina,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Delfinopolis,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Desterro_de_Entre_Rios,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Divinesia,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Divisa_Nova,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Dom_Vicoso,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Doresopolis,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Eloi_Mendes,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Entre_Rios_de_Minas,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Fama,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Grao_Mogol,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Guape,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Heliodora,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ibituruna,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ijaci,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ilicinea,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Inconfidentes,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ingai,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itajuba,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itamogi,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itapecerica,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itumirim,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itutinga,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Jacutinga,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Jesuania,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Lambari,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Lavras,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Luminarias,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Machado,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Maria_da_Fe,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Moeda,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monsenhor_Paulo,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Alegre_de_Minas,2021-12-31T00:00:00,3.0,0,-100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Formoso,2021-12-31T00:00:00,1.0,0,-100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Siao,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Muzambinho,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Natercia,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Nazareno,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Nepomuceno,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Olimpio_Noronha,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Oliveira,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ouro_Fino,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Paraguacu,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Paraisopolis,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pedralva,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Perdoes,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Piranga,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pirangucu,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Piranguinho,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Poco_Fundo,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pocos_de_Caldas,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pouso_Alegre,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pouso_Alto,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Presidente_Bernardes,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ribeirao_Vermelho,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santa_Barbara_do_Monte_Verde,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santa_Rita_do_Sapucai,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santana_da_Vargem,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santana_do_Jacare,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santo_Antonio_do_Amparo,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santo_Antonio_do_Grama,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Bento_Abade,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Goncalo_do_Sapucai,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Joao_del_Rei,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Lourenco,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Roque_de_Minas,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Sebastiao_da_Bela_Vista,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Sebastiao_do_Paraiso,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tiago,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tomas_de_Aquino,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tome_das_Letras,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Senador_Jose_Bento,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Senhora_de_Oliveira,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Serrania,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Silvianopolis,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Soledade_de_Minas,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Tres_Coracoes,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Tres_Pontas,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Turvolandia,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Uberlandia,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Vargem_Bonita,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Varginha,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Virginia,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Aguanil,2022-12-31T00:00:00,1.56,3.2248475551605225,106.72,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Aiuruoca,2022-12-31T00:00:00,1.5,4.098643779754639,173.24,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Albertina,2022-12-31T00:00:00,1.44,2.016658306121826,40.05,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Alfenas,2022-12-31T00:00:00,0.9243951612903224,5.849842548370361,532.83,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Alterosa,2022-12-31T00:00:00,1.080104712041885,5.386158466339111,398.67,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Andradas,2022-12-31T00:00:00,1.26,1.5361452102661133,21.92,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Andrelandia,2022-12-31T00:00:00,1.8000000000000005,3.4192612171173096,89.96,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Arceburgo,2022-12-31T00:00:00,0.9244897959183672,3.3614883422851562,263.6,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Baependi,2022-12-31T00:00:00,1.079558011049724,5.532553672790527,412.48,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bandeira_do_Sul,2022-12-31T00:00:00,1.110344827586207,2.754955768585205,148.12,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Boa_Esperanca,2022-12-31T00:00:00,0.9726256983240223,4.081170558929443,319.6,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bom_Sucesso,2022-12-31T00:00:00,1.440136054421769,4.313514709472656,199.52,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Borda_da_Mata,2022-12-31T00:00:00,1.2,3.3483476638793945,179.03,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Brazopolis,2022-12-31T00:00:00,1.200934579439252,3.571136236190796,197.36,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Bueno_Brandao,2022-12-31T00:00:00,1.440196078431373,5.09006929397583,253.43,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cachoeira_de_Minas,2022-12-31T00:00:00,1.5,2.8318474292755127,88.79,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Caete,2022-12-31T00:00:00,1.5333333333333332,1.6613277196884155,8.35,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Camacho,2022-12-31T00:00:00,1.380176211453745,4.217696189880371,205.59,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cambuquira,2022-12-31T00:00:00,1.32,5.495028972625732,316.29,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campanha,2022-12-31T00:00:00,1.266469038208169,3.1252236366271973,146.77,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campestre,2022-12-31T00:00:00,1.020018115942029,5.800132751464844,468.63,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campo_Belo,2022-12-31T00:00:00,1.2,3.028071165084839,152.34,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campo_do_Meio,2022-12-31T00:00:00,1.580968858131488,9.345786094665527,491.14,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Campos_Gerais,2022-12-31T00:00:00,1.535771358328211,10.120387077331543,558.98,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Candeias,2022-12-31T00:00:00,1.020017406440383,3.2975409030914307,223.28,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Capetinga,2022-12-31T00:00:00,1.407056229327453,3.8969733715057373,176.96,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Capitolio,2022-12-31T00:00:00,1.08,5.757059097290039,433.06,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_da_Cachoeira,2022-12-31T00:00:00,1.2,3.005380868911743,150.45,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_de_Minas,2022-12-31T00:00:00,1.14,2.8577945232391357,150.68,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carmo_do_Rio_Claro,2022-12-31T00:00:00,1.619555143651529,6.880746364593506,324.85,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Carvalhopolis,2022-12-31T00:00:00,1.44,3.9676623344421387,175.53,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cassia,2022-12-31T00:00:00,1.413626373626374,4.65195369720459,229.08,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_da_Barra_de_Minas,2022-12-31T00:00:00,1.370833333333333,3.367638349533081,145.66,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_das_Pedras,2022-12-31T00:00:00,1.375,2.5808913707733154,87.7,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_do_Rio_Verde,2022-12-31T00:00:00,1.5,4.389683246612549,192.65,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Conceicao_dos_Ouros,2022-12-31T00:00:00,1.261168384879725,2.254509925842285,78.76,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Coqueiral,2022-12-31T00:00:00,1.2,4.772289276123047,297.69,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cordislandia,2022-12-31T00:00:00,1.260122699386503,2.6510510444641113,110.38,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Corrego_Danta,2022-12-31T00:00:00,1.5,4.149839878082275,176.66,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cristais,2022-12-31T00:00:00,1.059063136456212,3.753509521484375,254.42,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Cristina,2022-12-31T00:00:00,1.320183486238532,4.85384464263916,267.66,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Delfinopolis,2022-12-31T00:00:00,1.3799999999999997,5.256850242614746,280.93,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Desterro_de_Entre_Rios,2022-12-31T00:00:00,1.8000000000000005,5.891134738922119,227.29,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Divinesia,2022-12-31T00:00:00,2.2230769230769227,2.463062286376953,10.8,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Divisa_Nova,2022-12-31T00:00:00,1.260204081632653,4.136423587799072,228.23,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Dom_Vicoso,2022-12-31T00:00:00,1.320588235294118,3.5714101791381836,170.44,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Doresopolis,2022-12-31T00:00:00,1.32,4.390198707580566,232.59,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Eloi_Mendes,2022-12-31T00:00:00,1.090201870999508,7.011645317077637,543.15,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Entre_Rios_de_Minas,2022-12-31T00:00:00,1.8000000000000005,2.1962149143218994,22.01,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Fama,2022-12-31T00:00:00,1.379787234042553,2.75256085395813,99.49,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Grao_Mogol,2022-12-31T00:00:00,1.177777777777778,2.107107162475586,78.91,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Guape,2022-12-31T00:00:00,1.262758620689655,3.0788373947143555,143.82,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Heliodora,2022-12-31T00:00:00,1.080140597539543,4.211134433746338,289.87,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ibituruna,2022-12-31T00:00:00,1.2,2.295135974884033,91.26,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ijaci,2022-12-31T00:00:00,1.173913043478261,7.599606513977051,547.37,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ilicinea,2022-12-31T00:00:00,1.080069324090121,3.7964279651641846,251.5,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Inconfidentes,2022-12-31T00:00:00,1.739917695473251,7.336954593658447,321.68,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ingai,2022-12-31T00:00:00,1.380228136882129,2.8730504512786865,108.16,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itajuba,2022-12-31T00:00:00,1.068965517241379,5.2643022537231445,392.47,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itamogi,2022-12-31T00:00:00,1.32,7.213621616363525,446.49,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itapecerica,2022-12-31T00:00:00,1.040506329113924,3.3202245235443115,219.1,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itumirim,2022-12-31T00:00:00,1.249307479224377,5.276803970336914,322.38,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Itutinga,2022-12-31T00:00:00,1.8000000000000005,3.7804207801818848,110.02,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Jacutinga,2022-12-31T00:00:00,1.289920424403183,3.3605873584747314,160.53,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Jesuania,2022-12-31T00:00:00,1.2,2.8434340953826904,136.95,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Lambari,2022-12-31T00:00:00,1.2,5.099208831787109,324.93,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Lavras,2022-12-31T00:00:00,1.260078277886497,3.5117263793945312,178.69,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Luminarias,2022-12-31T00:00:00,1.380229885057471,3.8685450553894043,180.28,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Machado,2022-12-31T00:00:00,0.964047619047619,6.131402015686035,536.01,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Maria_da_Fe,2022-12-31T00:00:00,1.2,2.5879502296447754,115.66,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Moeda,2022-12-31T00:00:00,1.25,7.819309234619141,525.54,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monsenhor_Paulo,2022-12-31T00:00:00,1.23,5.039582252502441,309.72,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Alegre_de_Minas,2022-12-31T00:00:00,2.3296703296703294,6.840167045593262,193.61,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Formoso,2022-12-31T00:00:00,0.6000000000000001,2.8314099311828613,371.9,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Monte_Siao,2022-12-31T00:00:00,1.2,2.175415515899658,81.28,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Muzambinho,2022-12-31T00:00:00,1.43993993993994,6.403170108795166,344.68,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Natercia,2022-12-31T00:00:00,1.4399193548387097,3073.636474609375,213358.93,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Nazareno,2022-12-31T00:00:00,1.319811320754717,3.968745708465576,200.71,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Nepomuceno,2022-12-31T00:00:00,0.8699884125144843,3.869894504547119,344.82,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Olimpio_Noronha,2022-12-31T00:00:00,1.2,3.0704994201660156,155.87,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Oliveira,2022-12-31T00:00:00,1.535560504825538,3.5226659774780273,129.41,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ouro_Fino,2022-12-31T00:00:00,1.2,2.575129747390747,114.59,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Paraguacu,2022-12-31T00:00:00,1.043954802259887,12.819527626037598,1127.98,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Paraisopolis,2022-12-31T00:00:00,1.322222222222222,8.609626770019531,551.15,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pedralva,2022-12-31T00:00:00,1.320091324200913,2.272067070007324,72.11,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Perdoes,2022-12-31T00:00:00,1.259859154929577,3.185792922973633,152.87,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Piranga,2022-12-31T00:00:00,1.8000000000000005,3.231870174407959,79.55,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pirangucu,2022-12-31T00:00:00,1.333333333333333,1.979649543762207,48.47,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Piranguinho,2022-12-31T00:00:00,1.380549682875264,2.2431273460388184,62.48,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Poco_Fundo,2022-12-31T00:00:00,1.079978925184405,5.064929485321045,368.98,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pocos_de_Caldas,2022-12-31T00:00:00,1.169867549668874,4.129161834716797,252.96,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pouso_Alegre,2022-12-31T00:00:00,1.5,3.0986173152923584,106.57,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Pouso_Alto,2022-12-31T00:00:00,1.5,2.4034652709960938,60.23,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Presidente_Bernardes,2022-12-31T00:00:00,1.501449275362319,3.0026955604553223,99.99,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Ribeirao_Vermelho,2022-12-31T00:00:00,1.32,3.8891735076904297,194.63,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santa_Barbara_do_Monte_Verde,2022-12-31T00:00:00,1.3,18.756675720214844,1342.82,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santa_Rita_do_Sapucai,2022-12-31T00:00:00,1.14,2.2027502059936523,93.22,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santana_da_Vargem,2022-12-31T00:00:00,0.9900921658986176,6.263181209564209,532.59,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santana_do_Jacare,2022-12-31T00:00:00,1.5,3.8413355350494385,156.09,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santo_Antonio_do_Amparo,2022-12-31T00:00:00,1.26,4.477952003479004,255.39,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Santo_Antonio_do_Grama,2022-12-31T00:00:00,1.565217391304348,3.941624164581299,151.83,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Bento_Abade,2022-12-31T00:00:00,1.2,3.62134051322937,201.78,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Goncalo_do_Sapucai,2022-12-31T00:00:00,1.08,7.9021315574646,631.68,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Joao_del_Rei,2022-12-31T00:00:00,1.836244541484716,5.037176609039307,174.32,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Lourenco,2022-12-31T00:00:00,1.8000000000000005,23.601171493530273,1211.18,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Roque_de_Minas,2022-12-31T00:00:00,1.32,3.705921173095703,180.75,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Sebastiao_da_Bela_Vista,2022-12-31T00:00:00,1.5,2.6238880157470703,74.93,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Sebastiao_do_Paraiso,2022-12-31T00:00:00,1.3172147001934242,4.970091342926025,277.32,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tiago,2022-12-31T00:00:00,1.3210526315789468,8.89037036895752,572.98,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tomas_de_Aquino,2022-12-31T00:00:00,1.2,5.551388740539551,362.62,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Sao_Tome_das_Letras,2022-12-31T00:00:00,1.434375,7.802493095397949,443.96,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Senador_Jose_Bento,2022-12-31T00:00:00,1.32,2.6793243885040283,102.98,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Senhora_de_Oliveira,2022-12-31T00:00:00,1.5,2.2497262954711914,49.98,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Serrania,2022-12-31T00:00:00,1.2,5.683959484100342,373.66,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Silvianopolis,2022-12-31T00:00:00,0.9,3.3865280151367188,276.28,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Soledade_de_Minas,2022-12-31T00:00:00,1.5,16.037273406982422,969.15,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Tres_Coracoes,2022-12-31T00:00:00,1.08,3.9489572048187256,265.64,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Tres_Pontas,2022-12-31T00:00:00,0.975023651844844,7.285892963409424,647.25,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Turvolandia,2022-12-31T00:00:00,1.4398692810457523,5.118766784667969,255.5,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Uberlandia,2022-12-31T00:00:00,1.681818181818182,2.646045684814453,57.33,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Vargem_Bonita,2022-12-31T00:00:00,1.235217391304348,3.92775821685791,217.98,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Varginha,2022-12-31T00:00:00,1.020039292730845,4.8514404296875,375.61,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste (2022),Virginia,2022-12-31T00:00:00,1.62,1.9572498798370361,20.82,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 4
        learning_rate: 0.0015883477260597609
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 700
        ",2025-09-23T09:52:42
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Aguanil,2012-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Aguanil,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Aguanil,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Aguanil,2015-12-31T00:00:00,0.9,1.159468412399292,28.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Aguanil,2016-12-31T00:00:00,1.8,1.809268593788147,0.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Aguanil,2017-12-31T00:00:00,1.85,1.5783088207244873,14.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Aguanil,2018-12-31T00:00:00,2.1,2.0489487648010254,2.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Aguanil,2019-12-31T00:00:00,1.8,1.7583026885986328,2.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Aguanil,2020-12-31T00:00:00,2.16,2.1517388820648193,0.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Aiuruoca,2012-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Aiuruoca,2013-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Aiuruoca,2014-12-31T00:00:00,1.0,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Aiuruoca,2015-12-31T00:00:00,1.09,1.5427544116973877,41.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Aiuruoca,2016-12-31T00:00:00,1.19,1.1631627082824707,2.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Aiuruoca,2017-12-31T00:00:00,1.5,1.3317835330963135,11.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Aiuruoca,2018-12-31T00:00:00,1.77,1.7598917484283447,0.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Aiuruoca,2019-12-31T00:00:00,1.54,1.6010637283325195,3.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Aiuruoca,2020-12-31T00:00:00,1.8,1.809586763381958,0.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Albertina,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Albertina,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Albertina,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Albertina,2015-12-31T00:00:00,1.08,1.0758544206619263,0.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Albertina,2016-12-31T00:00:00,1.2,1.193422555923462,0.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Albertina,2017-12-31T00:00:00,1.83,1.248286485671997,31.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Albertina,2018-12-31T00:00:00,1.56,1.8954758644104004,21.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Albertina,2019-12-31T00:00:00,1.56,1.4408214092254639,7.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Albertina,2020-12-31T00:00:00,1.68,1.6422723531723022,2.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Alfenas,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Alfenas,2013-12-31T00:00:00,1.98,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Alfenas,2014-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Alfenas,2015-12-31T00:00:00,1.38,1.4705090522766113,6.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Alfenas,2016-12-31T00:00:00,2.25,2.206185817718506,1.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Alfenas,2017-12-31T00:00:00,1.68,1.7243046760559082,2.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Alfenas,2018-12-31T00:00:00,2.34,2.2596182823181152,3.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Alfenas,2019-12-31T00:00:00,1.76,1.7442882061004639,0.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Alfenas,2020-12-31T00:00:00,2.36,2.849871873855591,20.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Alterosa,2012-12-31T00:00:00,1.59,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Alterosa,2013-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Alterosa,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Alterosa,2015-12-31T00:00:00,1.08,1.1032049655914307,2.15,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Alterosa,2016-12-31T00:00:00,1.92,1.9021645784378052,0.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Alterosa,2017-12-31T00:00:00,1.8,1.9713518619537354,9.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Alterosa,2018-12-31T00:00:00,1.96,1.8704864978790283,4.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Alterosa,2019-12-31T00:00:00,1.74,1.7480823993682861,0.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Alterosa,2020-12-31T00:00:00,1.98,1.9581525325775146,1.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Andradas,2012-12-31T00:00:00,1.98,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Andradas,2013-12-31T00:00:00,1.59,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Andradas,2014-12-31T00:00:00,1.21,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Andradas,2015-12-31T00:00:00,1.89,1.8754189014434814,0.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Andradas,2016-12-31T00:00:00,1.8,1.8580018281936646,3.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Andradas,2017-12-31T00:00:00,1.34,1.363943099975586,1.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Andradas,2018-12-31T00:00:00,1.73,1.6542448997497559,4.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Andradas,2019-12-31T00:00:00,1.62,1.5701125860214233,3.08,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Andradas,2020-12-31T00:00:00,2.57,2.6213912963867188,2.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Andrelandia,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Andrelandia,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Andrelandia,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Andrelandia,2015-12-31T00:00:00,1.2,0.9029824733734131,24.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Andrelandia,2016-12-31T00:00:00,1.5,1.5008647441864014,0.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Andrelandia,2017-12-31T00:00:00,1.4,1.3364684581756592,4.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Andrelandia,2018-12-31T00:00:00,1.5,1.4797494411468506,1.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Andrelandia,2019-12-31T00:00:00,1.5,1.4903979301452637,0.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Andrelandia,2020-12-31T00:00:00,1.8,1.7931219339370728,0.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Arceburgo,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Arceburgo,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Arceburgo,2014-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Arceburgo,2015-12-31T00:00:00,1.32,1.287894368171692,2.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Arceburgo,2016-12-31T00:00:00,1.8,1.7891547679901123,0.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Arceburgo,2017-12-31T00:00:00,1.02,1.0466246604919434,2.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Arceburgo,2018-12-31T00:00:00,1.72,1.897986650466919,10.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Arceburgo,2019-12-31T00:00:00,1.5,1.468726396560669,2.08,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Arceburgo,2020-12-31T00:00:00,1.84,1.8007729053497314,2.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Baependi,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Baependi,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Baependi,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Baependi,2015-12-31T00:00:00,0.84,1.0957680940628052,30.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Baependi,2016-12-31T00:00:00,1.8,1.749979853630066,2.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Baependi,2017-12-31T00:00:00,1.56,1.81355619430542,16.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Baependi,2018-12-31T00:00:00,1.56,1.870140790939331,19.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Baependi,2019-12-31T00:00:00,1.44,1.5013229846954346,4.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Baependi,2020-12-31T00:00:00,1.68,1.5271999835968018,9.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bandeira_do_Sul,2012-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bandeira_do_Sul,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bandeira_do_Sul,2014-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bandeira_do_Sul,2015-12-31T00:00:00,1.26,1.3063113689422607,3.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bandeira_do_Sul,2016-12-31T00:00:00,1.5,1.4942119121551514,0.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bandeira_do_Sul,2017-12-31T00:00:00,1.76,1.6583590507507324,5.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bandeira_do_Sul,2018-12-31T00:00:00,1.8,1.6144943237304688,10.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bandeira_do_Sul,2019-12-31T00:00:00,1.5,1.5228488445281982,1.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bandeira_do_Sul,2020-12-31T00:00:00,1.5,1.5718106031417847,4.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Boa_Esperanca,2012-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Boa_Esperanca,2013-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Boa_Esperanca,2014-12-31T00:00:00,1.15,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Boa_Esperanca,2015-12-31T00:00:00,1.26,1.2852152585983276,2.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Boa_Esperanca,2016-12-31T00:00:00,1.92,1.914249300956726,0.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Boa_Esperanca,2017-12-31T00:00:00,2.53,2.0268449783325195,19.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Boa_Esperanca,2018-12-31T00:00:00,1.8,2.1513986587524414,19.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Boa_Esperanca,2019-12-31T00:00:00,1.92,1.8089022636413574,5.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Boa_Esperanca,2020-12-31T00:00:00,2.06,2.2222959995269775,7.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bom_Sucesso,2012-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bom_Sucesso,2013-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bom_Sucesso,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bom_Sucesso,2015-12-31T00:00:00,1.14,1.1073962450027466,2.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bom_Sucesso,2016-12-31T00:00:00,1.92,1.889886736869812,1.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bom_Sucesso,2017-12-31T00:00:00,1.48,1.484447956085205,0.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bom_Sucesso,2018-12-31T00:00:00,1.7,1.7162988185882568,0.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bom_Sucesso,2019-12-31T00:00:00,1.5,1.481091022491455,1.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bom_Sucesso,2020-12-31T00:00:00,2.1,2.0366086959838867,3.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Borda_da_Mata,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Borda_da_Mata,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Borda_da_Mata,2014-12-31T00:00:00,0.78,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Borda_da_Mata,2015-12-31T00:00:00,1.2,1.3059289455413818,8.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Borda_da_Mata,2016-12-31T00:00:00,1.8,1.6921076774597168,5.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Borda_da_Mata,2017-12-31T00:00:00,1.67,1.6714951992034912,0.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Borda_da_Mata,2018-12-31T00:00:00,1.8,1.7330704927444458,3.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Borda_da_Mata,2019-12-31T00:00:00,1.56,1.5454760789871216,0.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Borda_da_Mata,2020-12-31T00:00:00,1.62,1.6649463176727295,2.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Brazopolis,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Brazopolis,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Brazopolis,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Brazopolis,2015-12-31T00:00:00,1.08,1.108765721321106,2.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Brazopolis,2016-12-31T00:00:00,1.44,1.4445581436157227,0.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Brazopolis,2017-12-31T00:00:00,0.63,0.9397026896476746,49.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Brazopolis,2018-12-31T00:00:00,1.56,1.2734546661376953,18.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Brazopolis,2019-12-31T00:00:00,1.56,1.5547842979431152,0.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Brazopolis,2020-12-31T00:00:00,1.68,1.6129190921783447,3.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bueno_Brandao,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bueno_Brandao,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bueno_Brandao,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bueno_Brandao,2015-12-31T00:00:00,1.26,1.237379789352417,1.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bueno_Brandao,2016-12-31T00:00:00,2.1,2.1094319820404053,0.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bueno_Brandao,2017-12-31T00:00:00,1.2,1.2453292608261108,3.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bueno_Brandao,2018-12-31T00:00:00,1.8,2.124958038330078,18.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bueno_Brandao,2019-12-31T00:00:00,1.56,1.4778560400009155,5.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bueno_Brandao,2020-12-31T00:00:00,1.8,1.72833251953125,3.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cachoeira_de_Minas,2012-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cachoeira_de_Minas,2013-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cachoeira_de_Minas,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cachoeira_de_Minas,2015-12-31T00:00:00,1.02,1.0172789096832275,0.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cachoeira_de_Minas,2016-12-31T00:00:00,1.56,1.5905320644378662,1.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cachoeira_de_Minas,2017-12-31T00:00:00,2.28,2.1033201217651367,7.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cachoeira_de_Minas,2018-12-31T00:00:00,2.2,2.146641254425049,2.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cachoeira_de_Minas,2019-12-31T00:00:00,1.68,1.602474570274353,4.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cachoeira_de_Minas,2020-12-31T00:00:00,1.86,1.9091486930847168,2.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Caete,2012-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Caete,2013-12-31T00:00:00,0.93,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Caete,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Caete,2015-12-31T00:00:00,1.08,1.0729249715805054,0.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Caete,2016-12-31T00:00:00,1.2,1.20125150680542,0.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Caete,2017-12-31T00:00:00,1.53,1.5171582698822021,0.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Caete,2018-12-31T00:00:00,1.5,1.5382769107818604,2.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Caete,2019-12-31T00:00:00,1.31,1.3109732866287231,0.07,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Caete,2020-12-31T00:00:00,1.2,1.2018885612487793,0.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Camacho,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Camacho,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Camacho,2014-12-31T00:00:00,0.67,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Camacho,2015-12-31T00:00:00,1.02,1.039942979812622,1.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Camacho,2016-12-31T00:00:00,1.5,1.5436317920684814,2.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Camacho,2017-12-31T00:00:00,1.73,1.3696764707565308,20.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Camacho,2018-12-31T00:00:00,1.8,1.8401422500610352,2.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Camacho,2019-12-31T00:00:00,1.5,1.4654208421707153,2.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Camacho,2020-12-31T00:00:00,2.1,2.0818357467651367,0.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cambuquira,2012-12-31T00:00:00,1.15,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cambuquira,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cambuquira,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cambuquira,2015-12-31T00:00:00,1.08,1.0832768678665161,0.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cambuquira,2016-12-31T00:00:00,1.68,1.6560684442520142,1.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cambuquira,2017-12-31T00:00:00,1.82,1.87092924118042,2.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cambuquira,2018-12-31T00:00:00,1.74,1.7847018241882324,2.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cambuquira,2019-12-31T00:00:00,1.68,1.6875885725021362,0.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cambuquira,2020-12-31T00:00:00,1.8,1.77700674533844,1.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campanha,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campanha,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campanha,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campanha,2015-12-31T00:00:00,1.02,1.0586577653884888,3.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campanha,2016-12-31T00:00:00,1.5,1.5229921340942383,1.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campanha,2017-12-31T00:00:00,1.88,1.7059398889541626,9.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campanha,2018-12-31T00:00:00,1.8,1.7400221824645996,3.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campanha,2019-12-31T00:00:00,1.51,1.5165948867797852,0.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campanha,2020-12-31T00:00:00,1.68,1.7273821830749512,2.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campestre,2012-12-31T00:00:00,1.35,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campestre,2013-12-31T00:00:00,1.31,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campestre,2014-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campestre,2015-12-31T00:00:00,1.91,1.3400760889053345,29.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campestre,2016-12-31T00:00:00,1.85,1.9675568342208862,6.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campestre,2017-12-31T00:00:00,2.11,2.0133447647094727,4.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campestre,2018-12-31T00:00:00,1.54,1.8749016523361206,21.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campestre,2019-12-31T00:00:00,1.55,1.6572707891464233,6.92,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campestre,2020-12-31T00:00:00,2.14,2.107668876647949,1.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campo_Belo,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campo_Belo,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campo_Belo,2014-12-31T00:00:00,0.63,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campo_Belo,2015-12-31T00:00:00,0.84,0.913375973701477,8.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campo_Belo,2016-12-31T00:00:00,1.62,1.6150989532470703,0.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campo_Belo,2017-12-31T00:00:00,1.32,1.6262562274932861,23.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campo_Belo,2018-12-31T00:00:00,1.26,1.6546587944030762,31.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campo_Belo,2019-12-31T00:00:00,1.26,1.2458417415618896,1.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campo_Belo,2020-12-31T00:00:00,1.8,1.775882363319397,1.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campo_do_Meio,2012-12-31T00:00:00,1.17,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campo_do_Meio,2013-12-31T00:00:00,1.17,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campo_do_Meio,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campo_do_Meio,2015-12-31T00:00:00,0.9,0.8854026198387146,1.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campo_do_Meio,2016-12-31T00:00:00,1.8,1.8061559200286865,0.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campo_do_Meio,2017-12-31T00:00:00,2.08,2.0828697681427,0.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campo_do_Meio,2018-12-31T00:00:00,1.82,1.9199854135513306,5.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campo_do_Meio,2019-12-31T00:00:00,1.62,1.623877763748169,0.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campo_do_Meio,2020-12-31T00:00:00,2.4,1.9318395853042603,19.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campos_Gerais,2012-12-31T00:00:00,1.65,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campos_Gerais,2013-12-31T00:00:00,1.22,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campos_Gerais,2014-12-31T00:00:00,1.15,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campos_Gerais,2015-12-31T00:00:00,1.32,1.3674145936965942,3.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campos_Gerais,2016-12-31T00:00:00,2.5,2.5383710861206055,1.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campos_Gerais,2017-12-31T00:00:00,1.81,1.982367753982544,9.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campos_Gerais,2018-12-31T00:00:00,2.21,2.209437370300293,0.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campos_Gerais,2019-12-31T00:00:00,1.59,1.4540034532546997,8.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campos_Gerais,2020-12-31T00:00:00,2.69,2.6270382404327393,2.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Candeias,2012-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Candeias,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Candeias,2014-12-31T00:00:00,0.99,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Candeias,2015-12-31T00:00:00,1.2,1.1398987770080566,5.01,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Candeias,2016-12-31T00:00:00,2.28,2.3081021308898926,1.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Candeias,2017-12-31T00:00:00,1.38,1.6621882915496826,20.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Candeias,2018-12-31T00:00:00,2.04,2.2086172103881836,8.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Candeias,2019-12-31T00:00:00,1.5,1.534045696258545,2.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Candeias,2020-12-31T00:00:00,1.86,1.8119171857833862,2.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Capetinga,2012-12-31T00:00:00,1.81,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Capetinga,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Capetinga,2014-12-31T00:00:00,1.59,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Capetinga,2015-12-31T00:00:00,1.2,1.192002773284912,0.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Capetinga,2016-12-31T00:00:00,1.93,1.9360005855560303,0.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Capetinga,2017-12-31T00:00:00,2.09,2.043588161468506,2.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Capetinga,2018-12-31T00:00:00,2.7,2.739926338195801,1.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Capetinga,2019-12-31T00:00:00,2.04,2.0864968299865723,2.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Capetinga,2020-12-31T00:00:00,2.21,2.1823863983154297,1.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Capitolio,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Capitolio,2013-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Capitolio,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Capitolio,2015-12-31T00:00:00,1.2,1.1956579685211182,0.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Capitolio,2016-12-31T00:00:00,1.32,1.3423311710357666,1.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Capitolio,2017-12-31T00:00:00,1.47,1.4507207870483398,1.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Capitolio,2018-12-31T00:00:00,1.8,1.8226841688156128,1.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Capitolio,2019-12-31T00:00:00,1.5,1.4809346199035645,1.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Capitolio,2020-12-31T00:00:00,2.1,2.1174678802490234,0.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_da_Cachoeira,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_da_Cachoeira,2013-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_da_Cachoeira,2014-12-31T00:00:00,1.15,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_da_Cachoeira,2015-12-31T00:00:00,1.26,1.248246669769287,0.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_da_Cachoeira,2016-12-31T00:00:00,1.44,1.6624433994293213,15.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_da_Cachoeira,2017-12-31T00:00:00,1.73,1.504688024520874,13.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_da_Cachoeira,2018-12-31T00:00:00,1.98,1.7254345417022705,12.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_da_Cachoeira,2019-12-31T00:00:00,1.62,1.709087610244751,5.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_da_Cachoeira,2020-12-31T00:00:00,1.8,1.820115566253662,1.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_de_Minas,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_de_Minas,2013-12-31T00:00:00,1.74,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_de_Minas,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_de_Minas,2015-12-31T00:00:00,1.32,1.267394781112671,3.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_de_Minas,2016-12-31T00:00:00,1.5,1.486907958984375,0.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_de_Minas,2017-12-31T00:00:00,1.38,1.434916377067566,3.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_de_Minas,2018-12-31T00:00:00,1.56,1.508012056350708,3.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_de_Minas,2019-12-31T00:00:00,1.5,1.5458825826644897,3.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_de_Minas,2020-12-31T00:00:00,1.74,1.781479835510254,2.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_do_Rio_Claro,2012-12-31T00:00:00,1.66,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_do_Rio_Claro,2013-12-31T00:00:00,1.94,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_do_Rio_Claro,2014-12-31T00:00:00,1.65,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_do_Rio_Claro,2015-12-31T00:00:00,1.53,1.5246081352233887,0.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_do_Rio_Claro,2016-12-31T00:00:00,2.37,2.2823781967163086,3.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_do_Rio_Claro,2017-12-31T00:00:00,1.82,2.045761823654175,12.4,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_do_Rio_Claro,2018-12-31T00:00:00,2.22,2.2409133911132812,0.94,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_do_Rio_Claro,2019-12-31T00:00:00,1.94,1.8397998809814453,5.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_do_Rio_Claro,2020-12-31T00:00:00,2.78,2.7457714080810547,1.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carvalhopolis,2012-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carvalhopolis,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carvalhopolis,2014-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carvalhopolis,2015-12-31T00:00:00,1.44,1.455777883529663,1.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carvalhopolis,2016-12-31T00:00:00,1.8,1.7802207469940186,1.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carvalhopolis,2017-12-31T00:00:00,1.44,1.490381121635437,3.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carvalhopolis,2018-12-31T00:00:00,1.56,1.711681842803955,9.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carvalhopolis,2019-12-31T00:00:00,1.56,1.5113294124603271,3.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carvalhopolis,2020-12-31T00:00:00,1.68,1.6862305402755737,0.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cassia,2012-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cassia,2013-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cassia,2014-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cassia,2015-12-31T00:00:00,1.14,1.1300179958343506,0.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cassia,2016-12-31T00:00:00,1.56,1.5192255973815918,2.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cassia,2017-12-31T00:00:00,1.6,1.6007258892059326,0.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cassia,2018-12-31T00:00:00,2.1,2.0851919651031494,0.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cassia,2019-12-31T00:00:00,1.56,1.5851845741271973,1.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cassia,2020-12-31T00:00:00,2.17,2.145719051361084,1.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_da_Barra_de_Minas,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_da_Barra_de_Minas,2013-12-31T00:00:00,1.46,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_da_Barra_de_Minas,2014-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_da_Barra_de_Minas,2015-12-31T00:00:00,1.2,1.4814075231552124,23.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_da_Barra_de_Minas,2016-12-31T00:00:00,2.1,2.149197578430176,2.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_da_Barra_de_Minas,2017-12-31T00:00:00,2.63,2.626051187515259,0.15,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_da_Barra_de_Minas,2018-12-31T00:00:00,2.08,2.6124260425567627,25.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_da_Barra_de_Minas,2019-12-31T00:00:00,1.67,1.5640133619308472,6.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_da_Barra_de_Minas,2020-12-31T00:00:00,1.91,1.9346662759780884,1.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_das_Pedras,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_das_Pedras,2013-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_das_Pedras,2014-12-31T00:00:00,1.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_das_Pedras,2015-12-31T00:00:00,1.26,1.320650577545166,4.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_das_Pedras,2016-12-31T00:00:00,1.44,1.4293920993804932,0.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_das_Pedras,2017-12-31T00:00:00,1.47,1.4501471519470215,1.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_das_Pedras,2018-12-31T00:00:00,1.56,1.5123214721679688,3.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_das_Pedras,2019-12-31T00:00:00,1.68,1.5090293884277344,10.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_das_Pedras,2020-12-31T00:00:00,1.74,1.7767548561096191,2.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_do_Rio_Verde,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_do_Rio_Verde,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_do_Rio_Verde,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_do_Rio_Verde,2015-12-31T00:00:00,1.62,1.2975529432296753,19.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_do_Rio_Verde,2016-12-31T00:00:00,1.62,1.6968427896499634,4.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_do_Rio_Verde,2017-12-31T00:00:00,2.04,1.860877513885498,8.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_do_Rio_Verde,2018-12-31T00:00:00,1.98,2.044170379638672,3.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_do_Rio_Verde,2019-12-31T00:00:00,1.8,1.6957175731658936,5.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_do_Rio_Verde,2020-12-31T00:00:00,1.8,1.9026437997817993,5.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_dos_Ouros,2012-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_dos_Ouros,2013-12-31T00:00:00,1.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_dos_Ouros,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_dos_Ouros,2015-12-31T00:00:00,1.32,1.309022307395935,0.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_dos_Ouros,2016-12-31T00:00:00,1.5,1.5296638011932373,1.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_dos_Ouros,2017-12-31T00:00:00,1.52,1.5605518817901611,2.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_dos_Ouros,2018-12-31T00:00:00,1.5,1.5150823593139648,1.01,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_dos_Ouros,2019-12-31T00:00:00,1.5,1.502378225326538,0.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_dos_Ouros,2020-12-31T00:00:00,1.5,1.5053446292877197,0.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Coqueiral,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Coqueiral,2013-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Coqueiral,2014-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Coqueiral,2015-12-31T00:00:00,1.26,1.1792713403701782,6.41,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Coqueiral,2016-12-31T00:00:00,1.68,1.6899669170379639,0.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Coqueiral,2017-12-31T00:00:00,1.75,1.7342860698699951,0.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Coqueiral,2018-12-31T00:00:00,1.8,1.6926336288452148,5.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Coqueiral,2019-12-31T00:00:00,1.5,1.4836145639419556,1.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Coqueiral,2020-12-31T00:00:00,2.16,2.0370776653289795,5.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cordislandia,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cordislandia,2013-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cordislandia,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cordislandia,2015-12-31T00:00:00,1.26,1.195666790008545,5.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cordislandia,2016-12-31T00:00:00,1.62,1.5719826221466064,2.96,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cordislandia,2017-12-31T00:00:00,2.1,1.954573631286621,6.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cordislandia,2018-12-31T00:00:00,1.86,1.8951036930084229,1.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cordislandia,2019-12-31T00:00:00,1.5,1.4643831253051758,2.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cordislandia,2020-12-31T00:00:00,1.62,1.7702758312225342,9.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Corrego_Danta,2012-12-31T00:00:00,1.25,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Corrego_Danta,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Corrego_Danta,2014-12-31T00:00:00,1.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Corrego_Danta,2015-12-31T00:00:00,1.32,1.3545842170715332,2.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Corrego_Danta,2016-12-31T00:00:00,1.5,1.4809355735778809,1.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Corrego_Danta,2017-12-31T00:00:00,1.44,1.453413486480713,0.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Corrego_Danta,2018-12-31T00:00:00,1.8,1.7807748317718506,1.07,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Corrego_Danta,2019-12-31T00:00:00,1.5,1.569751262664795,4.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Corrego_Danta,2020-12-31T00:00:00,1.8,1.7946748733520508,0.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cristais,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cristais,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cristais,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cristais,2015-12-31T00:00:00,1.2,1.2151623964309692,1.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cristais,2016-12-31T00:00:00,1.92,1.8280994892120361,4.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cristais,2017-12-31T00:00:00,2.4,2.376159429550171,0.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cristais,2018-12-31T00:00:00,1.92,2.005603313446045,4.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cristais,2019-12-31T00:00:00,1.74,1.80980384349823,4.01,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cristais,2020-12-31T00:00:00,1.92,2.0062191486358643,4.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cristina,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cristina,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cristina,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cristina,2015-12-31T00:00:00,1.08,1.0892044305801392,0.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cristina,2016-12-31T00:00:00,1.44,1.4779515266418457,2.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cristina,2017-12-31T00:00:00,1.62,1.575239896774292,2.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cristina,2018-12-31T00:00:00,1.56,1.5601024627685547,0.01,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cristina,2019-12-31T00:00:00,1.5,1.49946928024292,0.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cristina,2020-12-31T00:00:00,2.1,2.235072374343872,6.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Delfinopolis,2012-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Delfinopolis,2013-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Delfinopolis,2014-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Delfinopolis,2015-12-31T00:00:00,1.32,1.3086179494857788,0.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Delfinopolis,2016-12-31T00:00:00,1.5,1.5031293630599976,0.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Delfinopolis,2017-12-31T00:00:00,1.24,1.2806174755096436,3.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Delfinopolis,2018-12-31T00:00:00,1.8,1.7941763401031494,0.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Delfinopolis,2019-12-31T00:00:00,1.56,1.521855115890503,2.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Delfinopolis,2020-12-31T00:00:00,1.8,1.7544772624969482,2.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Desterro_de_Entre_Rios,2012-12-31T00:00:00,0.57,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Desterro_de_Entre_Rios,2013-12-31T00:00:00,0.57,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Desterro_de_Entre_Rios,2014-12-31T00:00:00,3.28,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Desterro_de_Entre_Rios,2015-12-31T00:00:00,1.51,1.5625202655792236,3.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Desterro_de_Entre_Rios,2016-12-31T00:00:00,2.28,2.5910701751708984,13.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Desterro_de_Entre_Rios,2017-12-31T00:00:00,2.08,2.0651743412017822,0.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Desterro_de_Entre_Rios,2018-12-31T00:00:00,2.1,2.2606096267700195,7.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Desterro_de_Entre_Rios,2019-12-31T00:00:00,1.8,1.7664878368377686,1.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Desterro_de_Entre_Rios,2020-12-31T00:00:00,2.4,2.3912720680236816,0.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Divinesia,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Divinesia,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Divinesia,2014-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Divinesia,2015-12-31T00:00:00,1.5,1.5647540092468262,4.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Divinesia,2016-12-31T00:00:00,1.8,1.7711114883422852,1.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Divinesia,2017-12-31T00:00:00,2.04,2.0354690551757812,0.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Divinesia,2018-12-31T00:00:00,4.0,3.769927501678467,5.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Divinesia,2019-12-31T00:00:00,2.0,1.934491753578186,3.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Divinesia,2020-12-31T00:00:00,2.1,1.980061650276184,5.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Divisa_Nova,2012-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Divisa_Nova,2013-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Divisa_Nova,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Divisa_Nova,2015-12-31T00:00:00,1.08,1.117981195449829,3.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Divisa_Nova,2016-12-31T00:00:00,1.68,1.6868183612823486,0.41,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Divisa_Nova,2017-12-31T00:00:00,2.28,2.2074999809265137,3.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Divisa_Nova,2018-12-31T00:00:00,1.8,1.7411510944366455,3.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Divisa_Nova,2019-12-31T00:00:00,1.8,1.7407615184783936,3.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Divisa_Nova,2020-12-31T00:00:00,1.8,1.8516743183135986,2.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Dom_Vicoso,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Dom_Vicoso,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Dom_Vicoso,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Dom_Vicoso,2015-12-31T00:00:00,1.32,1.2009036540985107,9.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Dom_Vicoso,2016-12-31T00:00:00,1.5,1.4970933198928833,0.19,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Dom_Vicoso,2017-12-31T00:00:00,1.16,1.444516658782959,24.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Dom_Vicoso,2018-12-31T00:00:00,1.5,1.511002540588379,0.73,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Dom_Vicoso,2019-12-31T00:00:00,1.65,1.6038126945495605,2.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Dom_Vicoso,2020-12-31T00:00:00,1.43,1.4649324417114258,2.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Doresopolis,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Doresopolis,2013-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Doresopolis,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Doresopolis,2015-12-31T00:00:00,1.2,1.2012829780578613,0.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Doresopolis,2016-12-31T00:00:00,1.26,1.2698454856872559,0.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Doresopolis,2017-12-31T00:00:00,1.43,1.423482060432434,0.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Doresopolis,2018-12-31T00:00:00,1.8,1.8161416053771973,0.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Doresopolis,2019-12-31T00:00:00,1.74,1.6476829051971436,5.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Doresopolis,2020-12-31T00:00:00,1.8,1.7834374904632568,0.92,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Eloi_Mendes,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Eloi_Mendes,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Eloi_Mendes,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Eloi_Mendes,2015-12-31T00:00:00,1.26,1.2204492092132568,3.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Eloi_Mendes,2016-12-31T00:00:00,1.74,1.7714474201202393,1.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Eloi_Mendes,2017-12-31T00:00:00,1.83,2.180109977722168,19.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Eloi_Mendes,2018-12-31T00:00:00,1.72,1.825746774673462,6.15,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Eloi_Mendes,2019-12-31T00:00:00,1.5,1.5720586776733398,4.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Eloi_Mendes,2020-12-31T00:00:00,2.11,1.7836036682128906,15.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Entre_Rios_de_Minas,2012-12-31T00:00:00,1.58,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Entre_Rios_de_Minas,2013-12-31T00:00:00,1.58,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Entre_Rios_de_Minas,2014-12-31T00:00:00,1.58,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Entre_Rios_de_Minas,2015-12-31T00:00:00,1.63,1.5806550979614258,3.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Entre_Rios_de_Minas,2016-12-31T00:00:00,2.4,2.4042956829071045,0.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Entre_Rios_de_Minas,2017-12-31T00:00:00,2.28,2.2329418659210205,2.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Entre_Rios_de_Minas,2018-12-31T00:00:00,2.1,2.215639114379883,5.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Entre_Rios_de_Minas,2019-12-31T00:00:00,1.92,1.9458861351013184,1.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Entre_Rios_de_Minas,2020-12-31T00:00:00,1.8,1.8161952495574951,0.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Fama,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Fama,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Fama,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Fama,2015-12-31T00:00:00,1.08,1.1090937852859497,2.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Fama,2016-12-31T00:00:00,1.68,1.4636623859405518,12.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Fama,2017-12-31T00:00:00,1.32,1.8017923831939697,36.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Fama,2018-12-31T00:00:00,1.51,1.6768600940704346,11.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Fama,2019-12-31T00:00:00,1.62,1.574767827987671,2.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Fama,2020-12-31T00:00:00,1.8,1.771059513092041,1.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Grao_Mogol,2012-12-31T00:00:00,0.3,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Grao_Mogol,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Grao_Mogol,2014-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Grao_Mogol,2015-12-31T00:00:00,0.9,1.007103443145752,11.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Grao_Mogol,2016-12-31T00:00:00,0.6,0.5925709009170532,1.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Grao_Mogol,2017-12-31T00:00:00,3.5,3.4899706840515137,0.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Grao_Mogol,2018-12-31T00:00:00,1.0,0.8672840595245361,13.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Grao_Mogol,2019-12-31T00:00:00,0.73,0.7893197536468506,8.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Grao_Mogol,2020-12-31T00:00:00,0.77,0.7420811653137207,3.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Guape,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Guape,2013-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Guape,2014-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Guape,2015-12-31T00:00:00,1.8,1.828873872756958,1.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Guape,2016-12-31T00:00:00,1.92,1.9210323095321655,0.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Guape,2017-12-31T00:00:00,1.92,1.5433900356292725,19.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Guape,2018-12-31T00:00:00,2.1,2.0562045574188232,2.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Guape,2019-12-31T00:00:00,1.62,1.6159014701843262,0.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Guape,2020-12-31T00:00:00,1.85,1.8062652349472046,2.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Heliodora,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Heliodora,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Heliodora,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Heliodora,2015-12-31T00:00:00,1.2,1.2722090482711792,6.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Heliodora,2016-12-31T00:00:00,1.5,1.631364107131958,8.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Heliodora,2017-12-31T00:00:00,1.57,1.3890091180801392,11.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Heliodora,2018-12-31T00:00:00,1.8,1.8051838874816895,0.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Heliodora,2019-12-31T00:00:00,1.56,1.5921521186828613,2.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Heliodora,2020-12-31T00:00:00,1.8,1.8175824880599976,0.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ibituruna,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ibituruna,2013-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ibituruna,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ibituruna,2015-12-31T00:00:00,1.2,1.18319833278656,1.4,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ibituruna,2016-12-31T00:00:00,1.74,1.7189316749572754,1.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ibituruna,2017-12-31T00:00:00,1.62,1.465693712234497,9.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ibituruna,2018-12-31T00:00:00,1.66,1.7071869373321533,2.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ibituruna,2019-12-31T00:00:00,1.66,1.6635055541992188,0.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ibituruna,2020-12-31T00:00:00,1.8,1.8007993698120117,0.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ijaci,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ijaci,2013-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ijaci,2014-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ijaci,2015-12-31T00:00:00,0.84,0.8420534729957581,0.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ijaci,2016-12-31T00:00:00,1.8,1.8345980644226074,1.92,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ijaci,2017-12-31T00:00:00,1.25,1.5804165601730347,26.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ijaci,2018-12-31T00:00:00,2.0,1.9172590970993042,4.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ijaci,2019-12-31T00:00:00,1.42,1.448155164718628,1.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ijaci,2020-12-31T00:00:00,2.46,2.512629985809326,2.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ilicinea,2012-12-31T00:00:00,1.69,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ilicinea,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ilicinea,2014-12-31T00:00:00,1.35,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ilicinea,2015-12-31T00:00:00,1.5,1.4689444303512573,2.07,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ilicinea,2016-12-31T00:00:00,2.46,2.4823789596557617,0.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ilicinea,2017-12-31T00:00:00,1.92,2.0923516750335693,8.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ilicinea,2018-12-31T00:00:00,2.46,2.1551337242126465,12.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ilicinea,2019-12-31T00:00:00,1.86,1.8361231088638306,1.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ilicinea,2020-12-31T00:00:00,2.1,2.5118441581726074,19.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Inconfidentes,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Inconfidentes,2013-12-31T00:00:00,1.4,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Inconfidentes,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Inconfidentes,2015-12-31T00:00:00,1.2,1.19416344165802,0.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Inconfidentes,2016-12-31T00:00:00,2.1,2.1515073776245117,2.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Inconfidentes,2017-12-31T00:00:00,1.3,1.352323293685913,4.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Inconfidentes,2018-12-31T00:00:00,2.88,2.489123582839966,13.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Inconfidentes,2019-12-31T00:00:00,1.5,1.5317771434783936,2.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Inconfidentes,2020-12-31T00:00:00,2.46,2.8679745197296143,16.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ingai,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ingai,2013-12-31T00:00:00,1.68,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ingai,2014-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ingai,2015-12-31T00:00:00,1.2,1.1541653871536255,3.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ingai,2016-12-31T00:00:00,1.74,1.8365471363067627,5.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ingai,2017-12-31T00:00:00,2.22,1.7026710510253906,23.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ingai,2018-12-31T00:00:00,1.8,1.9596589803695679,8.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ingai,2019-12-31T00:00:00,1.5,1.5262079238891602,1.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ingai,2020-12-31T00:00:00,1.68,1.6704509258270264,0.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itajuba,2012-12-31T00:00:00,0.91,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itajuba,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itajuba,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itajuba,2015-12-31T00:00:00,1.5,1.5048089027404785,0.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itajuba,2016-12-31T00:00:00,1.8,1.7535803318023682,2.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itajuba,2017-12-31T00:00:00,2.33,2.3054535388946533,1.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itajuba,2018-12-31T00:00:00,1.82,1.976781964302063,8.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itajuba,2019-12-31T00:00:00,1.82,1.810960292816162,0.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itajuba,2020-12-31T00:00:00,1.59,1.9001659154891968,19.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itamogi,2012-12-31T00:00:00,1.95,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itamogi,2013-12-31T00:00:00,1.17,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itamogi,2014-12-31T00:00:00,1.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itamogi,2015-12-31T00:00:00,1.58,1.5597949028015137,1.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itamogi,2016-12-31T00:00:00,1.95,1.8813585042953491,3.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itamogi,2017-12-31T00:00:00,1.42,1.407165288925171,0.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itamogi,2018-12-31T00:00:00,2.1,2.2161476612091064,5.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itamogi,2019-12-31T00:00:00,1.85,1.895580768585205,2.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itamogi,2020-12-31T00:00:00,2.4,2.3821260929107666,0.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itapecerica,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itapecerica,2013-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itapecerica,2014-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itapecerica,2015-12-31T00:00:00,1.2,1.2628767490386963,5.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itapecerica,2016-12-31T00:00:00,1.5,1.4840192794799805,1.07,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itapecerica,2017-12-31T00:00:00,1.56,1.5465538501739502,0.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itapecerica,2018-12-31T00:00:00,1.8,1.8220808506011963,1.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itapecerica,2019-12-31T00:00:00,1.2,1.2515753507614136,4.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itapecerica,2020-12-31T00:00:00,1.8,1.7223477363586426,4.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itumirim,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itumirim,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itumirim,2014-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itumirim,2015-12-31T00:00:00,1.08,1.0794800519943237,0.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itumirim,2016-12-31T00:00:00,1.62,1.6215413808822632,0.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itumirim,2017-12-31T00:00:00,1.32,1.5562273263931274,17.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itumirim,2018-12-31T00:00:00,1.8,1.533545732498169,14.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itumirim,2019-12-31T00:00:00,1.6,1.63187837600708,1.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itumirim,2020-12-31T00:00:00,2.05,1.9269593954086304,6.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itutinga,2012-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itutinga,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itutinga,2014-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itutinga,2015-12-31T00:00:00,1.26,1.3551889657974243,7.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itutinga,2016-12-31T00:00:00,1.68,1.6755850315093994,0.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itutinga,2017-12-31T00:00:00,1.49,1.4874286651611328,0.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itutinga,2018-12-31T00:00:00,1.52,1.5861022472381592,4.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itutinga,2019-12-31T00:00:00,1.52,1.5051777362823486,0.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itutinga,2020-12-31T00:00:00,1.8,1.7665133476257324,1.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Jacutinga,2012-12-31T00:00:00,1.68,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Jacutinga,2013-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Jacutinga,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Jacutinga,2015-12-31T00:00:00,1.32,1.5017608404159546,13.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Jacutinga,2016-12-31T00:00:00,1.5,1.4974298477172852,0.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Jacutinga,2017-12-31T00:00:00,1.37,1.3580901622772217,0.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Jacutinga,2018-12-31T00:00:00,1.74,1.6756165027618408,3.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Jacutinga,2019-12-31T00:00:00,1.68,1.6903562545776367,0.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Jacutinga,2020-12-31T00:00:00,1.8,1.8184936046600342,1.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Jesuania,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Jesuania,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Jesuania,2014-12-31T00:00:00,1.05,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Jesuania,2015-12-31T00:00:00,0.96,1.1069777011871338,15.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Jesuania,2016-12-31T00:00:00,1.56,1.479438304901123,5.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Jesuania,2017-12-31T00:00:00,1.52,1.4647576808929443,3.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Jesuania,2018-12-31T00:00:00,1.68,1.783173680305481,6.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Jesuania,2019-12-31T00:00:00,1.5,1.6250910758972168,8.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Jesuania,2020-12-31T00:00:00,1.5,1.5921159982681274,6.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Lambari,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Lambari,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Lambari,2014-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Lambari,2015-12-31T00:00:00,1.08,1.1050264835357666,2.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Lambari,2016-12-31T00:00:00,1.5,1.44411301612854,3.73,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Lambari,2017-12-31T00:00:00,1.44,1.5102189779281616,4.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Lambari,2018-12-31T00:00:00,1.56,1.604712724685669,2.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Lambari,2019-12-31T00:00:00,1.56,1.5299803018569946,1.92,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Lambari,2020-12-31T00:00:00,1.8,1.7228368520736694,4.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Lavras,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Lavras,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Lavras,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Lavras,2015-12-31T00:00:00,0.84,0.8556072115898132,1.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Lavras,2016-12-31T00:00:00,1.68,1.7476942539215088,4.03,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Lavras,2017-12-31T00:00:00,2.25,1.5847954750061035,29.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Lavras,2018-12-31T00:00:00,1.92,2.147162914276123,11.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Lavras,2019-12-31T00:00:00,1.5,1.606032133102417,7.07,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Lavras,2020-12-31T00:00:00,1.8,1.8516381978988647,2.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Luminarias,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Luminarias,2013-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Luminarias,2014-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Luminarias,2015-12-31T00:00:00,0.84,0.8969110250473022,6.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Luminarias,2016-12-31T00:00:00,1.86,1.9183439016342163,3.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Luminarias,2017-12-31T00:00:00,2.33,2.161457061767578,7.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Luminarias,2018-12-31T00:00:00,2.0,2.459416627883911,22.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Luminarias,2019-12-31T00:00:00,1.72,1.726354718208313,0.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Luminarias,2020-12-31T00:00:00,1.86,1.9074280261993408,2.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Machado,2012-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Machado,2013-12-31T00:00:00,1.62,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Machado,2014-12-31T00:00:00,1.15,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Machado,2015-12-31T00:00:00,1.32,1.3767030239105225,4.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Machado,2016-12-31T00:00:00,1.86,1.8961869478225708,1.95,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Machado,2017-12-31T00:00:00,1.51,1.3450974225997925,10.92,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Machado,2018-12-31T00:00:00,1.98,2.073185443878174,4.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Machado,2019-12-31T00:00:00,1.53,1.5510867834091187,1.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Machado,2020-12-31T00:00:00,2.21,2.0361552238464355,7.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Maria_da_Fe,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Maria_da_Fe,2013-12-31T00:00:00,0.89,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Maria_da_Fe,2014-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Maria_da_Fe,2015-12-31T00:00:00,1.51,1.4417918920516968,4.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Maria_da_Fe,2016-12-31T00:00:00,1.91,1.9258549213409424,0.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Maria_da_Fe,2017-12-31T00:00:00,1.51,1.5222867727279663,0.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Maria_da_Fe,2018-12-31T00:00:00,1.5,1.6499534845352173,10.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Maria_da_Fe,2019-12-31T00:00:00,1.5,1.482274055480957,1.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Maria_da_Fe,2020-12-31T00:00:00,1.73,1.5093865394592285,12.75,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Moeda,2012-12-31T00:00:00,0.77,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Moeda,2013-12-31T00:00:00,0.77,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Moeda,2014-12-31T00:00:00,0.69,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Moeda,2015-12-31T00:00:00,0.94,0.978086531162262,4.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Moeda,2016-12-31T00:00:00,0.94,0.9366270303726196,0.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Moeda,2017-12-31T00:00:00,2.0,1.9366432428359985,3.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Moeda,2018-12-31T00:00:00,1.2,1.2356761693954468,2.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Moeda,2019-12-31T00:00:00,1.0,0.9770218133926392,2.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Moeda,2020-12-31T00:00:00,1.2,1.2574166059494019,4.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monsenhor_Paulo,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monsenhor_Paulo,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monsenhor_Paulo,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monsenhor_Paulo,2015-12-31T00:00:00,1.26,1.226335048675537,2.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monsenhor_Paulo,2016-12-31T00:00:00,1.62,1.6338948011398315,0.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monsenhor_Paulo,2017-12-31T00:00:00,1.72,1.7371395826339722,1.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monsenhor_Paulo,2018-12-31T00:00:00,1.8,1.6902961730957031,6.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monsenhor_Paulo,2019-12-31T00:00:00,1.5,1.5007109642028809,0.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monsenhor_Paulo,2020-12-31T00:00:00,2.1,1.8437997102737427,12.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Alegre_de_Minas,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Alegre_de_Minas,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Alegre_de_Minas,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Alegre_de_Minas,2015-12-31T00:00:00,1.2,1.550210952758789,29.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Alegre_de_Minas,2016-12-31T00:00:00,1.5,1.6461410522460938,9.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Alegre_de_Minas,2017-12-31T00:00:00,3.27,3.333087921142578,1.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Alegre_de_Minas,2018-12-31T00:00:00,1.8,1.8142977952957153,0.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Alegre_de_Minas,2019-12-31T00:00:00,1.8,1.8817222118377686,4.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Alegre_de_Minas,2020-12-31T00:00:00,3.0,3.146216630935669,4.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Formoso,2012-12-31T00:00:00,0.45,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Formoso,2013-12-31T00:00:00,0.45,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Formoso,2014-12-31T00:00:00,0.42,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Formoso,2015-12-31T00:00:00,0.42,0.4224751591682434,0.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Formoso,2016-12-31T00:00:00,0.42,0.41953176259994507,0.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Formoso,2017-12-31T00:00:00,1.33,1.36080002784729,2.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Formoso,2018-12-31T00:00:00,1.2,1.367970585823059,14.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Formoso,2019-12-31T00:00:00,1.2,1.2156375646591187,1.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Formoso,2020-12-31T00:00:00,0.6,0.6016768217086792,0.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Siao,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Siao,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Siao,2014-12-31T00:00:00,0.66,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Siao,2015-12-31T00:00:00,1.2,1.1589480638504028,3.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Siao,2016-12-31T00:00:00,1.62,1.6002681255340576,1.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Siao,2017-12-31T00:00:00,1.2,1.7213633060455322,43.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Siao,2018-12-31T00:00:00,1.8,1.845621109008789,2.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Siao,2019-12-31T00:00:00,1.56,1.5984315872192383,2.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Siao,2020-12-31T00:00:00,1.8,1.767592191696167,1.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Muzambinho,2012-12-31T00:00:00,1.74,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Muzambinho,2013-12-31T00:00:00,1.35,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Muzambinho,2014-12-31T00:00:00,1.35,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Muzambinho,2015-12-31T00:00:00,1.48,1.5131069421768188,2.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Muzambinho,2016-12-31T00:00:00,1.98,1.9736541509628296,0.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Muzambinho,2017-12-31T00:00:00,1.62,1.5744290351867676,2.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Muzambinho,2018-12-31T00:00:00,1.3,1.804200291633606,38.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Muzambinho,2019-12-31T00:00:00,2.1,1.5119383335113525,28.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Muzambinho,2020-12-31T00:00:00,1.76,1.6125032901763916,8.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Natercia,2012-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Natercia,2013-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Natercia,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Natercia,2015-12-31T00:00:00,1.38,1.3407628536224365,2.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Natercia,2016-12-31T00:00:00,1.56,1.5967637300491333,2.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Natercia,2017-12-31T00:00:00,1.6,1.5154821872711182,5.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Natercia,2018-12-31T00:00:00,1.8,1.7139263153076172,4.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Natercia,2019-12-31T00:00:00,1.44,1.5802150964736938,9.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Natercia,2020-12-31T00:00:00,1.44,1.625365972518921,12.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Nazareno,2012-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Nazareno,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Nazareno,2014-12-31T00:00:00,1.3,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Nazareno,2015-12-31T00:00:00,1.8,1.6896858215332031,6.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Nazareno,2016-12-31T00:00:00,1.92,1.891727328300476,1.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Nazareno,2017-12-31T00:00:00,1.59,1.6602715253829956,4.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Nazareno,2018-12-31T00:00:00,1.8,1.8261094093322754,1.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Nazareno,2019-12-31T00:00:00,1.68,1.685213565826416,0.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Nazareno,2020-12-31T00:00:00,2.1,2.1701481342315674,3.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Nepomuceno,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Nepomuceno,2013-12-31T00:00:00,1.68,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Nepomuceno,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Nepomuceno,2015-12-31T00:00:00,1.26,1.2781553268432617,1.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Nepomuceno,2016-12-31T00:00:00,1.74,1.7515170574188232,0.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Nepomuceno,2017-12-31T00:00:00,1.69,1.7388367652893066,2.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Nepomuceno,2018-12-31T00:00:00,1.74,1.722508430480957,1.01,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Nepomuceno,2019-12-31T00:00:00,1.5,1.5669279098510742,4.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Nepomuceno,2020-12-31T00:00:00,1.92,1.9116904735565186,0.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Olimpio_Noronha,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Olimpio_Noronha,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Olimpio_Noronha,2014-12-31T00:00:00,0.72,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Olimpio_Noronha,2015-12-31T00:00:00,1.2,0.8001638650894165,33.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Olimpio_Noronha,2016-12-31T00:00:00,1.5,1.5043582916259766,0.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Olimpio_Noronha,2017-12-31T00:00:00,1.23,1.4702633619308472,19.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Olimpio_Noronha,2018-12-31T00:00:00,1.5,1.5100505352020264,0.67,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Olimpio_Noronha,2019-12-31T00:00:00,1.5,1.471727967262268,1.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Olimpio_Noronha,2020-12-31T00:00:00,1.56,1.4618570804595947,6.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Oliveira,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Oliveira,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Oliveira,2014-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Oliveira,2015-12-31T00:00:00,1.32,1.3143961429595947,0.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Oliveira,2016-12-31T00:00:00,1.74,1.7650622129440308,1.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Oliveira,2017-12-31T00:00:00,1.4,1.458280086517334,4.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Oliveira,2018-12-31T00:00:00,2.1,2.0033185482025146,4.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Oliveira,2019-12-31T00:00:00,1.56,1.5175163745880127,2.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Oliveira,2020-12-31T00:00:00,1.95,1.9434752464294434,0.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ouro_Fino,2012-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ouro_Fino,2013-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ouro_Fino,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ouro_Fino,2015-12-31T00:00:00,1.29,1.28975510597229,0.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ouro_Fino,2016-12-31T00:00:00,1.44,1.4111344814300537,2.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ouro_Fino,2017-12-31T00:00:00,1.42,1.4413135051727295,1.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ouro_Fino,2018-12-31T00:00:00,1.69,1.4990320205688477,11.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ouro_Fino,2019-12-31T00:00:00,1.44,1.4389402866363525,0.07,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ouro_Fino,2020-12-31T00:00:00,2.1,2.062077522277832,1.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Paraguacu,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Paraguacu,2013-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Paraguacu,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Paraguacu,2015-12-31T00:00:00,1.2,1.2086352109909058,0.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Paraguacu,2016-12-31T00:00:00,1.98,2.027987241744995,2.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Paraguacu,2017-12-31T00:00:00,1.56,1.4209568500518799,8.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Paraguacu,2018-12-31T00:00:00,1.98,1.934047818183899,2.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Paraguacu,2019-12-31T00:00:00,1.56,1.5847725868225098,1.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Paraguacu,2020-12-31T00:00:00,2.34,2.319258689880371,0.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Paraisopolis,2012-12-31T00:00:00,1.06,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Paraisopolis,2013-12-31T00:00:00,1.06,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Paraisopolis,2014-12-31T00:00:00,1.11,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Paraisopolis,2015-12-31T00:00:00,1.2,1.1968767642974854,0.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Paraisopolis,2016-12-31T00:00:00,1.5,1.486956238746643,0.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Paraisopolis,2017-12-31T00:00:00,2.1,1.6343321800231934,22.17,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Paraisopolis,2018-12-31T00:00:00,1.8,1.9128329753875732,6.27,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Paraisopolis,2019-12-31T00:00:00,1.2,1.2379181385040283,3.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Paraisopolis,2020-12-31T00:00:00,2.4,2.3254129886627197,3.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pedralva,2012-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pedralva,2013-12-31T00:00:00,1.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pedralva,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pedralva,2015-12-31T00:00:00,0.96,1.3582561016082764,41.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pedralva,2016-12-31T00:00:00,2.28,2.1793479919433594,4.41,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pedralva,2017-12-31T00:00:00,1.43,2.245609998703003,57.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pedralva,2018-12-31T00:00:00,1.8,1.9102517366409302,6.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pedralva,2019-12-31T00:00:00,1.5,1.4957029819488525,0.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pedralva,2020-12-31T00:00:00,1.68,1.6427921056747437,2.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Perdoes,2012-12-31T00:00:00,1.68,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Perdoes,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Perdoes,2014-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Perdoes,2015-12-31T00:00:00,1.14,1.1551992893218994,1.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Perdoes,2016-12-31T00:00:00,1.68,1.622381567955017,3.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Perdoes,2017-12-31T00:00:00,1.84,1.654737949371338,10.07,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Perdoes,2018-12-31T00:00:00,1.8,1.9037785530090332,5.77,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Perdoes,2019-12-31T00:00:00,1.74,1.7199690341949463,1.15,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Perdoes,2020-12-31T00:00:00,1.92,1.8869943618774414,1.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Piranga,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Piranga,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Piranga,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Piranga,2015-12-31T00:00:00,1.32,0.9471177458763123,28.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Piranga,2016-12-31T00:00:00,1.5,1.5178484916687012,1.19,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Piranga,2017-12-31T00:00:00,2.5,2.541130542755127,1.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Piranga,2018-12-31T00:00:00,1.8,1.9588454961776733,8.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Piranga,2019-12-31T00:00:00,2.1,2.007323980331421,4.41,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Piranga,2020-12-31T00:00:00,2.4,2.4479684829711914,2.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pirangucu,2012-12-31T00:00:00,1.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pirangucu,2013-12-31T00:00:00,1.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pirangucu,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pirangucu,2015-12-31T00:00:00,1.32,1.3404574394226074,1.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pirangucu,2016-12-31T00:00:00,1.5,1.4820520877838135,1.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pirangucu,2017-12-31T00:00:00,1.2,1.2064789533615112,0.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pirangucu,2018-12-31T00:00:00,1.17,1.1326942443847656,3.19,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pirangucu,2019-12-31T00:00:00,1.17,1.1846110820770264,1.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pirangucu,2020-12-31T00:00:00,1.33,1.2289409637451172,7.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Piranguinho,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Piranguinho,2013-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Piranguinho,2014-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Piranguinho,2015-12-31T00:00:00,1.26,1.2888280153274536,2.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Piranguinho,2016-12-31T00:00:00,1.5,1.4992798566818237,0.05,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Piranguinho,2017-12-31T00:00:00,1.41,1.305946707725525,7.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Piranguinho,2018-12-31T00:00:00,1.5,1.451098918914795,3.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Piranguinho,2019-12-31T00:00:00,1.5,1.482014536857605,1.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Piranguinho,2020-12-31T00:00:00,1.46,1.4743351936340332,0.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Poco_Fundo,2012-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Poco_Fundo,2013-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Poco_Fundo,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Poco_Fundo,2015-12-31T00:00:00,1.2,1.1462798118591309,4.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Poco_Fundo,2016-12-31T00:00:00,1.41,1.4201619625091553,0.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Poco_Fundo,2017-12-31T00:00:00,1.2,1.1136338710784912,7.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Poco_Fundo,2018-12-31T00:00:00,1.8,1.5025213956832886,16.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Poco_Fundo,2019-12-31T00:00:00,1.2,1.2719566822052002,6.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Poco_Fundo,2020-12-31T00:00:00,1.74,1.7611217498779297,1.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pocos_de_Caldas,2012-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pocos_de_Caldas,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pocos_de_Caldas,2014-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pocos_de_Caldas,2015-12-31T00:00:00,1.5,1.5207949876785278,1.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pocos_de_Caldas,2016-12-31T00:00:00,1.56,1.5555942058563232,0.28,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pocos_de_Caldas,2017-12-31T00:00:00,1.77,1.8696820735931396,5.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pocos_de_Caldas,2018-12-31T00:00:00,1.8,1.738240361213684,3.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pocos_de_Caldas,2019-12-31T00:00:00,1.08,1.095019817352295,1.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pocos_de_Caldas,2020-12-31T00:00:00,1.8,1.595308780670166,11.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pouso_Alegre,2012-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pouso_Alegre,2013-12-31T00:00:00,1.14,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pouso_Alegre,2014-12-31T00:00:00,0.78,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pouso_Alegre,2015-12-31T00:00:00,0.72,0.7620061635971069,5.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pouso_Alegre,2016-12-31T00:00:00,1.49,1.5509048700332642,4.09,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pouso_Alegre,2017-12-31T00:00:00,1.41,1.4593327045440674,3.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pouso_Alegre,2018-12-31T00:00:00,1.51,1.7241089344024658,14.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pouso_Alegre,2019-12-31T00:00:00,1.5,1.499462604522705,0.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pouso_Alegre,2020-12-31T00:00:00,1.64,1.665757656097412,1.57,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pouso_Alto,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pouso_Alto,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pouso_Alto,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pouso_Alto,2015-12-31T00:00:00,1.32,2.336686372756958,77.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pouso_Alto,2016-12-31T00:00:00,1.5,1.4947508573532104,0.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pouso_Alto,2017-12-31T00:00:00,1.5,1.5245860815048218,1.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pouso_Alto,2018-12-31T00:00:00,1.65,1.5962035655975342,3.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pouso_Alto,2019-12-31T00:00:00,1.65,1.6339619159698486,0.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pouso_Alto,2020-12-31T00:00:00,1.45,1.6333998441696167,12.65,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Presidente_Bernardes,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Presidente_Bernardes,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Presidente_Bernardes,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Presidente_Bernardes,2015-12-31T00:00:00,1.26,1.2696278095245361,0.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Presidente_Bernardes,2016-12-31T00:00:00,1.5,1.5048344135284424,0.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Presidente_Bernardes,2017-12-31T00:00:00,1.2,1.1924450397491455,0.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Presidente_Bernardes,2018-12-31T00:00:00,1.5,1.5236403942108154,1.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Presidente_Bernardes,2019-12-31T00:00:00,1.26,1.2433116436004639,1.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Presidente_Bernardes,2020-12-31T00:00:00,1.5,1.4647306203842163,2.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ribeirao_Vermelho,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ribeirao_Vermelho,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ribeirao_Vermelho,2014-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ribeirao_Vermelho,2015-12-31T00:00:00,1.14,1.1272010803222656,1.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ribeirao_Vermelho,2016-12-31T00:00:00,1.62,1.6490304470062256,1.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ribeirao_Vermelho,2017-12-31T00:00:00,1.51,1.5454373359680176,2.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ribeirao_Vermelho,2018-12-31T00:00:00,1.8,1.725687861442566,4.13,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ribeirao_Vermelho,2019-12-31T00:00:00,1.5,1.498367428779602,0.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ribeirao_Vermelho,2020-12-31T00:00:00,1.92,1.9664709568023682,2.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santa_Barbara_do_Monte_Verde,2012-12-31T00:00:00,0.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santa_Barbara_do_Monte_Verde,2013-12-31T00:00:00,0.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santa_Barbara_do_Monte_Verde,2014-12-31T00:00:00,0.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santa_Barbara_do_Monte_Verde,2015-12-31T00:00:00,1.33,1.5416302680969238,15.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santa_Barbara_do_Monte_Verde,2016-12-31T00:00:00,3.0,3.0031893253326416,0.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santa_Barbara_do_Monte_Verde,2017-12-31T00:00:00,0.67,0.6889356374740601,2.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santa_Barbara_do_Monte_Verde,2018-12-31T00:00:00,1.0,0.7866437435150146,21.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santa_Barbara_do_Monte_Verde,2019-12-31T00:00:00,0.67,0.6262911558151245,6.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santa_Barbara_do_Monte_Verde,2020-12-31T00:00:00,1.6,1.6136488914489746,0.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santa_Rita_do_Sapucai,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santa_Rita_do_Sapucai,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santa_Rita_do_Sapucai,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santa_Rita_do_Sapucai,2015-12-31T00:00:00,1.2,1.138225793838501,5.15,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santa_Rita_do_Sapucai,2016-12-31T00:00:00,1.68,1.6539108753204346,1.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santa_Rita_do_Sapucai,2017-12-31T00:00:00,1.79,1.7677301168441772,1.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santa_Rita_do_Sapucai,2018-12-31T00:00:00,1.8,1.8501198291778564,2.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santa_Rita_do_Sapucai,2019-12-31T00:00:00,1.5,1.6626980304718018,10.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santa_Rita_do_Sapucai,2020-12-31T00:00:00,1.68,1.6723414659500122,0.46,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santana_da_Vargem,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santana_da_Vargem,2013-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santana_da_Vargem,2014-12-31T00:00:00,1.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santana_da_Vargem,2015-12-31T00:00:00,1.14,1.0994291305541992,3.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santana_da_Vargem,2016-12-31T00:00:00,1.74,1.7745580673217773,1.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santana_da_Vargem,2017-12-31T00:00:00,2.09,1.9045641422271729,8.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santana_da_Vargem,2018-12-31T00:00:00,1.8,1.9527904987335205,8.49,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santana_da_Vargem,2019-12-31T00:00:00,1.8,1.7952760457992554,0.26,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santana_da_Vargem,2020-12-31T00:00:00,2.22,1.9617081880569458,11.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santana_do_Jacare,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santana_do_Jacare,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santana_do_Jacare,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santana_do_Jacare,2015-12-31T00:00:00,1.68,1.2289998531341553,26.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santana_do_Jacare,2016-12-31T00:00:00,1.56,1.7368345260620117,11.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santana_do_Jacare,2017-12-31T00:00:00,1.2,1.4277905225753784,18.98,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santana_do_Jacare,2018-12-31T00:00:00,1.8,1.729935646057129,3.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santana_do_Jacare,2019-12-31T00:00:00,1.2,1.3061721324920654,8.85,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santana_do_Jacare,2020-12-31T00:00:00,1.8,1.9027094841003418,5.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santo_Antonio_do_Amparo,2012-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santo_Antonio_do_Amparo,2013-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santo_Antonio_do_Amparo,2014-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santo_Antonio_do_Amparo,2015-12-31T00:00:00,1.2,1.2756366729736328,6.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santo_Antonio_do_Amparo,2016-12-31T00:00:00,1.8,1.7934155464172363,0.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santo_Antonio_do_Amparo,2017-12-31T00:00:00,1.34,1.3882853984832764,3.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santo_Antonio_do_Amparo,2018-12-31T00:00:00,2.16,1.961677074432373,9.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santo_Antonio_do_Amparo,2019-12-31T00:00:00,1.64,1.6462509632110596,0.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santo_Antonio_do_Amparo,2020-12-31T00:00:00,2.1,2.0831990242004395,0.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santo_Antonio_do_Grama,2012-12-31T00:00:00,0.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santo_Antonio_do_Grama,2013-12-31T00:00:00,0.8,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santo_Antonio_do_Grama,2014-12-31T00:00:00,0.6,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santo_Antonio_do_Grama,2015-12-31T00:00:00,0.9,0.9226999878883362,2.52,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santo_Antonio_do_Grama,2016-12-31T00:00:00,0.9,0.9016602635383606,0.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santo_Antonio_do_Grama,2017-12-31T00:00:00,3.33,3.1915383338928223,4.16,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santo_Antonio_do_Grama,2018-12-31T00:00:00,1.8,2.1527445316314697,19.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santo_Antonio_do_Grama,2019-12-31T00:00:00,1.2,1.219542384147644,1.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santo_Antonio_do_Grama,2020-12-31T00:00:00,1.7,1.8298203945159912,7.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Bento_Abade,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Bento_Abade,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Bento_Abade,2014-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Bento_Abade,2015-12-31T00:00:00,1.08,1.0728839635849,0.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Bento_Abade,2016-12-31T00:00:00,1.62,1.6135621070861816,0.4,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Bento_Abade,2017-12-31T00:00:00,2.41,1.8798069953918457,22.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Bento_Abade,2018-12-31T00:00:00,2.4,2.048886299133301,14.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Bento_Abade,2019-12-31T00:00:00,1.44,1.4002753496170044,2.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Bento_Abade,2020-12-31T00:00:00,1.8,1.7502700090408325,2.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Goncalo_do_Sapucai,2012-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Goncalo_do_Sapucai,2013-12-31T00:00:00,1.26,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Goncalo_do_Sapucai,2014-12-31T00:00:00,0.96,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Goncalo_do_Sapucai,2015-12-31T00:00:00,1.26,1.3529698848724365,7.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Goncalo_do_Sapucai,2016-12-31T00:00:00,1.5,1.4920350313186646,0.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Goncalo_do_Sapucai,2017-12-31T00:00:00,2.04,1.7228820323944092,15.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Goncalo_do_Sapucai,2018-12-31T00:00:00,2.22,2.0699028968811035,6.76,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Goncalo_do_Sapucai,2019-12-31T00:00:00,1.5,1.412943720817566,5.8,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Goncalo_do_Sapucai,2020-12-31T00:00:00,2.4,2.6298766136169434,9.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Joao_del_Rei,2012-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Joao_del_Rei,2013-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Joao_del_Rei,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Joao_del_Rei,2015-12-31T00:00:00,1.62,1.719114065170288,6.12,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Joao_del_Rei,2016-12-31T00:00:00,1.5,1.5516729354858398,3.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Joao_del_Rei,2017-12-31T00:00:00,1.75,1.7939627170562744,2.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Joao_del_Rei,2018-12-31T00:00:00,1.8,1.7656035423278809,1.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Joao_del_Rei,2019-12-31T00:00:00,1.98,1.962945580482483,0.86,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Joao_del_Rei,2020-12-31T00:00:00,1.97,1.9829868078231812,0.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Lourenco,2012-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Lourenco,2013-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Lourenco,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Lourenco,2015-12-31T00:00:00,1.32,1.357548475265503,2.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Lourenco,2016-12-31T00:00:00,1.6,1.5799527168273926,1.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Lourenco,2017-12-31T00:00:00,1.77,1.708348035812378,3.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Lourenco,2018-12-31T00:00:00,1.6,1.7165627479553223,7.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Lourenco,2019-12-31T00:00:00,1.6,1.5950233936309814,0.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Lourenco,2020-12-31T00:00:00,3.39,3.4474973678588867,1.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Roque_de_Minas,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Roque_de_Minas,2013-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Roque_de_Minas,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Roque_de_Minas,2015-12-31T00:00:00,1.08,1.0845260620117188,0.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Roque_de_Minas,2016-12-31T00:00:00,1.32,1.3247181177139282,0.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Roque_de_Minas,2017-12-31T00:00:00,1.46,1.4743964672088623,0.99,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Roque_de_Minas,2018-12-31T00:00:00,1.62,1.678717851638794,3.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Roque_de_Minas,2019-12-31T00:00:00,1.5,1.5102461576461792,0.68,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Roque_de_Minas,2020-12-31T00:00:00,1.8,1.8069534301757812,0.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Sebastiao_da_Bela_Vista,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Sebastiao_da_Bela_Vista,2013-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Sebastiao_da_Bela_Vista,2014-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Sebastiao_da_Bela_Vista,2015-12-31T00:00:00,1.02,1.0390403270721436,1.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Sebastiao_da_Bela_Vista,2016-12-31T00:00:00,1.56,1.5645971298217773,0.29,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Sebastiao_da_Bela_Vista,2017-12-31T00:00:00,1.58,1.677679419517517,6.18,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Sebastiao_da_Bela_Vista,2018-12-31T00:00:00,1.32,1.423128604888916,7.81,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Sebastiao_da_Bela_Vista,2019-12-31T00:00:00,1.44,1.434971570968628,0.35,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Sebastiao_da_Bela_Vista,2020-12-31T00:00:00,1.5,1.4868299961090088,0.88,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Sebastiao_do_Paraiso,2012-12-31T00:00:00,1.62,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Sebastiao_do_Paraiso,2013-12-31T00:00:00,1.71,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Sebastiao_do_Paraiso,2014-12-31T00:00:00,1.42,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Sebastiao_do_Paraiso,2015-12-31T00:00:00,1.38,1.3435769081115723,2.64,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Sebastiao_do_Paraiso,2016-12-31T00:00:00,1.7,1.7245219945907593,1.44,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Sebastiao_do_Paraiso,2017-12-31T00:00:00,1.54,1.527441382408142,0.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Sebastiao_do_Paraiso,2018-12-31T00:00:00,1.89,1.8312209844589233,3.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Sebastiao_do_Paraiso,2019-12-31T00:00:00,1.47,1.4733511209487915,0.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Sebastiao_do_Paraiso,2020-12-31T00:00:00,1.93,1.895646333694458,1.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tiago,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tiago,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tiago,2014-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tiago,2015-12-31T00:00:00,1.62,1.5003124475479126,7.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tiago,2016-12-31T00:00:00,1.62,1.615077257156372,0.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tiago,2017-12-31T00:00:00,2.17,2.1614439487457275,0.39,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tiago,2018-12-31T00:00:00,2.7,2.0639824867248535,23.56,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tiago,2019-12-31T00:00:00,1.68,1.6120553016662598,4.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tiago,2020-12-31T00:00:00,2.7,2.6662375926971436,1.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tomas_de_Aquino,2012-12-31T00:00:00,1.75,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tomas_de_Aquino,2013-12-31T00:00:00,1.05,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tomas_de_Aquino,2014-12-31T00:00:00,1.35,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tomas_de_Aquino,2015-12-31T00:00:00,0.96,0.8960198163986206,6.66,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tomas_de_Aquino,2016-12-31T00:00:00,1.8,1.7545180320739746,2.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tomas_de_Aquino,2017-12-31T00:00:00,1.5,1.5932793617248535,6.22,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tomas_de_Aquino,2018-12-31T00:00:00,2.1,2.1542515754699707,2.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tomas_de_Aquino,2019-12-31T00:00:00,1.56,1.5255601406097412,2.21,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tomas_de_Aquino,2020-12-31T00:00:00,2.1,1.991758108139038,5.15,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tome_das_Letras,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tome_das_Letras,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tome_das_Letras,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tome_das_Letras,2015-12-31T00:00:00,1.02,1.0688120126724243,4.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tome_das_Letras,2016-12-31T00:00:00,1.62,1.5853607654571533,2.14,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tome_das_Letras,2017-12-31T00:00:00,1.05,1.5320658683776855,45.91,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tome_das_Letras,2018-12-31T00:00:00,1.5,1.6289684772491455,8.6,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tome_das_Letras,2019-12-31T00:00:00,1.44,1.4406458139419556,0.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tome_das_Letras,2020-12-31T00:00:00,2.13,2.1198582649230957,0.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Senador_Jose_Bento,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Senador_Jose_Bento,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Senador_Jose_Bento,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Senador_Jose_Bento,2015-12-31T00:00:00,1.5,1.417402982711792,5.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Senador_Jose_Bento,2016-12-31T00:00:00,1.38,1.46132493019104,5.89,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Senador_Jose_Bento,2017-12-31T00:00:00,1.15,1.1003979444503784,4.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Senador_Jose_Bento,2018-12-31T00:00:00,1.32,1.3534432649612427,2.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Senador_Jose_Bento,2019-12-31T00:00:00,1.2,1.21477472782135,1.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Senador_Jose_Bento,2020-12-31T00:00:00,1.62,1.5681167840957642,3.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Senhora_de_Oliveira,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Senhora_de_Oliveira,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Senhora_de_Oliveira,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Senhora_de_Oliveira,2015-12-31T00:00:00,1.26,1.268858790397644,0.7,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Senhora_de_Oliveira,2016-12-31T00:00:00,1.2,1.1837306022644043,1.36,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Senhora_de_Oliveira,2017-12-31T00:00:00,2.0,2.0173463821411133,0.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Senhora_de_Oliveira,2018-12-31T00:00:00,1.8,1.5730931758880615,12.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Senhora_de_Oliveira,2019-12-31T00:00:00,1.66,1.7067897319793701,2.82,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Senhora_de_Oliveira,2020-12-31T00:00:00,1.8,1.738313913345337,3.43,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Serrania,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Serrania,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Serrania,2014-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Serrania,2015-12-31T00:00:00,0.9,1.0113344192504883,12.37,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Serrania,2016-12-31T00:00:00,1.56,1.5299699306488037,1.93,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Serrania,2017-12-31T00:00:00,1.5,1.3934800624847412,7.1,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Serrania,2018-12-31T00:00:00,1.8,1.7986606359481812,0.07,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Serrania,2019-12-31T00:00:00,1.68,1.5184494256973267,9.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Serrania,2020-12-31T00:00:00,1.8,1.8848097324371338,4.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Silvianopolis,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Silvianopolis,2013-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Silvianopolis,2014-12-31T00:00:00,0.78,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Silvianopolis,2015-12-31T00:00:00,0.9,0.9257981181144714,2.87,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Silvianopolis,2016-12-31T00:00:00,1.5,1.4581127166748047,2.79,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Silvianopolis,2017-12-31T00:00:00,1.07,1.7291769981384277,61.61,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Silvianopolis,2018-12-31T00:00:00,1.2,1.213361382484436,1.11,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Silvianopolis,2019-12-31T00:00:00,1.2,1.097965955734253,8.5,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Silvianopolis,2020-12-31T00:00:00,1.5,1.5135090351104736,0.9,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Soledade_de_Minas,2012-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Soledade_de_Minas,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Soledade_de_Minas,2014-12-31T00:00:00,1.06,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Soledade_de_Minas,2015-12-31T00:00:00,1.71,1.4274182319641113,16.53,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Soledade_de_Minas,2016-12-31T00:00:00,1.6,1.624837875366211,1.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Soledade_de_Minas,2017-12-31T00:00:00,1.6,1.6855154037475586,5.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Soledade_de_Minas,2018-12-31T00:00:00,1.8,1.73634672164917,3.54,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Soledade_de_Minas,2019-12-31T00:00:00,1.8,1.792502999305725,0.42,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Soledade_de_Minas,2020-12-31T00:00:00,3.2,3.254934310913086,1.72,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Tres_Coracoes,2012-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Tres_Coracoes,2013-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Tres_Coracoes,2014-12-31T00:00:00,0.9,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Tres_Coracoes,2015-12-31T00:00:00,0.96,0.9096779823303223,5.24,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Tres_Coracoes,2016-12-31T00:00:00,1.68,1.788743495941162,6.47,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Tres_Coracoes,2017-12-31T00:00:00,2.67,2.5832908153533936,3.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Tres_Coracoes,2018-12-31T00:00:00,2.1,2.3696300983428955,12.84,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Tres_Coracoes,2019-12-31T00:00:00,1.56,1.4886012077331543,4.58,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Tres_Coracoes,2020-12-31T00:00:00,2.1,2.1852447986602783,4.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Tres_Pontas,2012-12-31T00:00:00,1.38,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Tres_Pontas,2013-12-31T00:00:00,1.53,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Tres_Pontas,2014-12-31T00:00:00,1.02,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Tres_Pontas,2015-12-31T00:00:00,1.14,1.2726027965545654,11.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Tres_Pontas,2016-12-31T00:00:00,1.86,1.766165018081665,5.04,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Tres_Pontas,2017-12-31T00:00:00,1.88,2.1898984909057617,16.48,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Tres_Pontas,2018-12-31T00:00:00,2.22,1.9907221794128418,10.33,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Tres_Pontas,2019-12-31T00:00:00,1.74,1.653057336807251,5.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Tres_Pontas,2020-12-31T00:00:00,2.26,2.3971853256225586,6.07,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Turvolandia,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Turvolandia,2013-12-31T00:00:00,1.08,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Turvolandia,2014-12-31T00:00:00,0.84,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Turvolandia,2015-12-31T00:00:00,1.08,1.0883877277374268,0.78,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Turvolandia,2016-12-31T00:00:00,1.5,1.4662734270095825,2.25,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Turvolandia,2017-12-31T00:00:00,1.8,1.6634140014648438,7.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Turvolandia,2018-12-31T00:00:00,2.29,2.2480835914611816,1.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Turvolandia,2019-12-31T00:00:00,2.1,1.9355641603469849,7.83,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Turvolandia,2020-12-31T00:00:00,1.62,2.3051950931549072,42.3,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Uberlandia,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Uberlandia,2013-12-31T00:00:00,2.1,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Uberlandia,2014-12-31T00:00:00,1.56,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Uberlandia,2015-12-31T00:00:00,1.32,1.3758845329284668,4.23,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Uberlandia,2016-12-31T00:00:00,1.62,1.5976347923278809,1.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Uberlandia,2017-12-31T00:00:00,3.15,3.1660122871398926,0.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Uberlandia,2018-12-31T00:00:00,2.64,2.5292041301727295,4.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Uberlandia,2019-12-31T00:00:00,2.02,1.9449794292449951,3.71,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Uberlandia,2020-12-31T00:00:00,1.92,1.9836955070495605,3.32,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Vargem_Bonita,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Vargem_Bonita,2013-12-31T00:00:00,1.44,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Vargem_Bonita,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Vargem_Bonita,2015-12-31T00:00:00,1.08,1.085956335067749,0.55,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Vargem_Bonita,2016-12-31T00:00:00,1.32,1.320063591003418,0.0,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Vargem_Bonita,2017-12-31T00:00:00,1.67,1.6447166204452515,1.51,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Vargem_Bonita,2018-12-31T00:00:00,2.4,2.3345558643341064,2.73,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Vargem_Bonita,2019-12-31T00:00:00,2.1,2.027629852294922,3.45,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Vargem_Bonita,2020-12-31T00:00:00,1.8,2.134573221206665,18.59,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Varginha,2012-12-31T00:00:00,1.32,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Varginha,2013-12-31T00:00:00,1.5,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Varginha,2014-12-31T00:00:00,1.03,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Varginha,2015-12-31T00:00:00,1.2,1.1757755279541016,2.02,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Varginha,2016-12-31T00:00:00,1.74,1.6595573425292969,4.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Varginha,2017-12-31T00:00:00,2.12,2.1485061645507812,1.34,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Varginha,2018-12-31T00:00:00,2.1,2.0214626789093018,3.74,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Varginha,2019-12-31T00:00:00,1.56,1.581599473953247,1.38,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Varginha,2020-12-31T00:00:00,1.9,1.911861538887024,0.62,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Virginia,2012-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Virginia,2013-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Virginia,2014-12-31T00:00:00,1.2,-,-,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Virginia,2015-12-31T00:00:00,1.5,1.4953397512435913,0.31,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Virginia,2016-12-31T00:00:00,1.6,1.6031802892684937,0.2,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Virginia,2017-12-31T00:00:00,1.4,1.5127729177474976,8.06,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Virginia,2018-12-31T00:00:00,1.8,1.7875632047653198,0.69,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Virginia,2019-12-31T00:00:00,1.36,1.3332161903381348,1.97,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Virginia,2020-12-31T00:00:00,1.53,1.5549368858337402,1.63,treino,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Aguanil,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Aiuruoca,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Albertina,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Alfenas,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Alterosa,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Andradas,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Andrelandia,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Arceburgo,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Baependi,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bandeira_do_Sul,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Boa_Esperanca,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bom_Sucesso,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Borda_da_Mata,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Brazopolis,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bueno_Brandao,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cachoeira_de_Minas,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Caete,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Camacho,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cambuquira,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campanha,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campestre,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campo_Belo,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campo_do_Meio,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campos_Gerais,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Candeias,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Capetinga,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Capitolio,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_da_Cachoeira,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_de_Minas,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_do_Rio_Claro,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carvalhopolis,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cassia,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_da_Barra_de_Minas,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_das_Pedras,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_do_Rio_Verde,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_dos_Ouros,2021-12-31T00:00:00,1.0,0,-100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Coqueiral,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cordislandia,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Corrego_Danta,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cristais,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cristina,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Delfinopolis,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Desterro_de_Entre_Rios,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Divinesia,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Divisa_Nova,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Dom_Vicoso,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Doresopolis,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Eloi_Mendes,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Entre_Rios_de_Minas,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Fama,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Grao_Mogol,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Guape,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Heliodora,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ibituruna,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ijaci,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ilicinea,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Inconfidentes,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ingai,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itajuba,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itamogi,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itapecerica,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itumirim,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itutinga,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Jacutinga,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Jesuania,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Lambari,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Lavras,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Luminarias,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Machado,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Maria_da_Fe,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Moeda,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monsenhor_Paulo,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Alegre_de_Minas,2021-12-31T00:00:00,3.0,1,-66.67,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Formoso,2021-12-31T00:00:00,1.0,0,-100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Siao,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Muzambinho,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Natercia,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Nazareno,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Nepomuceno,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Olimpio_Noronha,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Oliveira,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ouro_Fino,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Paraguacu,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Paraisopolis,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pedralva,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Perdoes,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Piranga,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pirangucu,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Piranguinho,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Poco_Fundo,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pocos_de_Caldas,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pouso_Alegre,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pouso_Alto,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Presidente_Bernardes,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ribeirao_Vermelho,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santa_Barbara_do_Monte_Verde,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santa_Rita_do_Sapucai,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santana_da_Vargem,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santana_do_Jacare,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santo_Antonio_do_Amparo,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santo_Antonio_do_Grama,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Bento_Abade,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Goncalo_do_Sapucai,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Joao_del_Rei,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Lourenco,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Roque_de_Minas,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Sebastiao_da_Bela_Vista,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Sebastiao_do_Paraiso,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tiago,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tomas_de_Aquino,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tome_das_Letras,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Senador_Jose_Bento,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Senhora_de_Oliveira,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Serrania,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Silvianopolis,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Soledade_de_Minas,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Tres_Coracoes,2021-12-31T00:00:00,2.0,1,-50.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Tres_Pontas,2021-12-31T00:00:00,1.0,2,100.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Turvolandia,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Uberlandia,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Vargem_Bonita,2021-12-31T00:00:00,2.0,2,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Varginha,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Virginia,2021-12-31T00:00:00,1.0,1,0.0,validacao,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Aguanil,2022-12-31T00:00:00,1.56,2.4520771503448486,57.18,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Aiuruoca,2022-12-31T00:00:00,1.5,2.394806146621704,59.65,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Albertina,2022-12-31T00:00:00,1.44,1.721755862236023,19.57,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Alfenas,2022-12-31T00:00:00,0.9243951612903225,3.2901153564453125,255.92,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Alterosa,2022-12-31T00:00:00,1.080104712041885,2.7713077068328857,156.58,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Andradas,2022-12-31T00:00:00,1.26,-0.5295789241790771,-142.03,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Andrelandia,2022-12-31T00:00:00,1.8000000000000003,2.1568503379821777,19.83,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Arceburgo,2022-12-31T00:00:00,0.9244897959183672,2.16202974319458,133.86,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Baependi,2022-12-31T00:00:00,1.079558011049724,2.2181408405303955,105.47,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bandeira_do_Sul,2022-12-31T00:00:00,1.110344827586207,2.0034961700439453,80.44,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Boa_Esperanca,2022-12-31T00:00:00,0.9726256983240223,2.780283212661743,185.85,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bom_Sucesso,2022-12-31T00:00:00,1.440136054421769,2.642458200454712,83.49,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Borda_da_Mata,2022-12-31T00:00:00,1.2,1.8046833276748657,50.39,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Brazopolis,2022-12-31T00:00:00,1.200934579439252,2.335864782333374,94.5,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Bueno_Brandao,2022-12-31T00:00:00,1.440196078431373,2.1004745960235596,45.85,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cachoeira_de_Minas,2022-12-31T00:00:00,1.5,2.245602607727051,49.71,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Caete,2022-12-31T00:00:00,1.5333333333333332,1.4304746389389038,-6.71,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Camacho,2022-12-31T00:00:00,1.380176211453745,2.634428024291992,90.88,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cambuquira,2022-12-31T00:00:00,1.32,2.829833507537842,114.38,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campanha,2022-12-31T00:00:00,1.266469038208169,2.095520257949829,65.46,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campestre,2022-12-31T00:00:00,1.020018115942029,2.9833312034606934,192.48,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campo_Belo,2022-12-31T00:00:00,1.2,2.0793309211730957,73.28,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campo_do_Meio,2022-12-31T00:00:00,1.580968858131488,4.206784248352051,166.09,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Campos_Gerais,2022-12-31T00:00:00,1.535771358328211,4.400080680847168,186.51,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Candeias,2022-12-31T00:00:00,1.020017406440383,2.1244089603424072,108.27,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Capetinga,2022-12-31T00:00:00,1.407056229327453,2.5786027908325195,83.26,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Capitolio,2022-12-31T00:00:00,1.08,3.072575807571411,184.5,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_da_Cachoeira,2022-12-31T00:00:00,1.2,2.1789281368255615,81.58,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_de_Minas,2022-12-31T00:00:00,1.14,1.9225059747695923,68.64,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carmo_do_Rio_Claro,2022-12-31T00:00:00,1.619555143651529,3.903294324874878,141.01,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Carvalhopolis,2022-12-31T00:00:00,1.44,2.4245755672454834,68.37,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cassia,2022-12-31T00:00:00,1.413626373626374,2.5555078983306885,80.78,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_da_Barra_de_Minas,2022-12-31T00:00:00,1.370833333333333,2.4439496994018555,78.28,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_das_Pedras,2022-12-31T00:00:00,1.375,2.0576651096343994,49.65,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_do_Rio_Verde,2022-12-31T00:00:00,1.5,2.8109145164489746,87.39,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Conceicao_dos_Ouros,2022-12-31T00:00:00,1.261168384879725,1.7420654296875,38.13,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Coqueiral,2022-12-31T00:00:00,1.2,2.9260849952697754,143.84,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cordislandia,2022-12-31T00:00:00,1.260122699386503,1.9251437187194824,52.77,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Corrego_Danta,2022-12-31T00:00:00,1.5,2.328397035598755,55.23,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cristais,2022-12-31T00:00:00,1.059063136456212,2.4992170333862305,135.98,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Cristina,2022-12-31T00:00:00,1.320183486238532,2.8482182025909424,115.74,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Delfinopolis,2022-12-31T00:00:00,1.3799999999999997,2.435816526412964,76.51,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Desterro_de_Entre_Rios,2022-12-31T00:00:00,1.8000000000000003,3.727123260498047,107.06,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Divinesia,2022-12-31T00:00:00,2.2230769230769227,2.239584445953369,0.74,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Divisa_Nova,2022-12-31T00:00:00,1.260204081632653,2.3059709072113037,82.98,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Dom_Vicoso,2022-12-31T00:00:00,1.320588235294118,2.160133123397827,63.57,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Doresopolis,2022-12-31T00:00:00,1.32,2.50156307220459,89.51,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Eloi_Mendes,2022-12-31T00:00:00,1.090201870999508,3.2870090007781982,201.5,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Entre_Rios_de_Minas,2022-12-31T00:00:00,1.8000000000000003,1.99937105178833,11.08,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Fama,2022-12-31T00:00:00,1.379787234042553,2.099592447280884,52.17,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Grao_Mogol,2022-12-31T00:00:00,1.177777777777778,1.2352070808410645,4.88,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Guape,2022-12-31T00:00:00,1.262758620689655,2.2596211433410645,78.94,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Heliodora,2022-12-31T00:00:00,1.080140597539543,2.5253689289093018,133.8,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ibituruna,2022-12-31T00:00:00,1.2,1.9706194400787354,64.22,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ijaci,2022-12-31T00:00:00,1.173913043478261,4.077824115753174,247.37,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ilicinea,2022-12-31T00:00:00,1.080069324090121,2.631511688232422,143.64,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Inconfidentes,2022-12-31T00:00:00,1.739917695473251,3.084515333175659,77.28,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ingai,2022-12-31T00:00:00,1.380228136882129,2.0646495819091797,49.59,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itajuba,2022-12-31T00:00:00,1.068965517241379,2.677288055419922,150.46,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itamogi,2022-12-31T00:00:00,1.32,3.8370206356048584,190.68,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itapecerica,2022-12-31T00:00:00,1.040506329113924,2.0214619636535645,94.28,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itumirim,2022-12-31T00:00:00,1.249307479224377,3.0294251441955566,142.49,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Itutinga,2022-12-31T00:00:00,1.8000000000000003,2.453977584838867,36.33,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Jacutinga,2022-12-31T00:00:00,1.289920424403183,2.062589406967163,59.9,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Jesuania,2022-12-31T00:00:00,1.2,1.896887183189392,58.07,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Lambari,2022-12-31T00:00:00,1.2,2.6947641372680664,124.56,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Lavras,2022-12-31T00:00:00,1.260078277886497,2.3361542224884033,85.4,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Luminarias,2022-12-31T00:00:00,1.380229885057471,2.5567626953125,85.24,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Machado,2022-12-31T00:00:00,0.964047619047619,3.0361108779907227,214.93,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Maria_da_Fe,2022-12-31T00:00:00,1.2,2.009967803955078,67.5,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Moeda,2022-12-31T00:00:00,1.25,3.2367870807647705,158.94,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monsenhor_Paulo,2022-12-31T00:00:00,1.23,2.9430782794952393,139.27,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Alegre_de_Minas,2022-12-31T00:00:00,2.3296703296703294,3.360860824584961,44.26,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Formoso,2022-12-31T00:00:00,0.6000000000000001,1.6864392757415771,181.07,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Monte_Siao,2022-12-31T00:00:00,1.2,1.6770708560943604,39.76,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Muzambinho,2022-12-31T00:00:00,1.43993993993994,3.2415833473205566,125.12,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Natercia,2022-12-31T00:00:00,1.4399193548387097,49.94193649291992,3368.38,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Nazareno,2022-12-31T00:00:00,1.319811320754717,2.6988697052001953,104.49,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Nepomuceno,2022-12-31T00:00:00,0.8699884125144843,2.5348281860351562,191.36,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Olimpio_Noronha,2022-12-31T00:00:00,1.2,1.9762678146362305,64.69,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Oliveira,2022-12-31T00:00:00,1.535560504825538,2.491546869277954,62.26,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ouro_Fino,2022-12-31T00:00:00,1.2,1.70101797580719,41.75,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Paraguacu,2022-12-31T00:00:00,1.043954802259887,4.368391990661621,318.45,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Paraisopolis,2022-12-31T00:00:00,1.322222222222222,3.243332624435425,145.29,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pedralva,2022-12-31T00:00:00,1.320091324200913,1.8546448945999146,40.49,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Perdoes,2022-12-31T00:00:00,1.259859154929577,2.3838400840759277,89.21,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Piranga,2022-12-31T00:00:00,1.8000000000000003,2.664311647415161,48.02,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pirangucu,2022-12-31T00:00:00,1.333333333333333,1.6234221458435059,21.76,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Piranguinho,2022-12-31T00:00:00,1.380549682875264,2.0283854007720947,46.93,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Poco_Fundo,2022-12-31T00:00:00,1.079978925184405,2.738147020339966,153.54,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pocos_de_Caldas,2022-12-31T00:00:00,1.169867549668874,2.1409013271331787,83.0,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pouso_Alegre,2022-12-31T00:00:00,1.5,2.0639095306396484,37.59,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Pouso_Alto,2022-12-31T00:00:00,1.5,1.7950984239578247,19.67,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Presidente_Bernardes,2022-12-31T00:00:00,1.501449275362319,2.1394944190979004,42.5,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Ribeirao_Vermelho,2022-12-31T00:00:00,1.32,2.632430076599121,99.43,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santa_Barbara_do_Monte_Verde,2022-12-31T00:00:00,1.3,4.385586738586426,237.35,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santa_Rita_do_Sapucai,2022-12-31T00:00:00,1.14,1.8199151754379272,59.64,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santana_da_Vargem,2022-12-31T00:00:00,0.9900921658986176,3.336796283721924,237.02,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santana_do_Jacare,2022-12-31T00:00:00,1.5,2.276181697845459,51.75,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santo_Antonio_do_Amparo,2022-12-31T00:00:00,1.26,2.7407374382019043,117.52,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Santo_Antonio_do_Grama,2022-12-31T00:00:00,1.565217391304348,2.167158603668213,38.46,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Bento_Abade,2022-12-31T00:00:00,1.2,2.3488669395446777,95.74,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Goncalo_do_Sapucai,2022-12-31T00:00:00,1.08,3.6492159366607666,237.89,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Joao_del_Rei,2022-12-31T00:00:00,1.836244541484716,2.915224552154541,58.76,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Lourenco,2022-12-31T00:00:00,1.8000000000000003,5.409464359283447,200.53,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Roque_de_Minas,2022-12-31T00:00:00,1.32,2.167754650115967,64.22,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Sebastiao_da_Bela_Vista,2022-12-31T00:00:00,1.5,1.8496125936508179,23.31,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Sebastiao_do_Paraiso,2022-12-31T00:00:00,1.3172147001934242,2.7386422157287598,107.91,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tiago,2022-12-31T00:00:00,1.3210526315789468,4.072947978973389,208.31,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tomas_de_Aquino,2022-12-31T00:00:00,1.2,3.00760555267334,150.63,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Sao_Tome_das_Letras,2022-12-31T00:00:00,1.434375,3.5316548347473145,146.22,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Senador_Jose_Bento,2022-12-31T00:00:00,1.32,1.690018653869629,28.03,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Senhora_de_Oliveira,2022-12-31T00:00:00,1.5,1.943535566329956,29.57,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Serrania,2022-12-31T00:00:00,1.2,2.940592050552368,145.05,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Silvianopolis,2022-12-31T00:00:00,0.9,1.9053024053573608,111.7,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Soledade_de_Minas,2022-12-31T00:00:00,1.5,4.607689380645752,207.18,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Tres_Coracoes,2022-12-31T00:00:00,1.08,2.635343551635742,144.01,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Tres_Pontas,2022-12-31T00:00:00,0.9750236518448441,3.54465913772583,263.55,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Turvolandia,2022-12-31T00:00:00,1.4398692810457523,2.6342785358428955,82.95,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Uberlandia,2022-12-31T00:00:00,1.6818181818181819,2.035141944885254,21.01,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Vargem_Bonita,2022-12-31T00:00:00,1.235217391304348,2.566344976425171,107.76,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Varginha,2022-12-31T00:00:00,1.020039292730845,2.6479382514953613,159.59,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
IBGE - Cluster V5 Cluster 3 Teste 2 (2022),Virginia,2022-12-31T00:00:00,1.62,1.7136486768722534,5.78,teste,V29 - Cluster V5,LSTM,"IBGE - Cluster V5 Cluster 3 Teste 2 (2022)
        Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
        Para esse treinamento foi utilizado o dataset V29 - Cluster V5, dividido em 5 Clusters.
        Os dados incluem as safras de 2024 e 2025. Sendo que 2025 não possui dados reais, apenas previsão.
        O modelo foi treinado com as seguintes configurações:
        input_size: 3

        encoder_n_layers = 3
        learning_rate: 0.006293703490570872
        encoder_hidden_size: 64
        decoder_layers: 3
        decoder_hidden_size: 192
        batch_size: 32
        dropout: 0.3
        weight_decay: 0.0001
        steps: 500
        ",2025-09-23T10:13:59
