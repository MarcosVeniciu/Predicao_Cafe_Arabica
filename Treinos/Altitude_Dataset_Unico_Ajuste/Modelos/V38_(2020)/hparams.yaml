alias: null
batch_size: 32
context_size: null
dataloader_kwargs: null
decoder_hidden_size: 64
decoder_layers: 1
drop_last_loader: false
early_stop_patience_steps: -1
encoder_bias: true
encoder_dropout: 0.3
encoder_hidden_size: 192
encoder_n_layers: 4
exclude_insample_y: false
futr_exog_list:
- precomediocafe
- cdd_1
- cdd_2
- cdd_3
- cdd_4
- cdd_5
- cdd_6
- cdd_7
- cdd_8
- cdd_9
- cdd_10
- cdd_11
- cdd_12
- frost_1
- frost_2
- frost_3
- frost_4
- frost_5
- frost_6
- frost_7
- frost_8
- frost_9
- frost_10
- frost_11
- frost_12
- prcptot_1
- prcptot_2
- prcptot_3
- prcptot_4
- prcptot_5
- prcptot_6
- prcptot_7
- prcptot_8
- prcptot_9
- prcptot_10
- prcptot_11
- prcptot_12
- tnn_1
- tnn_2
- tnn_3
- tnn_4
- tnn_5
- tnn_6
- tnn_7
- tnn_8
- tnn_9
- tnn_10
- tnn_11
- tnn_12
- txx_1
- txx_2
- txx_3
- txx_4
- txx_5
- txx_6
- txx_7
- txx_8
- txx_9
- txx_10
- txx_11
- txx_12
- wd30_1
- wd30_2
- wd30_3
- wd30_4
- wd30_5
- wd30_6
- wd30_7
- wd30_8
- wd30_9
- wd30_10
- wd30_11
- wd30_12
- tmin7_1
- tmin7_2
- tmin7_3
- tmin7_4
- tmin7_5
- tmin7_6
- tmin7_7
- tmin7_8
- tmin7_9
- tmin7_10
- tmin7_11
- tmin7_12
- altitude_terras baixas
- "altitude_terras de m\xE9dia altitude"
- altitude_terras altas
- altitude_terras muito altas
- cluster_0
- cluster_1
- cluster_2
- cluster_3
h: 1
h_train: 1
hist_exog_list: null
inference_input_size: null
inference_windows_batch_size: 1024
input_size: 6
learning_rate: 0.0010330837083315822
logger: !!python/object:pytorch_lightning.loggers.csv_logs.CSVLogger
  _experiment: null
  _flush_logs_every_n_steps: 100
  _fs: !!python/object/apply:fsspec.spec.make_instance
  - !!python/name:fsspec.implementations.local.LocalFileSystem ''
  - !!python/tuple []
  - {}
  _name: trial_78
  _prefix: ''
  _root_dir: Logs
  _save_dir: Logs
  _version: null
loss: !!python/object:neuralforecast.losses.pytorch.HuberLoss
  _backward_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _backward_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _buffers: {}
  _forward_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _forward_hooks_always_called: !!python/object/apply:collections.OrderedDict
  - []
  _forward_hooks_with_kwargs: !!python/object/apply:collections.OrderedDict
  - []
  _forward_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _forward_pre_hooks_with_kwargs: !!python/object/apply:collections.OrderedDict
  - []
  _is_full_backward_hook: null
  _load_state_dict_post_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _load_state_dict_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _modules: {}
  _non_persistent_buffers_set: !!set {}
  _parameters: {}
  _state_dict_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _state_dict_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  delta: 1.0
  horizon_weight: null
  is_distribution_output: false
  output_names:
  - ''
  outputsize_multiplier: 1
  training: true
lr_scheduler: !!python/name:torch.optim.lr_scheduler.StepLR ''
lr_scheduler_kwargs:
  gamma: 0.1
  step_size: 500
max_steps: 1000
n_samples: 100
n_series: 1
num_lr_decays: -1
optimizer: !!python/name:torch.optim.adamw.AdamW ''
optimizer_kwargs:
  weight_decay: 0.0001
random_seed: 42
recurrent: false
scaler_type: revin
start_padding_enabled: false
stat_exog_list: null
step_size: 1
val_check_steps: 100
valid_batch_size: null
valid_loss: null
windows_batch_size: 128
