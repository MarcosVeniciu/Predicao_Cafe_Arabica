treino_id,unique_id,ds,y,y_pred,diferença_%,flag,dataset,modelo,comentario,data_treino
V38_2020,Abadia_dos_Dourados,2019-12-31T00:00:00,2.4,1.1580756,-51.746851205825806,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Abre_Campo,2019-12-31T00:00:00,1.5,1.0741079,-28.392807642618816,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Acucena,2019-12-31T00:00:00,0.8571428571428571,0.6779447,-20.90644935766856,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Agua_Boa,2019-12-31T00:00:00,1.092380952380952,1.1355517,3.9519856676602574,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Aguanil,2019-12-31T00:00:00,1.8000000000000005,1.6534741,-8.140328195359986,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Aguas_Vermelhas,2019-12-31T00:00:00,2.7000000000000006,3.2085133,18.833824440284985,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Aimores,2019-12-31T00:00:00,1.49025069637883,1.1953337,-19.78975603513628,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Aiuruoca,2019-12-31T00:00:00,1.538461538461539,1.7631521,14.60488796234127,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Albertina,2019-12-31T00:00:00,1.56,1.3460321,-13.71588829236153,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Alfenas,2019-12-31T00:00:00,1.7572173913043478,2.023863,15.174314070578518,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Almenara,2019-12-31T00:00:00,0.7857142857142858,1.2082251,53.77410758625375,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Alpinopolis,2019-12-31T00:00:00,2.1000392310710083,2.1142316,0.675813821728106,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Alterosa,2019-12-31T00:00:00,1.739944346066279,1.4664868,-15.716452945557824,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Alto_Caparao,2019-12-31T00:00:00,1.32,1.3408219,1.5774138046033406,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Alto_Jequitiba,2019-12-31T00:00:00,1.5,1.4299664,-4.668903350830078,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Alvarenga,2019-12-31T00:00:00,0.6601705237515224,0.6748157,2.2183951086663862,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Amparo_do_Serra,2019-12-31T00:00:00,1.260869565217391,1.2328176,-2.224807081551357,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Andradas,2019-12-31T00:00:00,1.62,1.6124562,-0.4656665119124113,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Andrelandia,2019-12-31T00:00:00,1.5,1.4066195,-6.225363413492838,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Angelandia,2019-12-31T00:00:00,1.219512195121951,1.1670706,-4.3002085685729785,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Antonio_Dias,2019-12-31T00:00:00,1.0,0.82410234,-17.589765787124634,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Antonio_Prado_de_Minas,2019-12-31T00:00:00,0.597560975609756,0.8309247,39.05270318595734,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Araguari,2019-12-31T00:00:00,1.680014528284754,2.2566004,34.32028961367203,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Araponga,2019-12-31T00:00:00,0.9,1.3051074,45.01192834642198,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Arapua,2019-12-31T00:00:00,1.2,1.5578969,29.824737707773853,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Araxa,2019-12-31T00:00:00,1.387894736842105,1.7692678,27.47852920717393,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Arceburgo,2019-12-31T00:00:00,1.5,1.5199099,1.3273239135742188,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Areado,2019-12-31T00:00:00,1.9231597845601445,1.4557712,-24.303158817227192,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Aricanduva,2019-12-31T00:00:00,0.9608695652173912,0.88995945,-7.379785274488344,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Astolfo_Dutra,2019-12-31T00:00:00,1.2,1.2682046,5.683714151382451,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ataleia,2019-12-31T00:00:00,0.9,0.8211205,-8.764388826158314,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Baependi,2019-12-31T00:00:00,1.439956331877729,1.475409,2.4620676510617923,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Bambui,2019-12-31T00:00:00,1.26,1.7414585,38.21099485669817,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Bandeira,2019-12-31T00:00:00,0.9,0.9296011,3.289008140563962,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Bandeira_do_Sul,2019-12-31T00:00:00,1.5,1.5678396,4.52264149983724,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Berilo,2019-12-31T00:00:00,0.7142857142857143,0.69979954,-2.0280647277832053,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Berizal,2019-12-31T00:00:00,1.2,1.1738715,-2.177373568216956,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Boa_Esperanca,2019-12-31T00:00:00,1.92,1.8835878,-1.8964668114980023,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Bocaiuva,2019-12-31T00:00:00,1.6230769230769229,1.8272513,12.579464912414563,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Bom_Jesus_da_Penha,2019-12-31T00:00:00,2.219967266775777,1.8074183,-18.583558710301308,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Bom_Jesus_do_Amparo,2019-12-31T00:00:00,1.8000000000000005,1.504158,-16.4356655544705,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Bom_Jesus_do_Galho,2019-12-31T00:00:00,1.080232558139535,1.1120285,2.9434329855172567,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Bom_Sucesso,2019-12-31T00:00:00,1.5,1.3527882,-9.814119338989258,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Bonfinopolis_de_Minas,2019-12-31T00:00:00,2.4,2.358391,-1.7337063948313358,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Borda_da_Mata,2019-12-31T00:00:00,1.5606557377049175,1.7650019,13.093608692914522,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Botelhos,2019-12-31T00:00:00,1.92,1.9175936,-0.1253334184487624,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Botumirim,2019-12-31T00:00:00,0.7199999999999999,0.8017965,11.360624432563805,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Brazopolis,2019-12-31T00:00:00,1.559426229508197,1.3372146,-14.249576939546502,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Bueno_Brandao,2019-12-31T00:00:00,1.56,1.638566,5.036283150697362,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Buritis,2019-12-31T00:00:00,3.12,1.7223854,-44.79533953544421,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Buritizeiro,2019-12-31T00:00:00,2.880232558139535,2.0799122,-27.78665806720658,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cabo_Verde,2019-12-31T00:00:00,2.040029112081514,1.4658374,-28.14625287710919,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cachoeira_de_Minas,2019-12-31T00:00:00,1.68,2.1718125,29.2745556150164,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Caete,2019-12-31T00:00:00,1.3125,1.1428659,-12.924503144763763,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Caiana,2019-12-31T00:00:00,1.080049875311721,1.2499483,15.730605756292364,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cajuri,2019-12-31T00:00:00,1.184993531694696,1.4299563,20.672077838510404,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Caldas,2019-12-31T00:00:00,1.44,1.5261961,5.98584181732602,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Camacho,2019-12-31T00:00:00,1.5,1.4991734,-0.0551064809163411,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cambuquira,2019-12-31T00:00:00,1.679869186046512,1.5906088,-5.313529860991431,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Campanha,2019-12-31T00:00:00,1.506616257088847,1.6279999,8.056706152716114,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Campestre,2019-12-31T00:00:00,1.5499999999999998,1.3395997,-13.574211059078085,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Campo_Belo,2019-12-31T00:00:00,1.26,1.1145043,-11.547274816603888,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Campo_do_Meio,2019-12-31T00:00:00,1.619877049180328,1.5870959,-2.0236839907294613,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Campos_Altos,2019-12-31T00:00:00,1.199978657560559,1.9037762,58.65083573181506,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Campos_Gerais,2019-12-31T00:00:00,1.5913557213930347,1.8037765,13.348415967629798,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cana_Verde,2019-12-31T00:00:00,1.2,1.3043101,8.692506949106857,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Canaa,2019-12-31T00:00:00,1.26,1.3378739,6.180471087258959,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Candeias,2019-12-31T00:00:00,1.5,1.4411539,-3.9230744043986,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Caparao,2019-12-31T00:00:00,1.32,1.4139683,7.118812474337487,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Capela_Nova,2019-12-31T00:00:00,1.8000000000000005,1.8103713,0.5761822064717462,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Capelinha,2019-12-31T00:00:00,1.140074211502783,1.0213575,-10.41306556968597,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Capetinga,2019-12-31T00:00:00,2.04,1.6425412,-19.48327597449808,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Capitao_Eneas,2019-12-31T00:00:00,0.5333333333333333,0.7104262,33.20491462945938,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Capitolio,2019-12-31T00:00:00,1.500213219616205,1.5543453,3.608289128884168,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Caputira,2019-12-31T00:00:00,1.2,1.138324,-5.139664808909094,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Carai,2019-12-31T00:00:00,1.2,0.74903476,-37.58043646812439,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Caranaiba,2019-12-31T00:00:00,1.444444444444444,0.43140632,-70.13340867482698,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Carangola,2019-12-31T00:00:00,1.26,1.1337117,-10.02288129594591,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Caratinga,2019-12-31T00:00:00,0.9960199004975124,1.5527946,55.899954902065865,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Careacu,2019-12-31T00:00:00,1.2,1.4791827,23.265226682027183,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Carmo_da_Cachoeira,2019-12-31T00:00:00,1.6199809705042818,1.7229862,6.3584235052545335,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Carmo_da_Mata,2019-12-31T00:00:00,1.080487804878049,1.2031178,11.349507325389824,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Carmo_de_Minas,2019-12-31T00:00:00,1.5,1.4108179,-5.945475896199545,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Carmo_do_Paranaiba,2019-12-31T00:00:00,1.793633952254642,2.007618,11.930193332693548,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Carmo_do_Rio_Claro,2019-12-31T00:00:00,1.937142857142857,2.0015125,3.322918084518752,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Carmopolis_de_Minas,2019-12-31T00:00:00,1.5,1.5825542,5.503614743550619,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Carrancas,2019-12-31T00:00:00,1.875,1.288508,-31.279570261637364,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Carvalhopolis,2019-12-31T00:00:00,1.560199625701809,1.6421001,5.249358396061144,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Casa_Grande,2019-12-31T00:00:00,1.5,0.99413425,-33.724383513132736,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cascalho_Rico,2019-12-31T00:00:00,1.8000000000000005,2.0013967,11.188703113132036,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cassia,2019-12-31T00:00:00,1.563673469387755,1.4854271,-5.004006893383985,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cataguases,2019-12-31T00:00:00,0.5,0.61087227,22.17445373535156,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Catas_Altas_da_Noruega,2019-12-31T00:00:00,0.75,0.69471055,-7.371926307678223,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Catuji,2019-12-31T00:00:00,1.25974025974026,0.55283254,-56.115354766550766,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Caxambu,2019-12-31T00:00:00,0.8979591836734695,0.75192845,-16.26251367005436,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Chale,2019-12-31T00:00:00,1.2,1.284656,7.054670651753748,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Claraval,2019-12-31T00:00:00,1.680106729914023,1.4574741,-13.251099673574595,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Claudio,2019-12-31T00:00:00,1.44,1.1811448,-17.97605322466956,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Coimbra,2019-12-31T00:00:00,1.5,1.6594428,10.62951882680257,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Conceicao_da_Aparecida,2019-12-31T00:00:00,1.968025889967637,1.7701111,-10.056514347304478,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Conceicao_da_Barra_de_Minas,2019-12-31T00:00:00,1.6656441717791413,1.8453294,10.787732166479955,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Conceicao_das_Pedras,2019-12-31T00:00:00,1.679708222811671,1.6733619,-0.3778230800395235,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Conceicao_de_Ipanema,2019-12-31T00:00:00,1.185699039487727,1.3464987,13.561593874631743,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Conceicao_do_Rio_Verde,2019-12-31T00:00:00,1.8000000000000005,1.5724764,-12.640200720893024,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Conceicao_dos_Ouros,2019-12-31T00:00:00,1.5028571428571431,1.57004,4.470341377838465,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Congonhal,2019-12-31T00:00:00,1.501818181818182,1.6481624,9.744467400465396,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Congonhas_do_Norte,2019-12-31T00:00:00,0.9,0.8961995,-0.4222750663757348,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Conselheiro_Pena,2019-12-31T00:00:00,1.3,1.3984145,7.570345585162819,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Coqueiral,2019-12-31T00:00:00,1.5,1.6895291,12.635270754496256,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cordislandia,2019-12-31T00:00:00,1.5,1.9219751,28.131675720214844,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Coroaci,2019-12-31T00:00:00,1.456,1.2466595,-14.377780406029666,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Coromandel,2019-12-31T00:00:00,1.6463414634146338,2.2980864,39.58747051380301,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Corrego_Danta,2019-12-31T00:00:00,1.5,1.6910174,12.734492619832356,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Corrego_Fundo,2019-12-31T00:00:00,1.804347826086957,1.931625,7.053916138338728,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Corrego_Novo,2019-12-31T00:00:00,1.145454545454546,0.6035299,-47.310884320546734,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cristais,2019-12-31T00:00:00,1.739953810623557,1.6900241,-2.869597619302044,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cristina,2019-12-31T00:00:00,1.500597371565114,1.426185,-4.95884912978315,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cruzeiro_da_Fortaleza,2019-12-31T00:00:00,1.5,2.0478115,36.52076721191406,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cruzilia,2019-12-31T00:00:00,1.2,1.0590212,-11.748230457305905,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cuparaque,2019-12-31T00:00:00,1.5,0.91643476,-38.90434900919597,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Datas,2019-12-31T00:00:00,2.0,3.5518427,77.59213447570805,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Delfinopolis,2019-12-31T00:00:00,1.558823529411765,1.4037905,-9.945516766242276,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Desterro_de_Entre_Rios,2019-12-31T00:00:00,1.8000000000000005,1.1656278,-35.24289793438383,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Diamantina,2019-12-31T00:00:00,1.7228915662650603,1.8535776,7.585274089466434,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Divinesia,2019-12-31T00:00:00,2.0,1.9866595,-0.6670236587524194,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Divino,2019-12-31T00:00:00,1.079956453368816,1.1801312,9.275813232506456,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Divisa_Nova,2019-12-31T00:00:00,1.799757281553398,1.562188,-13.20007173740132,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Divisopolis,2019-12-31T00:00:00,1.080402010050251,1.0022775,-7.231059906094546,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Dom_Cavati,2019-12-31T00:00:00,0.7826086956521741,1.2285453,56.98078937000696,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Dom_Vicoso,2019-12-31T00:00:00,1.65,1.517261,-8.044786164254848,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Dores_do_Turvo,2019-12-31T00:00:00,1.5,0.614756,-59.01626745859782,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Doresopolis,2019-12-31T00:00:00,1.7400000000000002,1.5765175,-9.395548118942097,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Durande,2019-12-31T00:00:00,1.32,1.8179765,37.72549051226991,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Eloi_Mendes,2019-12-31T00:00:00,1.5,1.7944491,19.62993939717611,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Entre_Folhas,2019-12-31T00:00:00,0.8400000000000001,1.0893539,29.684990360623303,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Entre_Rios_de_Minas,2019-12-31T00:00:00,1.921428571428572,2.1488762,11.837422537537764,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ervalia,2019-12-31T00:00:00,1.199920191540303,1.5802355,31.69504875434292,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Esmeraldas,2019-12-31T00:00:00,2.1500000000000004,2.0116262,-6.435988670171709,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Espera_Feliz,2019-12-31T00:00:00,0.9,1.5233847,69.26496558719211,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Espirito_Santo_do_Dourado,2019-12-31T00:00:00,1.2,1.7803221,48.3601729075114,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Estrela_do_Indaia,2019-12-31T00:00:00,1.62,1.6433353,1.4404532350139787,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Estrela_do_Sul,2019-12-31T00:00:00,1.679876706296786,2.5263264,50.38760930807526,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Eugenopolis,2019-12-31T00:00:00,0.7199999999999999,1.0059915,39.72103595733645,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Fama,2019-12-31T00:00:00,1.619932432432432,1.5853508,-2.1347606766335527,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Faria_Lemos,2019-12-31T00:00:00,1.0796875,1.0734365,-0.5789639463300389,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Felicio_dos_Santos,2019-12-31T00:00:00,1.8000000000000005,1.2245253,-31.970814863840747,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ferros,2019-12-31T00:00:00,0.8363636363636363,0.64384466,-23.01857277103092,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Fervedouro,2019-12-31T00:00:00,1.079947575360419,1.2057979,11.653374497172935,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Formiga,2019-12-31T00:00:00,1.2400000000000002,1.6618612,34.02106300477056,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Formoso,2019-12-31T00:00:00,3.0,2.5897608,-13.674640655517578,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Fortaleza_de_Minas,2019-12-31T00:00:00,1.4403669724770642,1.9371291,34.488583598167274,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Franciscopolis,2019-12-31T00:00:00,3.0,1.0025525,-66.58158302307129,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Frei_Gaspar,2019-12-31T00:00:00,1.2,0.63504595,-47.07950452963511,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Grao_Mogol,2019-12-31T00:00:00,0.7250000000000001,1.3197476,82.03414719680258,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Guape,2019-12-31T00:00:00,1.6177358490566045,1.8738563,15.832031982774213,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Guaraciaba,2019-12-31T00:00:00,1.197368421052632,1.1366436,-5.071519495366734,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Guaranesia,2019-12-31T00:00:00,1.260049474335189,1.5582752,23.667780870308835,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Guarani,2019-12-31T00:00:00,1.8000000000000005,2.1222584,17.90324581993949,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Guarda-Mor,2019-12-31T00:00:00,1.7992125984251972,2.099236,16.67526190860003,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Guaxupe,2019-12-31T00:00:00,1.32,1.5329585,16.133220268018313,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Guimarania,2019-12-31T00:00:00,1.560154738878143,1.5171654,-2.75545209505821,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Guiricema,2019-12-31T00:00:00,1.5,1.634651,8.976729710896809,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Heliodora,2019-12-31T00:00:00,1.5599383667180282,1.8024194,15.544271652804929,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Iapu,2019-12-31T00:00:00,1.5625,1.3558358,-13.22650909423828,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ibia,2019-12-31T00:00:00,1.199972848221559,1.7090923,42.42757758561236,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ibiraci,2019-12-31T00:00:00,1.283972495924009,1.7144253,33.52508179389722,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ibitiura_de_Minas,2019-12-31T00:00:00,1.32,1.6863308,27.75233297637014,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ibituruna,2019-12-31T00:00:00,1.6599999999999997,1.8658481,12.40048580859083,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ijaci,2019-12-31T00:00:00,1.416666666666667,2.3778603,67.84896289601042,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ilicinea,2019-12-31T00:00:00,1.8601303639326447,2.0033357,7.698672801878454,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Imbe_de_Minas,2019-12-31T00:00:00,0.9601626016260164,1.2325273,28.36651353892582,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Inconfidentes,2019-12-31T00:00:00,1.5,2.1515214,43.43476295471192,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Indaiabira,2019-12-31T00:00:00,2.4,2.783635,15.98478754361471,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Indianopolis,2019-12-31T00:00:00,1.8000000000000005,2.055194,14.177438947889524,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ingai,2019-12-31T00:00:00,1.5,1.9046116,26.974105834960938,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Inhapim,2019-12-31T00:00:00,1.319886363636364,1.3358228,1.207411294346754,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Irai_de_Minas,2019-12-31T00:00:00,1.67972027972028,1.6586049,-1.2570795071909295,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Itabirinha,2019-12-31T00:00:00,1.098484848484848,0.68480194,-37.65940995051941,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Itacambira,2019-12-31T00:00:00,0.6000000000000001,1.8691123,211.51870886484767,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Itaipe,2019-12-31T00:00:00,0.9610983981693364,0.7477439,-22.199027069977344,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Itajuba,2019-12-31T00:00:00,1.8235294117647065,1.7068276,-6.399774551391622,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Itamarandiba,2019-12-31T00:00:00,1.214953271028037,1.4750983,21.41193307363073,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Itamarati_de_Minas,2019-12-31T00:00:00,0.9,0.83138376,-7.624026139577232,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Itambacuri,2019-12-31T00:00:00,0.9,1.1044598,22.717751397026905,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Itamogi,2019-12-31T00:00:00,1.849947396107312,1.5574825,-15.809363861908368,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Itanhomi,2019-12-31T00:00:00,0.96,1.6522809,72.11259653170906,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Itapecerica,2019-12-31T00:00:00,1.2,0.96488845,-19.5926288763682,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ituiutaba,2019-12-31T00:00:00,1.076923076923077,0.86859065,-19.34515365532468,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Itumirim,2019-12-31T00:00:00,1.601593625498008,1.7769108,10.946419464414976,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Itutinga,2019-12-31T00:00:00,1.521739130434783,1.4973089,-1.6054184096200332,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Jacui,2019-12-31T00:00:00,1.68,1.4761207,-12.135672001611615,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Jacutinga,2019-12-31T00:00:00,1.6801232665639447,1.5455165,-8.011720229489622,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Jequeri,2019-12-31T00:00:00,1.32,1.3823341,4.722281297047928,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Jequitinhonha,2019-12-31T00:00:00,2.0375,3.5675092,75.09247481457297,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Jesuania,2019-12-31T00:00:00,1.5,1.5954778,6.365187962849935,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Joao_Pinheiro,2019-12-31T00:00:00,2.4,2.1570659,-10.122255484263098,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Jose_Goncalves_de_Minas,2019-12-31T00:00:00,0.958823529411765,0.9810203,2.314997670109259,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Juiz_de_Fora,2019-12-31T00:00:00,0.9,0.18562658,-79.37482429875267,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Juruaia,2019-12-31T00:00:00,1.68,1.6155558,-3.8359664735339902,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ladainha,2019-12-31T00:00:00,1.118556701030928,0.77951247,-30.31086718431817,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Lagoa_Dourada,2019-12-31T00:00:00,2.7000000000000006,1.8102778,-32.95267334690802,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Lagoa_Formosa,2019-12-31T00:00:00,2.25,1.7625138,-21.66605525546604,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Lagoa_Grande,2019-12-31T00:00:00,1.2,2.4689403,105.74502150217693,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Lajinha,2019-12-31T00:00:00,1.055939660590823,1.489936,41.10048611249249,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Lambari,2019-12-31T00:00:00,1.559769167353669,1.5818282,1.414252165508021,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Lamim,2019-12-31T00:00:00,1.5200000000000002,0.9273256,-38.991736424596695,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Lavras,2019-12-31T00:00:00,1.5,2.8684125,91.22749964396158,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Luisburgo,2019-12-31T00:00:00,1.6399999999999997,1.4700862,-10.36059652886738,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Luminarias,2019-12-31T00:00:00,1.720238095238095,1.6044223,-6.732542704545896,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Machado,2019-12-31T00:00:00,1.5270920664493093,1.8482401,21.03003988473479,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Malacacheta,2019-12-31T00:00:00,1.5,1.5564983,3.766552607218424,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Manhuacu,2019-12-31T00:00:00,1.019980879541109,1.3531289,32.66218389049334,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Manhumirim,2019-12-31T00:00:00,1.2,1.3952887,16.274058818817146,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Mantena,2019-12-31T00:00:00,0.279,0.726701,160.46631584030752,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Mar_de_Espanha,2019-12-31T00:00:00,1.8000000000000005,1.5857147,-11.90473900900948,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Maria_da_Fe,2019-12-31T00:00:00,1.5,1.6620953,10.8063538869222,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Martins_Soares,2019-12-31T00:00:00,1.6199186991869925,1.5429561,-4.751015307762716,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Mata_Verde,2019-12-31T00:00:00,1.020366598778004,1.4015653,37.358995778356025,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Matipo,2019-12-31T00:00:00,1.32,1.2250644,-7.192091147104904,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Matutina,2019-12-31T00:00:00,1.8000000000000005,1.9285767,7.1431504355536415,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Medeiros,2019-12-31T00:00:00,1.199936224489796,1.8501235,54.18515475291126,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Minas_Novas,2019-12-31T00:00:00,0.9,0.86357284,-4.047462675306535,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Miradouro,2019-12-31T00:00:00,1.32,1.3738878,4.0824073733705415,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Mirai,2019-12-31T00:00:00,1.2,0.9990127,-16.748940944671627,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Moeda,2019-12-31T00:00:00,1.0,0.92423356,-7.576644420623779,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Monsenhor_Paulo,2019-12-31T00:00:00,1.5,1.5981395,6.542634963989258,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Monte_Alegre_de_Minas,2019-12-31T00:00:00,1.8000000000000005,1.4902139,-17.21034049987794,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Monte_Belo,2019-12-31T00:00:00,1.640077821011673,1.4266746,-13.01177382327766,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Monte_Carmelo,2019-12-31T00:00:00,1.6200304645849195,2.2265358,37.43789674286269,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Monte_Formoso,2019-12-31T00:00:00,1.2,0.74495566,-37.92036175727844,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Monte_Santo_de_Minas,2019-12-31T00:00:00,1.589970501474926,1.4455211,-9.085035545264189,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Monte_Siao,2019-12-31T00:00:00,1.5601626016260162,1.5358284,-1.559725225189187,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Muriae,2019-12-31T00:00:00,1.02054794520548,1.1781702,15.444865642777966,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Mutum,2019-12-31T00:00:00,1.4430666666666667,1.3677863,-5.216694428895856,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Muzambinho,2019-12-31T00:00:00,2.1,1.3014474,-38.02631468999954,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Natercia,2019-12-31T00:00:00,1.4399193548387097,2.000203,38.91075826499082,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Nazareno,2019-12-31T00:00:00,1.680203045685279,1.6362616,-2.615247212147774,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Nepomuceno,2019-12-31T00:00:00,1.5,1.6969905,13.132699330647789,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ninheira,2019-12-31T00:00:00,2.7000871839581526,2.6930296,-0.2613819988843537,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Nova_Belem,2019-12-31T00:00:00,0.9,0.955339,6.148779392242429,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Nova_Era,2019-12-31T00:00:00,1.5,1.5387542,2.5836149851481123,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Nova_Ponte,2019-12-31T00:00:00,1.679452054794521,1.4769341,-12.058574632174846,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Nova_Resende,2019-12-31T00:00:00,2.1150040551500404,1.5581453,-26.32896940038379,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Novo_Cruzeiro,2019-12-31T00:00:00,1.079404466501241,0.97947437,-9.25789209617968,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Novorizonte,2019-12-31T00:00:00,1.6000000000000003,0.81504244,-49.05984774231912,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Olimpio_Noronha,2019-12-31T00:00:00,1.5,1.4999317,-0.0045537948608398,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Oliveira,2019-12-31T00:00:00,1.56,1.5967222,2.353990077972409,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Orizania,2019-12-31T00:00:00,1.379912663755459,1.4808714,7.316316305836502,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ouro_Fino,2019-12-31T00:00:00,1.439922480620155,1.56311,8.555148973118417,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ouro_Verde_de_Minas,2019-12-31T00:00:00,1.5,1.0497792,-30.01472155253093,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Padre_Paraiso,2019-12-31T00:00:00,0.6000000000000001,0.627251,4.541838169097885,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Paracatu,2019-12-31T00:00:00,2.4,2.624561,9.356711308161422,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Paraguacu,2019-12-31T00:00:00,1.5599709934735322,1.6881503,8.216774141136755,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Paraisopolis,2019-12-31T00:00:00,1.2,1.8209053,51.742110649744674,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Passa_Tempo,2019-12-31T00:00:00,1.5,1.51744,1.1626640955607097,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Passos,2019-12-31T00:00:00,1.56,1.3565803,-13.0397270887326,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Patis,2019-12-31T00:00:00,3.0,2.8290074,-5.699753761291504,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Patos_de_Minas,2019-12-31T00:00:00,1.62,1.4226662,-12.181099255879726,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Patrocinio,2019-12-31T00:00:00,1.384841075794621,2.4447737,76.53821198280248,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Paula_Candido,2019-12-31T00:00:00,1.32,1.3883276,5.176333225134642,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pecanha,2019-12-31T00:00:00,1.44,0.9399115,-34.72836911678314,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pedra_Azul,2019-12-31T00:00:00,1.2,1.0916269,-9.031093120574948,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pedra_Bonita,2019-12-31T00:00:00,1.2,0.94127303,-21.56058053175608,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pedra_Dourada,2019-12-31T00:00:00,0.96,1.0582861,10.238132377465584,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pedra_do_Anta,2019-12-31T00:00:00,1.318181818181818,1.1983529,-9.090467157035018,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pedralva,2019-12-31T00:00:00,1.5,1.9309946,28.73297532399496,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pedrinopolis,2019-12-31T00:00:00,1.5,0.58050853,-61.29943132400513,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Perdizes,2019-12-31T00:00:00,1.199035812672176,1.7677977,47.43493812512834,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Perdoes,2019-12-31T00:00:00,1.7399328859060397,1.5024643,-13.648146626574526,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Piedade_de_Caratinga,2019-12-31T00:00:00,1.44,1.4942746,3.769070572323273,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pimenta,2019-12-31T00:00:00,1.5,2.2645671,50.97114245096842,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Piracema,2019-12-31T00:00:00,1.166666666666667,1.33763,14.654002870832144,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Piranga,2019-12-31T00:00:00,2.1,1.571794,-25.15266509283157,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pirangucu,2019-12-31T00:00:00,1.166666666666667,1.1509393,-1.3480561120169754,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Piranguinho,2019-12-31T00:00:00,1.5,1.4710363,-1.9309123357137044,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pirapora,2019-12-31T00:00:00,3.0,2.2888327,-23.7055778503418,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Piumhi,2019-12-31T00:00:00,1.3199752300070773,1.7021462,28.9528874351962,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Poco_Fundo,2019-12-31T00:00:00,1.199923204914885,1.5112253,25.94350509770717,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pocos_de_Caldas,2019-12-31T00:00:00,1.08,1.7833209,65.1223059053774,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pocrane,2019-12-31T00:00:00,1.07741935483871,1.2157501,12.839080973299632,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ponte_Nova,2019-12-31T00:00:00,1.166666666666667,1.2825344,9.93151664733884,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ponto_dos_Volantes,2019-12-31T00:00:00,0.6000000000000001,0.44134474,-26.44254366556805,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Porto_Firme,2019-12-31T00:00:00,1.119607843137255,1.1799815,5.392390500016887,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pote,2019-12-31T00:00:00,0.7250000000000001,0.65789115,-9.256392511828205,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pouso_Alegre,2019-12-31T00:00:00,1.5,1.4591362,-2.7242501576741533,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pouso_Alto,2019-12-31T00:00:00,1.65,1.5058347,-8.737290989268905,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pratapolis,2019-12-31T00:00:00,1.738461538461539,0.9422826,-45.79790255664726,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pratinha,2019-12-31T00:00:00,1.7400000000000002,1.7592511,1.106386075074633,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Presidente_Bernardes,2019-12-31T00:00:00,1.2571428571428571,1.2668262,0.7702621546658622,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Presidente_Kubitschek,2019-12-31T00:00:00,1.315789473684211,0.85362625,-35.124404907226584,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Presidente_Olegario,2019-12-31T00:00:00,1.8693227091633469,2.2424903,19.962715939995764,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Quartel_Geral,2019-12-31T00:00:00,3.0,3.099258,3.308598200480143,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Raul_Soares,2019-12-31T00:00:00,1.2,1.144266,-4.6444992224375365,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Reduto,2019-12-31T00:00:00,1.259851301115242,1.4512377,15.19118782059213,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ribeirao_Vermelho,2019-12-31T00:00:00,1.5,1.8317536,22.116907437642418,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Rio_Paranaiba,2019-12-31T00:00:00,1.142998097117485,1.8909411,65.43694585359621,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Rio_Pardo_de_Minas,2019-12-31T00:00:00,2.75,3.0301924,10.188813643022018,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Rio_Vermelho,2019-12-31T00:00:00,1.2,1.1229106,-6.424115101496374,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ritapolis,2019-12-31T00:00:00,1.8008849557522122,1.7090822,-5.097644334928985,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Romaria,2019-12-31T00:00:00,2.2,1.7631587,-19.85642368143256,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Rosario_da_Limeira,2019-12-31T00:00:00,1.2,0.96666324,-19.44472988446553,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sabinopolis,2019-12-31T00:00:00,1.2,0.79671574,-33.607021967569985,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sacramento,2019-12-31T00:00:00,1.231428571428572,1.4887053,20.89253993156056,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santa_Barbara,2019-12-31T00:00:00,1.071428571428571,1.039731,-2.9584376017252176,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santa_Barbara_do_Leste,2019-12-31T00:00:00,1.139892904953146,1.3324118,16.88920601773666,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santa_Barbara_do_Monte_Verde,2019-12-31T00:00:00,0.6666666666666667,0.7287663,9.314948320388782,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santa_Margarida,2019-12-31T00:00:00,1.2,1.4613681,21.780673662821457,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santa_Maria_do_Suacui,2019-12-31T00:00:00,0.8,0.755942,-5.507251620292669,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santa_Rita_de_Caldas,2019-12-31T00:00:00,1.9210526315789471,1.837234,-4.363160590602915,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santa_Rita_de_Minas,2019-12-31T00:00:00,1.26,1.3429637,6.5844202798510345,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santa_Rita_do_Itueto,2019-12-31T00:00:00,1.649769585253456,1.2151678,-26.343183211108144,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santa_Rita_do_Sapucai,2019-12-31T00:00:00,1.5,1.8019354,20.12902895609537,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santa_Rosa_da_Serra,2019-12-31T00:00:00,1.44,1.4309568,-0.6279971864488353,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santana_da_Vargem,2019-12-31T00:00:00,1.7999440402909912,1.7383459,-3.4222274402539923,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santana_do_Jacare,2019-12-31T00:00:00,1.2,1.3694732,14.122768243153894,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santana_do_Manhuacu,2019-12-31T00:00:00,1.5,1.5046184,0.3078937530517578,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santo_Antonio_do_Amparo,2019-12-31T00:00:00,1.639983909895414,1.7976686,9.615013012852144,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santo_Antonio_do_Grama,2019-12-31T00:00:00,1.2,1.3098004,9.150032202402755,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santo_Antonio_do_Retiro,2019-12-31T00:00:00,2.1,1.0006214,-52.351360093979615,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Bento_Abade,2019-12-31T00:00:00,1.44,1.6708856,16.03371964560615,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Domingos_das_Dores,2019-12-31T00:00:00,1.296118830857691,1.6782137,29.47992696339008,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Domingos_do_Prata,2019-12-31T00:00:00,0.7211538461538461,0.8596395,19.203347524007164,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Francisco_de_Paula,2019-12-31T00:00:00,1.6399999999999997,1.2997606,-20.746306093727654,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Francisco_do_Gloria,2019-12-31T00:00:00,0.9,1.0952253,21.691703796386715,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Geraldo,2019-12-31T00:00:00,2.0,0.8521193,-57.3940336704254,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Goncalo_do_Abaete,2019-12-31T00:00:00,1.92,1.9813696,3.196334093809132,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Goncalo_do_Rio_Preto,2019-12-31T00:00:00,1.6000000000000003,2.0077157,25.48223137855528,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Goncalo_do_Sapucai,2019-12-31T00:00:00,1.5,2.4866107,65.77404340108237,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Gotardo,2019-12-31T00:00:00,1.379944289693593,1.9351344,40.23279238959984,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Joao_Batista_do_Gloria,2019-12-31T00:00:00,1.68,1.5467515,-7.931458382379438,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Joao_da_Mata,2019-12-31T00:00:00,1.3799999999999997,1.4646585,6.134673823481046,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Joao_del_Rei,2019-12-31T00:00:00,1.982758620689655,1.6443832,-17.065891182940934,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Joao_do_Manhuacu,2019-12-31T00:00:00,1.320060560181681,1.4596233,10.572452569229323,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Joao_do_Manteninha,2019-12-31T00:00:00,0.9,0.44546318,-50.50409105088976,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Joao_do_Paraiso,2019-12-31T00:00:00,1.5857142857142863,2.196099,38.49273243465934,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Jose_da_Barra,2019-12-31T00:00:00,1.702112676056338,1.5056937,-11.53971794769199,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Jose_do_Alegre,2019-12-31T00:00:00,1.5,1.5858002,5.720011393229166,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Jose_do_Mantimento,2019-12-31T00:00:00,1.56039603960396,1.3349376,-14.448797702789284,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Lourenco,2019-12-31T00:00:00,1.6000000000000003,1.5328205,-4.198721051216144,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Miguel_do_Anta,2019-12-31T00:00:00,1.303164556962025,1.2793893,-1.824427669982733,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Pedro_da_Uniao,2019-12-31T00:00:00,1.62,1.6345147,0.8959684842898454,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Roque_de_Minas,2019-12-31T00:00:00,1.5000955109837628,1.3764992,-8.239231039183478,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Sebastiao_da_Bela_Vista,2019-12-31T00:00:00,1.44,1.4238195,-1.1236429214477504,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Sebastiao_da_Vargem_Alegre,2019-12-31T00:00:00,1.02,1.0013192,-1.8314539217481445,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Sebastiao_do_Anta,2019-12-31T00:00:00,1.5,1.4167912,-5.547253290812174,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Sebastiao_do_Maranhao,2019-12-31T00:00:00,0.925925925925926,0.825034,-10.896325588226318,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Sebastiao_do_Paraiso,2019-12-31T00:00:00,1.470008496176721,1.6570926,12.72673427183601,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Tiago,2019-12-31T00:00:00,1.679886685552408,1.7765462,5.753932996302792,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Tomas_de_Aquino,2019-12-31T00:00:00,1.560034623469766,1.4508984,-6.995755923497332,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Tome_das_Letras,2019-12-31T00:00:00,1.440140845070423,1.3946378,-3.1596230411296644,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Senador_Firmino,2019-12-31T00:00:00,1.32258064516129,1.6724448,26.453144957379628,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Senador_Jose_Bento,2019-12-31T00:00:00,1.2,1.2491856,4.098796844482426,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Senador_Modestino_Goncalves,2019-12-31T00:00:00,1.833333333333333,1.457419,-20.504416118968606,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Senhora_de_Oliveira,2019-12-31T00:00:00,1.6625,1.4438608,-13.151231923497711,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Senhora_dos_Remedios,2019-12-31T00:00:00,1.8000000000000005,1.1848099,-34.17722649044462,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sericita,2019-12-31T00:00:00,0.9,1.3469231,49.6581236521403,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Serra_do_Salitre,2019-12-31T00:00:00,1.4904255319148938,1.881331,26.227773656851884,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Serrania,2019-12-31T00:00:00,1.68,1.4996512,-10.735047998882472,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Setubinha,2019-12-31T00:00:00,0.9,0.66937613,-25.62487390306261,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Silvianopolis,2019-12-31T00:00:00,1.2,1.1268739,-6.093845764795935,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Simonesia,2019-12-31T00:00:00,1.32,1.2176478,-7.753955234180801,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Soledade_de_Minas,2019-12-31T00:00:00,1.8000000000000005,1.6380965,-8.994641568925658,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Taiobeiras,2019-12-31T00:00:00,2.579831932773109,1.7997738,-30.236780565802352,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Tapira,2019-12-31T00:00:00,1.8000000000000005,1.4204117,-21.088238557179785,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Tapirai,2019-12-31T00:00:00,1.679835390946502,1.7220736,2.514422798437096,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Teixeiras,2019-12-31T00:00:00,0.96,1.1926229,24.231552084287024,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Teofilo_Otoni,2019-12-31T00:00:00,0.90625,0.8425164,-7.032670645878233,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Tiros,2019-12-31T00:00:00,1.5,1.9172386,27.81590620676677,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Tocos_do_Moji,2019-12-31T00:00:00,1.2,1.6781778,39.84815279642741,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Tombos,2019-12-31T00:00:00,0.96,1.1062005,15.229214231173216,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Tres_Coracoes,2019-12-31T00:00:00,1.56,1.6379837,4.998953831501493,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Tres_Pontas,2019-12-31T00:00:00,1.7400000000000002,1.8245342,4.858286079319031,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Tupaciguara,2019-12-31T00:00:00,2.4,2.2621765,-5.742645263671872,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Turmalina,2019-12-31T00:00:00,1.199233716475096,1.3962834,16.431298499671023,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Turvolandia,2019-12-31T00:00:00,2.1,2.029577,-3.353475389026464,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ubaporanga,2019-12-31T00:00:00,1.320030895983522,1.2152696,-7.936278667416465,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Uberaba,2019-12-31T00:00:00,2.476744186046512,2.066271,-16.573093082983185,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Uberlandia,2019-12-31T00:00:00,2.015625,2.3629718,17.232708598292152,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Unai,2019-12-31T00:00:00,2.819938392607113,2.4967616,-11.46042172461305,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Urucuia,2019-12-31T00:00:00,2.400355871886121,2.113814,-11.937469760959807,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Vargem_Bonita,2019-12-31T00:00:00,2.1,1.5952384,-24.036264419555668,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Vargem_Grande_do_Rio_Pardo,2019-12-31T00:00:00,2.1,1.7817957,-15.152583803449362,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Varginha,2019-12-31T00:00:00,1.5600442722744878,1.8054237,15.729006455696506,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Varjao_de_Minas,2019-12-31T00:00:00,2.494512195121952,2.261867,-9.326278268780989,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Varzea_da_Palma,2019-12-31T00:00:00,3.6004056795131847,3.2425401,-9.93958987652416,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Vermelho_Novo,2019-12-31T00:00:00,1.079912663755459,1.1359149,5.185813620367128,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Vicosa,2019-12-31T00:00:00,0.8395833333333333,1.4690084,74.968747879672,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Vieiras,2019-12-31T00:00:00,1.019736842105263,1.1670644,14.447608455534915,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Virginia,2019-12-31T00:00:00,1.36,1.9132125,40.67739248275758,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Virginopolis,2019-12-31T00:00:00,1.5066666666666668,1.2464693,-17.269739429507645,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Visconde_do_Rio_Branco,2019-12-31T00:00:00,0.5,0.82983685,65.96736907958984,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Abadia_dos_Dourados,2020-12-31T00:00:00,2.584210526315789,1.1715122,-54.66653222707526,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Abre_Campo,2020-12-31T00:00:00,1.5,1.0866318,-27.55788167317708,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Acucena,2020-12-31T00:00:00,1.166666666666667,0.6150977,-47.27733986718315,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Agua_Boa,2020-12-31T00:00:00,1.33,1.1485621,-13.641949345294698,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Aguanil,2020-12-31T00:00:00,2.1644859813084114,1.6200645,-25.152460631105367,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Aguas_Vermelhas,2020-12-31T00:00:00,3.6000000000000005,2.0135465,-44.06815369923911,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Aimores,2020-12-31T00:00:00,2.063157894736842,1.6111505,-21.90852153057953,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Aiuruoca,2020-12-31T00:00:00,1.8000000000000005,1.3754715,-23.584918181101493,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Albertina,2020-12-31T00:00:00,1.68,1.5022601,-10.579756611869444,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Alfenas,2020-12-31T00:00:00,2.364130434782609,1.9180055,-18.87057337267646,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Almenara,2020-12-31T00:00:00,0.78,1.3188099,69.07818806477081,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Alpinopolis,2020-12-31T00:00:00,2.765998457979954,2.1399417,-22.63402439077558,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Alterosa,2020-12-31T00:00:00,1.980023501762632,1.7534343,-11.443763224944142,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Alto_Caparao,2020-12-31T00:00:00,1.92,1.4732248,-23.26954379677772,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Alto_Jequitiba,2020-12-31T00:00:00,1.8000000000000005,1.3140092,-26.999489466349296,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Alvarenga,2020-12-31T00:00:00,0.9,0.5920354,-34.21828746795654,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Amparo_do_Serra,2020-12-31T00:00:00,1.4392156862745098,1.1982354,-16.743862369080006,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Andradas,2020-12-31T00:00:00,2.568,1.6412971,-36.08656144959162,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Andrelandia,2020-12-31T00:00:00,1.8000000000000005,1.3653405,-24.14775159623889,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Angelandia,2020-12-31T00:00:00,1.8400349650349648,1.733295,-5.800976787213767,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Antonio_Dias,2020-12-31T00:00:00,1.333333333333333,0.81405336,-38.94599825143813,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Antonio_Prado_de_Minas,2020-12-31T00:00:00,1.5,0.7208878,-51.94081465403239,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Araguari,2020-12-31T00:00:00,1.979964695498676,2.2899172,15.654447567275351,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Araponga,2020-12-31T00:00:00,1.8000000000000005,1.0106192,-43.85449091593425,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Arapua,2020-12-31T00:00:00,1.5,1.4092355,-6.050968170166016,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Araxa,2020-12-31T00:00:00,1.786008230452675,1.598691,-10.488039227674635,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Arceburgo,2020-12-31T00:00:00,1.8387096774193543,1.7572412,-4.430739084879542,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Areado,2020-12-31T00:00:00,2.078746484531941,1.7032498,-18.0636106999998,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Aricanduva,2020-12-31T00:00:00,1.3196428571428571,0.92732537,-29.72906548857528,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Astolfo_Dutra,2020-12-31T00:00:00,1.75,1.2389218,-29.20447077069964,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ataleia,2020-12-31T00:00:00,1.204819277108434,0.87286615,-27.552109241485617,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Baependi,2020-12-31T00:00:00,1.67948717948718,1.450229,-13.650484121482814,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Bambui,2020-12-31T00:00:00,1.7998829724985372,1.2414591,-31.02556387221705,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Bandeira,2020-12-31T00:00:00,1.083333333333333,0.9196365,-15.110478034386244,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Bandeira_do_Sul,2020-12-31T00:00:00,1.5,1.600921,6.728068987528483,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Berilo,2020-12-31T00:00:00,0.8428571428571429,0.72740257,-13.698000422978806,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Berizal,2020-12-31T00:00:00,3.340236686390532,0.15689546,-95.30286403542814,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Boa_Esperanca,2020-12-31T00:00:00,2.063248407643312,1.7213883,-16.569021276379146,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Bocaiuva,2020-12-31T00:00:00,1.622950819672131,1.8492532,13.94388266284058,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Bom_Jesus_da_Penha,2020-12-31T00:00:00,1.986087924318308,2.0517755,3.307382838002596,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Bom_Jesus_do_Amparo,2020-12-31T00:00:00,1.5,1.2625628,-15.829149881998696,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Bom_Jesus_do_Galho,2020-12-31T00:00:00,1.44,0.9893435,-31.295588612556458,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Bom_Sucesso,2020-12-31T00:00:00,2.1,1.4972044,-28.704551288059783,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Bonfinopolis_de_Minas,2020-12-31T00:00:00,3.3,2.1320004,-35.39392586910363,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Borda_da_Mata,2020-12-31T00:00:00,1.62,2.3557518,45.41677486749342,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Botelhos,2020-12-31T00:00:00,1.716062736614386,1.8716666,9.067489824346154,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Botumirim,2020-12-31T00:00:00,0.9200000000000002,0.7825302,-14.942370808642858,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Brazopolis,2020-12-31T00:00:00,1.680327868852459,1.5014209,-10.647149085998532,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Bueno_Brandao,2020-12-31T00:00:00,1.8000000000000005,2.0287614,12.708965937296531,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Buritis,2020-12-31T00:00:00,3.3,1.955505,-40.74227231921571,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Buritizeiro,2020-12-31T00:00:00,3.0,2.5061574,-16.4614200592041,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cabo_Verde,2020-12-31T00:00:00,2.249052581714827,1.6450609,-26.8553830066894,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cachoeira_de_Minas,2020-12-31T00:00:00,1.8596638655462183,2.7894795,49.9991232703511,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Caete,2020-12-31T00:00:00,1.2,1.1558973,-3.67522835731506,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Caiana,2020-12-31T00:00:00,1.5,1.0260633,-31.595778465271,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cajuri,2020-12-31T00:00:00,1.8000000000000005,1.2637595,-29.7911392317878,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Caldas,2020-12-31T00:00:00,1.68,1.4002095,-16.65419368516831,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Camacho,2020-12-31T00:00:00,2.1,1.3129,-37.48095489683605,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cambuquira,2020-12-31T00:00:00,1.800145348837209,1.664125,-7.556077805458641,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Campanha,2020-12-31T00:00:00,1.6833930704898452,1.5520275,-7.803620490053205,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Campestre,2020-12-31T00:00:00,2.138000770416025,1.2832284,-39.979984332761184,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Campo_Belo,2020-12-31T00:00:00,1.8000000000000005,1.160334,-35.53700049718222,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Campo_do_Meio,2020-12-31T00:00:00,2.4,1.4708999,-38.71250251928965,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Campos_Altos,2020-12-31T00:00:00,2.1000529941706416,1.3763962,-34.45897874863921,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Campos_Gerais,2020-12-31T00:00:00,2.690649114843395,1.6786234,-37.61269618468362,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cana_Verde,2020-12-31T00:00:00,1.5,1.3105605,-12.629302342732748,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Canaa,2020-12-31T00:00:00,1.8000000000000005,1.2511331,-30.492606427934444,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Candeias,2020-12-31T00:00:00,1.859937013094646,1.5231842,-18.105604139499167,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Caparao,2020-12-31T00:00:00,1.9199600798403191,1.3510264,-29.632577780614405,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Capela_Nova,2020-12-31T00:00:00,1.8000000000000005,1.8854364,4.746467537350109,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Capelinha,2020-12-31T00:00:00,1.434123222748815,1.0560473,-26.36286034461132,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Capetinga,2020-12-31T00:00:00,2.213808463251671,2.0371406,-7.980268318168621,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Capitao_Eneas,2020-12-31T00:00:00,3.0,0.4969708,-83.4343065818151,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Capitolio,2020-12-31T00:00:00,2.1,1.4095061,-32.88066273643857,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Caputira,2020-12-31T00:00:00,1.8000000000000005,0.9344611,-48.08549351162381,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Carai,2020-12-31T00:00:00,1.5225,1.2574792,-17.40694969941438,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Caranaiba,2020-12-31T00:00:00,1.645161290322581,1.1884791,-27.759115602455903,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Carangola,2020-12-31T00:00:00,1.5,1.5269198,1.7946561177571614,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Caratinga,2020-12-31T00:00:00,2.040022111663903,1.4189757,-30.443121044826498,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Careacu,2020-12-31T00:00:00,1.320454545454546,1.3811357,4.595474860343956,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Carmo_da_Cachoeira,2020-12-31T00:00:00,1.8000000000000005,1.3921075,-22.6606951819526,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Carmo_da_Mata,2020-12-31T00:00:00,1.68,1.07148,-36.221426441555934,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Carmo_de_Minas,2020-12-31T00:00:00,1.7400000000000002,1.3521106,-22.29249285555435,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Carmo_do_Paranaiba,2020-12-31T00:00:00,1.947480785653288,2.030984,4.287751634192552,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Carmo_do_Rio_Claro,2020-12-31T00:00:00,2.7847803881511743,1.9818242,-28.833736115976727,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Carmopolis_de_Minas,2020-12-31T00:00:00,1.981818181818182,1.4471841,-26.97694979676413,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Carrancas,2020-12-31T00:00:00,1.785714285714286,1.082124,-39.40105628967287,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Carvalhopolis,2020-12-31T00:00:00,1.679765395894428,1.5607649,-7.084351624023977,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Casa_Grande,2020-12-31T00:00:00,1.553846153846154,1.279387,-17.663213050011375,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cascalho_Rico,2020-12-31T00:00:00,2.478504672897196,1.8428476,-25.64679801374178,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cassia,2020-12-31T00:00:00,2.1679245283018864,1.5953043,-26.413293918181324,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cataguases,2020-12-31T00:00:00,1.25,0.70385474,-43.69162082672119,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Catas_Altas_da_Noruega,2020-12-31T00:00:00,1.0,0.687891,-31.210899353027344,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Catuji,2020-12-31T00:00:00,1.197183098591549,0.688853,-42.46051199295941,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Caxambu,2020-12-31T00:00:00,1.3265306122448983,0.70616055,-46.76635888906628,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Chale,2020-12-31T00:00:00,1.71015625,0.9783353,-42.79263541272592,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Claraval,2020-12-31T00:00:00,2.796008294453085,1.4911579,-46.66833098011862,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Claudio,2020-12-31T00:00:00,2.76,1.2505012,-54.69198710676552,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Coimbra,2020-12-31T00:00:00,1.8000000000000005,1.6190889,-10.050617323981404,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Conceicao_da_Aparecida,2020-12-31T00:00:00,2.243948871362524,1.8136611,-19.1754713475726,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Conceicao_da_Barra_de_Minas,2020-12-31T00:00:00,1.911042944785276,1.6390715,-14.231573444690971,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Conceicao_das_Pedras,2020-12-31T00:00:00,1.739921976592978,1.4381025,-17.346725709769768,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Conceicao_de_Ipanema,2020-12-31T00:00:00,1.500533617929563,1.3142618,-12.413705472077988,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Conceicao_do_Rio_Verde,2020-12-31T00:00:00,1.8000000000000005,1.5670631,-12.940939267476413,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Conceicao_dos_Ouros,2020-12-31T00:00:00,1.5028571428571431,1.671633,11.230333041782142,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Congonhal,2020-12-31T00:00:00,1.619354838709677,1.9218048,18.67718796331097,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Congonhas_do_Norte,2020-12-31T00:00:00,1.2,0.74690294,-37.75808811187744,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Conselheiro_Pena,2020-12-31T00:00:00,1.55981308411215,1.9602642,25.673019793163554,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Coqueiral,2020-12-31T00:00:00,2.160028248587571,1.4980569,-30.64642142713216,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cordislandia,2020-12-31T00:00:00,1.62,1.7917864,10.604100757175011,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Coroaci,2020-12-31T00:00:00,1.8000000000000005,1.4532098,-19.26612456639609,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Coromandel,2020-12-31T00:00:00,1.818934240362812,1.9008547,4.503761850404748,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Corrego_Danta,2020-12-31T00:00:00,1.8000000000000005,1.4214443,-21.03087239795262,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Corrego_Fundo,2020-12-31T00:00:00,1.5,1.7524836,16.832240422566734,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Corrego_Novo,2020-12-31T00:00:00,1.2545454545454553,0.47875118,-61.83867385421976,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cristais,2020-12-31T00:00:00,1.92,1.8694967,-2.63038004438082,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cristina,2020-12-31T00:00:00,2.100263852242744,1.4220122,-32.29363975512921,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cruzeiro_da_Fortaleza,2020-12-31T00:00:00,2.1,1.9975145,-4.880262556530184,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cruzilia,2020-12-31T00:00:00,1.2,0.9879056,-17.674531539281208,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Cuparaque,2020-12-31T00:00:00,1.018518518518519,1.370673,34.57516150041053,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Datas,2020-12-31T00:00:00,2.0,3.8314524,91.57261848449711,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Delfinopolis,2020-12-31T00:00:00,1.8000000000000005,1.3673413,-24.03659555647109,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Desterro_de_Entre_Rios,2020-12-31T00:00:00,2.4,1.511354,-37.026917934417725,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Diamantina,2020-12-31T00:00:00,2.3453815261044184,1.8939182,-19.249037500113683,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Divinesia,2020-12-31T00:00:00,2.1,2.080535,-0.9269078572591188,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Divino,2020-12-31T00:00:00,1.8000483851457605,0.98595375,-45.22626411809883,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Divisa_Nova,2020-12-31T00:00:00,1.8000000000000005,1.5628289,-13.176172309451644,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Divisopolis,2020-12-31T00:00:00,1.34029484029484,0.7366042,-45.0416287842636,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Dom_Cavati,2020-12-31T00:00:00,0.7894736842105263,1.5077772,90.98511377970378,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Dom_Vicoso,2020-12-31T00:00:00,1.4285714285714288,1.6835425,17.8479743003845,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Dores_do_Turvo,2020-12-31T00:00:00,1.625,0.8278397,-49.05602014981783,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Doresopolis,2020-12-31T00:00:00,1.8000000000000005,1.3124601,-27.08555195066665,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Durande,2020-12-31T00:00:00,2.4,1.3741939,-42.74192055066426,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Eloi_Mendes,2020-12-31T00:00:00,2.109128416709644,1.5130866,-28.260102827271,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Entre_Folhas,2020-12-31T00:00:00,1.26046511627907,0.8850745,-29.781912657607545,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Entre_Rios_de_Minas,2020-12-31T00:00:00,1.8000000000000005,1.8511331,2.8407282299465453,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ervalia,2020-12-31T00:00:00,1.7999614197530858,1.4678099,-18.453256862363578,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Esmeraldas,2020-12-31T00:00:00,2.096153846153846,1.7565132,-16.203038189389275,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Espera_Feliz,2020-12-31T00:00:00,2.04,0.8259874,-59.51042163605783,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Espirito_Santo_do_Dourado,2020-12-31T00:00:00,1.619148936170213,1.2802042,-20.93351338445436,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Estrela_do_Indaia,2020-12-31T00:00:00,1.8000000000000005,1.4649181,-18.615659077962253,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Estrela_do_Sul,2020-12-31T00:00:00,2.0627027027027025,2.1545765,4.454051336152508,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Eugenopolis,2020-12-31T00:00:00,1.8000000000000005,0.8842721,-50.87377230326335,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Fama,2020-12-31T00:00:00,1.8000000000000005,1.288473,-28.4181661076016,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Faria_Lemos,2020-12-31T00:00:00,1.44031007751938,0.97537416,-32.28026538028656,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Felicio_dos_Santos,2020-12-31T00:00:00,3.548821548821549,1.3481103,-62.01245118589962,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ferros,2020-12-31T00:00:00,1.2,0.5959356,-50.33870140711466,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Fervedouro,2020-12-31T00:00:00,1.5,1.104796,-26.346929868062336,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Formiga,2020-12-31T00:00:00,1.441791044776119,1.4010253,-2.8274381136054854,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Formoso,2020-12-31T00:00:00,3.0,2.8612943,-4.62352434794108,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Fortaleza_de_Minas,2020-12-31T00:00:00,1.68,1.7014723,1.2781120481945256,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Franciscopolis,2020-12-31T00:00:00,1.8000000000000005,2.1927857,21.821429994371183,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Frei_Gaspar,2020-12-31T00:00:00,1.08,0.7144057,-33.85132264207911,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Grao_Mogol,2020-12-31T00:00:00,0.7749999999999999,1.4805205,91.03490152666647,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Guape,2020-12-31T00:00:00,1.847986942328618,1.8626293,0.7923406671033216,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Guaraciaba,2020-12-31T00:00:00,1.2,1.1023408,-8.13826521237691,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Guaranesia,2020-12-31T00:00:00,1.564686285397002,1.3405746,-14.323105234216532,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Guarani,2020-12-31T00:00:00,1.127272727272727,1.6647892,47.6829128880655,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Guarda-Mor,2020-12-31T00:00:00,1.7994350282485878,1.8431127,2.4272995803569377,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Guaxupe,2020-12-31T00:00:00,1.7400000000000002,1.4306571,-17.778324806827246,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Guimarania,2020-12-31T00:00:00,2.149930843706777,1.3742721,-36.07831097913044,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Guiricema,2020-12-31T00:00:00,2.4,1.5369854,-35.9589417775472,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Heliodora,2020-12-31T00:00:00,1.8000000000000005,1.726944,-4.05866834852432,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Iapu,2020-12-31T00:00:00,1.0,1.5783086,57.83085823059082,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ibia,2020-12-31T00:00:00,1.746,1.4364381,-17.729777568804028,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ibiraci,2020-12-31T00:00:00,2.6315194346289745,1.8818126,-28.48950504731613,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ibitiura_de_Minas,2020-12-31T00:00:00,1.68,1.258115,-25.112199215661903,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ibituruna,2020-12-31T00:00:00,1.8000000000000005,1.4941113,-16.993816693623874,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ijaci,2020-12-31T00:00:00,2.458064516129032,1.3594556,-44.69406410777975,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ilicinea,2020-12-31T00:00:00,2.09995817649519,1.9347373,-7.867816303669503,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Imbe_de_Minas,2020-12-31T00:00:00,1.439877300613497,1.3729626,-4.647250606193925,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Inconfidentes,2020-12-31T00:00:00,2.46,2.827505,14.939232182696584,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Indaiabira,2020-12-31T00:00:00,3.0,2.4897766,-17.0074462890625,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Indianopolis,2020-12-31T00:00:00,1.8000000000000005,2.139616,18.867556254069,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ingai,2020-12-31T00:00:00,1.6791666666666667,1.4637728,-12.827427866441148,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Inhapim,2020-12-31T00:00:00,1.8000000000000005,1.3892097,-22.821680704752616,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Irai_de_Minas,2020-12-31T00:00:00,3.3595092024539883,1.850953,-44.90406570249967,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Itabirinha,2020-12-31T00:00:00,0.7992424242424243,1.2038057,50.61834163575375,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Itacambira,2020-12-31T00:00:00,0.75,0.27607962,-63.18938334782919,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Itaipe,2020-12-31T00:00:00,0.9594594594594597,1.0697061,11.49049308938039,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Itajuba,2020-12-31T00:00:00,1.5882352941176472,1.6581743,4.403565548084392,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Itamarandiba,2020-12-31T00:00:00,1.7196261682242993,1.4212126,-17.353400393672622,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Itamarati_de_Minas,2020-12-31T00:00:00,1.2,0.8513842,-29.0513147910436,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Itambacuri,2020-12-31T00:00:00,1.091304347826087,1.0381111,-4.874282529154634,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Itamogi,2020-12-31T00:00:00,2.400049176297025,1.920845,-19.966430241987613,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Itanhomi,2020-12-31T00:00:00,1.26,2.123145,68.50357963925316,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Itapecerica,2020-12-31T00:00:00,1.8000000000000005,1.2641909,-29.767171541849784,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ituiutaba,2020-12-31T00:00:00,0.75,0.89712167,19.6162223815918,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Itumirim,2020-12-31T00:00:00,2.050724637681159,1.4168742,-30.90860936329979,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Itutinga,2020-12-31T00:00:00,1.8000000000000005,1.4719481,-18.225102954440658,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Jacui,2020-12-31T00:00:00,1.68,1.7022792,1.326143457776028,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Jacutinga,2020-12-31T00:00:00,1.8000000000000005,1.706626,-5.187441243065742,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Jequeri,2020-12-31T00:00:00,2.1,1.4301498,-31.89762887500581,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Jequitinhonha,2020-12-31T00:00:00,2.4,4.2803316,78.34715048472087,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Jesuania,2020-12-31T00:00:00,1.5,1.5353065,2.3537635803222656,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Joao_Pinheiro,2020-12-31T00:00:00,3.0,2.4080634,-19.731219609578453,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Jose_Goncalves_de_Minas,2020-12-31T00:00:00,1.5,1.268403,-15.439796447753906,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Juiz_de_Fora,2020-12-31T00:00:00,1.222222222222222,0.075198434,-93.84740083055064,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Juruaia,2020-12-31T00:00:00,1.92,1.7721393,-7.701077560583746,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ladainha,2020-12-31T00:00:00,1.242268041237113,0.86505497,-30.36487003579672,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Lagoa_Dourada,2020-12-31T00:00:00,2.1,1.9727095,-6.061450640360518,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Lagoa_Formosa,2020-12-31T00:00:00,2.5494505494505484,1.9898784,-21.94873454241914,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Lagoa_Grande,2020-12-31T00:00:00,2.4,1.764702,-26.470751563707985,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Lajinha,2020-12-31T00:00:00,1.9200446677833607,1.051358,-45.24304552994536,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Lambari,2020-12-31T00:00:00,1.8000970402717127,1.6269553,-9.618468650910406,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Lamim,2020-12-31T00:00:00,2.387096774193548,1.1173049,-53.19398303289671,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Lavras,2020-12-31T00:00:00,1.8000000000000005,1.6739722,-7.001541720496298,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Luisburgo,2020-12-31T00:00:00,2.1,1.4518561,-30.86399350847517,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Luminarias,2020-12-31T00:00:00,1.860103626943005,1.334779,-28.24168477549857,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Machado,2020-12-31T00:00:00,2.211839166046165,1.5740503,-28.835227649594326,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Malacacheta,2020-12-31T00:00:00,1.8000000000000005,1.6832181,-6.487882137298598,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Manhuacu,2020-12-31T00:00:00,1.6800182481751822,1.0133674,-39.681166226902825,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Manhumirim,2020-12-31T00:00:00,1.68,1.0062733,-40.10278156825474,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Mantena,2020-12-31T00:00:00,0.7,0.61524785,-12.107450621468676,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Mar_de_Espanha,2020-12-31T00:00:00,1.8000000000000005,1.4598902,-18.894986311594657,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Maria_da_Fe,2020-12-31T00:00:00,1.7333333333333332,1.467675,-15.3264440022982,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Martins_Soares,2020-12-31T00:00:00,1.8000000000000005,1.376342,-23.53655232323542,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Mata_Verde,2020-12-31T00:00:00,1.319688109161793,0.7925838,-39.941580309649495,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Matipo,2020-12-31T00:00:00,1.56,1.0620732,-31.91838264465332,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Matutina,2020-12-31T00:00:00,1.82995951417004,1.9662287,7.4465696263102465,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Medeiros,2020-12-31T00:00:00,1.980113636363636,1.277102,-35.50360089908198,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Minas_Novas,2020-12-31T00:00:00,1.0,0.87671906,-12.328094244003296,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Miradouro,2020-12-31T00:00:00,1.5,1.3060913,-12.92724609375,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Mirai,2020-12-31T00:00:00,1.5011494252873558,1.0828841,-27.863005839664734,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Moeda,2020-12-31T00:00:00,1.2,0.9156246,-23.697948455810543,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Monsenhor_Paulo,2020-12-31T00:00:00,2.1,1.4397545,-31.44026256742932,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Monte_Alegre_de_Minas,2020-12-31T00:00:00,3.0,1.7497773,-41.674089431762695,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Monte_Belo,2020-12-31T00:00:00,1.8000000000000005,1.7990589,-0.0522825453016641,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Monte_Carmelo,2020-12-31T00:00:00,1.98,2.1078544,6.4572912273985095,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Monte_Formoso,2020-12-31T00:00:00,0.6000000000000001,1.6778271,179.63785330454505,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Monte_Santo_de_Minas,2020-12-31T00:00:00,2.123987903619159,1.6893868,-20.461559985516534,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Monte_Siao,2020-12-31T00:00:00,1.8000000000000005,1.970923,9.495719273885076,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Muriae,2020-12-31T00:00:00,1.56,1.1060896,-29.09682102692433,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Mutum,2020-12-31T00:00:00,1.65,1.4130533,-14.360407626990114,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Muzambinho,2020-12-31T00:00:00,1.764006791171477,1.7769041,0.7311374895611739,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Natercia,2020-12-31T00:00:00,1.4399193548387097,1.9429268,34.93302648924072,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Nazareno,2020-12-31T00:00:00,2.1,1.5944278,-24.074865522838778,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Nepomuceno,2020-12-31T00:00:00,1.920040743570155,1.4513409,-24.41093145378071,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ninheira,2020-12-31T00:00:00,3.0,2.6121354,-12.92881965637207,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Nova_Belem,2020-12-31T00:00:00,1.1,1.1733749,6.670444661920712,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Nova_Era,2020-12-31T00:00:00,1.565217391304348,1.3892078,-11.245054668850372,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Nova_Ponte,2020-12-31T00:00:00,1.8591549295774648,1.7010937,-8.501779671871299,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Nova_Resende,2020-12-31T00:00:00,2.353040067245727,1.6731726,-28.893153312292,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Novo_Cruzeiro,2020-12-31T00:00:00,1.19727047146402,1.2196153,1.866317536546755,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Novorizonte,2020-12-31T00:00:00,1.235294117647059,1.4145732,14.513067972092376,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Olimpio_Noronha,2020-12-31T00:00:00,1.5595854922279788,1.4344327,-8.024744258766528,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Oliveira,2020-12-31T00:00:00,1.947151898734177,1.4651129,-24.7561052875094,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Orizania,2020-12-31T00:00:00,1.679901960784314,1.3026497,-22.45680005062696,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ouro_Fino,2020-12-31T00:00:00,2.099920063948841,1.657831,-21.05266376280449,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ouro_Verde_de_Minas,2020-12-31T00:00:00,1.2,1.135468,-5.377666155497229,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Padre_Paraiso,2020-12-31T00:00:00,0.7219512195121951,0.48179212,-33.265280381247806,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Paracatu,2020-12-31T00:00:00,2.7000000000000006,2.4428496,-9.5240875526711,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Paraguacu,2020-12-31T00:00:00,2.3413259668508286,1.4750693,-36.99855102093663,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Paraisopolis,2020-12-31T00:00:00,2.4,1.7472923,-27.196154991785683,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Passa_Tempo,2020-12-31T00:00:00,1.511111111111111,1.3936104,-7.775785116588366,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Passos,2020-12-31T00:00:00,1.62,1.3679965,-15.555774429698054,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Patis,2020-12-31T00:00:00,3.6000000000000005,4.100637,13.906582196553533,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Patos_de_Minas,2020-12-31T00:00:00,1.941759465478842,1.613771,-16.891304486906915,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Patrocinio,2020-12-31T00:00:00,1.7479986236953782,2.2453375,28.45190241170249,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Paula_Candido,2020-12-31T00:00:00,1.62,1.3720783,-15.3038086714568,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pecanha,2020-12-31T00:00:00,2.0,1.3875766,-30.62117099761961,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pedra_Azul,2020-12-31T00:00:00,1.0,1.328064,32.806396484375,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pedra_Bonita,2020-12-31T00:00:00,1.7400000000000002,0.8481083,-51.25814415942664,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pedra_Dourada,2020-12-31T00:00:00,1.44,1.0392175,-27.83211999469333,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pedra_do_Anta,2020-12-31T00:00:00,1.5,1.2114338,-19.237748781840004,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pedralva,2020-12-31T00:00:00,1.68,1.4968247,-10.903289204552056,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pedrinopolis,2020-12-31T00:00:00,2.158490566037736,0.9907212,-54.10120195442146,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Perdizes,2020-12-31T00:00:00,2.050845253576073,1.6644355,-18.84148728604867,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Perdoes,2020-12-31T00:00:00,1.92,1.5775638,-17.835220694541928,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Piedade_de_Caratinga,2020-12-31T00:00:00,1.8000000000000005,1.4295723,-20.57931423187257,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pimenta,2020-12-31T00:00:00,1.8000000000000005,1.5173876,-15.700687302483466,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Piracema,2020-12-31T00:00:00,1.333333333333333,1.1447341,-14.144939184188823,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Piranga,2020-12-31T00:00:00,2.4,1.7694616,-26.272432009379067,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pirangucu,2020-12-31T00:00:00,1.333333333333333,1.1492679,-13.804906606674177,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Piranguinho,2020-12-31T00:00:00,1.458181818181818,1.4935662,2.426606669390302,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pirapora,2020-12-31T00:00:00,3.6000000000000005,2.6017923,-27.727990680270736,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Piumhi,2020-12-31T00:00:00,1.7399966931216928,1.4304404,-17.790623882940917,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Poco_Fundo,2020-12-31T00:00:00,1.740033329060377,1.3862553,-20.33168324248086,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pocos_de_Caldas,2020-12-31T00:00:00,1.8000000000000005,1.4449354,-19.72580883238052,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pocrane,2020-12-31T00:00:00,1.258064516129032,1.3895731,10.453246189997769,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ponte_Nova,2020-12-31T00:00:00,1.333333333333333,1.337648,0.3236025571823343,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ponto_dos_Volantes,2020-12-31T00:00:00,0.631578947368421,0.44023016,-30.29689118266105,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Porto_Firme,2020-12-31T00:00:00,1.56,1.1249084,-27.890484149639427,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pote,2020-12-31T00:00:00,0.6571428571428573,0.76062894,15.747881972271443,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pouso_Alegre,2020-12-31T00:00:00,1.6375,1.994241,21.78570987614057,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pouso_Alto,2020-12-31T00:00:00,1.45,1.5418596,6.335146673794453,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pratapolis,2020-12-31T00:00:00,2.402298850574712,1.5433387,-35.75575927798255,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Pratinha,2020-12-31T00:00:00,2.1,1.7216153,-18.018318357921785,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Presidente_Bernardes,2020-12-31T00:00:00,1.5,1.2865047,-14.233016967773438,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Presidente_Kubitschek,2020-12-31T00:00:00,1.789473684210526,1.4069811,-21.37458499740151,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Presidente_Olegario,2020-12-31T00:00:00,1.9814229249011863,2.0150323,1.6962237636794812,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Quartel_Geral,2020-12-31T00:00:00,3.6000000000000005,3.0549595,-15.1400129000346,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Raul_Soares,2020-12-31T00:00:00,1.320083682008368,1.2512605,-5.213545468265373,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Reduto,2020-12-31T00:00:00,1.8000000000000005,1.1242913,-37.53937217924331,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ribeirao_Vermelho,2020-12-31T00:00:00,1.92,1.4587085,-24.02559767166773,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Rio_Paranaiba,2020-12-31T00:00:00,1.818897637795276,1.6112981,-11.413481947663556,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Rio_Pardo_de_Minas,2020-12-31T00:00:00,3.4487179487179493,2.2954369,-33.44086430772974,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Rio_Vermelho,2020-12-31T00:00:00,0.9333333333333332,1.1342622,21.528093303952925,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ritapolis,2020-12-31T00:00:00,2.101769911504425,1.6892287,-19.62827878249319,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Romaria,2020-12-31T00:00:00,2.330769230769231,2.3295097,-0.0540377676683751,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Rosario_da_Limeira,2020-12-31T00:00:00,1.5,0.92930025,-38.04665009180705,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sabinopolis,2020-12-31T00:00:00,1.0,1.5892246,58.92245769500733,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sacramento,2020-12-31T00:00:00,1.8321428571428573,1.194685,-34.79302240858767,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santa_Barbara,2020-12-31T00:00:00,1.142857142857143,0.9682567,-15.27753770351411,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santa_Barbara_do_Leste,2020-12-31T00:00:00,1.4400953029271608,1.5246388,5.87068570474454,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santa_Barbara_do_Monte_Verde,2020-12-31T00:00:00,1.6000000000000003,0.33101225,-79.3117344379425,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santa_Margarida,2020-12-31T00:00:00,1.8000000000000005,1.1996269,-33.354059855143234,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santa_Maria_do_Suacui,2020-12-31T00:00:00,0.8,0.8182306,2.278828620910639,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santa_Rita_de_Caldas,2020-12-31T00:00:00,1.8000000000000005,2.1487489,19.37493748135035,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santa_Rita_de_Minas,2020-12-31T00:00:00,1.5,1.4337356,-4.417626063028971,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santa_Rita_do_Itueto,2020-12-31T00:00:00,1.77,1.4978595,-15.375170734642593,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santa_Rita_do_Sapucai,2020-12-31T00:00:00,1.68,2.1347632,27.069240524655303,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santa_Rosa_da_Serra,2020-12-31T00:00:00,2.1,1.3493319,-35.74610210600353,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santana_da_Vargem,2020-12-31T00:00:00,2.22,1.5827551,-28.70472572945259,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santana_do_Jacare,2020-12-31T00:00:00,1.8000000000000005,1.325753,-26.34705702463787,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santana_do_Manhuacu,2020-12-31T00:00:00,1.8000000000000005,1.5908031,-11.62204742431642,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santo_Antonio_do_Amparo,2020-12-31T00:00:00,2.1,1.6654513,-20.692795798892067,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santo_Antonio_do_Grama,2020-12-31T00:00:00,1.695652173913043,1.0402329,-38.65293172689583,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Santo_Antonio_do_Retiro,2020-12-31T00:00:00,0.975,1.5382589,57.77014463375778,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Bento_Abade,2020-12-31T00:00:00,1.8000000000000005,1.3216968,-26.57240231831869,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Domingos_das_Dores,2020-12-31T00:00:00,1.56,1.6536832,6.005332408807213,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Domingos_do_Prata,2020-12-31T00:00:00,0.8846153846153846,0.76738256,-13.252406016640036,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Francisco_de_Paula,2020-12-31T00:00:00,1.62,1.4007356,-13.534838476298775,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Francisco_do_Gloria,2020-12-31T00:00:00,1.679693486590038,0.84269834,-49.83023138594452,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Geraldo,2020-12-31T00:00:00,1.8000000000000005,0.9959165,-44.6713063451979,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Goncalo_do_Abaete,2020-12-31T00:00:00,2.44,1.7981648,-26.30471948717461,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Goncalo_do_Rio_Preto,2020-12-31T00:00:00,3.6000000000000005,2.1165378,-41.20728307300144,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Goncalo_do_Sapucai,2020-12-31T00:00:00,2.4,2.0396192,-15.01586635907491,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Gotardo,2020-12-31T00:00:00,1.38027397260274,1.6350639,18.459372493945285,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Joao_Batista_do_Gloria,2020-12-31T00:00:00,1.5,1.4353671,-4.308859507242838,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Joao_da_Mata,2020-12-31T00:00:00,1.6399999999999997,1.4798776,-9.763561516273295,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Joao_del_Rei,2020-12-31T00:00:00,1.9709821428571432,1.5749569,-20.092787261997465,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Joao_do_Manhuacu,2020-12-31T00:00:00,1.8000000000000005,1.1843511,-34.202717410193564,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Joao_do_Manteninha,2020-12-31T00:00:00,0.9166666666666664,0.62167394,-32.18102455139159,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Joao_do_Paraiso,2020-12-31T00:00:00,3.146938775510204,2.5706627,-18.31227360068592,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Jose_da_Barra,2020-12-31T00:00:00,2.537024221453287,1.6256609,-35.92253150149114,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Jose_do_Alegre,2020-12-31T00:00:00,1.359090909090909,1.7263186,27.020097496517543,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Jose_do_Mantimento,2020-12-31T00:00:00,1.8000000000000005,1.3482794,-25.09559128019546,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Lourenco,2020-12-31T00:00:00,3.3928571428571423,1.5865793,-53.237662064401725,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Miguel_do_Anta,2020-12-31T00:00:00,1.5,1.2904766,-13.968229293823242,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Pedro_da_Uniao,2020-12-31T00:00:00,2.1,1.731761,-17.535191490536647,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Roque_de_Minas,2020-12-31T00:00:00,1.8000000000000005,1.2023885,-33.20063749949138,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Sebastiao_da_Bela_Vista,2020-12-31T00:00:00,1.5,1.647456,9.830403327941896,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Sebastiao_da_Vargem_Alegre,2020-12-31T00:00:00,1.8000000000000005,1.0022299,-44.32055950164796,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Sebastiao_do_Anta,2020-12-31T00:00:00,1.8000000000000005,1.6197004,-10.016642676459432,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Sebastiao_do_Maranhao,2020-12-31T00:00:00,0.8148148148148149,0.8721305,7.034199346195559,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Sebastiao_do_Paraiso,2020-12-31T00:00:00,1.929071661237785,1.6554099,-14.186187822885485,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Tiago,2020-12-31T00:00:00,2.69971671388102,1.6814148,-37.71884161177613,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Tomas_de_Aquino,2020-12-31T00:00:00,2.099966151415999,1.9342357,-7.892053844773484,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sao_Tome_das_Letras,2020-12-31T00:00:00,2.133763094278808,1.3617983,-36.17856218015321,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Senador_Firmino,2020-12-31T00:00:00,1.376237623762376,1.5250075,10.80989648969912,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Senador_Jose_Bento,2020-12-31T00:00:00,1.620618556701031,1.2136029,-25.114833747460946,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Senador_Modestino_Goncalves,2020-12-31T00:00:00,3.6000000000000005,1.7284102,-51.98860433366564,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Senhora_de_Oliveira,2020-12-31T00:00:00,1.8000000000000005,1.6181096,-10.10502311918472,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Senhora_dos_Remedios,2020-12-31T00:00:00,1.8000000000000005,1.3604953,-24.416926172044555,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Sericita,2020-12-31T00:00:00,2.5200000000000005,1.2331156,-51.06684310095652,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Serra_do_Salitre,2020-12-31T00:00:00,1.8000000000000005,1.9568565,8.714249398973237,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Serrania,2020-12-31T00:00:00,1.8000000000000005,1.626852,-9.619331359863295,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Setubinha,2020-12-31T00:00:00,1.0,0.63126546,-36.873453855514526,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Silvianopolis,2020-12-31T00:00:00,1.50032154340836,1.2518661,-16.560146208745543,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Simonesia,2020-12-31T00:00:00,1.8000000000000005,1.1146927,-38.072628445095496,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Soledade_de_Minas,2020-12-31T00:00:00,3.2000000000000006,1.6095765,-49.700735509395614,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Taiobeiras,2020-12-31T00:00:00,3.240083507306889,2.1871648,-32.496653911993675,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Tapira,2020-12-31T00:00:00,2.1013698630137,1.4750898,-29.80341945508938,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Tapirai,2020-12-31T00:00:00,1.799716914366596,1.5778527,-12.327727022669803,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Teixeiras,2020-12-31T00:00:00,1.5,0.9336257,-37.75828679402669,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Teofilo_Otoni,2020-12-31T00:00:00,1.09375,1.0038146,-8.222667149135045,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Tiros,2020-12-31T00:00:00,1.740235294117647,1.755316,0.8665911438272836,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Tocos_do_Moji,2020-12-31T00:00:00,1.441340782122905,2.0201344,40.156614872836336,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Tombos,2020-12-31T00:00:00,1.5,0.9669608,-35.53594748179118,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Tres_Coracoes,2020-12-31T00:00:00,2.1,1.5542195,-25.989548365275063,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Tres_Pontas,2020-12-31T00:00:00,2.26,1.6125083,-28.650075355462263,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Tupaciguara,2020-12-31T00:00:00,2.1,2.3991122,14.243439265659871,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Turmalina,2020-12-31T00:00:00,1.320338983050847,1.7528708,32.75914902252477,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Turvolandia,2020-12-31T00:00:00,1.6202531645569618,2.5970752,60.28823647648098,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Ubaporanga,2020-12-31T00:00:00,1.6200873362445412,1.329149,-17.958187928418248,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Uberaba,2020-12-31T00:00:00,2.5325581395348844,2.0041137,-20.866034904458985,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Uberlandia,2020-12-31T00:00:00,1.920754716981132,2.5999568,35.36120608653911,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Unai,2020-12-31T00:00:00,2.3398907103825146,2.477851,5.896010570356815,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Urucuia,2020-12-31T00:00:00,2.4,2.5172815,4.88673051198324,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Vargem_Bonita,2020-12-31T00:00:00,1.8031222896790973,1.4058845,-22.03055154021511,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Vargem_Grande_do_Rio_Pardo,2020-12-31T00:00:00,1.8000000000000005,2.180839,21.1577256520589,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Varginha,2020-12-31T00:00:00,1.899977968715576,1.3859967,-27.05195943560581,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Varjao_de_Minas,2020-12-31T00:00:00,2.519786096256685,2.2998185,-8.729613232086413,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Varzea_da_Palma,2020-12-31T00:00:00,3.0,4.119021,37.30069796244304,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Vermelho_Novo,2020-12-31T00:00:00,1.320080321285141,1.0757056,-18.51210641324215,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Vicosa,2020-12-31T00:00:00,1.8000000000000005,1.0057932,-44.12259923087227,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Vieiras,2020-12-31T00:00:00,1.8000000000000005,1.1116531,-38.24149502648248,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Virginia,2020-12-31T00:00:00,1.5333333333333332,1.766758,15.223345549210269,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Virginopolis,2020-12-31T00:00:00,1.626666666666667,1.545443,-4.993254630292063,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2020,Visconde_do_Rio_Branco,2020-12-31T00:00:00,1.0,0.6348293,-36.51707172393799,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:11:36
V38_2021,Abadia_dos_Dourados,2020-12-31T00:00:00,2.584210526315789,1.14738667011261,-55.60010848851407,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Abre_Campo,2020-12-31T00:00:00,1.5,0.8667852878570557,-42.21431414286296,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Acucena,2020-12-31T00:00:00,1.166666666666667,0.6646914482116699,-43.02644729614259,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Agua_Boa,2020-12-31T00:00:00,1.33,1.121586799621582,-15.670165441986317,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Aguanil,2020-12-31T00:00:00,2.1644859813084114,1.3011023998260498,-39.88861969715573,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Aguas_Vermelhas,2020-12-31T00:00:00,3.6000000000000005,2.0292677879333496,-43.63145033518474,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Aimores,2020-12-31T00:00:00,2.063157894736842,1.479339599609375,-28.297315325055795,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Aiuruoca,2020-12-31T00:00:00,1.8000000000000005,1.8013259172439575,0.0736620691087362,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Albertina,2020-12-31T00:00:00,1.68,1.8937801122665403,12.725006682532175,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Alfenas,2020-12-31T00:00:00,2.364130434782609,1.4964004755020142,-36.70397988681136,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Almenara,2020-12-31T00:00:00,0.78,0.7818288803100586,0.2344718346228932,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Alpinopolis,2020-12-31T00:00:00,2.765998457979954,1.948782205581665,-29.545072595416887,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Alterosa,2020-12-31T00:00:00,1.980023501762632,1.5254861116409302,-22.95616136460345,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Alto_Caparao,2020-12-31T00:00:00,1.92,0.8700128793716431,-54.68682919939359,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Alto_Jequitiba,2020-12-31T00:00:00,1.8000000000000005,1.1459574699401855,-36.33569611443414,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Alvarenga,2020-12-31T00:00:00,0.9,0.596938967704773,-33.673448032803,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Amparo_do_Serra,2020-12-31T00:00:00,1.4392156862745098,1.208906888961792,-16.002382374589384,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Andradas,2020-12-31T00:00:00,2.568,1.446903944015503,-43.65638847291656,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Andrelandia,2020-12-31T00:00:00,1.8000000000000005,1.5674033164978027,-12.922037972344306,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Angelandia,2020-12-31T00:00:00,1.8400349650349648,1.5515388250350952,-15.67884010260576,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Antonio_Dias,2020-12-31T00:00:00,1.333333333333333,0.8094666004180908,-39.29000496864317,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Antonio_Prado_de_Minas,2020-12-31T00:00:00,1.5,0.7048454284667969,-53.01030476888021,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Araguari,2020-12-31T00:00:00,1.979964695498676,1.7710886001586914,-10.549485847644204,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Araponga,2020-12-31T00:00:00,1.8000000000000005,0.9379287958145142,-47.89284467697144,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Arapua,2020-12-31T00:00:00,1.5,1.3109971284866333,-12.600191434224447,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Araxa,2020-12-31T00:00:00,1.786008230452675,1.3441301584243774,-24.74109942462588,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Arceburgo,2020-12-31T00:00:00,1.8387096774193543,1.5030276775360107,-18.256389467339755,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Areado,2020-12-31T00:00:00,2.078746484531941,1.5468236207962036,-25.58863563661094,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Aricanduva,2020-12-31T00:00:00,1.3196428571428571,0.9323604106903076,-29.347519622926622,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Astolfo_Dutra,2020-12-31T00:00:00,1.75,1.155371904373169,-33.9787483215332,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ataleia,2020-12-31T00:00:00,1.204819277108434,1.0688374042510986,-11.286495447158837,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Baependi,2020-12-31T00:00:00,1.67948717948718,1.461693286895752,-12.967880627581204,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Bambui,2020-12-31T00:00:00,1.7998829724985372,1.2760099172592163,-29.10595095591676,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Bandeira,2020-12-31T00:00:00,1.083333333333333,0.78236985206604,-27.781244424673208,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Bandeira_do_Sul,2020-12-31T00:00:00,1.5,1.436253309249878,-4.249779383341471,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Berilo,2020-12-31T00:00:00,0.8428571428571429,0.7350656390190125,-12.78882248926971,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Berizal,2020-12-31T00:00:00,3.340236686390532,0.2425317615270614,-92.7390845530428,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Boa_Esperanca,2020-12-31T00:00:00,2.063248407643312,1.7385644912719729,-15.73654026187766,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Bocaiuva,2020-12-31T00:00:00,1.622950819672131,1.5768402814865112,-2.8411543730533366,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Bom_Jesus_da_Penha,2020-12-31T00:00:00,1.986087924318308,2.010539531707764,1.2311442555016017,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Bom_Jesus_do_Amparo,2020-12-31T00:00:00,1.5,1.4307788610458374,-4.614742596944174,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Bom_Jesus_do_Galho,2020-12-31T00:00:00,1.44,0.7212413549423218,-49.913794795672096,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Bom_Sucesso,2020-12-31T00:00:00,2.1,1.318481206893921,-37.215180624099006,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Bonfinopolis_de_Minas,2020-12-31T00:00:00,3.3,2.08618688583374,-36.78221558079574,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Borda_da_Mata,2020-12-31T00:00:00,1.62,2.349489212036133,45.03019827383535,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Botelhos,2020-12-31T00:00:00,1.716062736614386,2.415764331817627,40.77366055880217,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Botumirim,2020-12-31T00:00:00,0.9200000000000002,0.7157265543937683,-22.20363539198172,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Brazopolis,2020-12-31T00:00:00,1.680327868852459,2.109670639038086,25.55113071348609,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Bueno_Brandao,2020-12-31T00:00:00,1.8000000000000005,2.016472101211548,12.026227845085977,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Buritis,2020-12-31T00:00:00,3.3,2.5221047401428223,-23.572583632035684,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Buritizeiro,2020-12-31T00:00:00,3.0,3.386902570724488,12.89675235748291,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cabo_Verde,2020-12-31T00:00:00,2.249052581714827,1.6443841457366943,-26.885473505341224,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cachoeira_de_Minas,2020-12-31T00:00:00,1.8596638655462183,2.227104663848877,19.75845232626134,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Caete,2020-12-31T00:00:00,1.2,1.050863265991211,-12.428061167399084,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Caiana,2020-12-31T00:00:00,1.5,0.9597039222717284,-36.019738515218094,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cajuri,2020-12-31T00:00:00,1.8000000000000005,1.143739938735962,-36.45889229244657,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Caldas,2020-12-31T00:00:00,1.68,1.1968926191329956,-28.756391718274067,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Camacho,2020-12-31T00:00:00,2.1,1.1303950548171997,-46.17166405632383,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cambuquira,2020-12-31T00:00:00,1.800145348837209,1.4423800706863403,-19.874243953798764,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Campanha,2020-12-31T00:00:00,1.6833930704898452,1.3497135639190674,-19.82184151878928,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Campestre,2020-12-31T00:00:00,2.138000770416025,1.472806692123413,-31.11290171159174,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Campo_Belo,2020-12-31T00:00:00,1.8000000000000005,0.9907482862472534,-44.95842854181926,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Campo_do_Meio,2020-12-31T00:00:00,2.4,1.4335424900054932,-40.26906291643778,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Campos_Altos,2020-12-31T00:00:00,2.1000529941706416,1.3570172786712646,-35.38176024899879,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Campos_Gerais,2020-12-31T00:00:00,2.690649114843395,1.635934829711914,-39.19925044529148,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cana_Verde,2020-12-31T00:00:00,1.5,1.242533802986145,-17.164413134256996,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Canaa,2020-12-31T00:00:00,1.8000000000000005,1.078598976135254,-40.077834659152565,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Candeias,2020-12-31T00:00:00,1.859937013094646,1.393928050994873,-25.05509373806194,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Caparao,2020-12-31T00:00:00,1.9199600798403191,0.9672722816467284,-49.62018784644859,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Capela_Nova,2020-12-31T00:00:00,1.8000000000000005,1.695279598236084,-5.817800097995348,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Capelinha,2020-12-31T00:00:00,1.434123222748815,1.070746660232544,-25.33788985159722,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Capetinga,2020-12-31T00:00:00,2.213808463251671,1.4171229600906372,-35.98710170214326,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Capitao_Eneas,2020-12-31T00:00:00,3.0,0.4742827713489532,-84.19057428836823,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Capitolio,2020-12-31T00:00:00,2.1,1.4038386344909668,-33.150541214715865,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Caputira,2020-12-31T00:00:00,1.8000000000000005,0.7866078019142151,-56.29956656032139,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Carai,2020-12-31T00:00:00,1.5225,1.7357877492904663,14.009047572444423,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Caranaiba,2020-12-31T00:00:00,1.645161290322581,0.5567190647125244,-66.16021371355244,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Carangola,2020-12-31T00:00:00,1.5,1.563391089439392,4.226072629292807,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Caratinga,2020-12-31T00:00:00,2.040022111663903,0.8970857262611389,-56.0256861368307,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Careacu,2020-12-31T00:00:00,1.320454545454546,1.341298222541809,1.578522877520784,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Carmo_da_Cachoeira,2020-12-31T00:00:00,1.8000000000000005,1.390344738960266,-22.75862561331856,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Carmo_da_Mata,2020-12-31T00:00:00,1.68,1.1410282850265503,-32.081649700800575,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Carmo_de_Minas,2020-12-31T00:00:00,1.7400000000000002,1.9698681831359863,13.210815122757822,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Carmo_do_Paranaiba,2020-12-31T00:00:00,1.947480785653288,1.7662310600280762,-9.306881328968334,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Carmo_do_Rio_Claro,2020-12-31T00:00:00,2.7847803881511743,1.7718679904937744,-36.37315179204764,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Carmopolis_de_Minas,2020-12-31T00:00:00,1.981818181818182,1.5617892742156982,-21.19411919095101,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Carrancas,2020-12-31T00:00:00,1.785714285714286,0.9464543461799622,-46.998556613922126,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Carvalhopolis,2020-12-31T00:00:00,1.679765395894428,1.528576374053955,-9.000603430097993,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Casa_Grande,2020-12-31T00:00:00,1.553846153846154,1.0085880756378174,-35.0908664193484,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cascalho_Rico,2020-12-31T00:00:00,2.478504672897196,1.8034967184066768,-27.234483835024697,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cassia,2020-12-31T00:00:00,2.1679245283018864,1.2646095752716064,-41.66726937389456,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cataguases,2020-12-31T00:00:00,1.25,0.7748641967773438,-38.0108642578125,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Catas_Altas_da_Noruega,2020-12-31T00:00:00,1.0,0.6681996583938599,-33.180034160614014,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Catuji,2020-12-31T00:00:00,1.197183098591549,1.3975660800933838,16.737872572506202,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Caxambu,2020-12-31T00:00:00,1.3265306122448983,0.9631747603416444,-27.391441143476065,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Chale,2020-12-31T00:00:00,1.71015625,0.9673036336898804,-43.43770437994304,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Claraval,2020-12-31T00:00:00,2.796008294453085,0.9920300841331482,-64.51977320306216,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Claudio,2020-12-31T00:00:00,2.76,1.6762858629226685,-39.265004966569975,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Coimbra,2020-12-31T00:00:00,1.8000000000000005,1.302935004234314,-27.61472198698257,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Conceicao_da_Aparecida,2020-12-31T00:00:00,2.243948871362524,2.001014471054077,-10.826200338554829,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Conceicao_da_Barra_de_Minas,2020-12-31T00:00:00,1.911042944785276,1.7567925453186035,-8.071529731321863,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Conceicao_das_Pedras,2020-12-31T00:00:00,1.739921976592978,1.4622578620910645,-15.95842332226992,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Conceicao_de_Ipanema,2020-12-31T00:00:00,1.500533617929563,1.041780948638916,-30.57263521517326,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Conceicao_do_Rio_Verde,2020-12-31T00:00:00,1.8000000000000005,1.431074857711792,-20.49584123823379,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Conceicao_dos_Ouros,2020-12-31T00:00:00,1.5028571428571431,1.6453187465667725,9.479384277256704,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Congonhal,2020-12-31T00:00:00,1.619354838709677,1.6719152927398682,3.2457650895137977,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Congonhas_do_Norte,2020-12-31T00:00:00,1.2,0.7059913277626038,-41.16738935311635,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Conselheiro_Pena,2020-12-31T00:00:00,1.55981308411215,1.417941689491272,-9.095409960715369,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Coqueiral,2020-12-31T00:00:00,2.160028248587571,1.54459810256958,-28.49176377301625,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cordislandia,2020-12-31T00:00:00,1.62,1.5888192653656006,-1.924736705827131,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Coroaci,2020-12-31T00:00:00,1.8000000000000005,1.1983927488327026,-33.42262506484987,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Coromandel,2020-12-31T00:00:00,1.818934240362812,1.6822123527526855,-7.516593210255632,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Corrego_Danta,2020-12-31T00:00:00,1.8000000000000005,1.472350835800171,-18.20273134443496,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Corrego_Fundo,2020-12-31T00:00:00,1.5,1.9355641603469849,29.037610689798992,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Corrego_Novo,2020-12-31T00:00:00,1.2545454545454553,0.5652286410331726,-54.94554310605149,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cristais,2020-12-31T00:00:00,1.92,1.4263081550598145,-25.713116923967995,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cristina,2020-12-31T00:00:00,2.100263852242744,1.4406659603118896,-31.40547751781329,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cruzeiro_da_Fortaleza,2020-12-31T00:00:00,2.1,1.704552412033081,-18.83083752223424,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cruzilia,2020-12-31T00:00:00,1.2,1.158370018005371,-3.469165166219072,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cuparaque,2020-12-31T00:00:00,1.018518518518519,1.553483963012695,52.52388000488274,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Datas,2020-12-31T00:00:00,2.0,4.659273147583008,132.96365737915045,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Delfinopolis,2020-12-31T00:00:00,1.8000000000000005,1.3071320056915283,-27.38155523935955,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Desterro_de_Entre_Rios,2020-12-31T00:00:00,2.4,1.8850939273834229,-21.45441969235738,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Diamantina,2020-12-31T00:00:00,2.3453815261044184,1.5007898807525637,-36.01084241311846,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Divinesia,2020-12-31T00:00:00,2.1,1.394315481185913,-33.604024705432714,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Divino,2020-12-31T00:00:00,1.8000483851457605,0.9673847556114196,-46.25784708931116,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Divisa_Nova,2020-12-31T00:00:00,1.8000000000000005,1.2346243858337402,-31.409756342569995,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Divisopolis,2020-12-31T00:00:00,1.34029484029484,0.5217305421829224,-61.07344992329066,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Dom_Cavati,2020-12-31T00:00:00,0.7894736842105263,0.7543212175369263,-4.452645778656008,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Dom_Vicoso,2020-12-31T00:00:00,1.4285714285714288,1.994157075881958,39.59099531173704,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Dores_do_Turvo,2020-12-31T00:00:00,1.625,0.942768931388855,-41.98345037607047,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Doresopolis,2020-12-31T00:00:00,1.8000000000000005,1.9462270736694336,8.123726314968517,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Durande,2020-12-31T00:00:00,2.4,1.1350200176239014,-52.707499265670776,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Eloi_Mendes,2020-12-31T00:00:00,2.109128416709644,1.487302541732788,-29.48259907032774,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Entre_Folhas,2020-12-31T00:00:00,1.26046511627907,0.7681538462638855,-39.05790518570652,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Entre_Rios_de_Minas,2020-12-31T00:00:00,1.8000000000000005,1.7236799001693726,-4.240005546145984,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ervalia,2020-12-31T00:00:00,1.7999614197530858,1.1331554651260376,-37.045569272174674,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Esmeraldas,2020-12-31T00:00:00,2.096153846153846,2.075191259384156,-1.0000500110311084,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Espera_Feliz,2020-12-31T00:00:00,2.04,0.9777311086654664,-52.07200447718302,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Espirito_Santo_do_Dourado,2020-12-31T00:00:00,1.619148936170213,1.3422905206680298,-17.09900857897846,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Estrela_do_Indaia,2020-12-31T00:00:00,1.8000000000000005,1.362552046775818,-24.30266406801013,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Estrela_do_Sul,2020-12-31T00:00:00,2.0627027027027025,1.6977458000183103,-17.69314124649175,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Eugenopolis,2020-12-31T00:00:00,1.8000000000000005,0.8280820846557617,-53.99543974134657,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Fama,2020-12-31T00:00:00,1.8000000000000005,1.2557133436203003,-30.23814757665,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Faria_Lemos,2020-12-31T00:00:00,1.44031007751938,0.9571784138679504,-33.54358698118106,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Felicio_dos_Santos,2020-12-31T00:00:00,3.548821548821549,1.23997962474823,-65.05939767075671,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ferros,2020-12-31T00:00:00,1.2,0.6386438012123108,-46.77968323230744,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Fervedouro,2020-12-31T00:00:00,1.5,0.9970434308052064,-33.53043794631958,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Formiga,2020-12-31T00:00:00,1.441791044776119,1.0795294046401978,-25.12580733861981,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Formoso,2020-12-31T00:00:00,3.0,3.16469144821167,5.489714940388998,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Fortaleza_de_Minas,2020-12-31T00:00:00,1.68,1.5178897380828855,-9.649420352209178,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Franciscopolis,2020-12-31T00:00:00,1.8000000000000005,4.141213417053223,130.06741205851233,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Frei_Gaspar,2020-12-31T00:00:00,1.08,1.694348931312561,56.8841603067186,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Grao_Mogol,2020-12-31T00:00:00,0.7749999999999999,1.9389504194259644,150.18715089367285,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Guape,2020-12-31T00:00:00,1.847986942328618,1.7344772815704346,-6.142341060870901,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Guaraciaba,2020-12-31T00:00:00,1.2,1.0888351202011108,-9.26373998324076,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Guaranesia,2020-12-31T00:00:00,1.564686285397002,1.5561107397079468,-0.5480680548611975,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Guarani,2020-12-31T00:00:00,1.127272727272727,1.912284016609192,69.63809824758965,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Guarda-Mor,2020-12-31T00:00:00,1.7994350282485878,1.7737812995910645,-1.4256546224118158,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Guaxupe,2020-12-31T00:00:00,1.7400000000000002,1.489884614944458,-14.374447416985184,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Guimarania,2020-12-31T00:00:00,2.149930843706777,1.4163992404937744,-34.1188464438369,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Guiricema,2020-12-31T00:00:00,2.4,1.5104928016662598,-37.06279993057251,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Heliodora,2020-12-31T00:00:00,1.8000000000000005,1.706682205200195,-5.184321933322496,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Iapu,2020-12-31T00:00:00,1.0,1.478581786155701,47.85817861557007,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ibia,2020-12-31T00:00:00,1.746,1.2257527112960815,-29.79652283527597,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ibiraci,2020-12-31T00:00:00,2.6315194346289745,1.0471137762069702,-60.20877663194588,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ibitiura_de_Minas,2020-12-31T00:00:00,1.68,1.2818262577056885,-23.700817993709016,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ibituruna,2020-12-31T00:00:00,1.8000000000000005,1.7169699668884275,-4.6127796173095845,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ijaci,2020-12-31T00:00:00,2.458064516129032,1.7238256931304932,-29.87060828471747,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ilicinea,2020-12-31T00:00:00,2.09995817649519,1.6748254299163818,-20.24481969866422,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Imbe_de_Minas,2020-12-31T00:00:00,1.439877300613497,1.0653449296951294,-26.01140880259648,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Inconfidentes,2020-12-31T00:00:00,2.46,2.58341646194458,5.016929347340655,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Indaiabira,2020-12-31T00:00:00,3.0,1.920854091644287,-35.97153027852376,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Indianopolis,2020-12-31T00:00:00,1.8000000000000005,1.5778825283050537,-12.33985953860814,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ingai,2020-12-31T00:00:00,1.6791666666666667,1.3162541389465332,-21.612656737675444,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Inhapim,2020-12-31T00:00:00,1.8000000000000005,1.1729247570037842,-34.83751349978978,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Irai_de_Minas,2020-12-31T00:00:00,3.3595092024539883,1.1390948295593262,-66.09341540939187,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Itabirinha,2020-12-31T00:00:00,0.7992424242424243,1.170635223388672,46.46810377943571,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Itacambira,2020-12-31T00:00:00,0.75,0.7970246076583862,6.269947687784831,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Itaipe,2020-12-31T00:00:00,0.9594594594594597,1.1338852643966677,18.17959093711745,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Itajuba,2020-12-31T00:00:00,1.5882352941176472,1.941380381584168,22.23506106270684,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Itamarandiba,2020-12-31T00:00:00,1.7196261682242993,1.125601887702942,-34.543803269448496,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Itamarati_de_Minas,2020-12-31T00:00:00,1.2,0.885217547416687,-26.231871048609413,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Itambacuri,2020-12-31T00:00:00,1.091304347826087,0.9720354676246644,-10.92902089495109,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Itamogi,2020-12-31T00:00:00,2.400049176297025,1.603780746459961,-33.1771714388622,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Itanhomi,2020-12-31T00:00:00,1.26,0.9415329694747924,-25.275161152794247,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Itapecerica,2020-12-31T00:00:00,1.8000000000000005,0.965886652469635,-46.339630418353615,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ituiutaba,2020-12-31T00:00:00,0.75,0.9891596436500548,31.887952486673992,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Itumirim,2020-12-31T00:00:00,2.050724637681159,1.606623649597168,-21.655807899502047,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Itutinga,2020-12-31T00:00:00,1.8000000000000005,1.4637253284454346,-18.68192619747587,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Jacui,2020-12-31T00:00:00,1.68,1.563928484916687,-6.909018754959104,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Jacutinga,2020-12-31T00:00:00,1.8000000000000005,1.78495192527771,-0.8360041512383503,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Jequeri,2020-12-31T00:00:00,2.1,1.2830125093460083,-38.90416622161865,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Jequitinhonha,2020-12-31T00:00:00,2.4,2.795300006866455,16.47083361943563,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Jesuania,2020-12-31T00:00:00,1.5,1.949047327041626,29.93648846944173,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Joao_Pinheiro,2020-12-31T00:00:00,3.0,2.380368232727051,-20.65439224243164,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Jose_Goncalves_de_Minas,2020-12-31T00:00:00,1.5,1.4823747873306274,-1.1750141779581704,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Juiz_de_Fora,2020-12-31T00:00:00,1.222222222222222,0.3883639872074127,-68.22476468302987,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Juruaia,2020-12-31T00:00:00,1.92,1.7399271726608276,-9.37879309058189,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ladainha,2020-12-31T00:00:00,1.242268041237113,0.9180395603179932,-26.099720040792228,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Lagoa_Dourada,2020-12-31T00:00:00,2.1,1.9897847175598145,-5.248346782865982,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Lagoa_Formosa,2020-12-31T00:00:00,2.5494505494505484,2.0320515632629395,-20.294529199600188,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Lagoa_Grande,2020-12-31T00:00:00,2.4,1.610532522201538,-32.89447824160258,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Lajinha,2020-12-31T00:00:00,1.9200446677833607,0.8183621168136597,-57.37796466170568,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Lambari,2020-12-31T00:00:00,1.8000970402717127,1.7426362037658691,-3.192096604812495,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Lamim,2020-12-31T00:00:00,2.387096774193548,1.1073925495147705,-53.609231033840686,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Lavras,2020-12-31T00:00:00,1.8000000000000005,1.9281131029129028,7.117394606272363,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Luisburgo,2020-12-31T00:00:00,2.1,1.19857919216156,-42.924800373259046,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Luminarias,2020-12-31T00:00:00,1.860103626943005,1.2518352270126345,-32.700780274808224,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Machado,2020-12-31T00:00:00,2.211839166046165,1.4739887714385986,-33.35913415108439,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Malacacheta,2020-12-31T00:00:00,1.8000000000000005,1.6416864395141602,-8.795197804768893,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Manhuacu,2020-12-31T00:00:00,1.6800182481751822,0.8932579159736633,-46.83046348193477,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Manhumirim,2020-12-31T00:00:00,1.68,1.032374143600464,-38.54915811902001,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Mantena,2020-12-31T00:00:00,0.7,0.4136948585510254,-40.900734492710654,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Mar_de_Espanha,2020-12-31T00:00:00,1.8000000000000005,1.5909100770950315,-11.616106828053804,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Maria_da_Fe,2020-12-31T00:00:00,1.7333333333333332,1.4436262845993042,-16.71386819619398,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Martins_Soares,2020-12-31T00:00:00,1.8000000000000005,1.4085979461669922,-21.744558546278224,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Mata_Verde,2020-12-31T00:00:00,1.319688109161793,0.5545218586921692,-57.98083995434522,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Matipo,2020-12-31T00:00:00,1.56,0.9529802203178406,-38.91152433859997,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Matutina,2020-12-31T00:00:00,1.82995951417004,1.7341609001159668,-5.235012759149588,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Medeiros,2020-12-31T00:00:00,1.980113636363636,1.332463264465332,-32.70773757649971,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Minas_Novas,2020-12-31T00:00:00,1.0,0.8556756973266602,-14.432430267333984,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Miradouro,2020-12-31T00:00:00,1.5,1.139980673789978,-24.001288414001465,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Mirai,2020-12-31T00:00:00,1.5011494252873558,1.1747835874557495,-21.74106270394316,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Moeda,2020-12-31T00:00:00,1.2,0.7827072143554688,-34.77439880371094,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Monsenhor_Paulo,2020-12-31T00:00:00,2.1,1.4135912656784058,-32.68613020579021,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Monte_Alegre_de_Minas,2020-12-31T00:00:00,3.0,1.1733826398849487,-60.88724533716837,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Monte_Belo,2020-12-31T00:00:00,1.8000000000000005,1.4794394969940186,-17.80891683366565,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Monte_Carmelo,2020-12-31T00:00:00,1.98,1.470090627670288,-25.752998602510697,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Monte_Formoso,2020-12-31T00:00:00,0.6000000000000001,1.4480637311935425,141.3439551989237,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Monte_Santo_de_Minas,2020-12-31T00:00:00,2.123987903619159,1.6233824491500854,-23.569129259920427,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Monte_Siao,2020-12-31T00:00:00,1.8000000000000005,1.9541757106781008,8.565317259894462,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Muriae,2020-12-31T00:00:00,1.56,1.0418399572372437,-33.215387356586945,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Mutum,2020-12-31T00:00:00,1.65,1.1795742511749268,-28.51065144394383,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Muzambinho,2020-12-31T00:00:00,1.764006791171477,1.5041037797927856,-14.733674081044196,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Natercia,2020-12-31T00:00:00,1.4399193548387097,1.7315119504928589,20.25061991661412,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Nazareno,2020-12-31T00:00:00,2.1,1.6431150436401367,-21.756426493326828,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Nepomuceno,2020-12-31T00:00:00,1.920040743570155,1.4641835689544678,-23.74205735697353,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ninheira,2020-12-31T00:00:00,3.0,2.4882888793945312,-17.057037353515625,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Nova_Belem,2020-12-31T00:00:00,1.1,1.1009306907653809,0.0846082513982518,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Nova_Era,2020-12-31T00:00:00,1.565217391304348,1.868631362915039,19.38478151957193,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Nova_Ponte,2020-12-31T00:00:00,1.8591549295774648,1.2585359811782837,-32.30601919419838,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Nova_Resende,2020-12-31T00:00:00,2.353040067245727,1.8230855464935305,-22.522120559235407,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Novo_Cruzeiro,2020-12-31T00:00:00,1.19727047146402,1.1867471933364868,-0.8789390850561478,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Novorizonte,2020-12-31T00:00:00,1.235294117647059,1.525635004043579,23.503786041623044,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Olimpio_Noronha,2020-12-31T00:00:00,1.5595854922279788,1.6967929601669312,8.797688143593955,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Oliveira,2020-12-31T00:00:00,1.947151898734177,1.5425933599472046,-20.776937795657936,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Orizania,2020-12-31T00:00:00,1.679901960784314,1.1029679775238037,-34.343312688982806,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ouro_Fino,2020-12-31T00:00:00,2.099920063948841,1.6252630949020386,-22.603573211935657,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ouro_Verde_de_Minas,2020-12-31T00:00:00,1.2,1.5698224306106567,30.8185358842214,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Padre_Paraiso,2020-12-31T00:00:00,0.7219512195121951,0.6194342970848083,-14.199979120009653,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Paracatu,2020-12-31T00:00:00,2.7000000000000006,2.3332066535949707,-13.584938755741844,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Paraguacu,2020-12-31T00:00:00,2.3413259668508286,1.3346718549728394,-42.99504324175658,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Paraisopolis,2020-12-31T00:00:00,2.4,1.178449630737305,-50.89793205261231,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Passa_Tempo,2020-12-31T00:00:00,1.511111111111111,1.4063339233398438,-6.933784484863279,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Passos,2020-12-31T00:00:00,1.62,1.2453510761260986,-23.126476782339594,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Patis,2020-12-31T00:00:00,3.6000000000000005,4.239842891693115,17.773413658142072,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Patos_de_Minas,2020-12-31T00:00:00,1.941759465478842,1.861455202102661,-4.135644234203725,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Patrocinio,2020-12-31T00:00:00,1.7479986236953782,1.2880463600158691,-26.31307928075717,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Paula_Candido,2020-12-31T00:00:00,1.62,1.205789566040039,-25.56854530617043,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pecanha,2020-12-31T00:00:00,2.0,1.3038257360458374,-34.80871319770812,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pedra_Azul,2020-12-31T00:00:00,1.0,1.3465416431427002,34.65416431427002,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pedra_Bonita,2020-12-31T00:00:00,1.7400000000000002,0.7085394263267517,-59.2793433145545,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pedra_Dourada,2020-12-31T00:00:00,1.44,0.8699735403060913,-39.58517081207699,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pedra_do_Anta,2020-12-31T00:00:00,1.5,1.3618923425674438,-9.20717716217041,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pedralva,2020-12-31T00:00:00,1.68,1.4153550863265991,-15.752673432940526,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pedrinopolis,2020-12-31T00:00:00,2.158490566037736,0.8684746026992798,-59.764725574246654,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Perdizes,2020-12-31T00:00:00,2.050845253576073,1.3100017309188845,-36.12381389407,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Perdoes,2020-12-31T00:00:00,1.92,1.5228173732757568,-20.68659514188766,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Piedade_de_Caratinga,2020-12-31T00:00:00,1.8000000000000005,1.3694730997085571,-23.9181611273024,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pimenta,2020-12-31T00:00:00,1.8000000000000005,1.41217041015625,-21.54608832465279,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Piracema,2020-12-31T00:00:00,1.333333333333333,1.2325332164764404,-7.560008764266947,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Piranga,2020-12-31T00:00:00,2.4,1.8261561393737795,-23.91016085942586,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pirangucu,2020-12-31T00:00:00,1.333333333333333,1.211410641670227,-9.14420187473295,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Piranguinho,2020-12-31T00:00:00,1.458181818181818,1.6508687734603882,13.214192693667531,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pirapora,2020-12-31T00:00:00,3.6000000000000005,3.050846099853516,-15.254275004069024,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Piumhi,2020-12-31T00:00:00,1.7399966931216928,1.2063183784484863,-30.671225800765463,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Poco_Fundo,2020-12-31T00:00:00,1.740033329060377,1.227894306182861,-29.43271340406292,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pocos_de_Caldas,2020-12-31T00:00:00,1.8000000000000005,1.247806191444397,-30.677433808644626,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pocrane,2020-12-31T00:00:00,1.258064516129032,1.066287875175476,-15.24378428092368,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ponte_Nova,2020-12-31T00:00:00,1.333333333333333,1.096860647201538,-17.735451459884626,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ponto_dos_Volantes,2020-12-31T00:00:00,0.631578947368421,0.4801649451255798,-23.973883688449853,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Porto_Firme,2020-12-31T00:00:00,1.56,1.109151840209961,-28.90052306346405,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pote,2020-12-31T00:00:00,0.6571428571428573,0.7856184840202332,19.55063887264416,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pouso_Alegre,2020-12-31T00:00:00,1.6375,1.97368597984314,20.530441517138303,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pouso_Alto,2020-12-31T00:00:00,1.45,1.9819154739379885,36.68382578882679,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pratapolis,2020-12-31T00:00:00,2.402298850574712,1.66749107837677,-30.58769195273729,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pratinha,2020-12-31T00:00:00,2.1,1.8913205862045288,-9.93711494264149,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Presidente_Bernardes,2020-12-31T00:00:00,1.5,1.187349796295166,-20.8433469136556,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Presidente_Kubitschek,2020-12-31T00:00:00,1.789473684210526,1.1004153490066528,-38.50620108492234,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Presidente_Olegario,2020-12-31T00:00:00,1.9814229249011863,1.955296754837036,-1.3185559597506584,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Quartel_Geral,2020-12-31T00:00:00,3.6000000000000005,2.776338577270508,-22.87948396470813,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Raul_Soares,2020-12-31T00:00:00,1.320083682008368,1.3126989603042605,-0.559413149693099,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Reduto,2020-12-31T00:00:00,1.8000000000000005,0.9936254620552064,-44.79858544137743,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ribeirao_Vermelho,2020-12-31T00:00:00,1.92,1.632393717765808,-14.979493866364155,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Rio_Paranaiba,2020-12-31T00:00:00,1.818897637795276,1.3667254447937012,-24.85968333818181,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Rio_Pardo_de_Minas,2020-12-31T00:00:00,3.4487179487179493,2.1974294185638428,-36.282715744245465,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Rio_Vermelho,2020-12-31T00:00:00,0.9333333333333332,1.0221641063690186,9.517582825252012,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ritapolis,2020-12-31T00:00:00,2.101769911504425,1.6453375816345217,-21.716569800125924,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Romaria,2020-12-31T00:00:00,2.330769230769231,1.596304178237915,-31.51170192378583,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Rosario_da_Limeira,2020-12-31T00:00:00,1.5,0.8976622819900513,-40.15584786732991,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sabinopolis,2020-12-31T00:00:00,1.0,1.8943431377410889,89.43431377410889,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sacramento,2020-12-31T00:00:00,1.8321428571428573,1.123878002166748,-38.657730875889,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santa_Barbara,2020-12-31T00:00:00,1.142857142857143,0.9487384557724,-16.98538511991502,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santa_Barbara_do_Leste,2020-12-31T00:00:00,1.4400953029271608,0.8461515307426453,-41.243365697899016,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santa_Barbara_do_Monte_Verde,2020-12-31T00:00:00,1.6000000000000003,0.7551969289779663,-52.80019193887712,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santa_Margarida,2020-12-31T00:00:00,1.8000000000000005,1.0210245847702026,-43.276411957210975,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santa_Maria_do_Suacui,2020-12-31T00:00:00,0.8,0.7896699905395508,-1.291251182556158,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santa_Rita_de_Caldas,2020-12-31T00:00:00,1.8000000000000005,2.324209690093994,29.12276056077744,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santa_Rita_de_Minas,2020-12-31T00:00:00,1.5,1.1112910509109497,-25.91392993927002,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santa_Rita_do_Itueto,2020-12-31T00:00:00,1.77,1.6079622507095337,-9.15467510115629,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santa_Rita_do_Sapucai,2020-12-31T00:00:00,1.68,2.009676218032837,19.62358440671649,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santa_Rosa_da_Serra,2020-12-31T00:00:00,2.1,1.3733879327774048,-34.6005746296474,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santana_da_Vargem,2020-12-31T00:00:00,2.22,1.6467266082763672,-25.823125753316784,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santana_do_Jacare,2020-12-31T00:00:00,1.8000000000000005,1.249934196472168,-30.55921130710179,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santana_do_Manhuacu,2020-12-31T00:00:00,1.8000000000000005,1.631381630897522,-9.367687172359904,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santo_Antonio_do_Amparo,2020-12-31T00:00:00,2.1,1.5102920532226562,-28.081330798921133,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santo_Antonio_do_Grama,2020-12-31T00:00:00,1.695652173913043,0.6924676895141602,-59.16216190044696,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santo_Antonio_do_Retiro,2020-12-31T00:00:00,0.975,1.916208982467652,96.53425461206685,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Bento_Abade,2020-12-31T00:00:00,1.8000000000000005,1.490142583847046,-17.21430089738635,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Domingos_das_Dores,2020-12-31T00:00:00,1.56,1.243683934211731,-20.276670883863403,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Domingos_do_Prata,2020-12-31T00:00:00,0.8846153846153846,0.5916522741317749,-33.11756901119066,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Francisco_de_Paula,2020-12-31T00:00:00,1.62,1.4033055305480957,-13.37620181801879,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Francisco_do_Gloria,2020-12-31T00:00:00,1.679693486590038,0.8764739632606506,-47.8194104901848,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Geraldo,2020-12-31T00:00:00,1.8000000000000005,0.6579346656799316,-63.44807412889269,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Goncalo_do_Abaete,2020-12-31T00:00:00,2.44,1.9634983539581297,-19.528755985322544,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Goncalo_do_Rio_Preto,2020-12-31T00:00:00,3.6000000000000005,1.2540549039840698,-65.16514155599806,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Goncalo_do_Sapucai,2020-12-31T00:00:00,2.4,1.831609129905701,-23.6829529205958,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Gotardo,2020-12-31T00:00:00,1.38027397260274,1.4275877475738523,3.427853883377546,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Joao_Batista_do_Gloria,2020-12-31T00:00:00,1.5,1.564321756362915,4.288117090861002,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Joao_da_Mata,2020-12-31T00:00:00,1.6399999999999997,1.5347555875778198,-6.417342220864626,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Joao_del_Rei,2020-12-31T00:00:00,1.9709821428571432,1.7130941152572632,-13.084239678906709,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Joao_do_Manhuacu,2020-12-31T00:00:00,1.8000000000000005,1.030741572380066,-42.736579312218566,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Joao_do_Manteninha,2020-12-31T00:00:00,0.9166666666666664,0.6905497312545776,-24.66730204495516,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Joao_do_Paraiso,2020-12-31T00:00:00,3.146938775510204,1.9915711879730225,-36.71401542757581,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Jose_da_Barra,2020-12-31T00:00:00,2.537024221453287,1.621873378753662,-36.07182126843857,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Jose_do_Alegre,2020-12-31T00:00:00,1.359090909090909,2.0969061851501465,54.28741161639877,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Jose_do_Mantimento,2020-12-31T00:00:00,1.8000000000000005,1.1688079833984375,-35.066223144531264,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Lourenco,2020-12-31T00:00:00,3.3928571428571423,1.9068686962127688,-43.797554216886816,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Miguel_do_Anta,2020-12-31T00:00:00,1.5,1.1614450216293335,-22.57033189137777,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Pedro_da_Uniao,2020-12-31T00:00:00,2.1,1.65016770362854,-21.42058554149809,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Roque_de_Minas,2020-12-31T00:00:00,1.8000000000000005,1.4463248252868652,-19.648620817396388,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Sebastiao_da_Bela_Vista,2020-12-31T00:00:00,1.5,1.8081175088882449,20.54116725921631,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Sebastiao_da_Vargem_Alegre,2020-12-31T00:00:00,1.8000000000000005,0.9951371550559998,-44.71460249688891,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Sebastiao_do_Anta,2020-12-31T00:00:00,1.8000000000000005,1.2210904359817505,-32.16164244545831,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Sebastiao_do_Maranhao,2020-12-31T00:00:00,0.8148148148148149,0.9830107688903807,20.642230727455825,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Sebastiao_do_Paraiso,2020-12-31T00:00:00,1.929071661237785,1.3942677974700928,-27.72337982636354,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Tiago,2020-12-31T00:00:00,2.69971671388102,1.609328031539917,-40.389003658594895,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Tomas_de_Aquino,2020-12-31T00:00:00,2.099966151415999,1.2838925123214722,-38.86127586124432,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Tome_das_Letras,2020-12-31T00:00:00,2.133763094278808,1.417699098587036,-33.55873937513174,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Senador_Firmino,2020-12-31T00:00:00,1.376237623762376,1.2804012298583984,-6.963651643382553,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Senador_Jose_Bento,2020-12-31T00:00:00,1.620618556701031,1.1421574354171753,-29.52336435402926,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Senador_Modestino_Goncalves,2020-12-31T00:00:00,3.6000000000000005,1.7422956228256226,-51.60289936595493,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Senhora_de_Oliveira,2020-12-31T00:00:00,1.8000000000000005,1.508239984512329,-16.208889749315063,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Senhora_dos_Remedios,2020-12-31T00:00:00,1.8000000000000005,1.17397940158844,-34.77892213397557,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sericita,2020-12-31T00:00:00,2.5200000000000005,0.7508817315101624,-70.20310589245388,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Serra_do_Salitre,2020-12-31T00:00:00,1.8000000000000005,1.2122772932052612,-32.6512614885966,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Serrania,2020-12-31T00:00:00,1.8000000000000005,1.2222892045974731,-32.09504418902928,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Setubinha,2020-12-31T00:00:00,1.0,0.6710209846496582,-32.89790153503418,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Silvianopolis,2020-12-31T00:00:00,1.50032154340836,1.2642059326171875,-15.737667157319908,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Simonesia,2020-12-31T00:00:00,1.8000000000000005,1.1103134155273438,-38.315921359592025,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Soledade_de_Minas,2020-12-31T00:00:00,3.2000000000000006,1.9139165878295896,-40.19010663032533,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Taiobeiras,2020-12-31T00:00:00,3.240083507306889,1.4305601119995115,-55.84804808970579,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Tapira,2020-12-31T00:00:00,2.1013698630137,1.293025016784668,-38.46751875796564,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Tapirai,2020-12-31T00:00:00,1.799716914366596,1.6052005290985107,-10.808165646236906,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Teixeiras,2020-12-31T00:00:00,1.5,0.9272527694702148,-38.18314870198567,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Teofilo_Otoni,2020-12-31T00:00:00,1.09375,1.046880125999451,-4.285245622907366,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Tiros,2020-12-31T00:00:00,1.740235294117647,1.4293978214263916,-17.861807178716017,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Tocos_do_Moji,2020-12-31T00:00:00,1.441340782122905,1.4918222427368164,3.502395910810136,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Tombos,2020-12-31T00:00:00,1.5,0.8921896815299988,-40.52068789800008,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Tres_Coracoes,2020-12-31T00:00:00,2.1,1.4429523944854736,-31.28798121497745,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Tres_Pontas,2020-12-31T00:00:00,2.26,1.6800408363342283,-25.661909896715542,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Tupaciguara,2020-12-31T00:00:00,2.1,2.6964805126190186,28.40383393423897,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Turmalina,2020-12-31T00:00:00,1.320338983050847,2.515209913253784,90.49728482923403,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Turvolandia,2020-12-31T00:00:00,1.6202531645569618,2.719223976135254,67.82710477709773,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ubaporanga,2020-12-31T00:00:00,1.6200873362445412,1.1415736675262451,-29.536288446493213,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Uberaba,2020-12-31T00:00:00,2.5325581395348844,3.0451817512512207,20.241336367128056,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Uberlandia,2020-12-31T00:00:00,1.920754716981132,1.736464500427246,-9.59467728620427,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Unai,2020-12-31T00:00:00,2.3398907103825146,2.5653655529022217,9.636127085732456,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Urucuia,2020-12-31T00:00:00,2.4,3.0534942150115967,27.228925625483203,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Vargem_Bonita,2020-12-31T00:00:00,1.8031222896790973,3.568800210952759,97.92335946265185,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Vargem_Grande_do_Rio_Pardo,2020-12-31T00:00:00,1.8000000000000005,2.0556859970092773,14.2047776116265,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Varginha,2020-12-31T00:00:00,1.899977968715576,1.5122618675231934,-20.406347209093497,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Varjao_de_Minas,2020-12-31T00:00:00,2.519786096256685,2.3822479248046875,-5.4583272626323325,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Varzea_da_Palma,2020-12-31T00:00:00,3.0,4.77338981628418,59.11299387613932,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Vermelho_Novo,2020-12-31T00:00:00,1.320080321285141,0.8076003193855286,-38.821880277761935,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Vicosa,2020-12-31T00:00:00,1.8000000000000005,0.966919243335724,-46.28226425912646,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Vieiras,2020-12-31T00:00:00,1.8000000000000005,1.0319727659225464,-42.66817967096965,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Virginia,2020-12-31T00:00:00,1.5333333333333332,1.787272810935974,16.561270278433106,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Virginopolis,2020-12-31T00:00:00,1.626666666666667,1.7991544008255005,10.60375414910862,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Visconde_do_Rio_Branco,2020-12-31T00:00:00,1.0,0.6822109818458557,-31.77890181541443,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Abadia_dos_Dourados,2021-12-31T00:00:00,1.8000000000000005,0.5792490839958191,-67.81949533356561,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Abre_Campo,2021-12-31T00:00:00,1.2,1.9412745237350464,61.77287697792055,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Acucena,2021-12-31T00:00:00,0.9,0.8158478736877441,-9.35023625691732,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Agua_Boa,2021-12-31T00:00:00,0.6171428571428572,1.2334237098693848,99.8603233584651,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Aguanil,2021-12-31T00:00:00,1.7382352941176469,1.399227499961853,-19.50298646581556,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Aguas_Vermelhas,2021-12-31T00:00:00,3.0,3.5284783840179443,17.61594613393148,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Aimores,2021-12-31T00:00:00,1.634328358208955,1.7754127979278564,8.632563891476167,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Aiuruoca,2021-12-31T00:00:00,1.2,1.0999791622161863,-8.335069815317786,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Albertina,2021-12-31T00:00:00,1.56,1.4523669481277466,-6.899554607195735,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Alfenas,2021-12-31T00:00:00,1.6209774981853378,1.9411616325378416,19.752534178355084,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Almenara,2021-12-31T00:00:00,0.78,0.6857813596725464,-12.079312862494056,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Alpinopolis,2021-12-31T00:00:00,1.67993145468393,2.51163649559021,49.50827241119553,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Alterosa,2021-12-31T00:00:00,1.08,2.4356281757354736,125.52112738291422,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Alto_Caparao,2021-12-31T00:00:00,1.08,2.4091503620147705,123.0694779643306,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Alto_Jequitiba,2021-12-31T00:00:00,0.9,1.8216506242752075,102.4056249194675,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Alvarenga,2021-12-31T00:00:00,0.6304878048780488,0.7682484984397888,21.84985855331273,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Amparo_do_Serra,2021-12-31T00:00:00,1.2,1.6512730121612549,37.60608434677125,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Andradas,2021-12-31T00:00:00,1.26,1.436236023902893,13.98698602403913,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Andrelandia,2021-12-31T00:00:00,1.4,1.5667670965194702,11.911935465676452,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Angelandia,2021-12-31T00:00:00,1.5133433283358322,1.694737195968628,11.986299753425278,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Antonio_Dias,2021-12-31T00:00:00,1.5,1.1741297245025637,-21.72468503316244,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Antonio_Prado_de_Minas,2021-12-31T00:00:00,0.9,0.8003255724906921,-11.0749363899231,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Araguari,2021-12-31T00:00:00,1.8600340136054423,1.4799805879592896,-20.432606224736016,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Araponga,2021-12-31T00:00:00,1.2,1.524733304977417,27.06110874811809,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Arapua,2021-12-31T00:00:00,1.32,1.1684808731079102,-11.478721734249236,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Araxa,2021-12-31T00:00:00,1.250440917107584,1.4433681964874268,15.42874011401562,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Arceburgo,2021-12-31T00:00:00,1.354903268845897,2.2053163051605225,62.765590420267046,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Areado,2021-12-31T00:00:00,1.5228426395939092,1.7440555095672607,14.526311794916747,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Aricanduva,2021-12-31T00:00:00,0.8394736842105264,1.2730528116226196,51.64892426852521,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Astolfo_Dutra,2021-12-31T00:00:00,1.75,0.9699931740760804,-44.57181862422398,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ataleia,2021-12-31T00:00:00,0.6266666666666667,1.1140133142471311,77.76808206071244,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Baependi,2021-12-31T00:00:00,1.079646017699115,1.016311764717102,-5.866205399153654,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Bambui,2021-12-31T00:00:00,1.439910025706941,1.6731523275375366,16.198394182031095,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Bandeira,2021-12-31T00:00:00,0.96,0.9475588798522948,-1.295950015385931,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Bandeira_do_Sul,2021-12-31T00:00:00,1.8011695906432754,1.3377907276153564,-25.726553759017573,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Berilo,2021-12-31T00:00:00,1.8017241379310345,0.6857744455337524,-61.93787766415536,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Berizal,2021-12-31T00:00:00,3.541935483870968,2.3770694732666016,-32.88783818646207,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Boa_Esperanca,2021-12-31T00:00:00,1.570339108544351,2.364518404006958,50.57374494091172,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Bocaiuva,2021-12-31T00:00:00,1.7407407407407405,1.5881253480911257,-8.76726723731831,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Bom_Jesus_da_Penha,2021-12-31T00:00:00,1.519900497512438,2.224105834960937,46.33233153098148,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Bom_Jesus_do_Amparo,2021-12-31T00:00:00,1.2,2.341289758682251,95.1074798901876,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Bom_Jesus_do_Galho,2021-12-31T00:00:00,1.079802955665025,1.6727685928344729,54.91424468311944,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Bom_Sucesso,2021-12-31T00:00:00,1.37989417989418,1.7029849290847778,23.41416855714072,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Bonfinopolis_de_Minas,2021-12-31T00:00:00,3.0,2.8284873962402344,-5.717086791992188,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Borda_da_Mata,2021-12-31T00:00:00,1.2,1.7750566005706787,47.9213833808899,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Botelhos,2021-12-31T00:00:00,1.26,1.7737528085708618,40.77403242625887,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Botumirim,2021-12-31T00:00:00,0.7241379310344828,0.9620065689086914,32.84852618262881,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Brazopolis,2021-12-31T00:00:00,1.200934579439252,1.1976971626281738,-0.269574785046983,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Bueno_Brandao,2021-12-31T00:00:00,1.2,1.707355260848999,42.27960507074992,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Buritis,2021-12-31T00:00:00,3.1195039458850062,1.8628947734832764,-40.28233957066622,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Buritizeiro,2021-12-31T00:00:00,3.0,1.9161627292633057,-36.12790902455647,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cabo_Verde,2021-12-31T00:00:00,1.32,1.8388034105300903,39.30328867652199,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cachoeira_de_Minas,2021-12-31T00:00:00,1.5602040816326532,1.5927002429962158,2.0828147898163074,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Caete,2021-12-31T00:00:00,1.222222222222222,1.5386245250701904,25.887461142106503,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Caiana,2021-12-31T00:00:00,0.9,1.495089054107666,66.12100601196289,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cajuri,2021-12-31T00:00:00,1.2602564102564102,2.35649037361145,86.98499404037958,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Caldas,2021-12-31T00:00:00,1.2,1.2934404611587524,7.786705096562708,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Camacho,2021-12-31T00:00:00,1.5,1.806726694107056,20.44844627380371,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cambuquira,2021-12-31T00:00:00,1.2,1.253636360168457,4.4696966807047565,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Campanha,2021-12-31T00:00:00,1.325757575757576,1.093522071838379,-17.51719229561943,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Campestre,2021-12-31T00:00:00,1.2899602385685882,1.473392367362976,14.219983167693169,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Campo_Belo,2021-12-31T00:00:00,1.5,1.409480333328247,-6.034644444783529,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Campo_do_Meio,2021-12-31T00:00:00,1.255813953488372,2.6200594902038574,108.63436681252938,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Campos_Altos,2021-12-31T00:00:00,1.2,1.3501970767974854,12.516423066457117,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Campos_Gerais,2021-12-31T00:00:00,1.589070422535211,2.320643901824951,46.03782619794685,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cana_Verde,2021-12-31T00:00:00,1.32,1.1853746175765991,-10.198892607833404,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Canaa,2021-12-31T00:00:00,1.2,2.040147542953491,70.01229524612428,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Candeias,2021-12-31T00:00:00,1.199963309484498,2.1594836711883545,79.96247502901275,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Caparao,2021-12-31T00:00:00,0.9,2.41720986366272,168.5788737403022,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Capela_Nova,2021-12-31T00:00:00,1.8000000000000005,1.944361686706543,8.020093705919038,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Capelinha,2021-12-31T00:00:00,1.4350318471337582,1.2390691041946411,-13.655637213245177,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Capetinga,2021-12-31T00:00:00,1.6399999999999997,2.1809701919555664,32.98598731436383,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Capitao_Eneas,2021-12-31T00:00:00,2.0,0.6692869663238525,-66.53565168380736,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Capitolio,2021-12-31T00:00:00,1.2,1.8110451698303225,50.92043081919353,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Caputira,2021-12-31T00:00:00,1.38008658008658,2.1401917934417725,55.076632460805975,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Carai,2021-12-31T00:00:00,1.218,0.9698643684387208,-20.372383543618987,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Caranaiba,2021-12-31T00:00:00,2.28,1.060678005218506,-53.47903485883746,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Carangola,2021-12-31T00:00:00,1.02,1.637049436569214,60.49504280090332,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Caratinga,2021-12-31T00:00:00,1.26,1.7303575277328491,37.32996251848009,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Careacu,2021-12-31T00:00:00,1.2,1.0218406915664673,-14.846609036127722,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Carmo_da_Cachoeira,2021-12-31T00:00:00,1.439980158730159,1.188937783241272,-17.43373851138809,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Carmo_da_Mata,2021-12-31T00:00:00,1.32,1.597682237625122,21.036533153418333,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Carmo_de_Minas,2021-12-31T00:00:00,1.3799999999999997,1.4715293645858765,6.632562651150494,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Carmo_do_Paranaiba,2021-12-31T00:00:00,1.541078066914498,1.6694095134735107,8.327381286786748,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Carmo_do_Rio_Claro,2021-12-31T00:00:00,1.643702081051479,2.5794167518615723,56.92726690541846,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Carmopolis_de_Minas,2021-12-31T00:00:00,1.98,1.815653204917908,-8.300343185964246,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Carrancas,2021-12-31T00:00:00,1.214285714285714,1.0016531944274902,-17.510913400089017,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Carvalhopolis,2021-12-31T00:00:00,1.14,1.46694016456604,28.67896180403861,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Casa_Grande,2021-12-31T00:00:00,1.3230769230769233,2.083456039428711,57.47051460798394,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cascalho_Rico,2021-12-31T00:00:00,1.9411764705882348,1.994957447052002,2.7705351511637613,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cassia,2021-12-31T00:00:00,1.314977578475336,2.0571129322052,56.43711085860039,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cataguases,2021-12-31T00:00:00,1.25,0.4009987711906433,-67.92009830474854,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Catas_Altas_da_Noruega,2021-12-31T00:00:00,1.0,0.8517856597900391,-14.821434020996094,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Catuji,2021-12-31T00:00:00,1.384615384615385,0.9089118242263794,-34.35636825031707,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Caxambu,2021-12-31T00:00:00,1.4387755102040822,0.7035189270973206,-51.10293981876781,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Chale,2021-12-31T00:00:00,1.26016713091922,1.6592003107070925,31.66509981075291,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Claraval,2021-12-31T00:00:00,1.050113378684807,1.3905633687973022,32.42030784703314,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Claudio,2021-12-31T00:00:00,1.800653594771242,1.805715680122376,0.2811248851990596,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Coimbra,2021-12-31T00:00:00,1.501182033096927,1.9384677410125728,29.12942589737296,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Conceicao_da_Aparecida,2021-12-31T00:00:00,1.62,1.9526716470718384,20.535286856286312,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Conceicao_da_Barra_de_Minas,2021-12-31T00:00:00,1.462068965517241,2.0442757606506348,39.82074778035006,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Conceicao_das_Pedras,2021-12-31T00:00:00,1.5,1.457521915435791,-2.8318723042805987,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Conceicao_de_Ipanema,2021-12-31T00:00:00,1.29,1.557161808013916,20.71021767549736,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Conceicao_do_Rio_Verde,2021-12-31T00:00:00,1.500115340253749,1.4500941038131714,-3.3344926952161167,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Conceicao_dos_Ouros,2021-12-31T00:00:00,1.26,1.4482426643371582,14.939893995012554,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Congonhal,2021-12-31T00:00:00,1.6215384615384625,1.5050829648971558,-7.181790589833889,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Congonhas_do_Norte,2021-12-31T00:00:00,0.7333333333333333,0.9539456963539124,30.083504048260785,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Conselheiro_Pena,2021-12-31T00:00:00,1.2898734177215188,1.4683632850646973,13.837781668411289,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Coqueiral,2021-12-31T00:00:00,1.5,1.96081018447876,30.72067896525065,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cordislandia,2021-12-31T00:00:00,1.319791666666667,1.1981350183486938,-9.217867591574912,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Coroaci,2021-12-31T00:00:00,1.5,1.8675744533538816,24.504963556925453,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Coromandel,2021-12-31T00:00:00,1.249939246658566,1.3531595468521118,8.25802537759194,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Corrego_Danta,2021-12-31T00:00:00,1.08029197080292,1.62266206741333,50.20588056461228,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Corrego_Fundo,2021-12-31T00:00:00,1.1984126984126982,2.7544894218444824,129.8448126837118,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Corrego_Novo,2021-12-31T00:00:00,1.8000000000000005,1.1677308082580566,-35.12606620788576,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cristais,2021-12-31T00:00:00,1.318776371308017,1.529857516288757,16.00583310204302,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cristina,2021-12-31T00:00:00,1.68,1.531669020652771,-8.82922496114458,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cruzeiro_da_Fortaleza,2021-12-31T00:00:00,1.800184162062615,1.609487533569336,-10.593173327043516,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cruzilia,2021-12-31T00:00:00,1.5027322404371577,1.1034448146820068,-26.57076324116096,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Cuparaque,2021-12-31T00:00:00,1.32,1.5632565021514893,18.428522890264333,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Datas,2021-12-31T00:00:00,1.0,3.6294569969177246,262.94569969177246,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Delfinopolis,2021-12-31T00:00:00,0.9,1.8382099866867063,104.24555407630072,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Desterro_de_Entre_Rios,2021-12-31T00:00:00,1.5,2.3944363594055176,59.62909062703451,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Diamantina,2021-12-31T00:00:00,2.9196787148594376,1.627150297164917,-44.26954277935841,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Divinesia,2021-12-31T00:00:00,2.1,1.541405200958252,-26.599752335321337,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Divino,2021-12-31T00:00:00,1.08,1.7027732133865356,57.66418642467922,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Divisa_Nova,2021-12-31T00:00:00,1.2601319509896318,1.3866719007492063,10.041801547861544,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Divisopolis,2021-12-31T00:00:00,0.9595505617977528,1.0426385402679443,8.6590516204298,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Dom_Cavati,2021-12-31T00:00:00,0.6000000000000001,1.0210624933242798,70.17708222071327,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Dom_Vicoso,2021-12-31T00:00:00,1.2,1.476901888847351,23.07515740394593,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Dores_do_Turvo,2021-12-31T00:00:00,1.5,1.2430243492126465,-17.131710052490234,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Doresopolis,2021-12-31T00:00:00,1.2,1.7703256607055664,47.52713839213054,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Durande,2021-12-31T00:00:00,1.32,2.3953747749328613,81.46778597976221,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Eloi_Mendes,2021-12-31T00:00:00,1.037885462555066,1.5555806159973145,49.87979619328965,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Entre_Folhas,2021-12-31T00:00:00,0.8400000000000001,1.2952605485916138,54.197684356144485,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Entre_Rios_de_Minas,2021-12-31T00:00:00,1.8000000000000005,2.275315761566162,26.4064311981201,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ervalia,2021-12-31T00:00:00,1.08,1.6687822341918943,54.516873536286525,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Esmeraldas,2021-12-31T00:00:00,1.7115384615384608,2.634953737258911,53.952353188161176,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Espera_Feliz,2021-12-31T00:00:00,0.78,2.1893601417541504,180.6871976607885,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Espirito_Santo_do_Dourado,2021-12-31T00:00:00,1.200854700854701,1.3066790103912354,8.812415811939156,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Estrela_do_Indaia,2021-12-31T00:00:00,1.8000000000000005,1.4623562097549438,-18.757988346947577,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Estrela_do_Sul,2021-12-31T00:00:00,1.8000000000000005,2.527641534805298,40.42452971140541,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Eugenopolis,2021-12-31T00:00:00,1.5,0.8957786560058594,-40.281422932942704,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Fama,2021-12-31T00:00:00,1.5,1.4300312995910645,-4.664580027262369,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Faria_Lemos,2021-12-31T00:00:00,0.7199999999999999,1.2346186637878418,71.47481441497806,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Felicio_dos_Santos,2021-12-31T00:00:00,3.542087542087541,2.841937065124512,-19.76660567091444,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ferros,2021-12-31T00:00:00,1.205128205128205,0.9055896401405334,-24.85532773301956,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Fervedouro,2021-12-31T00:00:00,1.15006090133983,1.32543683052063,15.249273232094543,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Formiga,2021-12-31T00:00:00,1.347576301615799,1.403311252593994,4.135940273761608,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Formoso,2021-12-31T00:00:00,3.0,2.8819196224212646,-3.936012585957845,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Fortaleza_de_Minas,2021-12-31T00:00:00,1.26,0.8638665676116943,-31.43916130065918,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Franciscopolis,2021-12-31T00:00:00,1.2,1.79408860206604,49.50738350550334,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Frei_Gaspar,2021-12-31T00:00:00,1.2,0.974665105342865,-18.777907888094585,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Grao_Mogol,2021-12-31T00:00:00,1.155555555555555,2.098781108856201,81.62528826640211,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Guape,2021-12-31T00:00:00,1.376842105263158,1.6664936542510986,21.037383145148585,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Guaraciaba,2021-12-31T00:00:00,2.4,1.1739022731781006,-51.08740528424581,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Guaranesia,2021-12-31T00:00:00,1.031014249790444,1.4839727878570557,43.93329560272097,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Guarani,2021-12-31T00:00:00,0.953846153846154,1.088106989860535,14.075732807959248,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Guarda-Mor,2021-12-31T00:00:00,1.7994350282485878,1.7698211669921875,-1.645731065112356,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Guaxupe,2021-12-31T00:00:00,1.02,1.44290030002594,41.46081372803332,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Guimarania,2021-12-31T00:00:00,1.541380188439012,1.43806254863739,-6.702930307301648,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Guiricema,2021-12-31T00:00:00,2.1,2.023336887359619,-3.650624411446712,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Heliodora,2021-12-31T00:00:00,1.2,1.333662509918213,11.138542493184412,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Iapu,2021-12-31T00:00:00,1.5578947368421048,1.2067806720733645,-22.53772713042592,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ibia,2021-12-31T00:00:00,1.2,1.1601266860961914,-3.3227761586507127,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ibiraci,2021-12-31T00:00:00,1.327034071867436,1.3981868028640747,5.361786295095704,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ibitiura_de_Minas,2021-12-31T00:00:00,1.9198795180722887,1.2573912143707275,-34.50676448523979,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ibituruna,2021-12-31T00:00:00,1.6000000000000003,1.8071906566619875,12.949416041374183,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ijaci,2021-12-31T00:00:00,1.2375,1.8990916013717647,53.46194758559718,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ilicinea,2021-12-31T00:00:00,1.560035211267606,1.6466257572174072,5.550550739136343,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Imbe_de_Minas,2021-12-31T00:00:00,1.2,1.5102993249893188,25.858277082443244,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Inconfidentes,2021-12-31T00:00:00,1.5,1.982197403907776,32.14649359385173,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Indaiabira,2021-12-31T00:00:00,1.984444444444444,2.10524582862854,6.087415776354237,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Indianopolis,2021-12-31T00:00:00,1.919956379498364,1.3432453870773315,-30.037713282408653,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ingai,2021-12-31T00:00:00,1.320075757575758,1.1295245885849,-14.43486617319556,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Inhapim,2021-12-31T00:00:00,1.2,1.5267019271850586,27.22516059875489,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Irai_de_Minas,2021-12-31T00:00:00,2.472300469483568,1.4434947967529297,-41.61329439643487,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Itabirinha,2021-12-31T00:00:00,0.9659090909090908,1.2972294092178345,34.30139766019934,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Itacambira,2021-12-31T00:00:00,0.5,0.4790939688682556,-4.181206226348877,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Itaipe,2021-12-31T00:00:00,0.7792792792792793,0.9488354325294496,21.75807284481952,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Itajuba,2021-12-31T00:00:00,1.181818181818182,1.397770881652832,18.272920755239603,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Itamarandiba,2021-12-31T00:00:00,1.632,1.7285826206207275,5.918052734113214,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Itamarati_de_Minas,2021-12-31T00:00:00,1.2,0.8586191534996033,-28.44840387503306,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Itambacuri,2021-12-31T00:00:00,0.8987341772151899,0.8258581161499023,-8.108744822757346,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Itamogi,2021-12-31T00:00:00,1.260064724919094,2.136916160583496,69.58780912787658,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Itanhomi,2021-12-31T00:00:00,0.9606060606060604,1.1829071044921875,23.14174904808263,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Itapecerica,2021-12-31T00:00:00,1.222784810126582,1.945540189743042,59.10732400590096,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ituiutaba,2021-12-31T00:00:00,2.25,0.7768748998641968,-65.47222667270236,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Itumirim,2021-12-31T00:00:00,1.2595155709342565,1.564411759376526,24.207417159290085,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Itutinga,2021-12-31T00:00:00,1.2,1.7156600952148438,42.97167460123698,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Jacui,2021-12-31T00:00:00,0.96,1.6278012990951538,69.56263532241188,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Jacutinga,2021-12-31T00:00:00,1.32014652014652,1.6519591808319092,25.134532843260622,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Jequeri,2021-12-31T00:00:00,1.5,2.2890193462371826,52.60128974914551,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Jequitinhonha,2021-12-31T00:00:00,1.8000000000000005,1.2357232570648191,-31.34870794084338,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Jesuania,2021-12-31T00:00:00,1.2,1.3461174964904783,12.176458040873214,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Joao_Pinheiro,2021-12-31T00:00:00,2.4,1.8351658582687376,-23.534755905469257,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Jose_Goncalves_de_Minas,2021-12-31T00:00:00,1.502673796791444,1.264383316040039,-15.85776508915044,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Juiz_de_Fora,2021-12-31T00:00:00,1.142857142857143,0.3949050903320312,-65.44580459594727,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Juruaia,2021-12-31T00:00:00,1.5,1.953285217285156,30.21901448567708,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ladainha,2021-12-31T00:00:00,0.7199999999999999,0.971500277519226,34.93059409989254,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Lagoa_Dourada,2021-12-31T00:00:00,1.2,2.682966947555542,123.58057896296184,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Lagoa_Formosa,2021-12-31T00:00:00,1.4830188679245278,1.896539092063904,27.883679235861248,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Lagoa_Grande,2021-12-31T00:00:00,0.6000000000000001,1.4762554168701172,146.04256947835285,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Lajinha,2021-12-31T00:00:00,1.260014255167498,2.0284926891326904,60.98966188783602,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Lambari,2021-12-31T00:00:00,1.199954863461973,1.3029325008392334,8.58179257511079,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Lamim,2021-12-31T00:00:00,1.2800000000000002,1.8737729787826536,46.3885139673948,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Lavras,2021-12-31T00:00:00,1.259900454447089,1.7555091381072998,39.33713031937192,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Luisburgo,2021-12-31T00:00:00,1.3799999999999997,2.175713539123535,57.66040138576346,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Luminarias,2021-12-31T00:00:00,1.380229885057471,0.8935691714286804,-35.259395474437696,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Machado,2021-12-31T00:00:00,1.444286871961102,1.5781652927398682,9.269517252966615,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Malacacheta,2021-12-31T00:00:00,1.8000000000000005,1.7657090425491333,-1.9050531917148312,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Manhuacu,2021-12-31T00:00:00,0.9,1.8347163200378416,103.85736889309354,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Manhumirim,2021-12-31T00:00:00,1.2,1.4467039108276367,20.5586592356364,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Mantena,2021-12-31T00:00:00,0.7289999999999999,0.3069785535335541,-57.89045904889518,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Mar_de_Espanha,2021-12-31T00:00:00,1.4199999999999997,1.219895601272583,-14.091859065311038,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Maria_da_Fe,2021-12-31T00:00:00,1.444444444444444,1.4147077798843384,-2.058692161853465,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Martins_Soares,2021-12-31T00:00:00,1.2,2.104874849319458,75.40623744328818,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Mata_Verde,2021-12-31T00:00:00,1.319277108433735,1.0462234020233154,-20.697221581794352,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Matipo,2021-12-31T00:00:00,1.07995337995338,2.1597564220428467,99.98607922650145,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Matutina,2021-12-31T00:00:00,1.502024291497976,1.8069478273391724,20.30083917864568,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Medeiros,2021-12-31T00:00:00,1.500161864681127,1.481332540512085,-1.2551528346605705,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Minas_Novas,2021-12-31T00:00:00,1.7848101265822778,0.8008759021759033,-55.12822959439973,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Miradouro,2021-12-31T00:00:00,1.2,1.2092208862304688,0.7684071858723995,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Mirai,2021-12-31T00:00:00,1.019512195121951,1.6144875288009644,58.35882459530993,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Moeda,2021-12-31T00:00:00,1.8000000000000005,1.237528681755066,-31.248406569163016,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Monsenhor_Paulo,2021-12-31T00:00:00,1.41,1.4065004587173462,-0.2481944172095,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Monte_Alegre_de_Minas,2021-12-31T00:00:00,2.765957446808511,1.7871780395507812,-35.38664010854868,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Monte_Belo,2021-12-31T00:00:00,1.56,1.661832571029663,6.527728912157886,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Monte_Carmelo,2021-12-31T00:00:00,1.8000000000000005,1.2257411479949951,-31.903269555833614,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Monte_Formoso,2021-12-31T00:00:00,0.55,1.3621816635131836,147.66939336603335,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Monte_Santo_de_Minas,2021-12-31T00:00:00,1.200018932222643,2.3520941734313965,96.004755447892,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Monte_Siao,2021-12-31T00:00:00,1.5,1.532764196395874,2.1842797597249346,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Muriae,2021-12-31T00:00:00,0.9,1.4203383922576904,57.81537691752116,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Mutum,2021-12-31T00:00:00,1.319934249850568,1.5110572576522827,14.479736988668346,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Muzambinho,2021-12-31T00:00:00,1.199937762564182,1.6415507793426514,36.80299350149407,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Natercia,2021-12-31T00:00:00,1.4399193548387097,1.3789528608322144,-4.234021426382202,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Nazareno,2021-12-31T00:00:00,1.5,1.8746764659881592,24.97843106587728,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Nepomuceno,2021-12-31T00:00:00,1.379962721342032,1.6304757595062256,18.15360910043761,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ninheira,2021-12-31T00:00:00,2.100246002460024,2.597872972488404,23.69374680135127,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Nova_Belem,2021-12-31T00:00:00,1.0,1.8571360111236568,85.71360111236572,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Nova_Era,2021-12-31T00:00:00,1.5,1.9080783128738403,27.205220858256023,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Nova_Ponte,2021-12-31T00:00:00,2.5482352941176467,1.0639686584472656,-58.24684396675088,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Nova_Resende,2021-12-31T00:00:00,1.3800031392246113,1.8784029483795168,36.11584604328824,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Novo_Cruzeiro,2021-12-31T00:00:00,1.226392251815981,1.1362605094909668,-7.349340489680335,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Novorizonte,2021-12-31T00:00:00,1.307692307692308,1.1784077882766724,-9.886463249430951,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Olimpio_Noronha,2021-12-31T00:00:00,1.20026525198939,1.27728533744812,6.416922037114095,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Oliveira,2021-12-31T00:00:00,1.537805840568272,2.048256158828736,33.193417842127225,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Orizania,2021-12-31T00:00:00,1.08,2.3343193531036377,116.1406808429294,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ouro_Fino,2021-12-31T00:00:00,1.2,1.614474892616272,34.53957438468934,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ouro_Verde_de_Minas,2021-12-31T00:00:00,1.942857142857143,1.596506118774414,-17.826890945434577,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Padre_Paraiso,2021-12-31T00:00:00,0.4787878787878789,0.5796094536781311,21.057670704926096,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Paracatu,2021-12-31T00:00:00,2.4,2.024066925048828,-15.66387812296549,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Paraguacu,2021-12-31T00:00:00,0.9712280701754386,1.6026668548583984,65.01447024372962,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Paraisopolis,2021-12-31T00:00:00,1.2,1.065348505973816,-11.220957835515335,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Passa_Tempo,2021-12-31T00:00:00,1.511627906976744,1.572322130203247,4.0151563057532815,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Passos,2021-12-31T00:00:00,0.99,1.5973069667816162,61.34413805874911,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Patis,2021-12-31T00:00:00,2.111111111111112,3.124150276184082,47.9860657139828,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Patos_de_Minas,2021-12-31T00:00:00,1.7224109589041097,1.46191668510437,-15.12381655801122,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Patrocinio,2021-12-31T00:00:00,1.4369951534733445,1.3845624923706057,-3.648770907543038,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Paula_Candido,2021-12-31T00:00:00,1.5,1.5439352989196775,2.929019927978516,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pecanha,2021-12-31T00:00:00,1.807692307692308,1.9378340244293213,7.199329010983703,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pedra_Azul,2021-12-31T00:00:00,1.2,1.2425144910812378,3.54287425676982,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pedra_Bonita,2021-12-31T00:00:00,1.08,2.4880142211914062,130.37168714735242,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pedra_Dourada,2021-12-31T00:00:00,0.96,1.4365800619125366,49.643756449222586,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pedra_do_Anta,2021-12-31T00:00:00,0.9,1.5408754348754885,71.20838165283203,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pedralva,2021-12-31T00:00:00,1.5,1.4259287118911743,-4.938085873921713,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pedrinopolis,2021-12-31T00:00:00,1.514285714285714,0.312631219625473,-79.35454210020461,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Perdizes,2021-12-31T00:00:00,1.261308677098151,1.0303633213043213,-18.309979150001386,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Perdoes,2021-12-31T00:00:00,1.44017094017094,1.573258876800537,9.241120822351853,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Piedade_de_Caratinga,2021-12-31T00:00:00,1.2,1.749112248420715,45.759354035059616,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pimenta,2021-12-31T00:00:00,1.3502325581395351,2.261715888977051,67.50565488462482,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Piracema,2021-12-31T00:00:00,1.2,1.314791202545166,9.565933545430504,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Piranga,2021-12-31T00:00:00,2.1,2.6684436798095703,27.06874665759858,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pirangucu,2021-12-31T00:00:00,1.333333333333333,1.068967342376709,-19.82744932174681,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Piranguinho,2021-12-31T00:00:00,1.380549682875264,1.4074225425720217,1.946533328723788,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pirapora,2021-12-31T00:00:00,3.0,2.222315788269043,-25.922807057698567,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Piumhi,2021-12-31T00:00:00,1.5,1.9211562871932983,28.077085812886555,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Poco_Fundo,2021-12-31T00:00:00,0.9601760412194076,1.1413507461547852,18.8689049880154,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pocos_de_Caldas,2021-12-31T00:00:00,1.4199999999999997,1.124575972557068,-20.80450897485436,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pocrane,2021-12-31T00:00:00,1.3228346456692908,1.3995009660720823,5.795608744734855,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ponte_Nova,2021-12-31T00:00:00,1.2,1.716630935668945,43.05257797241212,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ponto_dos_Volantes,2021-12-31T00:00:00,0.5375,0.5679044723510742,5.65664601880451,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Porto_Firme,2021-12-31T00:00:00,1.319607843137255,1.2494431734085083,-5.317084927438464,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pote,2021-12-31T00:00:00,0.6000000000000001,0.6514284014701843,8.571400245030706,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pouso_Alegre,2021-12-31T00:00:00,1.2,1.498042106628418,24.836842219034835,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pouso_Alto,2021-12-31T00:00:00,1.5047619047619047,1.5443060398101809,2.6279330253601083,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pratapolis,2021-12-31T00:00:00,0.9602272727272728,1.742978572845459,81.51729516023714,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Pratinha,2021-12-31T00:00:00,1.35,1.948800563812256,44.35559731942635,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Presidente_Bernardes,2021-12-31T00:00:00,1.56,1.29276442527771,-17.13048555912116,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Presidente_Kubitschek,2021-12-31T00:00:00,0.7368421052631579,1.87073278427124,153.88516357966833,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Presidente_Olegario,2021-12-31T00:00:00,1.637164750957854,1.7226310968399048,5.220387614138842,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Quartel_Geral,2021-12-31T00:00:00,2.4571428571428573,3.2433671951293945,31.99750212735908,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Raul_Soares,2021-12-31T00:00:00,1.320079522862823,1.3567849397659302,2.780545888895013,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Reduto,2021-12-31T00:00:00,1.2,2.0900206565856934,74.16838804880778,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ribeirao_Vermelho,2021-12-31T00:00:00,1.258899676375405,1.6373826265335083,30.06458395857426,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Rio_Paranaiba,2021-12-31T00:00:00,1.080031384856807,1.0957071781158447,1.4514201604535784,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Rio_Pardo_de_Minas,2021-12-31T00:00:00,2.764006791171477,2.7602458000183105,-0.1360702573227898,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Rio_Vermelho,2021-12-31T00:00:00,0.7777777777777777,0.8803417086601257,13.186791113444752,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ritapolis,2021-12-31T00:00:00,1.5,1.970663070678711,31.377538045247395,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Romaria,2021-12-31T00:00:00,2.052631578947369,1.574199676513672,-23.308220887795493,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Rosario_da_Limeira,2021-12-31T00:00:00,0.9,1.2418328523635864,37.98142804039849,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sabinopolis,2021-12-31T00:00:00,1.2,2.2331349849700928,86.09458208084108,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sacramento,2021-12-31T00:00:00,1.25645342312009,1.369067907333374,8.962885702013054,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santa_Barbara,2021-12-31T00:00:00,0.9333333333333332,1.230512619018555,31.84063775198804,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santa_Barbara_do_Leste,2021-12-31T00:00:00,1.319917440660475,1.5935310125350952,20.72959743131407,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santa_Barbara_do_Monte_Verde,2021-12-31T00:00:00,1.4,0.140100747346878,-89.99280376093728,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santa_Margarida,2021-12-31T00:00:00,0.9,2.2660818099975586,151.78686777750653,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santa_Maria_do_Suacui,2021-12-31T00:00:00,0.8,0.7102415561676025,-11.219805479049688,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santa_Rita_de_Caldas,2021-12-31T00:00:00,1.682051282051282,1.6649682521820068,-1.0156069586916678,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santa_Rita_de_Minas,2021-12-31T00:00:00,1.2,1.3681344985961914,14.011208216349289,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santa_Rita_do_Itueto,2021-12-31T00:00:00,1.3799999999999997,1.6534006595611572,19.811641997185333,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santa_Rita_do_Sapucai,2021-12-31T00:00:00,1.5,1.6154506206512451,7.696708043416341,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santa_Rosa_da_Serra,2021-12-31T00:00:00,1.5,1.6140766143798828,7.60510762532552,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santana_da_Vargem,2021-12-31T00:00:00,1.44,2.103579521179199,46.081911192999954,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santana_do_Jacare,2021-12-31T00:00:00,1.2,1.1445529460906982,-4.620587825775143,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santana_do_Manhuacu,2021-12-31T00:00:00,1.32,1.731403112411499,31.166902455416583,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santo_Antonio_do_Amparo,2021-12-31T00:00:00,1.3799999999999997,1.6672084331512451,20.81220530081489,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santo_Antonio_do_Grama,2021-12-31T00:00:00,1.9130434782608696,4.679638862609863,144.61748600006098,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Santo_Antonio_do_Retiro,2021-12-31T00:00:00,1.2,1.1608736515045166,-3.26052904129028,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Bento_Abade,2021-12-31T00:00:00,1.32,0.930777668952942,-29.486540230837736,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Domingos_das_Dores,2021-12-31T00:00:00,1.2,1.6796181201934814,39.96817668279012,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Domingos_do_Prata,2021-12-31T00:00:00,0.903846153846154,1.0189367532730105,12.73342802169475,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Francisco_de_Paula,2021-12-31T00:00:00,1.3200867052023115,1.8351320028305047,39.01602035672799,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Francisco_do_Gloria,2021-12-31T00:00:00,0.78,1.9247804880142207,146.76672923259244,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Geraldo,2021-12-31T00:00:00,1.5,1.7528603076934814,16.857353846232094,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Goncalo_do_Abaete,2021-12-31T00:00:00,1.67887323943662,1.798222541809082,7.108893010440276,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Goncalo_do_Rio_Preto,2021-12-31T00:00:00,3.36,2.378045082092285,-29.22484874725341,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Goncalo_do_Sapucai,2021-12-31T00:00:00,1.62,1.3972426652908323,-13.750452759825157,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Gotardo,2021-12-31T00:00:00,1.26027397260274,1.070610523223877,-15.04938239636631,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Joao_Batista_do_Gloria,2021-12-31T00:00:00,1.110749185667752,1.611985445022583,45.12596235247307,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Joao_da_Mata,2021-12-31T00:00:00,0.8995327102803738,1.1634505987167358,29.339443182016343,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Joao_del_Rei,2021-12-31T00:00:00,1.296875,1.9566538333892824,50.87451245411333,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Joao_do_Manhuacu,2021-12-31T00:00:00,0.9,1.9456210136413568,116.18011262681748,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Joao_do_Manteninha,2021-12-31T00:00:00,0.7,0.9256513118743896,32.23590169634139,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Joao_do_Paraiso,2021-12-31T00:00:00,3.0614754098360666,0.9769675731658936,-68.08834165294807,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Jose_da_Barra,2021-12-31T00:00:00,1.682068965517241,2.181640625,29.69983215457158,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Jose_do_Alegre,2021-12-31T00:00:00,1.7823529411764714,1.458942174911499,-18.145158503315272,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Jose_do_Mantimento,2021-12-31T00:00:00,1.500917431192661,1.630322813987732,8.621752276688712,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Lourenco,2021-12-31T00:00:00,1.5087719298245608,1.5886688232421875,5.295491773028751,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Miguel_do_Anta,2021-12-31T00:00:00,1.2603053435114495,1.9372538328170776,53.713053966709445,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Pedro_da_Uniao,2021-12-31T00:00:00,1.479945054945055,2.132933616638184,44.12248681201017,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Roque_de_Minas,2021-12-31T00:00:00,1.2,1.6955809593200684,41.29841327667237,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Sebastiao_da_Bela_Vista,2021-12-31T00:00:00,1.2,1.4383448362350464,19.862069686253868,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Sebastiao_da_Vargem_Alegre,2021-12-31T00:00:00,1.020238095238095,1.5437649488449097,51.314184017470765,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Sebastiao_do_Anta,2021-12-31T00:00:00,1.5,1.6653777360916138,11.025182406107586,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Sebastiao_do_Maranhao,2021-12-31T00:00:00,0.9655172413793104,0.8297897577285767,-14.057489378111706,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Sebastiao_do_Paraiso,2021-12-31T00:00:00,1.14450771643146,1.7161908149719238,49.95013055245744,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Tiago,2021-12-31T00:00:00,1.5,1.679188251495361,11.94588343302409,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Tomas_de_Aquino,2021-12-31T00:00:00,1.2,1.8532462120056152,54.43718433380128,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sao_Tome_das_Letras,2021-12-31T00:00:00,1.2,1.3270514011383057,10.587616761525476,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Senador_Firmino,2021-12-31T00:00:00,1.563636363636364,1.3303920030593872,-14.91679050201595,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Senador_Jose_Bento,2021-12-31T00:00:00,1.32,1.169440984725952,-11.405986005609693,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Senador_Modestino_Goncalves,2021-12-31T00:00:00,2.7000000000000006,3.112034797668457,15.26054806179468,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Senhora_de_Oliveira,2021-12-31T00:00:00,1.62037037037037,1.9198238849639893,18.480559757777648,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Senhora_dos_Remedios,2021-12-31T00:00:00,1.5,1.8875885009765625,25.8392333984375,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Sericita,2021-12-31T00:00:00,0.9,3.986384868621826,342.9316520690918,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Serra_do_Salitre,2021-12-31T00:00:00,1.4676384839650147,0.9562112092971802,-34.84695177017625,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Serrania,2021-12-31T00:00:00,1.08,1.429567813873291,32.36739017345286,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Setubinha,2021-12-31T00:00:00,0.9329787234042556,0.6752502918243408,-27.624256064437823,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Silvianopolis,2021-12-31T00:00:00,0.9601265822784812,1.0541926622390747,9.797258163331431,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Simonesia,2021-12-31T00:00:00,1.08,1.69356369972229,56.81145367798981,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Soledade_de_Minas,2021-12-31T00:00:00,1.7204819277108432,1.3986505270004272,-18.70588673596956,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Taiobeiras,2021-12-31T00:00:00,3.49869451697128,2.4347033500671387,-30.411090815245228,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Tapira,2021-12-31T00:00:00,0.6000000000000001,2.060363531112671,243.39392185211176,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Tapirai,2021-12-31T00:00:00,1.396563119629874,1.715559720993042,22.841545568503232,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Teixeiras,2021-12-31T00:00:00,1.32,1.6677541732788086,26.345013127182465,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Teofilo_Otoni,2021-12-31T00:00:00,0.6800000000000002,0.8694674968719482,27.862867187051183,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Tiros,2021-12-31T00:00:00,1.2,1.2406797409057615,3.389978408813481,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Tocos_do_Moji,2021-12-31T00:00:00,1.259776536312849,1.3081982135772705,3.8436719424973154,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Tombos,2021-12-31T00:00:00,0.8497959183673469,1.0777405500411987,26.82345569649073,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Tres_Coracoes,2021-12-31T00:00:00,1.5,0.7944906949996948,-47.03395366668701,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Tres_Pontas,2021-12-31T00:00:00,1.3500296384113808,1.8951659202575684,40.37957881337074,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Tupaciguara,2021-12-31T00:00:00,1.887700534759358,2.3143277168273926,22.600363469326474,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Turmalina,2021-12-31T00:00:00,1.2797783933518008,1.5287902355194092,19.4574188360404,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Turvolandia,2021-12-31T00:00:00,1.3797385620915028,1.2189149856567385,-11.656090570591656,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Ubaporanga,2021-12-31T00:00:00,1.319867549668874,1.3315517902374268,0.885258567913423,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Uberaba,2021-12-31T00:00:00,2.0302325581395344,2.530532121658325,24.642475637237123,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Uberlandia,2021-12-31T00:00:00,1.77962962962963,1.5721293687820437,-11.659744105899756,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Unai,2021-12-31T00:00:00,2.639892904953146,2.337622880935669,-11.450086609586982,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Urucuia,2021-12-31T00:00:00,1.799276672694394,2.066614151000977,14.858052814426143,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Vargem_Bonita,2021-12-31T00:00:00,1.519565217391304,2.5475172996521,67.64777651501662,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Vargem_Grande_do_Rio_Pardo,2021-12-31T00:00:00,1.644444444444444,1.4716012477874756,-10.510734931842672,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Varginha,2021-12-31T00:00:00,1.2,1.3769066333770752,14.742219448089603,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Varjao_de_Minas,2021-12-31T00:00:00,2.390254805543138,2.4364383220672607,1.932158714502757,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Varzea_da_Palma,2021-12-31T00:00:00,1.68,2.7759180068969727,65.23321469624838,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Vermelho_Novo,2021-12-31T00:00:00,0.96,1.3434150218963623,39.9390647808711,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Vicosa,2021-12-31T00:00:00,0.9006711409395973,1.6768124103546145,86.17365807961068,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Vieiras,2021-12-31T00:00:00,0.78,1.549640417098999,98.6718483460255,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Virginia,2021-12-31T00:00:00,1.433333333333333,1.4863510131835938,3.698907896529827,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Virginopolis,2021-12-31T00:00:00,1.202380952380952,1.8055274486541748,50.16267889797101,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2021,Visconde_do_Rio_Branco,2021-12-31T00:00:00,1.25,0.7285169363021851,-41.7186450958252,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:11
V38_2022,Abadia_dos_Dourados,2021-12-31T00:00:00,1.8000000000000005,1.0760914087295532,-40.21714395946928,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Abre_Campo,2021-12-31T00:00:00,1.2,1.4856181144714355,23.8015095392863,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Acucena,2021-12-31T00:00:00,0.9,0.9730406999588012,8.115633328755694,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Agua_Boa,2021-12-31T00:00:00,0.6171428571428572,1.14785635471344,85.99524266189998,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Aguanil,2021-12-31T00:00:00,1.7382352941176469,1.5205076932907104,-12.525784142327986,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Aguas_Vermelhas,2021-12-31T00:00:00,3.0,3.363939046859741,12.131301561991377,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Aimores,2021-12-31T00:00:00,1.634328358208955,2.3954100608825684,46.56846947865946,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Aiuruoca,2021-12-31T00:00:00,1.2,1.171208739280701,-2.399271726608273,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Albertina,2021-12-31T00:00:00,1.56,1.576107144355774,1.0325092535752485,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Alfenas,2021-12-31T00:00:00,1.6209774981853378,1.9625747203826904,21.073532641863697,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Almenara,2021-12-31T00:00:00,0.78,0.6489949822425842,-16.795515097104587,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Alpinopolis,2021-12-31T00:00:00,1.67993145468393,2.2295079231262207,32.71421979212184,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Alterosa,2021-12-31T00:00:00,1.08,1.697333574295044,57.16051613842998,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Alto_Caparao,2021-12-31T00:00:00,1.08,1.3624660968780518,26.15426822944923,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Alto_Jequitiba,2021-12-31T00:00:00,0.9,1.5200152397155762,68.89058219061958,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Alvarenga,2021-12-31T00:00:00,0.6304878048780488,0.772674024105072,22.55177945186829,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Amparo_do_Serra,2021-12-31T00:00:00,1.2,1.412654161453247,17.721180121103927,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Andradas,2021-12-31T00:00:00,1.26,2.040089607238769,61.91187359037853,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Andrelandia,2021-12-31T00:00:00,1.4,1.5697758197784424,12.12684426988875,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Angelandia,2021-12-31T00:00:00,1.5133433283358322,0.9315576553344728,-38.44373329620634,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Antonio_Dias,2021-12-31T00:00:00,1.5,1.0899449586868286,-27.337002754211422,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Antonio_Prado_de_Minas,2021-12-31T00:00:00,0.9,1.0841225385665894,20.458059840732147,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Araguari,2021-12-31T00:00:00,1.8600340136054423,1.3228987455368042,-28.87771213535332,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Araponga,2021-12-31T00:00:00,1.2,1.4342169761657717,19.51808134714763,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Arapua,2021-12-31T00:00:00,1.32,1.1492528915405271,-12.935387004505507,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Araxa,2021-12-31T00:00:00,1.250440917107584,1.2891199588775637,3.0932322543834,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Arceburgo,2021-12-31T00:00:00,1.354903268845897,1.7537083625793457,29.43421149711667,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Areado,2021-12-31T00:00:00,1.5228426395939092,1.805734395980835,18.57655866940812,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Aricanduva,2021-12-31T00:00:00,0.8394736842105264,1.230983018875122,46.63747560267911,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Astolfo_Dutra,2021-12-31T00:00:00,1.75,0.5353279709815979,-69.40983022962298,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ataleia,2021-12-31T00:00:00,0.6266666666666667,0.6546999216079712,4.473391745952844,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Baependi,2021-12-31T00:00:00,1.079646017699115,1.3608119487762451,26.04241820632436,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Bambui,2021-12-31T00:00:00,1.439910025706941,1.4856528043746948,3.176780343986828,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Bandeira,2021-12-31T00:00:00,0.96,0.9341543912887572,-2.692250907421097,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Bandeira_do_Sul,2021-12-31T00:00:00,1.8011695906432754,1.2602815628051758,-30.0298223247776,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Berilo,2021-12-31T00:00:00,1.8017241379310345,0.689716100692749,-61.719106373034016,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Berizal,2021-12-31T00:00:00,3.541935483870968,2.872275352478028,-18.906615731494675,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Boa_Esperanca,2021-12-31T00:00:00,1.570339108544351,1.808521509170532,15.167577457009774,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Bocaiuva,2021-12-31T00:00:00,1.7407407407407405,1.6825493574142456,-3.342909254926302,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Bom_Jesus_da_Penha,2021-12-31T00:00:00,1.519900497512438,1.9716084003448489,29.719570693719984,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Bom_Jesus_do_Amparo,2021-12-31T00:00:00,1.2,1.2668468952178955,5.5705746014912965,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Bom_Jesus_do_Galho,2021-12-31T00:00:00,1.079802955665025,1.1388700008392334,5.470168873341374,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Bom_Sucesso,2021-12-31T00:00:00,1.37989417989418,1.6041381359100342,16.25080816219189,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Bonfinopolis_de_Minas,2021-12-31T00:00:00,3.0,2.400456666946411,-19.984777768452965,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Borda_da_Mata,2021-12-31T00:00:00,1.2,1.541407823562622,28.45065196355184,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Botelhos,2021-12-31T00:00:00,1.26,1.3517823219299316,7.284311264280288,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Botumirim,2021-12-31T00:00:00,0.7241379310344828,0.8585308790206909,18.559026150476367,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Brazopolis,2021-12-31T00:00:00,1.200934579439252,1.1565325260162354,-3.697291607986608,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Bueno_Brandao,2021-12-31T00:00:00,1.2,1.8379020690917969,53.15850575764974,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Buritis,2021-12-31T00:00:00,3.1195039458850062,2.194707155227661,-29.64563618767853,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Buritizeiro,2021-12-31T00:00:00,3.0,1.8464014530181885,-38.45328489939372,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cabo_Verde,2021-12-31T00:00:00,1.32,2.276453256607056,72.45858004598907,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cachoeira_de_Minas,2021-12-31T00:00:00,1.5602040816326532,1.23186194896698,-21.04481949067101,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Caete,2021-12-31T00:00:00,1.222222222222222,1.039491057395935,-14.950731667605304,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Caiana,2021-12-31T00:00:00,0.9,1.2952876091003418,43.92084545559353,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cajuri,2021-12-31T00:00:00,1.2602564102564102,1.3485177755355835,7.003445057757392,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Caldas,2021-12-31T00:00:00,1.2,1.6097724437713623,34.14770364761353,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Camacho,2021-12-31T00:00:00,1.5,1.51350736618042,0.9004910786946615,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cambuquira,2021-12-31T00:00:00,1.2,1.1435050964355469,-4.70790863037109,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Campanha,2021-12-31T00:00:00,1.325757575757576,1.019376516342163,-23.10988562447685,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Campestre,2021-12-31T00:00:00,1.2899602385685882,1.6706974506378174,29.51542231190912,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Campo_Belo,2021-12-31T00:00:00,1.5,1.223720908164978,-18.4186061223348,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Campo_do_Meio,2021-12-31T00:00:00,1.255813953488372,1.6163556575775146,28.709802362653942,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Campos_Altos,2021-12-31T00:00:00,1.2,1.582687258720398,31.890604893366504,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Campos_Gerais,2021-12-31T00:00:00,1.589070422535211,1.8083746433258057,13.800786779525827,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cana_Verde,2021-12-31T00:00:00,1.32,1.307809591293335,-0.9235158111109926,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Canaa,2021-12-31T00:00:00,1.2,1.4568727016448977,21.406058470408126,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Candeias,2021-12-31T00:00:00,1.199963309484498,1.703656554222107,41.97572048715345,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Caparao,2021-12-31T00:00:00,0.9,1.4451501369476318,60.57223743862576,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Capela_Nova,2021-12-31T00:00:00,1.8000000000000005,1.5956305265426636,-11.353859636518704,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Capelinha,2021-12-31T00:00:00,1.4350318471337582,1.1207846403121948,-21.89827406612758,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Capetinga,2021-12-31T00:00:00,1.6399999999999997,1.8503504991531368,12.826249948362047,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Capitao_Eneas,2021-12-31T00:00:00,2.0,1.9524505138397217,-2.3774743080138947,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Capitolio,2021-12-31T00:00:00,1.2,1.803025841712952,50.25215347607931,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Caputira,2021-12-31T00:00:00,1.38008658008658,1.486011266708374,7.675220391980682,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Carai,2021-12-31T00:00:00,1.218,1.3171868324279783,8.143418097535186,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Caranaiba,2021-12-31T00:00:00,2.28,0.9625380635261536,-57.783418266396765,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Carangola,2021-12-31T00:00:00,1.02,1.3679449558258057,34.11225057115742,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Caratinga,2021-12-31T00:00:00,1.26,1.47468364238739,17.038384316459535,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Careacu,2021-12-31T00:00:00,1.2,1.1489678621292114,-4.252678155899044,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Carmo_da_Cachoeira,2021-12-31T00:00:00,1.439980158730159,1.1864407062530518,-17.607149024934486,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Carmo_da_Mata,2021-12-31T00:00:00,1.32,1.220231533050537,-7.558217193141132,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Carmo_de_Minas,2021-12-31T00:00:00,1.3799999999999997,1.5095118284225464,9.3849151030831,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Carmo_do_Paranaiba,2021-12-31T00:00:00,1.541078066914498,1.7463083267211914,13.317317546255111,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Carmo_do_Rio_Claro,2021-12-31T00:00:00,1.643702081051479,2.135777950286865,29.93704728539398,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Carmopolis_de_Minas,2021-12-31T00:00:00,1.98,1.0629684925079346,-46.31472260060936,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Carrancas,2021-12-31T00:00:00,1.214285714285714,0.8953705430030823,-26.263602340922613,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Carvalhopolis,2021-12-31T00:00:00,1.14,1.545071363449097,35.53257574114884,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Casa_Grande,2021-12-31T00:00:00,1.3230769230769233,1.1415290832519531,-13.72163905653844,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cascalho_Rico,2021-12-31T00:00:00,1.9411764705882348,1.7883453369140625,-7.873119007457364,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cassia,2021-12-31T00:00:00,1.314977578475336,1.6372079849243164,24.50463123657164,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cataguases,2021-12-31T00:00:00,1.25,0.2129830867052078,-82.96135306358337,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Catas_Altas_da_Noruega,2021-12-31T00:00:00,1.0,0.7883211374282837,-21.16788625717163,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Catuji,2021-12-31T00:00:00,1.384615384615385,0.7988443374633789,-42.30568673875599,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Caxambu,2021-12-31T00:00:00,1.4387755102040822,1.057185173034668,-26.521881590498285,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Chale,2021-12-31T00:00:00,1.26016713091922,1.30899977684021,3.875092812916759,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Claraval,2021-12-31T00:00:00,1.050113378684807,1.5890662670135498,51.32330463247153,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Claudio,2021-12-31T00:00:00,1.800653594771242,0.6421084403991699,-64.34025721195174,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Coimbra,2021-12-31T00:00:00,1.501182033096927,1.457581639289856,-2.9044041858883536,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Conceicao_da_Aparecida,2021-12-31T00:00:00,1.62,2.082423210144043,28.544642601484128,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Conceicao_da_Barra_de_Minas,2021-12-31T00:00:00,1.462068965517241,1.7953016757965088,22.79185990117634,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Conceicao_das_Pedras,2021-12-31T00:00:00,1.5,1.5303713083267212,2.024753888448079,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Conceicao_de_Ipanema,2021-12-31T00:00:00,1.29,1.305855393409729,1.229100264320075,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Conceicao_do_Rio_Verde,2021-12-31T00:00:00,1.500115340253749,1.4724470376968384,-1.8444116805198785,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Conceicao_dos_Ouros,2021-12-31T00:00:00,1.26,1.4173548221588137,12.48847794911218,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Congonhal,2021-12-31T00:00:00,1.6215384615384625,1.3384472131729126,-17.458188940949448,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Congonhas_do_Norte,2021-12-31T00:00:00,0.7333333333333333,1.097492814064026,49.65811100873081,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Conselheiro_Pena,2021-12-31T00:00:00,1.2898734177215188,1.2227579355239868,-5.203261132095215,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Coqueiral,2021-12-31T00:00:00,1.5,1.641834735870361,9.45564905802409,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cordislandia,2021-12-31T00:00:00,1.319791666666667,1.2888798713684082,-2.3421723351482524,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Coroaci,2021-12-31T00:00:00,1.5,1.442958950996399,-3.802736600240072,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Coromandel,2021-12-31T00:00:00,1.249939246658566,1.322458028793335,5.801784553019824,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Corrego_Danta,2021-12-31T00:00:00,1.08029197080292,1.4768017530441284,36.703946058814566,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Corrego_Fundo,2021-12-31T00:00:00,1.1984126984126982,1.03936505317688,-13.271525364048417,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Corrego_Novo,2021-12-31T00:00:00,1.8000000000000005,0.8677773475646973,-51.79014735751682,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cristais,2021-12-31T00:00:00,1.318776371308017,1.5007970333099363,13.802238648041891,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cristina,2021-12-31T00:00:00,1.68,1.7004367113113403,1.2164709113893093,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cruzeiro_da_Fortaleza,2021-12-31T00:00:00,1.800184162062615,1.5499498844146729,-13.90048212407493,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cruzilia,2021-12-31T00:00:00,1.5027322404371577,1.2298799753189087,-18.15707800605076,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cuparaque,2021-12-31T00:00:00,1.32,0.5412195920944214,-58.99851575042262,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Datas,2021-12-31T00:00:00,1.0,1.6228054761886597,62.28054761886597,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Delfinopolis,2021-12-31T00:00:00,0.9,1.5047602653503418,67.19558503892686,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Desterro_de_Entre_Rios,2021-12-31T00:00:00,1.5,1.8807148933410645,25.380992889404297,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Diamantina,2021-12-31T00:00:00,2.9196787148594376,2.052483558654785,-29.701732310173107,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Divinesia,2021-12-31T00:00:00,2.1,1.2871134281158447,-38.70888437543597,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Divino,2021-12-31T00:00:00,1.08,1.4323549270629885,32.62545620953594,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Divisa_Nova,2021-12-31T00:00:00,1.2601319509896318,1.348726749420166,7.030596943515096,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Divisopolis,2021-12-31T00:00:00,0.9595505617977528,0.8697465062141418,-9.358970663865776,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Dom_Cavati,2021-12-31T00:00:00,0.6000000000000001,0.5353367328643799,-10.777211189270034,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Dom_Vicoso,2021-12-31T00:00:00,1.2,1.293284893035889,7.77374108632406,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Dores_do_Turvo,2021-12-31T00:00:00,1.5,1.2370154857635498,-17.53230094909668,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Doresopolis,2021-12-31T00:00:00,1.2,1.4042456150054932,17.020467917124435,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Durande,2021-12-31T00:00:00,1.32,1.9909272193908687,50.827819650823415,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Eloi_Mendes,2021-12-31T00:00:00,1.037885462555066,1.5281314849853516,47.235079410727856,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Entre_Folhas,2021-12-31T00:00:00,0.8400000000000001,1.016926646232605,21.06269598007201,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Entre_Rios_de_Minas,2021-12-31T00:00:00,1.8000000000000005,1.617143154144287,-10.15871365865073,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ervalia,2021-12-31T00:00:00,1.08,1.38023579120636,27.799610296885163,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Esmeraldas,2021-12-31T00:00:00,1.7115384615384608,1.7538414001464844,2.4716323681092445,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Espera_Feliz,2021-12-31T00:00:00,0.78,1.4304004907608032,83.38467830266707,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Espirito_Santo_do_Dourado,2021-12-31T00:00:00,1.200854700854701,1.158348560333252,-3.5396572533875736,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Estrela_do_Indaia,2021-12-31T00:00:00,1.8000000000000005,1.31087327003479,-27.17370722028945,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Estrela_do_Sul,2021-12-31T00:00:00,1.8000000000000005,1.3461101055145264,-25.21610524919299,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Eugenopolis,2021-12-31T00:00:00,1.5,1.321817398071289,-11.87884012858073,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Fama,2021-12-31T00:00:00,1.5,1.6240885257720947,8.272568384806316,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Faria_Lemos,2021-12-31T00:00:00,0.7199999999999999,1.3083577156066897,81.716349389818,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Felicio_dos_Santos,2021-12-31T00:00:00,3.542087542087541,3.4900918006896973,-1.4679406079049184,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ferros,2021-12-31T00:00:00,1.205128205128205,0.9255173802375792,-23.2017492994349,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Fervedouro,2021-12-31T00:00:00,1.15006090133983,1.3736282587051392,19.439610294102813,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Formiga,2021-12-31T00:00:00,1.347576301615799,1.0104992389678955,-25.0135789894594,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Formoso,2021-12-31T00:00:00,3.0,2.573260545730591,-14.224648475646973,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Fortaleza_de_Minas,2021-12-31T00:00:00,1.26,1.2916655540466309,2.513139210050068,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Franciscopolis,2021-12-31T00:00:00,1.2,0.6637997627258301,-44.68335310618082,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Frei_Gaspar,2021-12-31T00:00:00,1.2,0.9418670535087584,-21.51107887427012,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Grao_Mogol,2021-12-31T00:00:00,1.155555555555555,0.8018341660499573,-30.610504861061354,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Guape,2021-12-31T00:00:00,1.376842105263158,1.744645357131958,26.713538935425067,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Guaraciaba,2021-12-31T00:00:00,2.4,1.1605846881866455,-51.64230465888977,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Guaranesia,2021-12-31T00:00:00,1.031014249790444,1.6904840469360352,63.963208780056135,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Guarani,2021-12-31T00:00:00,0.953846153846154,0.6374461054801941,-33.170972812560315,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Guarda-Mor,2021-12-31T00:00:00,1.7994350282485878,1.516144037246704,-15.74332979822085,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Guaxupe,2021-12-31T00:00:00,1.02,1.56109881401062,53.04890333437452,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Guimarania,2021-12-31T00:00:00,1.541380188439012,1.5526151657104492,0.7288907276546219,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Guiricema,2021-12-31T00:00:00,2.1,2.354054450988769,12.097830999465211,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Heliodora,2021-12-31T00:00:00,1.2,1.399205207824707,16.600433985392257,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Iapu,2021-12-31T00:00:00,1.5578947368421048,0.9383547306060792,-39.76777067055571,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ibia,2021-12-31T00:00:00,1.2,1.104341745376587,-7.971521218617754,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ibiraci,2021-12-31T00:00:00,1.327034071867436,1.7494937181472778,31.83487562496009,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ibitiura_de_Minas,2021-12-31T00:00:00,1.9198795180722887,1.8427655696868896,-4.016603524310111,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ibituruna,2021-12-31T00:00:00,1.6000000000000003,1.627025842666626,1.6891151666641038,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ijaci,2021-12-31T00:00:00,1.2375,1.5693678855895996,26.817606916331275,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ilicinea,2021-12-31T00:00:00,1.560035211267606,1.9557242393493648,25.36410878573968,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Imbe_de_Minas,2021-12-31T00:00:00,1.2,1.2598522901535034,4.987690846125289,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Inconfidentes,2021-12-31T00:00:00,1.5,2.327686786651612,55.17911911010742,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Indaiabira,2021-12-31T00:00:00,1.984444444444444,2.315079689025879,16.661350510822604,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Indianopolis,2021-12-31T00:00:00,1.919956379498364,1.4489150047302246,-24.533962323207074,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ingai,2021-12-31T00:00:00,1.320075757575758,1.1923705339431765,-9.674082938020536,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Inhapim,2021-12-31T00:00:00,1.2,1.5493910312652588,29.115919272104907,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Irai_de_Minas,2021-12-31T00:00:00,2.472300469483568,1.5336649417877195,-37.96607812366421,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Itabirinha,2021-12-31T00:00:00,0.9659090909090908,0.6291641592979431,-34.863004684448235,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Itacambira,2021-12-31T00:00:00,0.5,1.721684813499451,244.3369626998901,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Itaipe,2021-12-31T00:00:00,0.7792792792792793,0.7853674292564392,0.7812539277049115,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Itajuba,2021-12-31T00:00:00,1.181818181818182,1.405787467956543,18.95124728863053,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Itamarandiba,2021-12-31T00:00:00,1.632,1.5913910865783691,-2.488291263580316,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Itamarati_de_Minas,2021-12-31T00:00:00,1.2,1.1758283376693726,-2.01430519421895,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Itambacuri,2021-12-31T00:00:00,0.8987341772151899,0.8200094103813171,-8.759516309684432,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Itamogi,2021-12-31T00:00:00,1.260064724919094,1.973605155944824,56.627284052535096,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Itanhomi,2021-12-31T00:00:00,0.9606060606060604,1.0384560823440552,8.104260938024687,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Itapecerica,2021-12-31T00:00:00,1.222784810126582,1.270397663116455,3.893804747619009,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ituiutaba,2021-12-31T00:00:00,2.25,0.6530454754829407,-70.97575664520264,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Itumirim,2021-12-31T00:00:00,1.2595155709342565,1.6221359968185425,28.790467879274367,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Itutinga,2021-12-31T00:00:00,1.2,1.6556934118270874,37.97445098559062,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Jacui,2021-12-31T00:00:00,0.96,1.6296718120574951,69.75748042265577,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Jacutinga,2021-12-31T00:00:00,1.32014652014652,1.7050540447235107,29.15642458643688,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Jequeri,2021-12-31T00:00:00,1.5,2.09525728225708,39.68381881713867,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Jequitinhonha,2021-12-31T00:00:00,1.8000000000000005,1.0461478233337402,-41.880676481458885,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Jesuania,2021-12-31T00:00:00,1.2,1.3014411926269531,8.453432718912765,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Joao_Pinheiro,2021-12-31T00:00:00,2.4,1.7140220403671265,-28.582414984703064,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Jose_Goncalves_de_Minas,2021-12-31T00:00:00,1.502673796791444,1.2437794208526611,-17.22891398596171,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Juiz_de_Fora,2021-12-31T00:00:00,1.142857142857143,0.1254803836345672,-89.02046643197536,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Juruaia,2021-12-31T00:00:00,1.5,1.7577816247940063,17.185441652933754,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ladainha,2021-12-31T00:00:00,0.7199999999999999,0.6037015914916992,-16.152556737263982,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Lagoa_Dourada,2021-12-31T00:00:00,1.2,2.1137118339538574,76.14265282948813,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Lagoa_Formosa,2021-12-31T00:00:00,1.4830188679245278,2.135030508041382,43.96516148370646,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Lagoa_Grande,2021-12-31T00:00:00,0.6000000000000001,1.697096824645996,182.84947077433264,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Lajinha,2021-12-31T00:00:00,1.260014255167498,1.3759710788726809,9.202818399048043,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Lambari,2021-12-31T00:00:00,1.199954863461973,1.4358949661254885,19.66241479973737,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Lamim,2021-12-31T00:00:00,1.2800000000000002,1.939095139503479,51.49180777370926,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Lavras,2021-12-31T00:00:00,1.259900454447089,1.2808918952941897,1.666118999561143,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Luisburgo,2021-12-31T00:00:00,1.3799999999999997,1.7673351764678955,28.0677664107171,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Luminarias,2021-12-31T00:00:00,1.380229885057471,1.0170460939407349,-26.31328266751836,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Machado,2021-12-31T00:00:00,1.444286871961102,1.7137744426727295,18.65886728899697,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Malacacheta,2021-12-31T00:00:00,1.8000000000000005,1.4294404983520508,-20.586638980441634,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Manhuacu,2021-12-31T00:00:00,0.9,1.4237416982650757,58.19352202945285,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Manhumirim,2021-12-31T00:00:00,1.2,1.3997944593429563,16.64953827857972,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Mantena,2021-12-31T00:00:00,0.7289999999999999,0.2039030045270919,-72.0297661828406,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Mar_de_Espanha,2021-12-31T00:00:00,1.4199999999999997,0.938964545726776,-33.8757362164242,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Maria_da_Fe,2021-12-31T00:00:00,1.444444444444444,1.5049654245376587,4.189914006453328,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Martins_Soares,2021-12-31T00:00:00,1.2,1.6264156103134155,35.53463419278463,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Mata_Verde,2021-12-31T00:00:00,1.319277108433735,1.304635524749756,-1.109818671936312,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Matipo,2021-12-31T00:00:00,1.07995337995338,1.4490538835525513,34.17744788345445,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Matutina,2021-12-31T00:00:00,1.502024291497976,1.5168434381484983,0.986611650317807,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Medeiros,2021-12-31T00:00:00,1.500161864681127,1.5149903297424316,0.9884576731629268,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Minas_Novas,2021-12-31T00:00:00,1.7848101265822778,0.8733214139938354,-51.0692257407709,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Miradouro,2021-12-31T00:00:00,1.2,1.3386883735656738,11.557364463806156,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Mirai,2021-12-31T00:00:00,1.019512195121951,1.4204466342926023,39.326105277504105,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Moeda,2021-12-31T00:00:00,1.8000000000000005,0.7317312359809875,-59.34826466772292,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Monsenhor_Paulo,2021-12-31T00:00:00,1.41,1.5300390720367432,8.513409364308016,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Monte_Alegre_de_Minas,2021-12-31T00:00:00,2.765957446808511,0.7785041332244873,-71.85408133726854,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Monte_Belo,2021-12-31T00:00:00,1.56,1.4649715423583984,-6.0915677975385645,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Monte_Carmelo,2021-12-31T00:00:00,1.8000000000000005,1.197283148765564,-33.48426951302423,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Monte_Formoso,2021-12-31T00:00:00,0.55,0.4702445566654205,-14.500989697196273,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Monte_Santo_de_Minas,2021-12-31T00:00:00,1.200018932222643,1.8129279613494875,51.07494662535286,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Monte_Siao,2021-12-31T00:00:00,1.5,1.604349136352539,6.956609090169271,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Muriae,2021-12-31T00:00:00,0.9,1.4061288833618164,56.23654259575738,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Mutum,2021-12-31T00:00:00,1.319934249850568,1.333998441696167,1.0655221536369155,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Muzambinho,2021-12-31T00:00:00,1.199937762564182,1.7161569595336914,43.02049765201034,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Natercia,2021-12-31T00:00:00,1.4399193548387097,1.3103729486465454,-8.996782059831068,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Nazareno,2021-12-31T00:00:00,1.5,1.9130586385726929,27.53724257151286,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Nepomuceno,2021-12-31T00:00:00,1.379962721342032,1.5430400371551514,11.817516030760926,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ninheira,2021-12-31T00:00:00,2.100246002460024,2.7951760292053223,33.08802997036182,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Nova_Belem,2021-12-31T00:00:00,1.0,0.5709074139595032,-42.90925860404968,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Nova_Era,2021-12-31T00:00:00,1.5,1.387821912765503,-7.478539148966472,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Nova_Ponte,2021-12-31T00:00:00,2.5482352941176467,1.1697101593017578,-54.09724674946933,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Nova_Resende,2021-12-31T00:00:00,1.3800031392246113,2.076045036315918,50.43770389409368,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Novo_Cruzeiro,2021-12-31T00:00:00,1.226392251815981,1.0030796527862549,-18.20890491594805,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Novorizonte,2021-12-31T00:00:00,1.307692307692308,0.9764683842658995,-25.32888826201945,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Olimpio_Noronha,2021-12-31T00:00:00,1.20026525198939,1.367180347442627,13.906517344943726,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Oliveira,2021-12-31T00:00:00,1.537805840568272,1.7869524955749512,16.201437686997664,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Orizania,2021-12-31T00:00:00,1.08,1.4735187292099,36.43691937128702,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ouro_Fino,2021-12-31T00:00:00,1.2,1.8012948036193848,50.1079003016154,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ouro_Verde_de_Minas,2021-12-31T00:00:00,1.942857142857143,0.8098015785217285,-58.31903639961692,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Padre_Paraiso,2021-12-31T00:00:00,0.4787878787878789,0.7198634743690491,50.35123198847224,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Paracatu,2021-12-31T00:00:00,2.4,1.7785577774047852,-25.893425941467285,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Paraguacu,2021-12-31T00:00:00,0.9712280701754386,1.7689623832702637,82.13666157226342,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Paraisopolis,2021-12-31T00:00:00,1.2,1.192699909210205,-0.6083408991495731,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Passa_Tempo,2021-12-31T00:00:00,1.511627906976744,1.2506544589996338,-17.264397327716523,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Passos,2021-12-31T00:00:00,0.99,1.106206297874451,11.73800988630815,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Patis,2021-12-31T00:00:00,2.111111111111112,2.340108871459961,10.847262332313914,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Patos_de_Minas,2021-12-31T00:00:00,1.7224109589041097,1.6481683254241943,-4.310390217625675,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Patrocinio,2021-12-31T00:00:00,1.4369951534733445,1.3118362426757812,-8.709765686755649,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Paula_Candido,2021-12-31T00:00:00,1.5,1.3810174465179443,-7.932170232137044,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pecanha,2021-12-31T00:00:00,1.807692307692308,1.5629701614379885,-13.537820856621948,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pedra_Azul,2021-12-31T00:00:00,1.2,0.7611235976219177,-36.57303353150685,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pedra_Bonita,2021-12-31T00:00:00,1.08,1.131904125213623,4.805937519779905,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pedra_Dourada,2021-12-31T00:00:00,0.96,1.2976694107055664,35.17389694849652,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pedra_do_Anta,2021-12-31T00:00:00,0.9,1.3827226161956787,53.6358462439643,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pedralva,2021-12-31T00:00:00,1.5,1.4123902320861816,-5.840651194254557,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pedrinopolis,2021-12-31T00:00:00,1.514285714285714,1.0050708055496216,-33.627399633515545,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Perdizes,2021-12-31T00:00:00,1.261308677098151,1.0379236936569214,-17.710572161856813,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Perdoes,2021-12-31T00:00:00,1.44017094017094,1.380624771118164,-4.134659809599276,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Piedade_de_Caratinga,2021-12-31T00:00:00,1.2,1.6695172786712646,39.126439889272056,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pimenta,2021-12-31T00:00:00,1.3502325581395351,1.3875356912612915,2.7627191254487147,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Piracema,2021-12-31T00:00:00,1.2,1.0859735012054443,-9.502208232879635,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Piranga,2021-12-31T00:00:00,2.1,1.4876251220703125,-29.160708472842263,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pirangucu,2021-12-31T00:00:00,1.333333333333333,1.2212891578674316,-8.403313159942606,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Piranguinho,2021-12-31T00:00:00,1.380549682875264,1.3707635402679443,-0.7088584155072225,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pirapora,2021-12-31T00:00:00,3.0,2.2244949340820312,-25.850168863932293,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Piumhi,2021-12-31T00:00:00,1.5,1.4220939874649048,-5.193734169006348,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Poco_Fundo,2021-12-31T00:00:00,0.9601760412194076,1.3159706592559814,37.05514434464753,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pocos_de_Caldas,2021-12-31T00:00:00,1.4199999999999997,1.4676650762557983,3.356695510971736,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pocrane,2021-12-31T00:00:00,1.3228346456692908,1.1212551593780518,-15.238449261302003,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ponte_Nova,2021-12-31T00:00:00,1.2,1.414325714111328,17.860476175944015,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ponto_dos_Volantes,2021-12-31T00:00:00,0.5375,0.5817388296127319,8.230479927950132,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Porto_Firme,2021-12-31T00:00:00,1.319607843137255,1.529699206352234,15.920742234716071,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pote,2021-12-31T00:00:00,0.6000000000000001,0.5922463536262512,-1.2922743956248113,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pouso_Alegre,2021-12-31T00:00:00,1.2,1.3171621561050415,9.763513008753463,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pouso_Alto,2021-12-31T00:00:00,1.5047619047619047,1.4165867567062378,-5.859740851800652,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pratapolis,2021-12-31T00:00:00,0.9602272727272728,2.0405702590942383,112.5090920713526,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pratinha,2021-12-31T00:00:00,1.35,1.694072961807251,25.48688605979636,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Presidente_Bernardes,2021-12-31T00:00:00,1.56,1.2406294345855713,-20.47247214195056,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Presidente_Kubitschek,2021-12-31T00:00:00,0.7368421052631579,1.1440024375915527,55.25747367313932,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Presidente_Olegario,2021-12-31T00:00:00,1.637164750957854,1.6315512657165527,-0.342878457285191,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Quartel_Geral,2021-12-31T00:00:00,2.4571428571428573,2.42996597290039,-1.1060359866120155,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Raul_Soares,2021-12-31T00:00:00,1.320079522862823,1.1507219076156616,-12.829349468271417,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Reduto,2021-12-31T00:00:00,1.2,1.5673696994781494,30.61414162317913,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ribeirao_Vermelho,2021-12-31T00:00:00,1.258899676375405,1.4964076280593872,18.86631287155539,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Rio_Paranaiba,2021-12-31T00:00:00,1.080031384856807,1.1319286823272705,4.805165682971714,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Rio_Pardo_de_Minas,2021-12-31T00:00:00,2.764006791171477,3.096021175384521,12.01206832318693,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Rio_Vermelho,2021-12-31T00:00:00,0.7777777777777777,0.8984602689743042,15.516320296696268,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ritapolis,2021-12-31T00:00:00,1.5,1.9965133666992188,33.10089111328125,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Romaria,2021-12-31T00:00:00,2.052631578947369,1.492762565612793,-27.27566988040241,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Rosario_da_Limeira,2021-12-31T00:00:00,0.9,1.2609814405441284,40.1090489493476,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sabinopolis,2021-12-31T00:00:00,1.2,0.7475066184997559,-37.70778179168701,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sacramento,2021-12-31T00:00:00,1.25645342312009,1.453564167022705,15.687867156518992,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santa_Barbara,2021-12-31T00:00:00,0.9333333333333332,1.0978128910064695,17.62280975069321,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santa_Barbara_do_Leste,2021-12-31T00:00:00,1.319917440660475,1.423532009124756,7.850079502884139,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santa_Barbara_do_Monte_Verde,2021-12-31T00:00:00,1.4,0.1971587836742401,-85.91722973755428,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santa_Margarida,2021-12-31T00:00:00,0.9,1.7862699031829834,98.47443368699815,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santa_Maria_do_Suacui,2021-12-31T00:00:00,0.8,0.7288923263549805,-8.888459205627447,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santa_Rita_de_Caldas,2021-12-31T00:00:00,1.682051282051282,1.8327794075012207,8.960970872785985,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santa_Rita_de_Minas,2021-12-31T00:00:00,1.2,1.3194947242736816,9.957893689473474,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santa_Rita_do_Itueto,2021-12-31T00:00:00,1.3799999999999997,1.3826028108596802,0.1886094825855438,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santa_Rita_do_Sapucai,2021-12-31T00:00:00,1.5,1.341849684715271,-10.543354352315266,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santa_Rosa_da_Serra,2021-12-31T00:00:00,1.5,1.4671591520309448,-2.1893898646036787,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santana_da_Vargem,2021-12-31T00:00:00,1.44,1.5968775749206543,10.894276036156551,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santana_do_Jacare,2021-12-31T00:00:00,1.2,1.4202146530151367,18.351221084594734,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santana_do_Manhuacu,2021-12-31T00:00:00,1.32,1.7289860248565674,30.98378976186116,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santo_Antonio_do_Amparo,2021-12-31T00:00:00,1.3799999999999997,1.5619946718215942,13.188019697217,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santo_Antonio_do_Grama,2021-12-31T00:00:00,1.9130434782608696,1.7650856971740725,-7.734156738628053,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santo_Antonio_do_Retiro,2021-12-31T00:00:00,1.2,0.763442873954773,-36.37976050376892,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Bento_Abade,2021-12-31T00:00:00,1.32,0.9136393666267396,-30.784896467671253,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Domingos_das_Dores,2021-12-31T00:00:00,1.2,1.4503852128982544,20.86543440818788,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Domingos_do_Prata,2021-12-31T00:00:00,0.903846153846154,0.7817348837852478,-13.51018307056833,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Francisco_de_Paula,2021-12-31T00:00:00,1.3200867052023115,1.3880677223205566,5.14973878990974,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Francisco_do_Gloria,2021-12-31T00:00:00,0.78,1.570533037185669,101.35038938277808,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Geraldo,2021-12-31T00:00:00,1.5,1.370558500289917,-8.629433314005535,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Goncalo_do_Abaete,2021-12-31T00:00:00,1.67887323943662,1.8936984539031985,12.795797170408608,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Goncalo_do_Rio_Preto,2021-12-31T00:00:00,3.36,1.670392394065857,-50.28594065280188,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Goncalo_do_Sapucai,2021-12-31T00:00:00,1.62,1.4043519496917725,-13.311608043717754,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Gotardo,2021-12-31T00:00:00,1.26027397260274,0.9676787853240968,-23.216792034066263,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Joao_Batista_do_Gloria,2021-12-31T00:00:00,1.110749185667752,1.3091434240341189,17.86129946582832,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Joao_da_Mata,2021-12-31T00:00:00,0.8995327102803738,1.288635015487671,43.25604847499302,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Joao_del_Rei,2021-12-31T00:00:00,1.296875,1.961275696754456,51.23089709913874,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Joao_do_Manhuacu,2021-12-31T00:00:00,0.9,1.4598883390426636,62.20981544918484,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Joao_do_Manteninha,2021-12-31T00:00:00,0.7,0.4896349906921386,-30.052144186837324,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Joao_do_Paraiso,2021-12-31T00:00:00,3.0614754098360666,1.609030842781067,-47.4426337833226,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Jose_da_Barra,2021-12-31T00:00:00,1.682068965517241,1.9701226949691768,17.124965465572274,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Jose_do_Alegre,2021-12-31T00:00:00,1.7823529411764714,1.2717993259429932,-28.6449223068288,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Jose_do_Mantimento,2021-12-31T00:00:00,1.500917431192661,1.4893940687179563,-0.7677545903073238,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Lourenco,2021-12-31T00:00:00,1.5087719298245608,2.3599295616149902,56.41393606052849,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Miguel_do_Anta,2021-12-31T00:00:00,1.2603053435114495,1.3073933124542236,3.736234967597446,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Pedro_da_Uniao,2021-12-31T00:00:00,1.479945054945055,1.860811948776245,25.7352050036297,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Roque_de_Minas,2021-12-31T00:00:00,1.2,1.4811391830444336,23.428265253702804,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Sebastiao_da_Bela_Vista,2021-12-31T00:00:00,1.2,1.2097795009613037,0.8149584134419796,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Sebastiao_da_Vargem_Alegre,2021-12-31T00:00:00,1.020238095238095,1.9160048961639404,87.7997797873641,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Sebastiao_do_Anta,2021-12-31T00:00:00,1.5,1.4391885995864868,-4.054093360900879,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Sebastiao_do_Maranhao,2021-12-31T00:00:00,0.9655172413793104,0.8316516876220703,-13.86464663914272,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Sebastiao_do_Paraiso,2021-12-31T00:00:00,1.14450771643146,1.76470685005188,54.18916139370224,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Tiago,2021-12-31T00:00:00,1.5,1.7949235439300537,19.66156959533692,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Tomas_de_Aquino,2021-12-31T00:00:00,1.2,1.9423086643219,61.85905536015829,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Tome_das_Letras,2021-12-31T00:00:00,1.2,1.6085386276245115,34.044885635375984,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Senador_Firmino,2021-12-31T00:00:00,1.563636363636364,1.1117570400238037,-28.89925906824513,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Senador_Jose_Bento,2021-12-31T00:00:00,1.32,1.4994887113571167,13.59762964826641,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Senador_Modestino_Goncalves,2021-12-31T00:00:00,2.7000000000000006,2.806851625442505,3.957467608981639,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Senhora_de_Oliveira,2021-12-31T00:00:00,1.62037037037037,1.4311134815216064,-11.679853711809413,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Senhora_dos_Remedios,2021-12-31T00:00:00,1.5,1.220836520195007,-18.610898653666176,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sericita,2021-12-31T00:00:00,0.9,2.334200859069824,159.35565100775827,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Serra_do_Salitre,2021-12-31T00:00:00,1.4676384839650147,1.0952894687652588,-25.37062221166394,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Serrania,2021-12-31T00:00:00,1.08,1.3781962394714355,27.6107629140218,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Setubinha,2021-12-31T00:00:00,0.9329787234042556,0.694575309753418,-25.552931451743127,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Silvianopolis,2021-12-31T00:00:00,0.9601265822784812,1.130076289176941,17.70076050755217,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Simonesia,2021-12-31T00:00:00,1.08,1.633273005485535,51.22898198940135,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Soledade_de_Minas,2021-12-31T00:00:00,1.7204819277108432,2.154599189758301,25.23230584729621,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Taiobeiras,2021-12-31T00:00:00,3.49869451697128,2.183349847793579,-37.59529912649697,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Tapira,2021-12-31T00:00:00,0.6000000000000001,1.4400689601898191,140.01149336496985,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Tapirai,2021-12-31T00:00:00,1.396563119629874,1.6096510887145996,15.25802637128206,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Teixeiras,2021-12-31T00:00:00,1.32,1.3592376708984375,2.9725508256392,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Teofilo_Otoni,2021-12-31T00:00:00,0.6800000000000002,0.68104088306427,0.1530710388632146,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Tiros,2021-12-31T00:00:00,1.2,1.0785295963287354,-10.122533639272053,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Tocos_do_Moji,2021-12-31T00:00:00,1.259776536312849,1.1025525331497192,-12.48030889853669,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Tombos,2021-12-31T00:00:00,0.8497959183673469,1.2712159156799316,49.59072975100061,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Tres_Coracoes,2021-12-31T00:00:00,1.5,0.8414884805679321,-43.90076796213786,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Tres_Pontas,2021-12-31T00:00:00,1.3500296384113808,1.5997750759124756,18.49925589744663,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Tupaciguara,2021-12-31T00:00:00,1.887700534759358,1.9316930770874023,2.3304831204941308,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Turmalina,2021-12-31T00:00:00,1.2797783933518008,1.2282968759536743,-4.022689995827629,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Turvolandia,2021-12-31T00:00:00,1.3797385620915028,1.3551685810089111,-1.780770774815977,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ubaporanga,2021-12-31T00:00:00,1.319867549668874,1.3213753700256348,0.1142402779081089,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Uberaba,2021-12-31T00:00:00,2.0302325581395344,2.0068302154541016,-1.152692709591767,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Uberlandia,2021-12-31T00:00:00,1.77962962962963,1.2357358932495115,-30.56218705986096,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Unai,2021-12-31T00:00:00,2.639892904953146,2.487016201019287,-5.791019160172033,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Urucuia,2021-12-31T00:00:00,1.799276672694394,1.784641146659851,-0.8134116479499773,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Vargem_Bonita,2021-12-31T00:00:00,1.519565217391304,1.5665326118469238,3.09084427032692,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Vargem_Grande_do_Rio_Pardo,2021-12-31T00:00:00,1.644444444444444,1.5332868099212646,-6.759585883166309,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Varginha,2021-12-31T00:00:00,1.2,1.2633967399597168,5.283061663309737,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Varjao_de_Minas,2021-12-31T00:00:00,2.390254805543138,2.3687214851379395,-0.9008797035053172,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Varzea_da_Palma,2021-12-31T00:00:00,1.68,2.262009620666504,34.64342980157762,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Vermelho_Novo,2021-12-31T00:00:00,0.96,1.2953543663024902,34.93274648984276,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Vicosa,2021-12-31T00:00:00,0.9006711409395973,1.3633862733840942,51.37448191820421,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Vieiras,2021-12-31T00:00:00,0.78,1.3963555097579956,79.01993714846097,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Virginia,2021-12-31T00:00:00,1.433333333333333,1.2811839580535889,-10.615072693935634,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Virginopolis,2021-12-31T00:00:00,1.202380952380952,1.5066249370574951,25.303460111712496,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Visconde_do_Rio_Branco,2021-12-31T00:00:00,1.25,0.8262217044830322,-33.90226364135742,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Abadia_dos_Dourados,2022-12-31T00:00:00,2.0384615384615383,2.6288771629333496,28.963785351447346,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Abre_Campo,2022-12-31T00:00:00,1.2,1.279740333557129,6.645027796427414,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Acucena,2022-12-31T00:00:00,1.0,0.9801798462867736,-1.982015371322632,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Agua_Boa,2022-12-31T00:00:00,0.9136363636363636,1.0523252487182615,15.17987796916298,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Aguanil,2022-12-31T00:00:00,1.56,1.8673099279403689,19.69935435515184,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Aguas_Vermelhas,2022-12-31T00:00:00,3.0,4.03709077835083,34.569692611694336,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Aimores,2022-12-31T00:00:00,2.332558139534884,1.911077857017517,-18.069443816796376,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Aiuruoca,2022-12-31T00:00:00,1.5,1.04668390750885,-30.221072832743328,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Albertina,2022-12-31T00:00:00,1.44,1.710962176322937,18.816817800203964,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Alfenas,2022-12-31T00:00:00,0.9243951612903224,2.044600248336792,121.18249142312952,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Almenara,2022-12-31T00:00:00,0.78,0.8751386404037476,12.197261590224045,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Alpinopolis,2022-12-31T00:00:00,1.4420494699646638,1.94443154335022,34.83806095763597,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Alterosa,2022-12-31T00:00:00,1.080104712041885,1.651641607284546,52.91495249217073,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Alto_Caparao,2022-12-31T00:00:00,1.5,1.865689873695373,24.379324913024902,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Alto_Jequitiba,2022-12-31T00:00:00,0.9,1.400714874267578,55.6349860297309,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Alvarenga,2022-12-31T00:00:00,0.9,0.901408076286316,0.1564529207017662,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Amparo_do_Serra,2022-12-31T00:00:00,1.8000000000000005,1.3271875381469729,-26.267358991834865,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Andradas,2022-12-31T00:00:00,1.26,2.421315193176269,92.1678724743071,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Andrelandia,2022-12-31T00:00:00,1.8000000000000005,1.4627681970596311,-18.735100163353827,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Angelandia,2022-12-31T00:00:00,1.9799126637554585,1.5414481163024902,-22.145650941051983,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Antonio_Dias,2022-12-31T00:00:00,1.5,1.4440433979034424,-3.730440139770508,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Antonio_Prado_de_Minas,2022-12-31T00:00:00,1.2,0.8274482488632202,-31.045979261398315,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Araguari,2022-12-31T00:00:00,1.919968366943456,2.112964630126953,10.05205432060022,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Araponga,2022-12-31T00:00:00,1.260041407867495,1.5145725011825562,20.20021657429748,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Arapua,2022-12-31T00:00:00,1.14,1.1826341152191162,3.739834668343536,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Araxa,2022-12-31T00:00:00,1.077872465471643,1.5138990879058838,40.45252443139916,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Arceburgo,2022-12-31T00:00:00,0.9244897959183672,1.9459682703018188,110.49104910549478,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Areado,2022-12-31T00:00:00,0.9076923076923076,1.8519306182861328,104.02625455694684,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Aricanduva,2022-12-31T00:00:00,1.2,1.3179761171340942,9.831343094507858,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Astolfo_Dutra,2022-12-31T00:00:00,0.625,1.1610573530197144,85.7691764831543,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ataleia,2022-12-31T00:00:00,0.7142857142857143,0.706438422203064,-1.0986208915710471,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Baependi,2022-12-31T00:00:00,1.079558011049724,1.3975163698196411,29.45264224020213,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Bambui,2022-12-31T00:00:00,1.5,1.5579148530960083,3.860990206400553,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Bandeira,2022-12-31T00:00:00,1.5,1.0202486515045166,-31.983423233032227,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Bandeira_do_Sul,2022-12-31T00:00:00,1.110344827586207,1.586967945098877,42.92568449648271,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Berilo,2022-12-31T00:00:00,1.5625,1.2255860567092896,-21.56249237060547,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Berizal,2022-12-31T00:00:00,3.570967741935484,5.008802890777588,40.26457959720437,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Boa_Esperanca,2022-12-31T00:00:00,0.9726256983240223,1.95125699043274,100.61746196867335,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Bocaiuva,2022-12-31T00:00:00,3.6000000000000005,1.6943483352661133,-52.93476846483019,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Bom_Jesus_da_Penha,2022-12-31T00:00:00,1.6298200514138823,1.748690843582153,7.2934918223118945,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Bom_Jesus_do_Amparo,2022-12-31T00:00:00,1.8000000000000005,1.2188451290130615,-32.2863817214966,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Bom_Jesus_do_Galho,2022-12-31T00:00:00,0.7801587301587303,1.209667444229126,55.05401624910464,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Bom_Sucesso,2022-12-31T00:00:00,1.440136054421769,1.6969666481018066,17.833772919681405,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Bonfinopolis_de_Minas,2022-12-31T00:00:00,3.3,2.928475141525269,-11.258329044688828,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Borda_da_Mata,2022-12-31T00:00:00,1.2,1.5052640438079834,25.43867031733196,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Botelhos,2022-12-31T00:00:00,0.9,1.340179681777954,48.90885353088378,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Botumirim,2022-12-31T00:00:00,0.7241379310344828,0.8867673873901367,22.458353496733167,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Brazopolis,2022-12-31T00:00:00,1.200934579439252,1.4639685153961182,21.902436690571733,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Bueno_Brandao,2022-12-31T00:00:00,1.440196078431373,2.118968725204468,47.13057179772338,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Buritis,2022-12-31T00:00:00,3.0,3.692670345306397,23.08901151021322,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Buritizeiro,2022-12-31T00:00:00,3.0,2.454121828079224,-18.19593906402588,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cabo_Verde,2022-12-31T00:00:00,1.35,2.037821054458618,50.94970773767541,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cachoeira_de_Minas,2022-12-31T00:00:00,1.5,1.493971824645996,-0.4018783569335937,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Caete,2022-12-31T00:00:00,1.5333333333333332,1.0532515048980713,-31.30968446316926,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Caiana,2022-12-31T00:00:00,0.9,1.2702983617782593,41.14426241980658,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cajuri,2022-12-31T00:00:00,1.050602409638554,1.2060283422470093,14.793982117547923,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Caldas,2022-12-31T00:00:00,1.2,2.02888298034668,69.07358169555665,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Camacho,2022-12-31T00:00:00,1.380176211453745,1.823211431503296,32.0999026336572,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cambuquira,2022-12-31T00:00:00,1.32,1.389676809310913,5.278546159917654,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Campanha,2022-12-31T00:00:00,1.266469038208169,1.353671312332153,6.885464349555698,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Campestre,2022-12-31T00:00:00,1.020018115942029,1.3911973237991333,36.38947211386584,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Campo_Belo,2022-12-31T00:00:00,1.2,1.5001367330551147,25.01139442125957,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Campo_do_Meio,2022-12-31T00:00:00,1.580968858131488,1.8387008905410769,16.302157445036354,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Campos_Altos,2022-12-31T00:00:00,1.680042238648363,1.700111746788025,1.194583545459429,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Campos_Gerais,2022-12-31T00:00:00,1.535771358328211,2.01077651977539,30.92941920496904,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cana_Verde,2022-12-31T00:00:00,1.02,1.431322693824768,40.32575429654589,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Canaa,2022-12-31T00:00:00,1.320338983050847,1.4481239318847656,9.678192530425166,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Candeias,2022-12-31T00:00:00,1.020017406440383,1.6954870223999023,66.2213812915945,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Caparao,2022-12-31T00:00:00,1.32,1.758517146110535,33.22099591746474,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Capela_Nova,2022-12-31T00:00:00,2.1016393442622947,1.8201874494552608,-13.39201683559208,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Capelinha,2022-12-31T00:00:00,1.576751592356688,1.3478357791900637,-14.51819134201577,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Capetinga,2022-12-31T00:00:00,1.407056229327453,1.811526775360108,28.745869397556632,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Capitao_Eneas,2022-12-31T00:00:00,2.6000000000000005,1.3617769479751587,-47.62396353941698,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Capitolio,2022-12-31T00:00:00,1.08,1.591197848320007,47.33313410370437,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Caputira,2022-12-31T00:00:00,1.440044247787611,1.386682391166687,-3.705570624160029,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Carai,2022-12-31T00:00:00,1.2,1.3240561485290527,10.338012377421066,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Caranaiba,2022-12-31T00:00:00,3.405405405405405,1.1768115758895874,-65.44283467625814,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Carangola,2022-12-31T00:00:00,1.02,1.3430558443069458,31.67214159872017,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Caratinga,2022-12-31T00:00:00,1.620022123893805,1.5770652294158936,-2.65162394045968,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Careacu,2022-12-31T00:00:00,1.2,1.2614890336990356,5.124086141586308,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Carmo_da_Cachoeira,2022-12-31T00:00:00,1.2,1.4543105363845823,21.192544698715217,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Carmo_da_Mata,2022-12-31T00:00:00,1.56,1.4143314361572266,-9.33772845145984,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Carmo_de_Minas,2022-12-31T00:00:00,1.14,1.658016562461853,45.440049338759046,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Carmo_do_Paranaiba,2022-12-31T00:00:00,1.392969472710453,1.6690105199813845,19.816733437367308,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Carmo_do_Rio_Claro,2022-12-31T00:00:00,1.619555143651529,2.1734843254089355,34.20255148018551,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Carmopolis_de_Minas,2022-12-31T00:00:00,1.8000000000000005,1.85753071308136,3.1961507267422,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Carrancas,2022-12-31T00:00:00,1.6785714285714293,1.290146827697754,-23.14018898821895,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Carvalhopolis,2022-12-31T00:00:00,1.44,1.555387258529663,8.01300406455994,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Casa_Grande,2022-12-31T00:00:00,2.107692307692308,1.238574743270874,-41.23550488130891,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cascalho_Rico,2022-12-31T00:00:00,2.580434782608696,2.195040464401245,-14.935247377879309,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cassia,2022-12-31T00:00:00,1.413626373626374,1.569464921951294,11.024026661666433,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cataguases,2022-12-31T00:00:00,1.5,0.6339972019195557,-57.733519872029625,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Catas_Altas_da_Noruega,2022-12-31T00:00:00,1.0,0.7944397330284119,-20.556026697158813,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Catuji,2022-12-31T00:00:00,1.3230769230769233,1.1740069389343262,-11.266917406126522,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Caxambu,2022-12-31T00:00:00,1.4387755102040822,1.710138201713562,18.860669338956743,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Chale,2022-12-31T00:00:00,1.44,1.4021198749542236,-2.630564239290022,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Claraval,2022-12-31T00:00:00,1.289915966386555,1.7798748016357422,37.98377941019757,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Claudio,2022-12-31T00:00:00,1.140522875816993,1.9036377668380733,66.90921394053032,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Coimbra,2022-12-31T00:00:00,1.799054373522459,1.429877758026123,-20.52059242509199,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Conceicao_da_Aparecida,2022-12-31T00:00:00,1.53,1.992938756942749,30.25743509429732,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Conceicao_da_Barra_de_Minas,2022-12-31T00:00:00,1.370833333333333,1.8533625602722168,35.19970044538972,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Conceicao_das_Pedras,2022-12-31T00:00:00,1.375,1.649101972579956,19.93468891490589,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Conceicao_de_Ipanema,2022-12-31T00:00:00,1.5,1.424973487854004,-5.00176747639974,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Conceicao_do_Rio_Verde,2022-12-31T00:00:00,1.5,1.538488268852234,2.565884590148926,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Conceicao_dos_Ouros,2022-12-31T00:00:00,1.261168384879725,1.3910565376281738,10.299033365067736,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Congonhal,2022-12-31T00:00:00,1.080597014925373,1.5197432041168213,40.639219165506965,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Congonhas_do_Norte,2022-12-31T00:00:00,0.9,1.3209718465805054,46.77464962005615,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Conselheiro_Pena,2022-12-31T00:00:00,1.8000000000000005,1.410996437072754,-21.611309051513683,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Coqueiral,2022-12-31T00:00:00,1.2,1.7777546644210815,48.14622203509013,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cordislandia,2022-12-31T00:00:00,1.260122699386503,1.4109227657318115,11.967093872582916,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Coroaci,2022-12-31T00:00:00,2.1,1.6477266550064087,-21.53682595207578,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Coromandel,2022-12-31T00:00:00,1.260025542784164,1.7028231620788574,35.14195579847404,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Corrego_Danta,2022-12-31T00:00:00,1.5,1.3143538236618042,-12.37641175587972,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Corrego_Fundo,2022-12-31T00:00:00,1.079051383399209,1.0392268896102903,-3.690694845639702,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Corrego_Novo,2022-12-31T00:00:00,1.377777777777778,1.1223318576812744,-18.540429684423643,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cristais,2022-12-31T00:00:00,1.059063136456212,1.422057867050171,34.27507936954496,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cristina,2022-12-31T00:00:00,1.320183486238532,2.2869114875793457,73.22679092852586,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cruzeiro_da_Fortaleza,2022-12-31T00:00:00,1.5598526703499078,1.847417950630188,18.43541289164016,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cruzilia,2022-12-31T00:00:00,1.5027322404371577,1.4608631134033203,-2.786200089888089,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Cuparaque,2022-12-31T00:00:00,1.02,1.1362591981887815,11.397960606743306,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Datas,2022-12-31T00:00:00,0.75,3.959723234176636,427.9630978902181,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Delfinopolis,2022-12-31T00:00:00,1.3799999999999997,1.1168094873428345,-19.07177627950473,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Desterro_de_Entre_Rios,2022-12-31T00:00:00,1.8000000000000005,1.882655024528504,4.591945807139063,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Diamantina,2022-12-31T00:00:00,2.965183752417796,2.746665477752685,-7.36946823234584,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Divinesia,2022-12-31T00:00:00,2.2230769230769227,1.3791072368621826,-37.9640343279987,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Divino,2022-12-31T00:00:00,1.08,1.6299264430999756,50.91911510184958,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Divisa_Nova,2022-12-31T00:00:00,1.260204081632653,1.4563871622085571,15.56756428861426,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Divisopolis,2022-12-31T00:00:00,1.259523809523809,1.184505820274353,-5.956059637953032,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Dom_Cavati,2022-12-31T00:00:00,0.6000000000000001,0.6177585124969482,2.959752082824692,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Dom_Vicoso,2022-12-31T00:00:00,1.320588235294118,1.306368350982666,-1.0767841126712014,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Dores_do_Turvo,2022-12-31T00:00:00,1.2,0.9543352127075196,-20.472065607706703,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Doresopolis,2022-12-31T00:00:00,1.32,1.3257547616958618,0.4359667951410419,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Durande,2022-12-31T00:00:00,1.5,2.0482664108276367,36.55109405517578,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Eloi_Mendes,2022-12-31T00:00:00,1.090201870999508,1.3333847522735596,22.30622490595242,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Entre_Folhas,2022-12-31T00:00:00,1.2,1.173276662826538,-2.226944764455156,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Entre_Rios_de_Minas,2022-12-31T00:00:00,1.8000000000000005,1.908400058746338,6.022225485907645,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ervalia,2022-12-31T00:00:00,1.2,1.1871769428253174,-1.0685880978902145,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Esmeraldas,2022-12-31T00:00:00,2.111111111111112,1.8307117223739624,-13.2820763086018,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Espera_Feliz,2022-12-31T00:00:00,1.2,1.5034537315368652,25.287810961405444,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Espirito_Santo_do_Dourado,2022-12-31T00:00:00,1.319148936170213,1.3941237926483154,5.683577829791661,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Estrela_do_Indaia,2022-12-31T00:00:00,1.86,1.587924838066101,-14.627696878166605,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Estrela_do_Sul,2022-12-31T00:00:00,1.460045146726862,1.91193437576294,30.950359997368945,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Eugenopolis,2022-12-31T00:00:00,1.8000000000000005,1.2794424295425415,-28.91986502541437,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Fama,2022-12-31T00:00:00,1.379787234042553,1.6896541118621826,22.45758405169252,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Faria_Lemos,2022-12-31T00:00:00,1.200305810397553,1.0572361946105957,-11.919430410786005,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Felicio_dos_Santos,2022-12-31T00:00:00,3.306397306397306,5.258059501647949,59.02685050808974,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ferros,2022-12-31T00:00:00,1.230769230769231,0.829079270362854,-32.637309283018126,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Fervedouro,2022-12-31T00:00:00,1.4399108138238568,1.3634519577026367,-5.309971658465037,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Formiga,2022-12-31T00:00:00,1.8000000000000005,1.1096467971801758,-38.35295571221246,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Formoso,2022-12-31T00:00:00,3.3607142857142858,2.897516250610352,-13.78272580543056,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Fortaleza_de_Minas,2022-12-31T00:00:00,1.5,1.2067025899887085,-19.55316066741944,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Franciscopolis,2022-12-31T00:00:00,1.255555555555556,1.43462872505188,14.262464827140835,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Frei_Gaspar,2022-12-31T00:00:00,1.133333333333333,0.9849048256874084,-13.09663302758159,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Grao_Mogol,2022-12-31T00:00:00,1.177777777777778,1.4107788801193235,19.783112462961423,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Guape,2022-12-31T00:00:00,1.262758620689655,1.5037293434143066,19.08288082745739,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Guaraciaba,2022-12-31T00:00:00,1.8000000000000005,1.1882420778274536,-33.98655123180814,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Guaranesia,2022-12-31T00:00:00,1.086968085106383,1.7620251178741455,62.10458632754556,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Guarani,2022-12-31T00:00:00,1.2,1.186430811882019,-1.1307656764984095,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Guarda-Mor,2022-12-31T00:00:00,1.858757062146893,2.043444395065308,9.936066239075805,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Guaxupe,2022-12-31T00:00:00,1.14,1.3298673629760742,16.655031840006522,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Guimarania,2022-12-31T00:00:00,1.2220588235294123,1.8068406581878664,47.85218382283375,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Guiricema,2022-12-31T00:00:00,2.4,2.365806579589844,-1.4247258504231737,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Heliodora,2022-12-31T00:00:00,1.080140597539543,1.3249527215957642,22.66483868987794,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Iapu,2022-12-31T00:00:00,1.5614035087719298,1.334221363067627,-14.549867758590182,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ibia,2022-12-31T00:00:00,1.14,1.256709337234497,10.237661160920805,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ibiraci,2022-12-31T00:00:00,1.377007874015748,2.068504810333252,50.217355279233175,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ibitiura_de_Minas,2022-12-31T00:00:00,1.3799999999999997,2.0426056385040283,48.01490134087165,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ibituruna,2022-12-31T00:00:00,1.2,1.6991345882415771,41.59454902013143,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ijaci,2022-12-31T00:00:00,1.173913043478261,1.7707087993621826,50.83815698270443,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ilicinea,2022-12-31T00:00:00,1.080069324090121,1.976707100868225,83.01668761247855,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Imbe_de_Minas,2022-12-31T00:00:00,1.3799999999999997,1.3591926097869873,-1.50778189949365,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Inconfidentes,2022-12-31T00:00:00,1.739917695473251,2.2416818141937256,28.838382414634665,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Indaiabira,2022-12-31T00:00:00,2.1723404255319148,2.9528424739837646,35.92908548211258,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Indianopolis,2022-12-31T00:00:00,1.8000000000000005,1.9256647825241089,6.981376806894922,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ingai,2022-12-31T00:00:00,1.380228136882129,1.485195517539978,7.605074686780801,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Inhapim,2022-12-31T00:00:00,1.8000000000000005,1.867262482643128,3.736804591284842,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Irai_de_Minas,2022-12-31T00:00:00,2.386666666666667,2.643129587173462,10.745653093860112,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Itabirinha,2022-12-31T00:00:00,0.8674242424242423,0.802558422088623,-7.477981034324668,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Itacambira,2022-12-31T00:00:00,0.75,1.922790288925171,156.37203852335614,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Itaipe,2022-12-31T00:00:00,0.9604651162790696,0.8194961547851562,-14.677155797187098,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Itajuba,2022-12-31T00:00:00,1.068965517241379,1.2889108657836914,20.57553260557117,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Itamarandiba,2022-12-31T00:00:00,2.136,1.9948346614837649,-6.608864162745107,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Itamarati_de_Minas,2022-12-31T00:00:00,1.261538461538461,0.9582386016845704,-24.042062061588908,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Itambacuri,2022-12-31T00:00:00,0.9620253164556964,0.9621538519859314,0.0133609301165394,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Itamogi,2022-12-31T00:00:00,1.32,1.7062379121780396,29.26044789227572,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Itanhomi,2022-12-31T00:00:00,1.081818181818182,1.1245323419570925,3.9483677439328817,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Itapecerica,2022-12-31T00:00:00,1.040506329113924,1.357454538345337,30.46095928136449,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ituiutaba,2022-12-31T00:00:00,1.75,0.9287073016166688,-46.93101133619036,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Itumirim,2022-12-31T00:00:00,1.249307479224377,1.6442230939865112,31.61076206854333,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Itutinga,2022-12-31T00:00:00,1.8000000000000005,1.586524486541748,-11.859750747680676,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Jacui,2022-12-31T00:00:00,1.08,1.311947226524353,21.4765950485512,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Jacutinga,2022-12-31T00:00:00,1.289920424403183,1.7447295188903809,35.258693938242565,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Jequeri,2022-12-31T00:00:00,1.8000000000000005,1.99214506149292,10.674725638495534,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Jequitinhonha,2022-12-31T00:00:00,2.4,1.7181761264801023,-28.40932806332906,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Jesuania,2022-12-31T00:00:00,1.2,1.3249142169952393,10.409518082936607,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Joao_Pinheiro,2022-12-31T00:00:00,2.4,2.4967041015625,4.0293375651041705,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Jose_Goncalves_de_Minas,2022-12-31T00:00:00,1.5,1.6825940608978271,12.172937393188477,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Juiz_de_Fora,2022-12-31T00:00:00,1.5714285714285707,0.6433815956115723,-59.0575348247181,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Juruaia,2022-12-31T00:00:00,1.5,1.7639739513397217,17.59826342264811,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ladainha,2022-12-31T00:00:00,0.6000000000000001,0.7984102964401245,33.06838274002073,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Lagoa_Dourada,2022-12-31T00:00:00,1.5,1.4206438064575195,-5.290412902832031,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Lagoa_Formosa,2022-12-31T00:00:00,2.088607594936709,2.025432586669922,-3.024742820046166,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Lagoa_Grande,2022-12-31T00:00:00,2.4,1.3980369567871094,-41.74846013387044,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Lajinha,2022-12-31T00:00:00,1.419975786924939,1.602735996246338,12.87065673966029,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Lambari,2022-12-31T00:00:00,1.2,1.396967887878418,16.413990656534835,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Lamim,2022-12-31T00:00:00,2.4,1.2444502115249634,-48.147907853126526,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Lavras,2022-12-31T00:00:00,1.260078277886497,1.6796573400497437,33.29785692893603,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Luisburgo,2022-12-31T00:00:00,1.5,1.779077172279358,18.605144818623863,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Luminarias,2022-12-31T00:00:00,1.380229885057471,1.4567455053329468,5.543686678852758,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Machado,2022-12-31T00:00:00,0.964047619047619,1.897277474403381,96.80329445527788,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Malacacheta,2022-12-31T00:00:00,1.5595238095238098,1.7090089321136477,9.58530557064608,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Manhuacu,2022-12-31T00:00:00,1.44,1.298806071281433,-9.805133938789364,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Manhumirim,2022-12-31T00:00:00,1.3799999999999997,1.3976120948791504,1.276238759358748,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Mantena,2022-12-31T00:00:00,0.75,0.6102075576782227,-18.638992309570312,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Mar_de_Espanha,2022-12-31T00:00:00,2.1,0.9844427108764648,-53.1217756725493,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Maria_da_Fe,2022-12-31T00:00:00,1.2,1.886983036994934,57.24858641624452,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Martins_Soares,2022-12-31T00:00:00,1.3799999999999997,1.5412341356277466,11.683633016503402,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Mata_Verde,2022-12-31T00:00:00,1.6792452830188678,1.762528896331787,4.959585961331152,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Matipo,2022-12-31T00:00:00,1.26,1.23625648021698,-1.8844063319857167,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Matutina,2022-12-31T00:00:00,1.8097165991902835,1.5520894527435305,-14.235772969205367,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Medeiros,2022-12-31T00:00:00,1.5,1.600093960762024,6.672930717468262,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Minas_Novas,2022-12-31T00:00:00,1.7848101265822778,1.5428814888000488,-13.554866939571696,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Miradouro,2022-12-31T00:00:00,0.96,1.1995971202850342,24.958033363024413,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Mirai,2022-12-31T00:00:00,1.2,1.1535005569458008,-3.874953587849932,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Moeda,2022-12-31T00:00:00,1.25,0.9290725588798524,-25.674195289611816,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Monsenhor_Paulo,2022-12-31T00:00:00,1.23,1.572219967842102,27.82276161317904,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Monte_Alegre_de_Minas,2022-12-31T00:00:00,2.3296703296703294,2.870039939880371,23.19511062694048,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Monte_Belo,2022-12-31T00:00:00,0.96,1.587626338005066,65.3777435421944,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Monte_Carmelo,2022-12-31T00:00:00,1.7458874458874465,2.1436054706573486,22.78027863174992,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Monte_Formoso,2022-12-31T00:00:00,0.6000000000000001,0.9160383939743042,52.67306566238401,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Monte_Santo_de_Minas,2022-12-31T00:00:00,1.4699677072120565,1.925304889678955,30.9759990122839,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Monte_Siao,2022-12-31T00:00:00,1.2,1.959460735321045,63.28839461008708,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Muriae,2022-12-31T00:00:00,0.9897142857142858,1.27848219871521,29.17689652145597,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Mutum,2022-12-31T00:00:00,1.379940564635958,1.43384850025177,3.9065403972694672,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Muzambinho,2022-12-31T00:00:00,1.43993993993994,1.6014857292175293,11.218925511874296,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Natercia,2022-12-31T00:00:00,1.4399193548387097,1.326047658920288,-7.9081995485210195,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Nazareno,2022-12-31T00:00:00,1.319811320754717,1.8362996578216555,39.13349801936772,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Nepomuceno,2022-12-31T00:00:00,0.8699884125144843,1.6941473484039309,94.73217390418117,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ninheira,2022-12-31T00:00:00,2.9401197604790417,2.923533201217652,-0.5641457019658208,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Nova_Belem,2022-12-31T00:00:00,0.96,0.9962460398674012,3.7756291528542993,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Nova_Era,2022-12-31T00:00:00,1.5,1.6343092918395996,8.95395278930664,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Nova_Ponte,2022-12-31T00:00:00,2.710714285714286,1.8405207395553589,-32.10200170283261,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Nova_Resende,2022-12-31T00:00:00,1.5,2.008439779281616,33.895985285441085,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Novo_Cruzeiro,2022-12-31T00:00:00,1.180722891566265,1.1197508573532104,-5.163957999677076,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Novorizonte,2022-12-31T00:00:00,1.461538461538461,1.1766880750656128,-19.48976328498436,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Olimpio_Noronha,2022-12-31T00:00:00,1.2,1.3684769868850708,14.03974890708924,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Oliveira,2022-12-31T00:00:00,1.535560504825538,1.8993511199951167,23.691063557987967,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Orizania,2022-12-31T00:00:00,1.5,1.7169568538665771,14.46379025777181,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ouro_Fino,2022-12-31T00:00:00,1.2,1.8521206378936768,54.34338649113973,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ouro_Verde_de_Minas,2022-12-31T00:00:00,2.0,1.1884944438934326,-40.57527780532836,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Padre_Paraiso,2022-12-31T00:00:00,0.6000000000000001,0.7330954074859619,22.182567914326967,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Paracatu,2022-12-31T00:00:00,2.4,2.482752799987793,3.448033332824711,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Paraguacu,2022-12-31T00:00:00,1.043954802259887,1.8738175630569456,79.49221163604254,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Paraisopolis,2022-12-31T00:00:00,1.322222222222222,0.993163764476776,-24.88677411520179,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Passa_Tempo,2022-12-31T00:00:00,1.507692307692308,1.3949460983276367,-7.478064906840447,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Passos,2022-12-31T00:00:00,1.290038314176245,1.0223522186279297,-20.750243818862582,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Patis,2022-12-31T00:00:00,2.044444444444444,1.892714023590088,-7.421596672223934,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Patos_de_Minas,2022-12-31T00:00:00,1.91614730878187,1.7885994911193848,-6.656472447495157,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Patrocinio,2022-12-31T00:00:00,0.9438953724513282,2.06040096282959,118.28700753968728,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Paula_Candido,2022-12-31T00:00:00,1.6198529411764713,1.3686578273773191,-15.50727892722862,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pecanha,2022-12-31T00:00:00,2.287671232876712,1.8104389905929563,-20.86105011180489,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pedra_Azul,2022-12-31T00:00:00,1.5333333333333332,1.0049967765808103,-34.45673196212105,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pedra_Bonita,2022-12-31T00:00:00,1.8000000000000005,1.449228286743164,-19.487317403157565,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pedra_Dourada,2022-12-31T00:00:00,1.2,1.178724765777588,-1.7729361852010057,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pedra_do_Anta,2022-12-31T00:00:00,1.438297872340426,1.236416935920715,-14.036100609062723,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pedralva,2022-12-31T00:00:00,1.320091324200913,1.821282982826233,37.96643833930997,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pedrinopolis,2022-12-31T00:00:00,2.02051282051282,1.584122657775879,-21.59799028774201,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Perdizes,2022-12-31T00:00:00,1.501272727272727,1.3638346195220947,-9.15477283067068,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Perdoes,2022-12-31T00:00:00,1.259859154929577,1.6582971811294556,31.62560073805633,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Piedade_de_Caratinga,2022-12-31T00:00:00,1.56,1.584079384803772,1.5435503079340973,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pimenta,2022-12-31T00:00:00,1.3502325581395351,1.316204071044922,-2.5201945316368755,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Piracema,2022-12-31T00:00:00,1.0,1.237806797027588,23.78067970275879,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Piranga,2022-12-31T00:00:00,1.8000000000000005,1.7292182445526123,-3.9323197470771087,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pirangucu,2022-12-31T00:00:00,1.333333333333333,1.3103151321411133,-1.726365089416482,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Piranguinho,2022-12-31T00:00:00,1.380549682875264,1.4326215982437134,3.771824803870843,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pirapora,2022-12-31T00:00:00,3.3595505617977524,2.793320655822754,-16.854334993904637,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Piumhi,2022-12-31T00:00:00,1.2,1.513411283493042,26.1176069577535,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Poco_Fundo,2022-12-31T00:00:00,1.079978925184405,1.345536231994629,24.58911934460947,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pocos_de_Caldas,2022-12-31T00:00:00,1.169867549668874,1.5191941261291504,29.86035270053878,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pocrane,2022-12-31T00:00:00,1.440944881889764,1.3202879428863523,-8.373459701329638,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ponte_Nova,2022-12-31T00:00:00,1.25,1.3539921045303345,8.319368362426758,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ponto_dos_Volantes,2022-12-31T00:00:00,0.6000000000000001,0.6460658311843872,7.677638530731186,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Porto_Firme,2022-12-31T00:00:00,1.32,1.5217053890228271,15.280711289608112,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pote,2022-12-31T00:00:00,1.2,0.7086814045906067,-40.9432162841161,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pouso_Alegre,2022-12-31T00:00:00,1.5,1.3859306573867798,-7.604622840881348,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pouso_Alto,2022-12-31T00:00:00,1.5,1.6342408657073977,8.949391047159832,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pratapolis,2022-12-31T00:00:00,1.2,1.266452431678772,5.5377026398976685,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Pratinha,2022-12-31T00:00:00,1.720111731843575,1.704385757446289,-0.9142414475849908,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Presidente_Bernardes,2022-12-31T00:00:00,1.501449275362319,1.3257794380187988,-11.700018124230589,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Presidente_Kubitschek,2022-12-31T00:00:00,0.896551724137931,2.027493476867676,126.14350318908691,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Presidente_Olegario,2022-12-31T00:00:00,1.8899598393574304,2.281317949295044,20.707218311616195,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Quartel_Geral,2022-12-31T00:00:00,3.0,2.8711869716644287,-4.293767611185709,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Raul_Soares,2022-12-31T00:00:00,0.8399548532731377,1.295844793319702,54.27552900849988,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Reduto,2022-12-31T00:00:00,1.260059171597633,1.4685418605804443,16.54546815594981,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ribeirao_Vermelho,2022-12-31T00:00:00,1.32,1.6568524837493896,25.51912755677193,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Rio_Paranaiba,2022-12-31T00:00:00,1.230031446540881,1.1728850603103638,-4.645928881836759,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Rio_Pardo_de_Minas,2022-12-31T00:00:00,2.515254237288135,3.532909870147705,40.45935467568372,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Rio_Vermelho,2022-12-31T00:00:00,0.9090909090909092,0.9425978064537048,3.685758709907535,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ritapolis,2022-12-31T00:00:00,1.8000000000000005,1.6376370191574097,-9.020165602366143,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Romaria,2022-12-31T00:00:00,1.910526315789474,2.364849805831909,23.780017385141228,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Rosario_da_Limeira,2022-12-31T00:00:00,1.02,1.087393045425415,6.607161316217159,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sabinopolis,2022-12-31T00:00:00,1.32,1.3144766092300415,-0.4184386946938301,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sacramento,2022-12-31T00:00:00,1.5575892857142857,1.5824896097183228,1.5986450492703654,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santa_Barbara,2022-12-31T00:00:00,1.083333333333333,0.9274622201919556,-14.38810275151177,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santa_Barbara_do_Leste,2022-12-31T00:00:00,1.05015873015873,1.4584381580352783,38.8778778056568,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santa_Barbara_do_Monte_Verde,2022-12-31T00:00:00,1.3,0.1938574165105819,-85.08789103764755,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santa_Margarida,2022-12-31T00:00:00,1.3799999999999997,1.5479652881622314,12.171397692915347,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santa_Maria_do_Suacui,2022-12-31T00:00:00,1.0,0.826965868473053,-17.303413152694702,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santa_Rita_de_Caldas,2022-12-31T00:00:00,1.8000000000000005,1.7919487953186035,-0.4472891489664861,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santa_Rita_de_Minas,2022-12-31T00:00:00,1.019909502262443,1.225377082824707,20.14566783685022,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santa_Rita_do_Itueto,2022-12-31T00:00:00,1.6399999999999997,1.6056127548217771,-2.096783242574533,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santa_Rita_do_Sapucai,2022-12-31T00:00:00,1.14,1.5183477401733398,33.1883982608193,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santa_Rosa_da_Serra,2022-12-31T00:00:00,2.22,1.8220808506011963,-17.92428600895511,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santana_da_Vargem,2022-12-31T00:00:00,0.9900921658986176,1.704026460647583,72.10786221108935,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santana_do_Jacare,2022-12-31T00:00:00,1.5,1.4948647022247314,-0.3423531850179037,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santana_do_Manhuacu,2022-12-31T00:00:00,1.26,1.594010353088379,26.50875818161737,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santo_Antonio_do_Amparo,2022-12-31T00:00:00,1.26,1.763139247894287,39.931686340816434,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santo_Antonio_do_Grama,2022-12-31T00:00:00,1.565217391304348,2.273833513259888,45.27269668049282,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Santo_Antonio_do_Retiro,2022-12-31T00:00:00,1.2,1.388341188430786,15.69509903589885,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Bento_Abade,2022-12-31T00:00:00,1.2,1.3661460876464844,13.845507303873704,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Domingos_das_Dores,2022-12-31T00:00:00,1.2,1.5428290367126465,28.569086392720543,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Domingos_do_Prata,2022-12-31T00:00:00,1.078125,0.8392569422721863,-22.155877818232,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Francisco_de_Paula,2022-12-31T00:00:00,1.62,1.5031208992004397,-7.2147593086148545,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Francisco_do_Gloria,2022-12-31T00:00:00,0.9601476014760146,1.3966320753097534,45.46014312411346,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Geraldo,2022-12-31T00:00:00,1.561038961038961,1.099906325340271,-29.54011060632208,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Goncalo_do_Abaete,2022-12-31T00:00:00,1.5,1.8900418281555176,26.00278854370117,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Goncalo_do_Rio_Preto,2022-12-31T00:00:00,3.0,8.526782035827637,184.2260678609212,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Goncalo_do_Sapucai,2022-12-31T00:00:00,1.08,1.51751446723938,40.51059881846109,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Gotardo,2022-12-31T00:00:00,1.50025974025974,1.0893243551254272,-27.390949320760114,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Joao_Batista_do_Gloria,2022-12-31T00:00:00,1.232209737827715,1.0905269384384155,-11.498269737672638,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Joao_da_Mata,2022-12-31T00:00:00,0.959748427672956,1.2580543756484983,31.081681342143685,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Joao_del_Rei,2022-12-31T00:00:00,1.836244541484716,1.607685089111328,-12.447114053152394,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Joao_do_Manhuacu,2022-12-31T00:00:00,1.2,1.5150249004364014,26.252075036366783,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Joao_do_Manteninha,2022-12-31T00:00:00,1.2,0.6943860054016113,-42.13449954986572,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Joao_do_Paraiso,2022-12-31T00:00:00,3.09016393442623,3.2033491134643555,3.66275645693668,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Jose_da_Barra,2022-12-31T00:00:00,2.3076923076923066,1.9165277481079104,-16.950464248657187,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Jose_do_Alegre,2022-12-31T00:00:00,1.682352941176471,1.361070156097412,-19.097228483720283,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Jose_do_Mantimento,2022-12-31T00:00:00,1.499236641221374,1.5670697689056396,4.52451106244338,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Lourenco,2022-12-31T00:00:00,1.8000000000000005,5.022475242614746,179.02640236748587,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Miguel_do_Anta,2022-12-31T00:00:00,1.5,1.2105648517608645,-19.29567654927572,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Pedro_da_Uniao,2022-12-31T00:00:00,1.4700000000000002,1.8795127868652344,27.858012711920686,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Roque_de_Minas,2022-12-31T00:00:00,1.32,1.3403853178024292,1.5443422577597832,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Sebastiao_da_Bela_Vista,2022-12-31T00:00:00,1.5,1.3207025527954102,-11.953163146972656,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Sebastiao_da_Vargem_Alegre,2022-12-31T00:00:00,1.020238095238095,1.651795506477356,61.90294345869071,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Sebastiao_do_Anta,2022-12-31T00:00:00,1.8000000000000005,1.9329193830490112,7.384410169389496,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Sebastiao_do_Maranhao,2022-12-31T00:00:00,1.141666666666667,0.9228174686431884,-19.16927281957476,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Sebastiao_do_Paraiso,2022-12-31T00:00:00,1.3172147001934242,1.6214513778686523,23.09696950926473,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Tiago,2022-12-31T00:00:00,1.3210526315789468,1.5563462972640991,17.811074294892016,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Tomas_de_Aquino,2022-12-31T00:00:00,1.2,1.5940688848495483,32.839073737462364,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sao_Tome_das_Letras,2022-12-31T00:00:00,1.434375,1.3085124492645264,-8.774731205958943,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Senador_Firmino,2022-12-31T00:00:00,1.565217391304348,1.1158132553100586,-28.711930910746258,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Senador_Jose_Bento,2022-12-31T00:00:00,1.32,1.6600991487503052,25.765087026538264,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Senador_Modestino_Goncalves,2022-12-31T00:00:00,2.7000000000000006,4.447127342224121,64.70842008237481,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Senhora_de_Oliveira,2022-12-31T00:00:00,1.5,1.4718692302703855,-1.8753846486409504,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Senhora_dos_Remedios,2022-12-31T00:00:00,1.466666666666667,1.2949506044387815,-11.707913333719446,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Sericita,2022-12-31T00:00:00,1.3799999999999997,1.8528119325637813,34.261734243752336,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Serra_do_Salitre,2022-12-31T00:00:00,1.5168750000000002,1.859346985816956,22.57746919271234,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Serrania,2022-12-31T00:00:00,1.2,1.4955377578735352,24.628146489461265,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Setubinha,2022-12-31T00:00:00,1.079761904761905,1.1274867057800293,4.419937470256281,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Silvianopolis,2022-12-31T00:00:00,0.9,1.3222695589065552,46.91883987850613,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Simonesia,2022-12-31T00:00:00,1.8000000000000005,1.3940668106079102,-22.551843855116115,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Soledade_de_Minas,2022-12-31T00:00:00,1.5,3.885146617889404,159.00977452596027,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Taiobeiras,2022-12-31T00:00:00,3.14031971580817,2.855409622192383,-9.072646080638473,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Tapira,2022-12-31T00:00:00,1.8000000000000005,1.0877799987792969,-39.56777784559463,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Tapirai,2022-12-31T00:00:00,1.324520819563781,1.539487361907959,16.229759409518024,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Teixeiras,2022-12-31T00:00:00,1.5,1.5066324472427368,0.4421631495157878,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Teofilo_Otoni,2022-12-31T00:00:00,0.8181818181818183,0.7406018376350403,-9.481997622383984,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Tiros,2022-12-31T00:00:00,1.6801801801801797,1.1251286268234253,-33.03523990487923,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Tocos_do_Moji,2022-12-31T00:00:00,1.5,0.979198694229126,-34.7200870513916,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Tombos,2022-12-31T00:00:00,1.2,0.9903858304023744,-17.467847466468807,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Tres_Coracoes,2022-12-31T00:00:00,1.08,1.4509180784225464,34.34426652060614,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Tres_Pontas,2022-12-31T00:00:00,0.975023651844844,1.6442656517028809,68.63854005918346,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Tupaciguara,2022-12-31T00:00:00,2.4,2.1305572986602783,-11.2267792224884,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Turmalina,2022-12-31T00:00:00,1.205163043478261,1.8780244588851929,55.8315672761558,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Turvolandia,2022-12-31T00:00:00,1.4398692810457523,1.5167827606201172,5.341698762994927,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Ubaporanga,2022-12-31T00:00:00,1.2,1.3387773036956787,11.56477530797323,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Uberaba,2022-12-31T00:00:00,2.102941176470588,2.718001127243042,29.247606050718105,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Uberlandia,2022-12-31T00:00:00,1.681818181818182,1.55938982963562,-7.279523643287455,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Unai,2022-12-31T00:00:00,2.52010582010582,2.706305503845215,7.388566077418767,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Urucuia,2022-12-31T00:00:00,1.9193245778611627,2.3657784461975098,23.26098844802278,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Vargem_Bonita,2022-12-31T00:00:00,1.235217391304348,1.3905502557754517,12.57534629649906,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Vargem_Grande_do_Rio_Pardo,2022-12-31T00:00:00,1.8000000000000005,1.954464077949524,8.581337663862424,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Varginha,2022-12-31T00:00:00,1.020039292730845,1.402742624282837,37.51848916794373,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Varjao_de_Minas,2022-12-31T00:00:00,2.383928571428572,2.4007368087768555,0.7050646378306146,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Varzea_da_Palma,2022-12-31T00:00:00,2.5200000000000005,2.110706329345703,-16.24181232755148,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Vermelho_Novo,2022-12-31T00:00:00,0.9598214285714286,1.206527829170227,25.70336452750272,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Vicosa,2022-12-31T00:00:00,1.079768786127168,0.9999340772628784,-7.393685563983997,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Vieiras,2022-12-31T00:00:00,1.32,1.1560542583465576,-12.420131943442607,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Virginia,2022-12-31T00:00:00,1.62,1.342234492301941,-17.146018993707358,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Virginopolis,2022-12-31T00:00:00,1.314606741573034,1.615400791168213,22.880914883735823,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2022,Visconde_do_Rio_Branco,2022-12-31T00:00:00,1.6666666666666672,1.1687623262405396,-29.87426042556765,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:12:46
V38_2023,Abadia_dos_Dourados,2022-12-31T00:00:00,2.0384615384615383,2.2366111278533936,9.720545894694784,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Abre_Campo,2022-12-31T00:00:00,1.2,1.0573254823684692,-11.889543135960894,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Acucena,2022-12-31T00:00:00,1.0,0.7348668575286865,-26.513314247131348,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Agua_Boa,2022-12-31T00:00:00,0.9136363636363636,1.050390124320984,14.968073308764412,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Aguanil,2022-12-31T00:00:00,1.56,1.5396642684936523,-1.3035725324581864,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Aguas_Vermelhas,2022-12-31T00:00:00,3.0,3.120037794113159,4.001259803771973,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Aimores,2022-12-31T00:00:00,2.332558139534884,1.6220014095306396,-30.462551734977566,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Aiuruoca,2022-12-31T00:00:00,1.5,0.7296693325042725,-51.3553778330485,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Albertina,2022-12-31T00:00:00,1.44,1.2738711833953855,-11.536723375320433,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Alfenas,2022-12-31T00:00:00,0.9243951612903224,1.6667985916137695,80.31234491612426,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Almenara,2022-12-31T00:00:00,0.78,0.9124841094017028,16.985142230987545,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Alpinopolis,2022-12-31T00:00:00,1.4420494699646638,1.6678471565246582,15.658109604625936,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Alterosa,2022-12-31T00:00:00,1.080104712041885,1.559676170349121,44.40045978511007,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Alto_Caparao,2022-12-31T00:00:00,1.5,1.4013431072235107,-6.577126185099284,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Alto_Jequitiba,2022-12-31T00:00:00,0.9,1.039903163909912,15.54479598999023,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Alvarenga,2022-12-31T00:00:00,0.9,0.6082639694213867,-32.41511450873481,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Amparo_do_Serra,2022-12-31T00:00:00,1.8000000000000005,0.9753723740577698,-45.812645885679466,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Andradas,2022-12-31T00:00:00,1.26,0.8739614486694336,-30.637980264330665,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Andrelandia,2022-12-31T00:00:00,1.8000000000000005,1.2650734186172483,-29.71814341015287,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Angelandia,2022-12-31T00:00:00,1.9799126637554585,1.3829361200332642,-30.151660457075973,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Antonio_Dias,2022-12-31T00:00:00,1.5,1.5074442625045776,0.4962841669718424,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Antonio_Prado_de_Minas,2022-12-31T00:00:00,1.2,0.7832189202308655,-34.73175664742787,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Araguari,2022-12-31T00:00:00,1.919968366943456,2.321605682373047,20.918954829916704,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Araponga,2022-12-31T00:00:00,1.260041407867495,1.078525424003601,-14.405557049993556,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Arapua,2022-12-31T00:00:00,1.14,1.2857906818389893,12.788656301665736,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Araxa,2022-12-31T00:00:00,1.077872465471643,1.3769267797470093,27.744869996703148,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Arceburgo,2022-12-31T00:00:00,0.9244897959183672,1.6731905937194824,80.98529600939216,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Areado,2022-12-31T00:00:00,0.9076923076923076,1.5633504390716553,72.23352294857222,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Aricanduva,2022-12-31T00:00:00,1.2,0.9899242520332336,-17.506312330563862,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Astolfo_Dutra,2022-12-31T00:00:00,0.625,1.29353666305542,106.96586608886716,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ataleia,2022-12-31T00:00:00,0.7142857142857143,0.8310863375663757,16.3520872592926,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Baependi,2022-12-31T00:00:00,1.079558011049724,1.2283360958099363,13.781388608801665,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Bambui,2022-12-31T00:00:00,1.5,1.4103437662124634,-5.977082252502441,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Bandeira,2022-12-31T00:00:00,1.5,0.9569984078407288,-36.200106143951416,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Bandeira_do_Sul,2022-12-31T00:00:00,1.110344827586207,1.3235113620758057,19.198228261485603,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Berilo,2022-12-31T00:00:00,1.5625,1.143088459968567,-26.84233856201172,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Berizal,2022-12-31T00:00:00,3.570967741935484,3.44429349899292,-3.5473365232334944,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Boa_Esperanca,2022-12-31T00:00:00,0.9726256983240223,1.8663175106048584,91.88445399096476,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Bocaiuva,2022-12-31T00:00:00,3.6000000000000005,1.6221213340759275,-54.94107405344646,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Bom_Jesus_da_Penha,2022-12-31T00:00:00,1.6298200514138823,1.5965498685836792,-2.041340870812146,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Bom_Jesus_do_Amparo,2022-12-31T00:00:00,1.8000000000000005,0.6806187629699707,-62.1878465016683,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Bom_Jesus_do_Galho,2022-12-31T00:00:00,0.7801587301587303,0.6573703289031982,-15.738899855744693,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Bom_Sucesso,2022-12-31T00:00:00,1.440136054421769,1.1223708391189575,-22.064944095188128,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Bonfinopolis_de_Minas,2022-12-31T00:00:00,3.3,2.3228554725646973,-29.6104402253122,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Borda_da_Mata,2022-12-31T00:00:00,1.2,1.569634199142456,30.802849928538013,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Botelhos,2022-12-31T00:00:00,0.9,1.0287044048309326,14.300489425659176,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Botumirim,2022-12-31T00:00:00,0.7241379310344828,0.7803528308868408,7.7630099796113505,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Brazopolis,2022-12-31T00:00:00,1.200934579439252,2.2029905319213867,83.43967853353185,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Bueno_Brandao,2022-12-31T00:00:00,1.440196078431373,1.263697624206543,-12.255168366870429,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Buritis,2022-12-31T00:00:00,3.0,3.0226738452911377,0.7557948430379231,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Buritizeiro,2022-12-31T00:00:00,3.0,2.488353490829468,-17.05488363901774,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cabo_Verde,2022-12-31T00:00:00,1.35,1.3748726844787598,1.8424210725007168,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cachoeira_de_Minas,2022-12-31T00:00:00,1.5,1.317936658859253,-12.137556076049805,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Caete,2022-12-31T00:00:00,1.5333333333333332,1.077499270439148,-29.728308449620783,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Caiana,2022-12-31T00:00:00,0.9,0.8313665390014648,-7.625940110948353,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cajuri,2022-12-31T00:00:00,1.050602409638554,0.9437912106513976,-10.16666228891511,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Caldas,2022-12-31T00:00:00,1.2,0.9742263555526732,-18.81447037061056,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Camacho,2022-12-31T00:00:00,1.380176211453745,1.2337443828582764,-10.609647332004906,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cambuquira,2022-12-31T00:00:00,1.32,1.4159061908721924,7.26562052062063,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Campanha,2022-12-31T00:00:00,1.266469038208169,1.3594341278076172,7.340494460960335,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Campestre,2022-12-31T00:00:00,1.020018115942029,1.214035987854004,19.02102216417905,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Campo_Belo,2022-12-31T00:00:00,1.2,1.1441222429275513,-4.65647975603739,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Campo_do_Meio,2022-12-31T00:00:00,1.580968858131488,1.4674965143203735,-7.177392725194152,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Campos_Altos,2022-12-31T00:00:00,1.680042238648363,1.2634520530700684,-24.796411423170667,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Campos_Gerais,2022-12-31T00:00:00,1.535771358328211,1.5822899341583252,3.029003997102319,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cana_Verde,2022-12-31T00:00:00,1.02,1.224295139312744,20.02893522673962,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Canaa,2022-12-31T00:00:00,1.320338983050847,1.028448462486267,-22.107240967022104,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Candeias,2022-12-31T00:00:00,1.020017406440383,1.2313711643218994,20.720603055107706,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Caparao,2022-12-31T00:00:00,1.32,1.005099177360535,-23.856122927232228,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Capela_Nova,2022-12-31T00:00:00,2.1016393442622947,1.7949141263961792,-14.594569648855732,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Capelinha,2022-12-31T00:00:00,1.576751592356688,1.2684998512268066,-19.54979735705569,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Capetinga,2022-12-31T00:00:00,1.407056229327453,1.9575605392456048,39.12454232062094,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Capitao_Eneas,2022-12-31T00:00:00,2.6000000000000005,0.6995888948440552,-73.09273481369019,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Capitolio,2022-12-31T00:00:00,1.08,0.9823012351989746,-9.046181926020877,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Caputira,2022-12-31T00:00:00,1.440044247787611,0.9162106513977052,-36.37621532773658,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Carai,2022-12-31T00:00:00,1.2,1.0835046768188477,-9.707943598429358,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Caranaiba,2022-12-31T00:00:00,3.405405405405405,0.8037036657333374,-76.39917806973533,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Carangola,2022-12-31T00:00:00,1.02,0.885603666305542,-13.176111146515494,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Caratinga,2022-12-31T00:00:00,1.620022123893805,0.7072668075561523,-56.342151312341294,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Careacu,2022-12-31T00:00:00,1.2,1.2504774332046509,4.206452767054244,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Carmo_da_Cachoeira,2022-12-31T00:00:00,1.2,1.3247722387313845,10.397686560948694,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Carmo_da_Mata,2022-12-31T00:00:00,1.56,0.930528163909912,-40.35075872372359,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Carmo_de_Minas,2022-12-31T00:00:00,1.14,1.2199265956878662,7.011104884900554,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Carmo_do_Paranaiba,2022-12-31T00:00:00,1.392969472710453,1.7103980779647827,22.787908240133525,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Carmo_do_Rio_Claro,2022-12-31T00:00:00,1.619555143651529,1.389925479888916,-14.178564074383942,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Carmopolis_de_Minas,2022-12-31T00:00:00,1.8000000000000005,1.3121662139892578,-27.1018770005968,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Carrancas,2022-12-31T00:00:00,1.6785714285714293,1.057426929473877,-37.0043531377265,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Carvalhopolis,2022-12-31T00:00:00,1.44,1.136207938194275,-21.096670958730908,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Casa_Grande,2022-12-31T00:00:00,2.107692307692308,0.7100526690483093,-66.31136971668606,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cascalho_Rico,2022-12-31T00:00:00,2.580434782608696,2.000243663787842,-22.4842388085588,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cassia,2022-12-31T00:00:00,1.413626373626374,1.498518943786621,6.005304636646823,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cataguases,2022-12-31T00:00:00,1.5,0.4862797856330871,-67.58134762446085,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Catas_Altas_da_Noruega,2022-12-31T00:00:00,1.0,0.7819678783416748,-21.80321216583252,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Catuji,2022-12-31T00:00:00,1.3230769230769233,1.1828105449676514,-10.601528578026365,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Caxambu,2022-12-31T00:00:00,1.4387755102040822,1.6703238487243652,16.09343062055867,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Chale,2022-12-31T00:00:00,1.44,1.2692939043045044,-11.854589978853856,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Claraval,2022-12-31T00:00:00,1.289915966386555,1.450863480567932,12.477364291585593,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Claudio,2022-12-31T00:00:00,1.140522875816993,1.021153688430786,-10.466180899764844,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Coimbra,2022-12-31T00:00:00,1.799054373522459,1.2895011901855469,-28.32338982280076,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Conceicao_da_Aparecida,2022-12-31T00:00:00,1.53,1.773625135421753,15.923211465474049,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Conceicao_da_Barra_de_Minas,2022-12-31T00:00:00,1.370833333333333,1.709191083908081,24.682632260771907,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Conceicao_das_Pedras,2022-12-31T00:00:00,1.375,1.2305816411972046,-10.50315336747603,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Conceicao_de_Ipanema,2022-12-31T00:00:00,1.5,1.2974284887313845,-13.504767417907717,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Conceicao_do_Rio_Verde,2022-12-31T00:00:00,1.5,1.601011872291565,6.734124819437663,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Conceicao_dos_Ouros,2022-12-31T00:00:00,1.261168384879725,1.2962301969528198,2.780105534951112,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Congonhal,2022-12-31T00:00:00,1.080597014925373,1.5024473667144775,39.03863752744476,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Congonhas_do_Norte,2022-12-31T00:00:00,0.9,0.7183520793914795,-20.183102289835613,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Conselheiro_Pena,2022-12-31T00:00:00,1.8000000000000005,1.3216480016708374,-26.575111018286822,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Coqueiral,2022-12-31T00:00:00,1.2,1.4223641157150269,18.530342976252243,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cordislandia,2022-12-31T00:00:00,1.260122699386503,1.386605143547058,10.037311780998296,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Coroaci,2022-12-31T00:00:00,2.1,1.551429271697998,-26.12241563342867,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Coromandel,2022-12-31T00:00:00,1.260025542784164,1.459747076034546,15.850594013282889,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Corrego_Danta,2022-12-31T00:00:00,1.5,0.9344894886016846,-37.700700759887695,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Corrego_Fundo,2022-12-31T00:00:00,1.079051383399209,0.9800947308540344,-9.170708093014357,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Corrego_Novo,2022-12-31T00:00:00,1.377777777777778,1.087133765220642,-21.095129943663085,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cristais,2022-12-31T00:00:00,1.059063136456212,1.4174840450286863,33.84320502097788,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cristina,2022-12-31T00:00:00,1.320183486238532,1.669166088104248,26.43440139219114,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cruzeiro_da_Fortaleza,2022-12-31T00:00:00,1.5598526703499078,1.824973225593567,16.996512573471886,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cruzilia,2022-12-31T00:00:00,1.5027322404371577,1.842703342437744,22.623531514948127,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cuparaque,2022-12-31T00:00:00,1.02,1.1607978343963623,13.80370925454532,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Datas,2022-12-31T00:00:00,0.75,1.087016224861145,44.935496648152665,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Delfinopolis,2022-12-31T00:00:00,1.3799999999999997,1.0421230792999268,-24.483834833338623,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Desterro_de_Entre_Rios,2022-12-31T00:00:00,1.8000000000000005,1.4731087684631348,-18.160623974270305,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Diamantina,2022-12-31T00:00:00,2.965183752417796,3.193591833114624,7.702999198973283,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Divinesia,2022-12-31T00:00:00,2.2230769230769227,0.9860411286354064,-55.6452087465042,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Divino,2022-12-31T00:00:00,1.08,0.8870515823364258,-17.86559422810873,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Divisa_Nova,2022-12-31T00:00:00,1.260204081632653,1.5489501953125,22.91264707742916,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Divisopolis,2022-12-31T00:00:00,1.259523809523809,1.162540078163147,-7.700031601413627,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Dom_Cavati,2022-12-31T00:00:00,0.6000000000000001,0.6200736165046692,3.345602750778183,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Dom_Vicoso,2022-12-31T00:00:00,1.320588235294118,1.0568965673446655,-19.967743230025352,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Dores_do_Turvo,2022-12-31T00:00:00,1.2,0.7777823805809021,-35.18480161825816,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Doresopolis,2022-12-31T00:00:00,1.32,0.9946739077568054,-24.64591607902989,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Durande,2022-12-31T00:00:00,1.5,1.384026288986206,-7.73158073425293,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Eloi_Mendes,2022-12-31T00:00:00,1.090201870999508,1.0859273672103882,-0.3920836959489858,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Entre_Folhas,2022-12-31T00:00:00,1.2,0.7783029675483704,-35.14141937096913,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Entre_Rios_de_Minas,2022-12-31T00:00:00,1.8000000000000005,1.8001322746276855,0.00734859042696,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ervalia,2022-12-31T00:00:00,1.2,0.7948559522628784,-33.76200397809346,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Esmeraldas,2022-12-31T00:00:00,2.111111111111112,1.4974106550216677,-29.070021604236818,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Espera_Feliz,2022-12-31T00:00:00,1.2,0.5128825902938843,-57.25978414217631,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Espirito_Santo_do_Dourado,2022-12-31T00:00:00,1.319148936170213,1.201857089996338,-8.891478661567929,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Estrela_do_Indaia,2022-12-31T00:00:00,1.86,1.732003927230835,-6.88150928866478,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Estrela_do_Sul,2022-12-31T00:00:00,1.460045146726862,1.979575276374817,35.583155138225735,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Eugenopolis,2022-12-31T00:00:00,1.8000000000000005,1.3031156063079834,-27.604688538445377,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Fama,2022-12-31T00:00:00,1.379787234042553,1.4170546531677246,2.7009540460802874,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Faria_Lemos,2022-12-31T00:00:00,1.200305810397553,0.8087371587753296,-32.62240740903621,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Felicio_dos_Santos,2022-12-31T00:00:00,3.306397306397306,3.099696636199951,-6.251537581325288,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ferros,2022-12-31T00:00:00,1.230769230769231,0.834336519241333,-32.21015781164171,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Fervedouro,2022-12-31T00:00:00,1.4399108138238568,0.8368707895278931,-41.88037331940846,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Formiga,2022-12-31T00:00:00,1.8000000000000005,1.27046799659729,-29.418444633483897,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Formoso,2022-12-31T00:00:00,3.3607142857142858,2.7009294033050537,-19.63228130441924,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Fortaleza_de_Minas,2022-12-31T00:00:00,1.5,0.5062931180000305,-66.24712546666464,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Franciscopolis,2022-12-31T00:00:00,1.255555555555556,1.376865267753601,9.661835484800047,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Frei_Gaspar,2022-12-31T00:00:00,1.133333333333333,0.9455504417419434,-16.569078669828507,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Grao_Mogol,2022-12-31T00:00:00,1.177777777777778,0.7496294975280762,-36.35221247403128,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Guape,2022-12-31T00:00:00,1.262758620689655,1.3320419788360596,5.486666811157103,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Guaraciaba,2022-12-31T00:00:00,1.8000000000000005,6.394309520721436,255.23941781785743,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Guaranesia,2022-12-31T00:00:00,1.086968085106383,1.7086083889007568,57.190299541640464,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Guarani,2022-12-31T00:00:00,1.2,1.3117891550064087,9.315762917200727,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Guarda-Mor,2022-12-31T00:00:00,1.858757062146893,1.9603594541549685,5.466146925662409,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Guaxupe,2022-12-31T00:00:00,1.14,1.2602014541625977,10.54398720724542,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Guimarania,2022-12-31T00:00:00,1.2220588235294123,1.4294296503067017,16.96897258827397,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Guiricema,2022-12-31T00:00:00,2.4,2.292652368545532,-4.472817977269488,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Heliodora,2022-12-31T00:00:00,1.080140597539543,1.1587445735931396,7.277198564024806,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Iapu,2022-12-31T00:00:00,1.5614035087719298,1.456924319267273,-6.69136382220836,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ibia,2022-12-31T00:00:00,1.14,1.1756563186645508,3.127747251276393,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ibiraci,2022-12-31T00:00:00,1.377007874015748,1.8860270977020264,36.96560007328301,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ibitiura_de_Minas,2022-12-31T00:00:00,1.3799999999999997,1.2467609643936155,-9.655002580172752,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ibituruna,2022-12-31T00:00:00,1.2,1.596325159072876,33.027096589406334,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ijaci,2022-12-31T00:00:00,1.173913043478261,1.2505521774291992,6.528518818042888,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ilicinea,2022-12-31T00:00:00,1.080069324090121,1.6234779357910156,50.31238269438645,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Imbe_de_Minas,2022-12-31T00:00:00,1.3799999999999997,1.1551562547683716,-16.29302501678465,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Inconfidentes,2022-12-31T00:00:00,1.739917695473251,1.2867730855941772,-26.04402559144156,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Indaiabira,2022-12-31T00:00:00,2.1723404255319148,2.438426971435547,12.24884197597523,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Indianopolis,2022-12-31T00:00:00,1.8000000000000005,2.100623607635498,16.70131153530543,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ingai,2022-12-31T00:00:00,1.380228136882129,1.563075065612793,13.247587398392463,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Inhapim,2022-12-31T00:00:00,1.8000000000000005,1.1880340576171875,-33.998107910156264,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Irai_de_Minas,2022-12-31T00:00:00,2.386666666666667,2.089476585388184,-12.452098377590092,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Itabirinha,2022-12-31T00:00:00,0.8674242424242423,0.9089418649673462,4.786311070471364,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Itacambira,2022-12-31T00:00:00,0.75,0.2275207936763763,-69.66389417648315,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Itaipe,2022-12-31T00:00:00,0.9604651162790696,0.844329297542572,-12.0916227740179,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Itajuba,2022-12-31T00:00:00,1.068965517241379,0.8468020558357239,-20.783033486335487,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Itamarandiba,2022-12-31T00:00:00,2.136,1.5625267028808594,-26.8480008014579,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Itamarati_de_Minas,2022-12-31T00:00:00,1.261538461538461,1.1151570081710815,-11.603407888877648,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Itambacuri,2022-12-31T00:00:00,0.9620253164556964,0.9813480377197266,2.008546026129458,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Itamogi,2022-12-31T00:00:00,1.32,1.2151165008544922,-7.945719632235444,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Itanhomi,2022-12-31T00:00:00,1.081818181818182,1.0027111768722534,-7.312412221892557,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Itapecerica,2022-12-31T00:00:00,1.040506329113924,1.02436101436615,-1.5516786679734274,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ituiutaba,2022-12-31T00:00:00,1.75,1.58440363407135,-9.462649481637138,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Itumirim,2022-12-31T00:00:00,1.249307479224377,1.3294858932495115,6.41782870578129,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Itutinga,2022-12-31T00:00:00,1.8000000000000005,1.240243673324585,-31.09757370418973,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Jacui,2022-12-31T00:00:00,1.08,1.2903635501861572,19.47810649871825,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Jacutinga,2022-12-31T00:00:00,1.289920424403183,1.2636462450027466,-2.036883741304653,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Jequeri,2022-12-31T00:00:00,1.8000000000000005,1.2849488258361816,-28.613954120212146,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Jequitinhonha,2022-12-31T00:00:00,2.4,1.7525925636291504,-26.9753098487854,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Jesuania,2022-12-31T00:00:00,1.2,1.3443013429641724,12.025111913681034,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Joao_Pinheiro,2022-12-31T00:00:00,2.4,2.314149856567383,-3.57708930969238,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Jose_Goncalves_de_Minas,2022-12-31T00:00:00,1.5,1.5058350563049316,0.3890037536621094,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Juiz_de_Fora,2022-12-31T00:00:00,1.5714285714285707,0.6642318367958069,-57.73070129481227,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Juruaia,2022-12-31T00:00:00,1.5,1.6561187505722046,10.40791670481364,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ladainha,2022-12-31T00:00:00,0.6000000000000001,0.8415796756744385,40.26327927907306,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Lagoa_Dourada,2022-12-31T00:00:00,1.5,0.7879388928413391,-47.470740477244064,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Lagoa_Formosa,2022-12-31T00:00:00,2.088607594936709,1.5359103679656982,-26.462473291339293,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Lagoa_Grande,2022-12-31T00:00:00,2.4,0.7333765029907227,-69.44264570871988,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Lajinha,2022-12-31T00:00:00,1.419975786924939,1.5309679508209229,7.816482852594656,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Lambari,2022-12-31T00:00:00,1.2,1.110719919204712,-7.440006732940671,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Lamim,2022-12-31T00:00:00,2.4,1.0368858575820925,-56.79642260074616,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Lavras,2022-12-31T00:00:00,1.260078277886497,1.617436408996582,28.35999456394681,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Luisburgo,2022-12-31T00:00:00,1.5,1.3244571685791016,-11.702855428059896,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Luminarias,2022-12-31T00:00:00,1.380229885057471,1.5606024265289309,13.06829705864173,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Machado,2022-12-31T00:00:00,0.964047619047619,1.1123497486114502,15.383278443272186,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Malacacheta,2022-12-31T00:00:00,1.5595238095238098,1.5816651582717896,1.4197506067406889,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Manhuacu,2022-12-31T00:00:00,1.44,0.812857985496521,-43.55152878496381,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Manhumirim,2022-12-31T00:00:00,1.3799999999999997,1.2100627422332764,-12.314294041066908,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Mantena,2022-12-31T00:00:00,0.75,0.5896080136299133,-21.385598182678223,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Mar_de_Espanha,2022-12-31T00:00:00,2.1,0.7875831127166748,-62.496042251586914,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Maria_da_Fe,2022-12-31T00:00:00,1.2,1.3140456676483154,9.503805637359624,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Martins_Soares,2022-12-31T00:00:00,1.3799999999999997,1.304007053375244,-5.506735262663446,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Mata_Verde,2022-12-31T00:00:00,1.6792452830188678,1.4597620964050293,-13.0703470680151,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Matipo,2022-12-31T00:00:00,1.26,0.9674149751663208,-23.221033716958665,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Matutina,2022-12-31T00:00:00,1.8097165991902835,1.5960912704467771,-11.804352617370464,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Medeiros,2022-12-31T00:00:00,1.5,1.186012625694275,-20.93249162038168,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Minas_Novas,2022-12-31T00:00:00,1.7848101265822778,1.501591444015503,-15.868280796294483,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Miradouro,2022-12-31T00:00:00,0.96,1.0375089645385742,8.073850472768164,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Mirai,2022-12-31T00:00:00,1.2,0.8398370742797852,-30.013577143351235,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Moeda,2022-12-31T00:00:00,1.25,1.6402053833007812,31.2164306640625,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Monsenhor_Paulo,2022-12-31T00:00:00,1.23,1.2911921739578247,4.974973492506075,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Monte_Alegre_de_Minas,2022-12-31T00:00:00,2.3296703296703294,2.730588436126709,17.209220607325733,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Monte_Belo,2022-12-31T00:00:00,0.96,1.63946270942688,70.77736556530002,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Monte_Carmelo,2022-12-31T00:00:00,1.7458874458874465,2.123241186141968,21.61386412070281,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Monte_Formoso,2022-12-31T00:00:00,0.6000000000000001,0.8497729301452637,41.62882169087726,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Monte_Santo_de_Minas,2022-12-31T00:00:00,1.4699677072120565,1.7066370248794556,16.100307272481977,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Monte_Siao,2022-12-31T00:00:00,1.2,1.7391084432601929,44.92570360501608,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Muriae,2022-12-31T00:00:00,0.9897142857142858,0.8144800662994385,-17.70553602632695,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Mutum,2022-12-31T00:00:00,1.379940564635958,1.3426172733306885,-2.7047028155966784,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Muzambinho,2022-12-31T00:00:00,1.43993993993994,1.3740370273590088,-4.576782041595429,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Natercia,2022-12-31T00:00:00,1.4399193548387097,1.3632867336273191,-5.32200785786189,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Nazareno,2022-12-31T00:00:00,1.319811320754717,1.3954966068267822,5.734553483658974,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Nepomuceno,2022-12-31T00:00:00,0.8699884125144843,1.533571481704712,76.27493190079467,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ninheira,2022-12-31T00:00:00,2.9401197604790417,2.634095430374145,-10.408566828415005,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Nova_Belem,2022-12-31T00:00:00,0.96,1.0163511037826538,5.869906644026455,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Nova_Era,2022-12-31T00:00:00,1.5,1.348555564880371,-10.096295674641926,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Nova_Ponte,2022-12-31T00:00:00,2.710714285714286,2.5021843910217285,-7.692802439251127,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Nova_Resende,2022-12-31T00:00:00,1.5,1.4243708848953247,-5.0419410069783535,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Novo_Cruzeiro,2022-12-31T00:00:00,1.180722891566265,1.1123028993606567,-5.794754441903565,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Novorizonte,2022-12-31T00:00:00,1.461538461538461,1.2959389686584473,-11.330491618106208,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Olimpio_Noronha,2022-12-31T00:00:00,1.2,1.1183165311813354,-6.806955734888708,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Oliveira,2022-12-31T00:00:00,1.535560504825538,1.2601226568222046,-17.93728395187054,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Orizania,2022-12-31T00:00:00,1.5,1.3841670751571655,-7.722194989522298,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ouro_Fino,2022-12-31T00:00:00,1.2,1.1031973361968994,-8.06688865025838,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ouro_Verde_de_Minas,2022-12-31T00:00:00,2.0,1.340442419052124,-32.977879047393785,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Padre_Paraiso,2022-12-31T00:00:00,0.6000000000000001,0.5336421728134155,-11.059637864430758,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Paracatu,2022-12-31T00:00:00,2.4,2.542577743530273,5.940739313761397,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Paraguacu,2022-12-31T00:00:00,1.043954802259887,1.01344096660614,-2.922907733906915,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Paraisopolis,2022-12-31T00:00:00,1.322222222222222,0.8548404574394226,-35.348200697858786,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Passa_Tempo,2022-12-31T00:00:00,1.507692307692308,1.1645675897598269,-22.75827210776662,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Passos,2022-12-31T00:00:00,1.290038314176245,1.30945086479187,1.5048041908756005,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Patis,2022-12-31T00:00:00,2.044444444444444,2.0117712020874023,-1.598147723985726,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Patos_de_Minas,2022-12-31T00:00:00,1.91614730878187,1.5332027673721311,-19.985130561448507,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Patrocinio,2022-12-31T00:00:00,0.9438953724513282,1.3529305458068848,43.33480015833519,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Paula_Candido,2022-12-31T00:00:00,1.6198529411764713,1.1481014490127563,-29.12310618895379,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pecanha,2022-12-31T00:00:00,2.287671232876712,1.4259135723114014,-37.66964624028005,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pedra_Azul,2022-12-31T00:00:00,1.5333333333333332,1.1854372024536133,-22.6888781008513,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pedra_Bonita,2022-12-31T00:00:00,1.8000000000000005,1.0131527185440063,-43.71373785866632,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pedra_Dourada,2022-12-31T00:00:00,1.2,0.8037266731262207,-33.022777239481606,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pedra_do_Anta,2022-12-31T00:00:00,1.438297872340426,0.7441157698631287,-48.26414026099551,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pedralva,2022-12-31T00:00:00,1.320091324200913,1.840877652168274,39.45078029223525,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pedrinopolis,2022-12-31T00:00:00,2.02051282051282,1.3606383800506592,-32.6587603782034,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Perdizes,2022-12-31T00:00:00,1.501272727272727,1.4043169021606443,-6.458241953693281,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Perdoes,2022-12-31T00:00:00,1.259859154929577,1.4950016736984253,18.664190981093608,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Piedade_de_Caratinga,2022-12-31T00:00:00,1.56,1.2108193635940552,-22.38337412858621,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pimenta,2022-12-31T00:00:00,1.3502325581395351,1.213064670562744,-10.158834250434056,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Piracema,2022-12-31T00:00:00,1.0,1.0779430866241455,7.794308662414551,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Piranga,2022-12-31T00:00:00,1.8000000000000005,1.8303108215332031,1.6839345296223809,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pirangucu,2022-12-31T00:00:00,1.333333333333333,1.537140965461731,15.285572409629848,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Piranguinho,2022-12-31T00:00:00,1.380549682875264,1.6080365180969238,16.477989748827742,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pirapora,2022-12-31T00:00:00,3.3595505617977524,2.89575457572937,-13.80529858196857,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Piumhi,2022-12-31T00:00:00,1.2,1.473128080368042,22.7606733640035,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Poco_Fundo,2022-12-31T00:00:00,1.079978925184405,0.7874127626419067,-27.08998812106847,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pocos_de_Caldas,2022-12-31T00:00:00,1.169867549668874,1.0599963665008545,-9.391762614418877,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pocrane,2022-12-31T00:00:00,1.440944881889764,1.3475022315979004,-6.484817807140253,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ponte_Nova,2022-12-31T00:00:00,1.25,1.122686505317688,-10.18507957458496,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ponto_dos_Volantes,2022-12-31T00:00:00,0.6000000000000001,0.5188406109809875,-13.52656483650209,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Porto_Firme,2022-12-31T00:00:00,1.32,1.3182257413864136,-0.1344135313323096,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pote,2022-12-31T00:00:00,1.2,0.695568859577179,-42.03592836856842,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pouso_Alegre,2022-12-31T00:00:00,1.5,1.1891430616378784,-20.723795890808105,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pouso_Alto,2022-12-31T00:00:00,1.5,1.378182053565979,-8.121196428934734,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pratapolis,2022-12-31T00:00:00,1.2,1.371188402175903,14.26570018132528,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pratinha,2022-12-31T00:00:00,1.720111731843575,1.41877543926239,-17.518413891533648,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Presidente_Bernardes,2022-12-31T00:00:00,1.501449275362319,1.3835434913635254,-7.852798355132004,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Presidente_Kubitschek,2022-12-31T00:00:00,0.896551724137931,1.06831955909729,19.15872005315927,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Presidente_Olegario,2022-12-31T00:00:00,1.8899598393574304,1.8823777437210083,-0.401177605922024,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Quartel_Geral,2022-12-31T00:00:00,3.0,2.839478015899658,-5.350732803344727,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Raul_Soares,2022-12-31T00:00:00,0.8399548532731377,1.2664239406585691,50.77285829393878,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Reduto,2022-12-31T00:00:00,1.260059171597633,1.083627700805664,-14.001840133290798,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ribeirao_Vermelho,2022-12-31T00:00:00,1.32,1.4290990829467771,8.26508204142252,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Rio_Paranaiba,2022-12-31T00:00:00,1.230031446540881,1.2315407991409302,0.1227084562995338,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Rio_Pardo_de_Minas,2022-12-31T00:00:00,2.515254237288135,2.974468469619751,18.257169614262363,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Rio_Vermelho,2022-12-31T00:00:00,0.9090909090909092,0.9906124472618104,8.967369198799137,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ritapolis,2022-12-31T00:00:00,1.8000000000000005,1.419583797454834,-21.134233474731456,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Romaria,2022-12-31T00:00:00,1.910526315789474,2.273841381072998,19.016491020349736,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Rosario_da_Limeira,2022-12-31T00:00:00,1.02,0.5739916563034058,-43.726308205548456,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sabinopolis,2022-12-31T00:00:00,1.32,1.0982763767242432,-16.79724418755734,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sacramento,2022-12-31T00:00:00,1.5575892857142857,1.3852194547653198,-11.066449450435185,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santa_Barbara,2022-12-31T00:00:00,1.083333333333333,0.7599784135818481,-29.84814643859861,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santa_Barbara_do_Leste,2022-12-31T00:00:00,1.05015873015873,0.6660723686218262,-36.57412451152501,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santa_Barbara_do_Monte_Verde,2022-12-31T00:00:00,1.3,0.7043153047561646,-45.82189963414119,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santa_Margarida,2022-12-31T00:00:00,1.3799999999999997,0.80863356590271,-41.40336478965869,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santa_Maria_do_Suacui,2022-12-31T00:00:00,1.0,0.7596414089202881,-24.03585910797119,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santa_Rita_de_Caldas,2022-12-31T00:00:00,1.8000000000000005,1.57035231590271,-12.758204672071685,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santa_Rita_de_Minas,2022-12-31T00:00:00,1.019909502262443,0.9649686813354492,-5.386832930286431,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santa_Rita_do_Itueto,2022-12-31T00:00:00,1.6399999999999997,1.4192898273468018,-13.457937356902312,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santa_Rita_do_Sapucai,2022-12-31T00:00:00,1.14,1.583512544631958,38.90460917824194,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santa_Rosa_da_Serra,2022-12-31T00:00:00,2.22,1.4522091150283811,-34.58517499872155,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santana_da_Vargem,2022-12-31T00:00:00,0.9900921658986176,1.5242102146148682,53.94629582100367,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santana_do_Jacare,2022-12-31T00:00:00,1.5,0.8730582594871521,-41.796116034189865,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santana_do_Manhuacu,2022-12-31T00:00:00,1.26,1.1748077869415283,-6.761286750672356,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santo_Antonio_do_Amparo,2022-12-31T00:00:00,1.26,1.0979913473129272,-12.857829578339109,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santo_Antonio_do_Grama,2022-12-31T00:00:00,1.565217391304348,2.9753293991088867,90.0904893875122,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santo_Antonio_do_Retiro,2022-12-31T00:00:00,1.2,1.4079933166503906,17.332776387532554,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Bento_Abade,2022-12-31T00:00:00,1.2,1.422316312789917,18.52635939915975,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Domingos_das_Dores,2022-12-31T00:00:00,1.2,1.149486780166626,-4.209434986114498,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Domingos_do_Prata,2022-12-31T00:00:00,1.078125,0.5390027761459351,-50.0055396038553,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Francisco_de_Paula,2022-12-31T00:00:00,1.62,1.396861553192139,-13.773978198016138,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Francisco_do_Gloria,2022-12-31T00:00:00,0.9601476014760146,0.4031316637992859,-58.01357383181917,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Geraldo,2022-12-31T00:00:00,1.561038961038961,0.9508413672447203,-39.08919694023005,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Goncalo_do_Abaete,2022-12-31T00:00:00,1.5,1.6986806392669678,13.245375951131184,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Goncalo_do_Rio_Preto,2022-12-31T00:00:00,3.0,4.06998348236084,35.66611607869466,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Goncalo_do_Sapucai,2022-12-31T00:00:00,1.08,1.170588731765747,8.387845533865462,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Gotardo,2022-12-31T00:00:00,1.50025974025974,1.1161623001098633,-25.602062752372323,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Joao_Batista_do_Gloria,2022-12-31T00:00:00,1.232209737827715,1.3206614255905151,7.178298064640617,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Joao_da_Mata,2022-12-31T00:00:00,0.959748427672956,0.8674275875091553,-9.619274958089328,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Joao_del_Rei,2022-12-31T00:00:00,1.836244541484716,1.282137393951416,-30.17610862904297,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Joao_do_Manhuacu,2022-12-31T00:00:00,1.2,1.0205905437469482,-14.950788021087645,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Joao_do_Manteninha,2022-12-31T00:00:00,1.2,0.7139464616775513,-40.50446152687073,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Joao_do_Paraiso,2022-12-31T00:00:00,3.09016393442623,2.658607244491577,-13.96549500584288,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Jose_da_Barra,2022-12-31T00:00:00,2.3076923076923066,1.2967075109481812,-43.809341192245455,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Jose_do_Alegre,2022-12-31T00:00:00,1.682352941176471,2.0251805782318115,20.37786653825449,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Jose_do_Mantimento,2022-12-31T00:00:00,1.499236641221374,1.4005552530288696,-6.582108886567248,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Lourenco,2022-12-31T00:00:00,1.8000000000000005,0.5112545490264893,-71.59696949852837,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Miguel_do_Anta,2022-12-31T00:00:00,1.5,1.0620250701904297,-29.198328653971355,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Pedro_da_Uniao,2022-12-31T00:00:00,1.4700000000000002,1.6129045486450195,9.721397867008116,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Roque_de_Minas,2022-12-31T00:00:00,1.32,1.1739012002944946,-11.068090886780714,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Sebastiao_da_Bela_Vista,2022-12-31T00:00:00,1.5,1.1802074909210205,-21.319500605265297,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Sebastiao_da_Vargem_Alegre,2022-12-31T00:00:00,1.020238095238095,0.6352536678314209,-37.734763013022906,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Sebastiao_do_Anta,2022-12-31T00:00:00,1.8000000000000005,1.4555597305297852,-19.135570526123058,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Sebastiao_do_Maranhao,2022-12-31T00:00:00,1.141666666666667,0.9197097420692444,-19.44148244648957,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Sebastiao_do_Paraiso,2022-12-31T00:00:00,1.3172147001934242,1.2908501625061035,-2.001536855263555,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Tiago,2022-12-31T00:00:00,1.3210526315789468,1.0444070100784302,-20.94130202593553,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Tomas_de_Aquino,2022-12-31T00:00:00,1.2,1.6229000091552734,35.241667429606125,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Tome_das_Letras,2022-12-31T00:00:00,1.434375,1.5079776048660278,5.131336286956191,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Senador_Firmino,2022-12-31T00:00:00,1.565217391304348,1.348363161087036,-13.854575819439363,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Senador_Jose_Bento,2022-12-31T00:00:00,1.32,1.041746735572815,-21.07979275963524,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Senador_Modestino_Goncalves,2022-12-31T00:00:00,2.7000000000000006,2.9968531131744385,10.994559747201398,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Senhora_de_Oliveira,2022-12-31T00:00:00,1.5,1.4780282974243164,-1.4647801717122395,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Senhora_dos_Remedios,2022-12-31T00:00:00,1.466666666666667,0.8293581604957581,-43.45285269347106,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sericita,2022-12-31T00:00:00,1.3799999999999997,0.7378014326095581,-46.53612807177114,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Serra_do_Salitre,2022-12-31T00:00:00,1.5168750000000002,1.4682905673980713,-3.2029292197398536,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Serrania,2022-12-31T00:00:00,1.2,1.2481062412261963,4.008853435516362,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Setubinha,2022-12-31T00:00:00,1.079761904761905,0.8668303489685059,-19.720232289576096,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Silvianopolis,2022-12-31T00:00:00,0.9,0.8857541680335999,-1.5828702184889076,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Simonesia,2022-12-31T00:00:00,1.8000000000000005,0.857446014881134,-52.36411028438145,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Soledade_de_Minas,2022-12-31T00:00:00,1.5,0.617729902267456,-58.81800651550293,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Taiobeiras,2022-12-31T00:00:00,3.14031971580817,2.4587321281433105,-21.70440112303823,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Tapira,2022-12-31T00:00:00,1.8000000000000005,0.9042909145355223,-49.76161585913765,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Tapirai,2022-12-31T00:00:00,1.324520819563781,1.3499929904937744,1.92312348388623,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Teixeiras,2022-12-31T00:00:00,1.5,1.308140516281128,-12.790632247924805,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Teofilo_Otoni,2022-12-31T00:00:00,0.8181818181818183,0.8092203140258789,-1.0952949523925977,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Tiros,2022-12-31T00:00:00,1.6801801801801797,1.4461160898208618,-13.930892241224822,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Tocos_do_Moji,2022-12-31T00:00:00,1.5,1.0640348196029663,-29.06434535980225,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Tombos,2022-12-31T00:00:00,1.2,0.6161718368530273,-48.65234692891438,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Tres_Coracoes,2022-12-31T00:00:00,1.08,1.4123830795288086,30.77621106748227,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Tres_Pontas,2022-12-31T00:00:00,0.975023651844844,1.411271333694458,44.74226661314204,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Tupaciguara,2022-12-31T00:00:00,2.4,2.2129712104797363,-7.792866230010984,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Turmalina,2022-12-31T00:00:00,1.205163043478261,1.5761501789093018,30.783149005326493,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Turvolandia,2022-12-31T00:00:00,1.4398692810457523,1.253267526626587,-12.959631605144024,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ubaporanga,2022-12-31T00:00:00,1.2,1.258102297782898,4.8418581485748335,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Uberaba,2022-12-31T00:00:00,2.102941176470588,1.691441297531128,-19.567826411107188,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Uberlandia,2022-12-31T00:00:00,1.681818181818182,1.856974124908448,10.414677697259023,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Unai,2022-12-31T00:00:00,2.52010582010582,2.507704257965088,-0.4921048172576953,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Urucuia,2022-12-31T00:00:00,1.9193245778611627,1.9579014778137207,2.009920593813628,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Vargem_Bonita,2022-12-31T00:00:00,1.235217391304348,1.30878746509552,5.956042580770697,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Vargem_Grande_do_Rio_Pardo,2022-12-31T00:00:00,1.8000000000000005,1.7500643730163574,-2.774201499091269,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Varginha,2022-12-31T00:00:00,1.020039292730845,1.1907449960708618,16.735208590151874,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Varjao_de_Minas,2022-12-31T00:00:00,2.383928571428572,2.3561787605285645,-1.1640370115358991,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Varzea_da_Palma,2022-12-31T00:00:00,2.5200000000000005,1.8558242321014404,-26.35618126581587,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Vermelho_Novo,2022-12-31T00:00:00,0.9598214285714286,0.797473132610321,-16.914427114087484,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Vicosa,2022-12-31T00:00:00,1.079768786127168,0.7907471656799316,-26.76699161529544,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Vieiras,2022-12-31T00:00:00,1.32,0.4652682542800903,-64.75240497878104,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Virginia,2022-12-31T00:00:00,1.62,1.279178023338318,-21.03839362109149,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Virginopolis,2022-12-31T00:00:00,1.314606741573034,1.3436927795410156,2.212527674487488,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Visconde_do_Rio_Branco,2022-12-31T00:00:00,1.6666666666666672,2.234874725341797,34.09248352050777,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Abadia_dos_Dourados,2023-12-31T00:00:00,2.103030303030303,0.7960410118103027,-62.14790577847264,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Abre_Campo,2023-12-31T00:00:00,1.8000000000000005,1.1864479780197144,-34.08622344334921,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Acucena,2023-12-31T00:00:00,1.6666666666666672,0.6471010446548462,-61.17393732070924,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Agua_Boa,2023-12-31T00:00:00,1.213636363636364,0.6203283071517944,-48.886806152286624,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Aguanil,2023-12-31T00:00:00,1.717774762550882,1.166910171508789,-32.068499494314565,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Aguas_Vermelhas,2023-12-31T00:00:00,3.0,2.9681413173675537,-1.0619560877482097,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Aimores,2023-12-31T00:00:00,1.544827586206897,1.5527139902114868,0.510503830654253,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Aiuruoca,2023-12-31T00:00:00,1.6000000000000003,0.9414512515068054,-41.15929678082468,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Albertina,2023-12-31T00:00:00,1.5,1.2847055196762085,-14.352965354919434,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Alfenas,2023-12-31T00:00:00,1.698430922311519,0.4431007504463196,-73.91117032635796,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Almenara,2023-12-31T00:00:00,0.78,0.5182616114616394,-33.55620365876418,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Alpinopolis,2023-12-31T00:00:00,1.8000000000000005,1.123477816581726,-37.58456574545967,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Alterosa,2023-12-31T00:00:00,1.2603960396039595,0.6701668500900269,-46.82886735342282,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Alto_Caparao,2023-12-31T00:00:00,1.32,1.0651202201843262,-19.309074228460144,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Alto_Jequitiba,2023-12-31T00:00:00,1.08,0.8510886430740356,-21.19549601166337,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Alvarenga,2023-12-31T00:00:00,1.75,0.4206833839416504,-75.96094948904855,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Amparo_do_Serra,2023-12-31T00:00:00,1.319444444444444,1.5055222511291504,14.102739032946175,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Andradas,2023-12-31T00:00:00,1.22,0.6842858791351318,-43.91099351351379,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Andrelandia,2023-12-31T00:00:00,1.8000000000000005,1.2227472066879272,-32.0695996284485,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Angelandia,2023-12-31T00:00:00,2.095663265306122,1.2851881980895996,-38.67391678014326,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Antonio_Dias,2023-12-31T00:00:00,1.477272727272727,1.4471657276153564,-2.038012284498935,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Antonio_Prado_de_Minas,2023-12-31T00:00:00,1.4857142857142862,0.450387954711914,-69.68542612515964,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Araguari,2023-12-31T00:00:00,3.0,1.347411870956421,-55.0862709681193,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Araponga,2023-12-31T00:00:00,1.5,0.7073313593864441,-52.844576040903725,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Arapua,2023-12-31T00:00:00,0.9,0.951722264289856,5.7469182544284365,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Araxa,2023-12-31T00:00:00,1.638401296246287,0.8219003677368164,-49.83522232191477,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Arceburgo,2023-12-31T00:00:00,1.8482558139534884,0.4680321812629699,-74.67708865139011,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Areado,2023-12-31T00:00:00,1.590034364261168,0.5239593982696533,-67.04729092360728,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Aricanduva,2023-12-31T00:00:00,1.2,0.887197732925415,-26.066855589548744,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Astolfo_Dutra,2023-12-31T00:00:00,0.625,-0.1300346553325653,-120.80554485321044,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ataleia,2023-12-31T00:00:00,0.6833333333333333,0.369601309299469,-45.91200351715088,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Baependi,2023-12-31T00:00:00,1.439779005524862,0.6806684732437134,-52.72410066879812,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Bambui,2023-12-31T00:00:00,1.5,0.9972787499427797,-33.5147500038147,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Bandeira,2023-12-31T00:00:00,0.95,1.1476484537124634,20.80510039078561,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Bandeira_do_Sul,2023-12-31T00:00:00,1.5,1.0106804370880127,-32.62130419413249,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Berilo,2023-12-31T00:00:00,1.7988826815642458,1.2408140897750854,-31.023067680204875,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Berizal,2023-12-31T00:00:00,3.570967741935484,1.949762821197509,-45.399595793023664,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Boa_Esperanca,2023-12-31T00:00:00,1.08,0.5383708477020264,-50.15084743499756,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Bocaiuva,2023-12-31T00:00:00,3.0,1.3621418476104736,-54.59527174631754,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Bom_Jesus_da_Penha,2023-12-31T00:00:00,1.2,1.3950406312942505,16.253385941187545,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Bom_Jesus_do_Amparo,2023-12-31T00:00:00,1.25,0.4750756919384002,-61.99394464492798,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Bom_Jesus_do_Galho,2023-12-31T00:00:00,1.2003192338387871,0.4408528208732605,-63.27203560144979,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Bom_Sucesso,2023-12-31T00:00:00,1.5,0.8344882726669312,-44.36744848887126,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Bonfinopolis_de_Minas,2023-12-31T00:00:00,3.0,1.996495604515076,-33.45014651616414,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Borda_da_Mata,2023-12-31T00:00:00,1.290476190476191,0.9446032047271729,-26.80196568534826,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Botelhos,2023-12-31T00:00:00,1.080052666227781,0.7582415342330933,-29.79587403998116,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Botumirim,2023-12-31T00:00:00,0.59375,0.6483616232872009,9.197747079949629,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Brazopolis,2023-12-31T00:00:00,1.440389294403893,1.00839364528656,-29.991589828922944,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Bueno_Brandao,2023-12-31T00:00:00,1.379901960784314,0.9004336595535278,-34.746548295232806,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Buritis,2023-12-31T00:00:00,3.0,1.8404570817947388,-38.65143060684204,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Buritizeiro,2023-12-31T00:00:00,3.0,2.4159092903137207,-19.469690322875977,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cabo_Verde,2023-12-31T00:00:00,1.319976635514019,0.8987724184989929,-31.90997519823544,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cachoeira_de_Minas,2023-12-31T00:00:00,1.6204081632653062,1.488424301147461,-8.14509980324234,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Caete,2023-12-31T00:00:00,1.166666666666667,1.345593810081482,15.336612292698424,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Caiana,2023-12-31T00:00:00,1.08,0.7280125617980957,-32.59142946313929,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cajuri,2023-12-31T00:00:00,0.8200000000000001,0.6288816928863525,-23.30711062361555,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Caldas,2023-12-31T00:00:00,1.56,0.9454798102378844,-39.39231985654587,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Camacho,2023-12-31T00:00:00,1.680155642023346,0.9754480719566344,-41.94299340137677,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cambuquira,2023-12-31T00:00:00,1.56,0.8310716152191162,-46.72617851159512,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Campanha,2023-12-31T00:00:00,1.327075098814229,0.8709303140640259,-34.37219077938985,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Campestre,2023-12-31T00:00:00,1.319964428634949,0.7022391557693481,-46.79863028615294,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Campo_Belo,2023-12-31T00:00:00,1.5,0.7115554809570312,-52.56296793619792,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Campo_do_Meio,2023-12-31T00:00:00,0.8771626297577856,0.7389986515045166,-15.7512385464279,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Campos_Altos,2023-12-31T00:00:00,1.380040526849037,0.5566803216934204,-59.66203087061111,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Campos_Gerais,2023-12-31T00:00:00,1.560242401107029,0.7478697299957275,-52.06708076481602,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cana_Verde,2023-12-31T00:00:00,1.3196428571428571,0.7140189409255981,-45.893016655164416,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Canaa,2023-12-31T00:00:00,1.560135135135135,0.8802724480628967,-43.57716660315776,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Candeias,2023-12-31T00:00:00,1.080032206119163,0.5064850449562073,-53.10463502045555,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Caparao,2023-12-31T00:00:00,1.32,0.9066052436828612,-31.317784569480207,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Capela_Nova,2023-12-31T00:00:00,1.8000000000000005,1.4080723524093628,-21.773758199479857,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Capelinha,2023-12-31T00:00:00,1.541750580945004,1.1750141382217407,-23.78701505002677,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Capetinga,2023-12-31T00:00:00,1.4484046164290565,1.2919291257858276,-10.803299635222675,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Capitao_Eneas,2023-12-31T00:00:00,3.0,0.4220992922782898,-85.93002359072366,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Capitolio,2023-12-31T00:00:00,1.32,0.5828897356987,-55.841686689492434,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Caputira,2023-12-31T00:00:00,1.380065005417118,1.1902304887771606,-13.75547643732773,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Carai,2023-12-31T00:00:00,1.2,0.8656512498855591,-27.862395842870075,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Caranaiba,2023-12-31T00:00:00,1.45,-0.016680285334587,-101.1503645058336,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Carangola,2023-12-31T00:00:00,1.140118343195266,0.6469594240188599,-43.255064013292845,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Caratinga,2023-12-31T00:00:00,1.3799999999999997,0.5829600095748901,-57.7565210452978,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Careacu,2023-12-31T00:00:00,1.5,0.8436418175697327,-43.75721216201782,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Carmo_da_Cachoeira,2023-12-31T00:00:00,1.32,0.8047850131988525,-39.03143839402632,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Carmo_da_Mata,2023-12-31T00:00:00,1.2,0.7712114453315735,-35.73237955570221,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Carmo_de_Minas,2023-12-31T00:00:00,1.5,0.8488014936447144,-43.41323375701904,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Carmo_do_Paranaiba,2023-12-31T00:00:00,2.369801007771799,1.2713654041290283,-46.35138562438088,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Carmo_do_Rio_Claro,2023-12-31T00:00:00,1.816856256463288,0.8421206474304199,-53.64957219732391,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Carmopolis_de_Minas,2023-12-31T00:00:00,1.5,1.3495649099349976,-10.029006004333496,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Carrancas,2023-12-31T00:00:00,1.214285714285714,0.8245378136634827,-32.09688593359552,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Carvalhopolis,2023-12-31T00:00:00,1.560106382978723,0.904985249042511,-41.99208086601019,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Casa_Grande,2023-12-31T00:00:00,2.523076923076923,0.3249130845069885,-87.12234726039375,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cascalho_Rico,2023-12-31T00:00:00,2.4,1.4537365436553955,-39.42764401435852,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cassia,2023-12-31T00:00:00,1.6377649325626198,0.997421383857727,-39.09862373856935,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cataguases,2023-12-31T00:00:00,1.333333333333333,0.1953509896993637,-85.34867577254772,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Catas_Altas_da_Noruega,2023-12-31T00:00:00,1.1,0.6641857624053955,-39.61947614496405,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Catuji,2023-12-31T00:00:00,1.384615384615385,0.9088045358657836,-34.36411685413787,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Caxambu,2023-12-31T00:00:00,1.316326530612245,0.0511499308049678,-96.11419130318848,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Chale,2023-12-31T00:00:00,1.3799999999999997,1.0568584203720093,-23.41605649478192,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Claraval,2023-12-31T00:00:00,1.8600214362272245,0.3394941091537475,-81.74783889360111,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Claudio,2023-12-31T00:00:00,2.398692810457516,0.5350304841995239,-77.69491441892993,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Coimbra,2023-12-31T00:00:00,1.8000000000000005,1.2097234725952148,-32.79314041137697,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Conceicao_da_Aparecida,2023-12-31T00:00:00,1.679948420373952,1.307662010192871,-22.160585745734444,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Conceicao_da_Barra_de_Minas,2023-12-31T00:00:00,1.680769230769231,0.8702946901321411,-48.220453218682685,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Conceicao_das_Pedras,2023-12-31T00:00:00,1.5598885793871868,1.2292555570602417,-21.19593839560237,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Conceicao_de_Ipanema,2023-12-31T00:00:00,1.5,1.0099135637283323,-32.67242908477783,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Conceicao_do_Rio_Verde,2023-12-31T00:00:00,1.44,1.059006929397583,-26.457852125167847,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Conceicao_dos_Ouros,2023-12-31T00:00:00,1.422222222222222,1.195450782775879,-15.944866836071004,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Congonhal,2023-12-31T00:00:00,1.2,0.7956315875053406,-33.69736770788828,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Congonhas_do_Norte,2023-12-31T00:00:00,1.111111111111111,0.3982841968536377,-64.1544222831726,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Conselheiro_Pena,2023-12-31T00:00:00,1.320048602673147,1.1748278141021729,-11.001169826390994,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Coqueiral,2023-12-31T00:00:00,1.32,0.7311404943466187,-44.61056861010465,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cordislandia,2023-12-31T00:00:00,1.14,0.8596022725105286,-24.596291885041342,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Coroaci,2023-12-31T00:00:00,2.4,1.232799410820007,-48.633357882499695,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Coromandel,2023-12-31T00:00:00,2.0926575541308825,0.6173702478408813,-70.49826682716437,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Corrego_Danta,2023-12-31T00:00:00,1.44,0.7785919904708862,-45.93111177285512,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Corrego_Fundo,2023-12-31T00:00:00,1.320158102766798,0.2625466287136078,-80.11248590881952,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Corrego_Novo,2023-12-31T00:00:00,1.8000000000000005,0.9146366119384766,-49.18685489230686,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cristais,2023-12-31T00:00:00,1.5631111111111111,0.5158545970916748,-66.99821315165572,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cristina,2023-12-31T00:00:00,1.68,1.1925660371780396,-29.013926358450025,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cruzeiro_da_Fortaleza,2023-12-31T00:00:00,1.5,1.2442032098770142,-17.053119341532387,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cruzilia,2023-12-31T00:00:00,1.5,0.5151739120483398,-65.65507253011069,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Cuparaque,2023-12-31T00:00:00,1.318367346938776,0.582673192024231,-55.803426611165165,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Datas,2023-12-31T00:00:00,0.6666666666666667,0.0056692119687795,-99.14961820468308,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Delfinopolis,2023-12-31T00:00:00,1.501818181818182,0.5929821729660034,-60.51571487514506,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Desterro_de_Entre_Rios,2023-12-31T00:00:00,1.375,1.105095148086548,-19.6294437755238,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Diamantina,2023-12-31T00:00:00,2.965183752417796,1.9692953824996948,-33.58605918119099,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Divinesia,2023-12-31T00:00:00,2.1,0.5320086479187012,-74.66625486101424,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Divino,2023-12-31T00:00:00,1.02,0.7497782707214355,-26.492326399859262,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Divisa_Nova,2023-12-31T00:00:00,1.680092592592593,0.8359743356704712,-50.242365250806905,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Divisopolis,2023-12-31T00:00:00,1.616883116883117,1.1322463750839231,-29.97351736428748,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Dom_Cavati,2023-12-31T00:00:00,0.6000000000000001,0.3687449395656585,-38.54251007239024,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Dom_Vicoso,2023-12-31T00:00:00,1.32,0.8866804838180542,-32.82723607438984,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Dores_do_Turvo,2023-12-31T00:00:00,1.5,0.2963230013847351,-80.24513324101767,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Doresopolis,2023-12-31T00:00:00,1.501960784313725,0.8174643516540527,-45.5735222789077,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Durande,2023-12-31T00:00:00,1.3799999999999997,0.6892398595809937,-50.055082639058426,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Eloi_Mendes,2023-12-31T00:00:00,1.577412806790921,0.512110710144043,-67.53476908902002,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Entre_Folhas,2023-12-31T00:00:00,1.3210526315789468,0.6929020881652832,-47.54924432214985,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Entre_Rios_de_Minas,2023-12-31T00:00:00,1.56,1.548776626586914,-0.7194470136593584,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ervalia,2023-12-31T00:00:00,1.380044843049327,0.5331328511238098,-61.36844003229582,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Esmeraldas,2023-12-31T00:00:00,2.222222222222222,1.4682259559631348,-33.92983198165893,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Espera_Feliz,2023-12-31T00:00:00,1.08,0.4482075870037079,-58.49929749965668,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Espirito_Santo_do_Dourado,2023-12-31T00:00:00,1.5,0.7488270401954651,-50.07819732030233,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Estrela_do_Indaia,2023-12-31T00:00:00,1.8000000000000005,1.1056745052337646,-38.57363859812419,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Estrela_do_Sul,2023-12-31T00:00:00,2.43015873015873,1.113123655319214,-54.19543417040465,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Eugenopolis,2023-12-31T00:00:00,1.68,0.8539840579032898,-49.16761560099465,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Fama,2023-12-31T00:00:00,1.559677419354839,0.9893503785133362,-36.56698710669408,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Faria_Lemos,2023-12-31T00:00:00,1.380152671755725,0.6737028360366821,-51.186354247342166,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Felicio_dos_Santos,2023-12-31T00:00:00,3.542087542087541,1.213199257850647,-65.74903235915949,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ferros,2023-12-31T00:00:00,1.17948717948718,1.0161101818084717,-13.851528064064391,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Fervedouro,2023-12-31T00:00:00,1.2,0.8071321249008179,-32.73898959159851,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Formiga,2023-12-31T00:00:00,2.021543985637344,0.6605561971664429,-67.32417390570971,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Formoso,2023-12-31T00:00:00,3.3803921568627446,2.138370513916016,-36.74193955352853,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Fortaleza_de_Minas,2023-12-31T00:00:00,1.5,0.9805654883384703,-34.628967444101974,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Franciscopolis,2023-12-31T00:00:00,1.2,0.376799464225769,-68.60004464785257,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Frei_Gaspar,2023-12-31T00:00:00,1.2,0.642249345779419,-46.47922118504842,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Grao_Mogol,2023-12-31T00:00:00,1.155555555555555,-0.0766575261950492,-106.63382438226388,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Guape,2023-12-31T00:00:00,1.560674157303371,0.8188025951385498,-47.535326877371546,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Guaraciaba,2023-12-31T00:00:00,1.5,3.916702270507813,161.1134847005208,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Guaranesia,2023-12-31T00:00:00,1.1961439588688951,0.8007423877716064,-33.056353139231724,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Guarani,2023-12-31T00:00:00,0.9655172413793104,0.3413644433021545,-64.64439694370543,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Guarda-Mor,2023-12-31T00:00:00,1.7994350282485878,1.401053786277771,-22.13924013464193,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Guaxupe,2023-12-31T00:00:00,1.2,0.7462272644042969,-37.81439463297526,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Guimarania,2023-12-31T00:00:00,1.7704600484261497,0.8032271265983582,-54.63172821592971,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Guiricema,2023-12-31T00:00:00,1.5,2.361947774887085,57.46318499247233,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Heliodora,2023-12-31T00:00:00,1.439872408293461,0.7714946269989014,-46.41923669380692,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Iapu,2023-12-31T00:00:00,1.559210526315789,1.1197798252105713,-28.18289728607304,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ibia,2023-12-31T00:00:00,1.668,0.6914215087890625,-58.54787117571567,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ibiraci,2023-12-31T00:00:00,1.804169884169884,0.6328818798065186,-64.92115928995713,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ibitiura_de_Minas,2023-12-31T00:00:00,1.150344827586207,1.0072367191314695,-12.440453073103654,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ibituruna,2023-12-31T00:00:00,1.8000000000000005,1.0128501653671265,-43.73054636849298,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ijaci,2023-12-31T00:00:00,1.971428571428572,0.3954561948776245,-79.94062779606253,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ilicinea,2023-12-31T00:00:00,1.560032362459547,0.6007300615310669,-61.49246156765903,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Imbe_de_Minas,2023-12-31T00:00:00,1.3799999999999997,0.9678288698196412,-29.867473201475264,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Inconfidentes,2023-12-31T00:00:00,1.7401360544217692,0.7555066347122192,-56.583473298398665,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Indaiabira,2023-12-31T00:00:00,1.9320754716981128,1.2443243265151978,-35.5964948190376,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Indianopolis,2023-12-31T00:00:00,2.7000000000000006,1.3444751501083374,-50.204624070061584,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ingai,2023-12-31T00:00:00,1.6197718631178712,0.7628585696220398,-52.903332438827135,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Inhapim,2023-12-31T00:00:00,2.7000000000000006,0.9041067361831664,-66.5145653265494,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Irai_de_Minas,2023-12-31T00:00:00,2.18825561312608,0.7522081136703491,-65.62521722058942,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Itabirinha,2023-12-31T00:00:00,1.027027027027027,0.5412651300430298,-47.29786891686288,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Itacambira,2023-12-31T00:00:00,0.75,0.2193759232759475,-70.74987689654031,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Itaipe,2023-12-31T00:00:00,0.9598214285714286,0.7525917887687683,-21.590436891067863,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Itajuba,2023-12-31T00:00:00,1.5862068965517242,1.087015151977539,-31.470783897068195,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Itamarandiba,2023-12-31T00:00:00,2.4,1.487105131149292,-38.03728620211283,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Itamarati_de_Minas,2023-12-31T00:00:00,1.2,0.926227331161499,-22.81438906987508,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Itambacuri,2023-12-31T00:00:00,0.8987341772151899,0.6583420038223267,-26.74786154652985,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Itamogi,2023-12-31T00:00:00,1.740011254924029,0.5626813173294067,-67.66220242903118,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Itanhomi,2023-12-31T00:00:00,1.078787878787879,0.8307321071624756,-22.993933886624475,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Itapecerica,2023-12-31T00:00:00,0.9037974683544304,0.5565260052680969,-38.42359325465035,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ituiutaba,2023-12-31T00:00:00,1.0,0.7429689168930054,-25.703108310699463,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Itumirim,2023-12-31T00:00:00,1.532033426183844,0.6280536651611328,-59.0052244013006,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Itutinga,2023-12-31T00:00:00,1.5,0.8636894822120667,-42.42070118586223,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Jacui,2023-12-31T00:00:00,1.32,0.6987132430076599,-47.067178560025766,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Jacutinga,2023-12-31T00:00:00,1.160053262316911,0.957665741443634,-17.446399010081613,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Jequeri,2023-12-31T00:00:00,1.5,1.316732406616211,-12.21783955891927,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Jequitinhonha,2023-12-31T00:00:00,2.7000000000000006,1.4854750633239746,-44.982405062075024,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Jesuania,2023-12-31T00:00:00,1.26,0.8996138572692871,-28.60207481989785,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Joao_Pinheiro,2023-12-31T00:00:00,3.3,2.076043605804444,-37.089587702895656,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Jose_Goncalves_de_Minas,2023-12-31T00:00:00,1.3210526315789468,1.319195032119751,-0.1406150985048641,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Juiz_de_Fora,2023-12-31T00:00:00,0.7142857142857143,0.7757526636123657,8.605372905731198,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Juruaia,2023-12-31T00:00:00,1.5,1.349252223968506,-10.049851735432942,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ladainha,2023-12-31T00:00:00,1.081818181818182,0.3306593894958496,-69.43484634912315,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Lagoa_Dourada,2023-12-31T00:00:00,1.8000000000000005,0.4681038856506347,-73.99422857496474,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Lagoa_Formosa,2023-12-31T00:00:00,1.978723404255319,1.197061538696289,-39.50334159276818,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Lagoa_Grande,2023-12-31T00:00:00,2.4,0.1585576832294464,-93.39342986543974,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Lajinha,2023-12-31T00:00:00,1.4399536768963517,1.051332712173462,-26.98843518081192,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Lambari,2023-12-31T00:00:00,1.56,0.8637046813964844,-44.63431529509716,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Lamim,2023-12-31T00:00:00,1.8000000000000005,0.6206554174423218,-65.51914347542657,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Lavras,2023-12-31T00:00:00,1.5,0.8742400407791138,-41.71733061472575,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Luisburgo,2023-12-31T00:00:00,1.44,1.244779348373413,-13.556989696290756,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Luminarias,2023-12-31T00:00:00,1.260224719101124,0.7852771878242493,-37.687527000393935,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Machado,2023-12-31T00:00:00,1.500560931145702,0.5327895879745483,-64.49397175976353,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Malacacheta,2023-12-31T00:00:00,1.619230769230769,1.4155151844024658,-12.5810099893964,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Manhuacu,2023-12-31T00:00:00,1.2,1.032168745994568,-13.985937833786007,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Manhumirim,2023-12-31T00:00:00,1.44,1.2403080463409424,-13.867496781879,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Mantena,2023-12-31T00:00:00,1.2,0.1797328293323516,-85.02226422230402,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Mar_de_Espanha,2023-12-31T00:00:00,1.5625,1.0735750198364258,-31.29119873046875,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Maria_da_Fe,2023-12-31T00:00:00,1.422222222222222,1.1383367776870728,-19.96069531887769,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Martins_Soares,2023-12-31T00:00:00,1.2,1.0910906791687012,-9.075776735941565,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Mata_Verde,2023-12-31T00:00:00,1.739700374531835,1.3378095626831057,-23.101151079356463,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Matipo,2023-12-31T00:00:00,1.25990675990676,1.1339311599731443,-9.99880339898631,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Matutina,2023-12-31T00:00:00,1.502024291497976,1.3993055820465088,-6.838684968871266,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Medeiros,2023-12-31T00:00:00,1.86,0.8204021453857422,-55.8923577749601,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Minas_Novas,2023-12-31T00:00:00,1.26,1.380517840385437,9.564907967098176,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Miradouro,2023-12-31T00:00:00,1.140084388185654,0.536851167678833,-52.91127803853315,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Mirai,2023-12-31T00:00:00,1.08,0.6051124334335327,-43.9710709783766,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Moeda,2023-12-31T00:00:00,1.0,1.3484731912612915,34.84731912612915,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Monsenhor_Paulo,2023-12-31T00:00:00,1.389931972789116,0.8103801608085632,-41.69641560353428,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Monte_Alegre_de_Minas,2023-12-31T00:00:00,2.338983050847458,1.4369463920593262,-38.56533541195636,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Monte_Belo,2023-12-31T00:00:00,1.3799999999999997,0.6887228488922119,-50.092547181723766,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Monte_Carmelo,2023-12-31T00:00:00,2.4900284900284904,1.3515892028808594,-45.71993018178701,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Monte_Formoso,2023-12-31T00:00:00,0.6000000000000001,0.5764518976211548,-3.9246837298075503,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Monte_Santo_de_Minas,2023-12-31T00:00:00,1.620050377833753,0.9700194597244264,-40.12411755852396,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Monte_Siao,2023-12-31T00:00:00,1.5,0.8457295894622803,-43.61802736918132,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Muriae,2023-12-31T00:00:00,1.057297297297297,0.4138128161430359,-60.86126227686008,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Mutum,2023-12-31T00:00:00,1.019985196150999,1.1713263988494873,14.837588160062255,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Muzambinho,2023-12-31T00:00:00,1.68,0.8074368238449097,-51.938284294945845,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Natercia,2023-12-31T00:00:00,1.5,1.6986491680145264,13.243277867635092,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Nazareno,2023-12-31T00:00:00,1.5599056603773582,0.9648640155792236,-38.14600202516013,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Nepomuceno,2023-12-31T00:00:00,1.650045578851413,0.51097571849823,-69.03263006504844,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ninheira,2023-12-31T00:00:00,3.0,2.05755615234375,-31.414794921875,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Nova_Belem,2023-12-31T00:00:00,0.96,0.4230928421020508,-55.92782894770304,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Nova_Era,2023-12-31T00:00:00,2.636363636363636,1.2853305339813232,-51.24608319381186,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Nova_Ponte,2023-12-31T00:00:00,2.6142857142857143,1.3831655979156494,-47.092026309237454,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Nova_Resende,2023-12-31T00:00:00,1.56,1.004306674003601,-35.621367051051216,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Novo_Cruzeiro,2023-12-31T00:00:00,1.209891435464415,1.0951998233795166,-9.479496153377944,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Novorizonte,2023-12-31T00:00:00,1.333333333333333,0.9617162346839904,-27.871282398700696,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Olimpio_Noronha,2023-12-31T00:00:00,1.2,0.946017324924469,-21.165222922960915,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Oliveira,2023-12-31T00:00:00,1.8240227434257288,0.8838938474655151,-51.541511713529474,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Orizania,2023-12-31T00:00:00,1.2,1.2279287576675415,2.327396472295129,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ouro_Fino,2023-12-31T00:00:00,1.68,0.6702792644500732,-60.10242473511469,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ouro_Verde_de_Minas,2023-12-31T00:00:00,2.5,0.7360517978668213,-70.55792808532715,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Padre_Paraiso,2023-12-31T00:00:00,0.7212121212121212,0.4831012487411499,-33.01537307370611,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Paracatu,2023-12-31T00:00:00,2.4,2.017416000366211,-15.940999984741207,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Paraguacu,2023-12-31T00:00:00,1.298291457286432,0.2585641741752624,-80.08427362560874,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Paraisopolis,2023-12-31T00:00:00,1.2,0.9232051372528076,-23.06623856226603,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Passa_Tempo,2023-12-31T00:00:00,1.625,1.2900712490081787,-20.61100006103516,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Passos,2023-12-31T00:00:00,1.829801324503311,1.0924540758132937,-40.29657421360573,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Patis,2023-12-31T00:00:00,1.2,1.0708122253417969,-10.76564788818359,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Patos_de_Minas,2023-12-31T00:00:00,1.782452316076294,1.6224383115768433,-8.97718289887771,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Patrocinio,2023-12-31T00:00:00,2.4370275910039414,0.5848426818847656,-76.001803014309,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Paula_Candido,2023-12-31T00:00:00,1.6197080291970802,1.113210916519165,-31.27088978678432,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pecanha,2023-12-31T00:00:00,2.30379746835443,1.2098126411437988,-47.48615458771421,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pedra_Azul,2023-12-31T00:00:00,1.166666666666667,1.2750846147537231,9.292966978890528,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pedra_Bonita,2023-12-31T00:00:00,1.08,0.873754620552063,-19.096794393327507,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pedra_Dourada,2023-12-31T00:00:00,1.2,0.5840475559234619,-51.32937033971151,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pedra_do_Anta,2023-12-31T00:00:00,1.5,0.9294713735580444,-38.03524176279704,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pedralva,2023-12-31T00:00:00,1.67998417721519,1.1495521068572998,-31.573634892035468,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pedrinopolis,2023-12-31T00:00:00,2.187804878048781,0.6006439328193665,-72.54581800937122,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Perdizes,2023-12-31T00:00:00,2.106451612903226,0.7528538703918457,-64.25961717894761,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Perdoes,2023-12-31T00:00:00,1.6799401197604789,0.8552652597427368,-49.089538985194416,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Piedade_de_Caratinga,2023-12-31T00:00:00,2.4,0.8705453276634216,-63.7272780140241,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pimenta,2023-12-31T00:00:00,1.504186046511628,0.6235823631286621,-58.54353491878097,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Piracema,2023-12-31T00:00:00,1.2,0.7529346942901611,-37.25544214248657,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Piranga,2023-12-31T00:00:00,2.1,1.5132718086242676,-27.939437684558687,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pirangucu,2023-12-31T00:00:00,1.333333333333333,1.2399656772613523,-7.002574205398539,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Piranguinho,2023-12-31T00:00:00,1.460887949260042,1.3407108783721924,-8.226303115767418,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pirapora,2023-12-31T00:00:00,3.6000000000000005,2.582557916641236,-28.26228009329903,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Piumhi,2023-12-31T00:00:00,1.7399633363886338,0.8688585162162781,-50.06455032439764,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Poco_Fundo,2023-12-31T00:00:00,1.380160799652325,0.4655045866966247,-66.27171364279513,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pocos_de_Caldas,2023-12-31T00:00:00,1.5,1.015785574913025,-32.28096167246501,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pocrane,2023-12-31T00:00:00,1.377952755905512,1.349751591682434,-2.046598775046228,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ponte_Nova,2023-12-31T00:00:00,1.333333333333333,0.9803005456924438,-26.477459073066694,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ponto_dos_Volantes,2023-12-31T00:00:00,0.6000000000000001,0.4748311042785644,-20.86148262023927,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Porto_Firme,2023-12-31T00:00:00,1.200764818355641,1.0161367654800415,-15.375871282474282,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pote,2023-12-31T00:00:00,1.125,0.48822683095932,-56.60205947028266,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pouso_Alegre,2023-12-31T00:00:00,1.566666666666667,1.0393569469451904,-33.658067216264456,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pouso_Alto,2023-12-31T00:00:00,1.8000000000000005,1.261702537536621,-29.90541458129884,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pratapolis,2023-12-31T00:00:00,1.8011363636363642,0.7577892541885376,-57.92715812707174,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Pratinha,2023-12-31T00:00:00,2.13,1.0252470970153809,-51.86633347345629,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Presidente_Bernardes,2023-12-31T00:00:00,1.320588235294118,0.9479705691337584,-28.21603708118535,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Presidente_Kubitschek,2023-12-31T00:00:00,0.8947368421052632,0.0939840972423553,-89.4958950140897,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Presidente_Olegario,2023-12-31T00:00:00,2.160074626865672,1.3583835363388062,-37.11404599433409,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Quartel_Geral,2023-12-31T00:00:00,3.0,2.0430831909179688,-31.897226969401043,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Raul_Soares,2023-12-31T00:00:00,1.5,0.7632954120635986,-49.113639195760086,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Reduto,2023-12-31T00:00:00,0.9,1.0505841970443726,16.731577449374726,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ribeirao_Vermelho,2023-12-31T00:00:00,1.5,0.8566476106643677,-42.89015928904216,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Rio_Paranaiba,2023-12-31T00:00:00,1.8000000000000005,0.8560401797294617,-52.442212237252136,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Rio_Pardo_de_Minas,2023-12-31T00:00:00,2.568224299065421,2.215048313140869,-13.751757821661956,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Rio_Vermelho,2023-12-31T00:00:00,0.9,0.4947429597377777,-45.02856002913581,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ritapolis,2023-12-31T00:00:00,2.102222222222222,1.191995620727539,-43.2983055679289,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Romaria,2023-12-31T00:00:00,2.131578947368421,1.343999981880188,-36.9481489982134,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Rosario_da_Limeira,2023-12-31T00:00:00,1.2,0.2762483954429626,-76.97930037975311,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sabinopolis,2023-12-31T00:00:00,1.2,0.9550299644470216,-20.414169629414875,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sacramento,2023-12-31T00:00:00,1.75,0.79925537109375,-54.32826450892857,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santa_Barbara,2023-12-31T00:00:00,1.3,0.941605269908905,-27.56882539162269,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santa_Barbara_do_Leste,2023-12-31T00:00:00,1.08,0.4542264938354492,-57.94199131153248,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santa_Barbara_do_Monte_Verde,2023-12-31T00:00:00,1.4,0.619152843952179,-55.77479686055864,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santa_Margarida,2023-12-31T00:00:00,1.32,1.149736762046814,-12.898730147968642,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santa_Maria_do_Suacui,2023-12-31T00:00:00,0.6666666666666667,0.6444981098175049,-3.325283527374278,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santa_Rita_de_Caldas,2023-12-31T00:00:00,1.68,1.5407010316848757,-8.291605256852646,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santa_Rita_de_Minas,2023-12-31T00:00:00,1.019930675909879,0.8283143043518066,-18.787195648089668,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santa_Rita_do_Itueto,2023-12-31T00:00:00,1.2,1.2389947175979614,3.2495597998301227,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santa_Rita_do_Sapucai,2023-12-31T00:00:00,1.3799999999999997,1.0742090940475464,-22.158761300902416,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santa_Rosa_da_Serra,2023-12-31T00:00:00,1.68,1.058088779449463,-37.018525032770064,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santana_da_Vargem,2023-12-31T00:00:00,1.5593593593593589,0.5419514179229736,-65.24525186127546,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santana_do_Jacare,2023-12-31T00:00:00,0.9011235955056182,0.5529845952987671,-38.63387907532386,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santana_do_Manhuacu,2023-12-31T00:00:00,1.32,0.8315136432647705,-37.00654217691133,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santo_Antonio_do_Amparo,2023-12-31T00:00:00,1.8000000000000005,0.5869659781455994,-67.39077899191115,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santo_Antonio_do_Grama,2023-12-31T00:00:00,1.521739130434783,2.509970426559448,64.94091374533514,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Santo_Antonio_do_Retiro,2023-12-31T00:00:00,1.02,0.7914413213729858,-22.407713590883745,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Bento_Abade,2023-12-31T00:00:00,1.5,0.2377809882164001,-84.14793411890665,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Domingos_das_Dores,2023-12-31T00:00:00,1.296078431372549,0.9417829513549804,-27.335959880326776,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Domingos_do_Prata,2023-12-31T00:00:00,1.2,0.7143911123275757,-40.46740730603536,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Francisco_de_Paula,2023-12-31T00:00:00,1.56,1.1112003326416016,-28.769209446051185,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Francisco_do_Gloria,2023-12-31T00:00:00,1.08,0.1516255140304565,-85.96060055273551,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Geraldo,2023-12-31T00:00:00,1.5,0.4006007313728332,-73.29328457514444,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Goncalo_do_Abaete,2023-12-31T00:00:00,1.619047619047619,1.108441710472107,-31.5374237649581,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Goncalo_do_Rio_Preto,2023-12-31T00:00:00,2.868421052631579,1.1206936836242676,-60.929944974566816,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Goncalo_do_Sapucai,2023-12-31T00:00:00,1.2,0.6019378900527954,-49.83850916226704,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Gotardo,2023-12-31T00:00:00,1.5,0.9144516587257384,-39.03655608495076,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Joao_Batista_do_Gloria,2023-12-31T00:00:00,1.5232974910394272,1.1701757907867432,-23.18140102835266,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Joao_da_Mata,2023-12-31T00:00:00,1.08,0.5622731447219849,-47.937671785001406,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Joao_del_Rei,2023-12-31T00:00:00,1.799568965517241,1.0183484554290771,-43.41153493184529,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Joao_do_Manhuacu,2023-12-31T00:00:00,1.2,1.0315924882888794,-14.033959309260046,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Joao_do_Manteninha,2023-12-31T00:00:00,1.2,0.4290703535079956,-64.24413720766702,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Joao_do_Paraiso,2023-12-31T00:00:00,3.601190476190476,1.7956196069717407,-50.13816628574339,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Jose_da_Barra,2023-12-31T00:00:00,2.2413698630136984,1.34326434135437,-40.06949216546325,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Jose_do_Alegre,2023-12-31T00:00:00,1.592307692307692,1.6208529472351074,1.7926971693545932,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Jose_do_Mantimento,2023-12-31T00:00:00,1.5,1.2252916097640991,-18.313892682393394,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Lourenco,2023-12-31T00:00:00,1.5,0.3252978920936584,-78.31347386042276,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Miguel_do_Anta,2023-12-31T00:00:00,1.5598870056497178,0.9574080109596252,-38.623245947173615,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Pedro_da_Uniao,2023-12-31T00:00:00,1.5,1.201142430305481,-19.923837979634605,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Roque_de_Minas,2023-12-31T00:00:00,1.8000000000000005,0.9107147455215454,-49.40473635991415,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Sebastiao_da_Bela_Vista,2023-12-31T00:00:00,1.5,1.0366638898849487,-30.88907400767009,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Sebastiao_da_Vargem_Alegre,2023-12-31T00:00:00,1.5,0.3034920990467071,-79.7671933968862,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Sebastiao_do_Anta,2023-12-31T00:00:00,1.7998212689901698,1.3074796199798584,-27.35503005176457,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Sebastiao_do_Maranhao,2023-12-31T00:00:00,1.2,0.8264544606208801,-31.128794948259987,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Sebastiao_do_Paraiso,2023-12-31T00:00:00,1.440017746228926,0.7512802481651306,-47.82840349484857,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Tiago,2023-12-31T00:00:00,1.560526315789474,0.5370854735374451,-65.58305565864603,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Tomas_de_Aquino,2023-12-31T00:00:00,1.319968346082828,1.0515471696853638,-20.33542525425233,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sao_Tome_das_Letras,2023-12-31T00:00:00,1.09812734082397,0.4843372702598572,-55.89425267415352,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Senador_Firmino,2023-12-31T00:00:00,1.436170212765957,1.1126844882965088,-22.524191185280102,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Senador_Jose_Bento,2023-12-31T00:00:00,1.2,0.9035455584526062,-24.704536795616143,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Senador_Modestino_Goncalves,2023-12-31T00:00:00,2.7000000000000006,1.9108457565307613,-29.22793494330514,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Senhora_de_Oliveira,2023-12-31T00:00:00,1.2,1.3818597793579102,15.154981613159183,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Senhora_dos_Remedios,2023-12-31T00:00:00,1.5,0.7226053476333618,-51.82631015777588,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Sericita,2023-12-31T00:00:00,1.26,0.3324138224124908,-73.61795060218327,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Serra_do_Salitre,2023-12-31T00:00:00,1.489636363636364,0.9802099466323853,-34.19803849044163,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Serrania,2023-12-31T00:00:00,0.9,0.712046205997467,-20.88375488917033,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Setubinha,2023-12-31T00:00:00,1.2,0.8042473196983337,-32.979390025138855,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Silvianopolis,2023-12-31T00:00:00,1.13974358974359,0.5821981430053711,-48.91849813901132,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Simonesia,2023-12-31T00:00:00,1.5,1.1386103630065918,-24.09264246622721,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Soledade_de_Minas,2023-12-31T00:00:00,1.5,0.3873379230499267,-74.17747179667154,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Taiobeiras,2023-12-31T00:00:00,3.0,2.108874797821045,-29.704173405965168,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Tapira,2023-12-31T00:00:00,1.92,0.2673362493515014,-86.07623701294264,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Tapirai,2023-12-31T00:00:00,1.5579665220086798,1.0785506963729858,-30.77189521489749,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Teixeiras,2023-12-31T00:00:00,1.5007092198581562,0.9491571187973022,-36.752762877873536,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Teofilo_Otoni,2023-12-31T00:00:00,1.2,0.5932514071464539,-50.56238273779551,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Tiros,2023-12-31T00:00:00,2.382038834951457,0.8492991924285889,-64.34570335433274,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Tocos_do_Moji,2023-12-31T00:00:00,1.5,1.0185190439224243,-32.09873040517171,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Tombos,2023-12-31T00:00:00,1.32,0.2747127413749695,-79.18842868371443,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Tres_Coracoes,2023-12-31T00:00:00,1.44,0.4681214690208435,-67.49156465133032,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Tres_Pontas,2023-12-31T00:00:00,1.5900000000000003,0.3626684844493866,-77.19066135538449,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Tupaciguara,2023-12-31T00:00:00,2.622222222222222,1.857872009277344,-29.148948798745355,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Turmalina,2023-12-31T00:00:00,1.360606060606061,1.0258171558380127,-24.60586605199464,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Turvolandia,2023-12-31T00:00:00,1.259748427672956,0.992450714111328,-21.218340717073804,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Ubaporanga,2023-12-31T00:00:00,1.5,1.1203839778900146,-25.30773480733236,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Uberaba,2023-12-31T00:00:00,2.1200980392156863,1.658353328704834,-21.77940368652344,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Uberlandia,2023-12-31T00:00:00,1.8000000000000005,1.420954346656799,-21.05809185240005,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Unai,2023-12-31T00:00:00,2.520095187731359,2.1492366790771484,-14.716051618195614,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Urucuia,2023-12-31T00:00:00,2.0994575045207946,1.1608068943023682,-44.70919788551164,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Vargem_Bonita,2023-12-31T00:00:00,1.487234042553192,0.913859486579895,-38.55308173211009,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Vargem_Grande_do_Rio_Pardo,2023-12-31T00:00:00,2.1,1.370850682258606,-34.721396082923526,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Varginha,2023-12-31T00:00:00,1.679990280646337,0.5330102443695068,-68.27301618885298,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Varjao_de_Minas,2023-12-31T00:00:00,2.3892857142857142,2.2467994689941406,-5.963549877674232,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Varzea_da_Palma,2023-12-31T00:00:00,3.3,1.2081677913665771,-63.388854807073415,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Vermelho_Novo,2023-12-31T00:00:00,1.5,0.6314939260482788,-57.900404930114746,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Vicosa,2023-12-31T00:00:00,1.5004329004329,0.5233168005943298,-65.1222790140536,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Vieiras,2023-12-31T00:00:00,1.5,0.2078099995851516,-86.14600002765656,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Virginia,2023-12-31T00:00:00,1.5,1.1080836057662964,-26.12775961558024,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Virginopolis,2023-12-31T00:00:00,1.3258426966292132,1.0255789756774902,-22.64700946161301,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2023,Visconde_do_Rio_Branco,2023-12-31T00:00:00,1.333333333333333,1.601715087890625,20.128631591796903,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:20
V38_2024,Abadia_dos_Dourados,2023-12-31T00:00:00,2.103030303030303,0.966163456439972,-54.058509996370205,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Abre_Campo,2023-12-31T00:00:00,1.8000000000000005,1.2884893417358398,-28.417258792453357,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Acucena,2023-12-31T00:00:00,1.6666666666666672,0.9706391096115112,-41.76165342330934,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Agua_Boa,2023-12-31T00:00:00,1.213636363636364,0.6371552348136902,-47.5003177307072,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Aguanil,2023-12-31T00:00:00,1.717774762550882,1.290397882461548,-24.87968093411052,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Aguas_Vermelhas,2023-12-31T00:00:00,3.0,2.365636110305786,-21.14546298980713,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Aimores,2023-12-31T00:00:00,1.544827586206897,2.3589203357696533,52.69796816366056,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Aiuruoca,2023-12-31T00:00:00,1.6000000000000003,1.4245827198028564,-10.963580012321488,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Albertina,2023-12-31T00:00:00,1.5,1.4741506576538086,-1.7232894897460938,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Alfenas,2023-12-31T00:00:00,1.698430922311519,0.8789638876914978,-48.24847592298593,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Almenara,2023-12-31T00:00:00,0.78,0.554313600063324,-28.934153838035392,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Alpinopolis,2023-12-31T00:00:00,1.8000000000000005,1.1496773958206177,-36.12903356552125,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Alterosa,2023-12-31T00:00:00,1.2603960396039595,0.8894886374473572,-29.427845732770525,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Alto_Caparao,2023-12-31T00:00:00,1.32,1.3163464069366455,-0.2767873532844359,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Alto_Jequitiba,2023-12-31T00:00:00,1.08,1.0996840000152588,1.8225925940054368,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Alvarenga,2023-12-31T00:00:00,1.75,0.8129814863204956,-53.54391506740025,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Amparo_do_Serra,2023-12-31T00:00:00,1.319444444444444,1.9259071350097656,45.963488127055975,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Andradas,2023-12-31T00:00:00,1.22,1.355051040649414,11.069757430279845,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Andrelandia,2023-12-31T00:00:00,1.8000000000000005,1.7503044605255127,-2.760863304138198,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Angelandia,2023-12-31T00:00:00,2.095663265306122,1.7383723258972168,-17.04906247696785,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Antonio_Dias,2023-12-31T00:00:00,1.477272727272727,1.5325286388397217,3.740400167611943,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Antonio_Prado_de_Minas,2023-12-31T00:00:00,1.4857142857142862,1.3686083555221558,-7.882129916778008,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Araguari,2023-12-31T00:00:00,3.0,1.1478899717330933,-61.73700094223023,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Araponga,2023-12-31T00:00:00,1.5,1.319575548171997,-12.028296788533527,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Arapua,2023-12-31T00:00:00,0.9,0.9137331247329712,1.5259027481079075,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Araxa,2023-12-31T00:00:00,1.638401296246287,0.912444829940796,-44.30883129601506,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Arceburgo,2023-12-31T00:00:00,1.8482558139534884,0.6315186619758606,-65.83164206988108,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Areado,2023-12-31T00:00:00,1.590034364261168,0.927194118499756,-41.68716479718413,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Aricanduva,2023-12-31T00:00:00,1.2,1.0790296792984009,-10.08086005846659,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Astolfo_Dutra,2023-12-31T00:00:00,0.625,0.8495935201644897,35.93496322631836,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ataleia,2023-12-31T00:00:00,0.6833333333333333,0.4468607604503631,-34.605742373117586,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Baependi,2023-12-31T00:00:00,1.439779005524862,0.9673457145690918,-32.81290317075764,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Bambui,2023-12-31T00:00:00,1.5,1.371596336364746,-8.560244242350262,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Bandeira,2023-12-31T00:00:00,0.95,1.475685954093933,55.33536358883505,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Bandeira_do_Sul,2023-12-31T00:00:00,1.5,1.2986500263214111,-13.423331578572592,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Berilo,2023-12-31T00:00:00,1.7988826815642458,1.4134998321533203,-21.42345653557629,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Berizal,2023-12-31T00:00:00,3.570967741935484,1.666496515274048,-53.33207590470146,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Boa_Esperanca,2023-12-31T00:00:00,1.08,0.7233074307441711,-33.02708974591008,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Bocaiuva,2023-12-31T00:00:00,3.0,3.5410561561584477,18.035205205281574,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Bom_Jesus_da_Penha,2023-12-31T00:00:00,1.2,1.7204424142837524,43.37020119031271,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Bom_Jesus_do_Amparo,2023-12-31T00:00:00,1.25,0.9292035102844238,-25.66371917724609,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Bom_Jesus_do_Galho,2023-12-31T00:00:00,1.2003192338387871,0.8542563915252686,-28.830900360295125,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Bom_Sucesso,2023-12-31T00:00:00,1.5,0.97927725315094,-34.71484978993733,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Bonfinopolis_de_Minas,2023-12-31T00:00:00,3.0,2.8018932342529297,-6.603558858235677,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Borda_da_Mata,2023-12-31T00:00:00,1.290476190476191,1.090963363647461,-15.460403554993835,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Botelhos,2023-12-31T00:00:00,1.080052666227781,1.4659793376922607,35.73220857945539,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Botumirim,2023-12-31T00:00:00,0.59375,0.6589232683181763,10.97655045358758,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Brazopolis,2023-12-31T00:00:00,1.440389294403893,1.603684663772583,11.33689135313034,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Bueno_Brandao,2023-12-31T00:00:00,1.379901960784314,1.4775586128234863,7.077071764117643,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Buritis,2023-12-31T00:00:00,3.0,2.3531064987182617,-21.563116709391277,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Buritizeiro,2023-12-31T00:00:00,3.0,2.782972812652588,-7.23423957824707,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cabo_Verde,2023-12-31T00:00:00,1.319976635514019,1.235925793647766,-6.36760072904792,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cachoeira_de_Minas,2023-12-31T00:00:00,1.6204081632653062,1.915189266204834,18.19178091188521,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Caete,2023-12-31T00:00:00,1.166666666666667,1.5821912288665771,35.61639104570658,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Caiana,2023-12-31T00:00:00,1.08,0.9164541959762572,-15.1431300021984,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cajuri,2023-12-31T00:00:00,0.8200000000000001,1.1982966661453247,46.13373977382008,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Caldas,2023-12-31T00:00:00,1.56,1.645516872406006,5.481850795256783,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Camacho,2023-12-31T00:00:00,1.680155642023346,1.233834147453308,-26.564294605025424,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cambuquira,2023-12-31T00:00:00,1.56,1.0868816375732422,-30.3281001555614,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Campanha,2023-12-31T00:00:00,1.327075098814229,1.1206779479980469,-15.552786048099506,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Campestre,2023-12-31T00:00:00,1.319964428634949,1.0944790840148926,-17.08268342149521,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Campo_Belo,2023-12-31T00:00:00,1.5,0.8480017781257629,-43.46654812494914,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Campo_do_Meio,2023-12-31T00:00:00,0.8771626297577856,0.9839178919792176,12.170521018538,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Campos_Altos,2023-12-31T00:00:00,1.380040526849037,0.7044572830200195,-48.9538698817444,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Campos_Gerais,2023-12-31T00:00:00,1.560242401107029,1.0583369731903076,-32.16842636507043,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cana_Verde,2023-12-31T00:00:00,1.3196428571428571,0.8142387866973877,-38.29854931657143,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Canaa,2023-12-31T00:00:00,1.560135135135135,1.5179738998413086,-2.702409191635468,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Candeias,2023-12-31T00:00:00,1.080032206119163,0.6748934984207153,-37.5117246877495,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Caparao,2023-12-31T00:00:00,1.32,1.2875910997390747,-2.455219716736769,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Capela_Nova,2023-12-31T00:00:00,1.8000000000000005,2.6875319480896,49.307330449422174,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Capelinha,2023-12-31T00:00:00,1.541750580945004,1.4631214141845703,-5.09999267924638,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Capetinga,2023-12-31T00:00:00,1.4484046164290565,1.177032232284546,-18.73595134027953,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Capitao_Eneas,2023-12-31T00:00:00,3.0,1.80010986328125,-39.996337890625,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Capitolio,2023-12-31T00:00:00,1.32,0.8329166769981384,-36.90025174256528,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Caputira,2023-12-31T00:00:00,1.380065005417118,1.4412423372268677,4.4329311713298,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Carai,2023-12-31T00:00:00,1.2,0.9761318564414978,-18.65567862987518,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Caranaiba,2023-12-31T00:00:00,1.45,4.07704496383667,181.17551474735652,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Carangola,2023-12-31T00:00:00,1.140118343195266,0.9604272842407228,-15.760737473177198,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Caratinga,2023-12-31T00:00:00,1.3799999999999997,1.1119180917739868,-19.426225233769053,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Careacu,2023-12-31T00:00:00,1.5,1.0952472686767578,-26.98351542154948,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Carmo_da_Cachoeira,2023-12-31T00:00:00,1.32,1.0249496698379517,-22.35229773954912,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Carmo_da_Mata,2023-12-31T00:00:00,1.2,2.2260541915893555,85.50451596577963,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Carmo_de_Minas,2023-12-31T00:00:00,1.5,1.120976209640503,-25.268252690633137,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Carmo_do_Paranaiba,2023-12-31T00:00:00,2.369801007771799,1.193416953086853,-49.64062597774988,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Carmo_do_Rio_Claro,2023-12-31T00:00:00,1.816856256463288,1.2179279327392578,-32.96509129951263,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Carmopolis_de_Minas,2023-12-31T00:00:00,1.5,1.9011683464050293,26.744556427001957,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Carrancas,2023-12-31T00:00:00,1.214285714285714,2.161492824554444,78.00529143389538,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Carvalhopolis,2023-12-31T00:00:00,1.560106382978723,1.3689993619918823,-12.249614710373695,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Casa_Grande,2023-12-31T00:00:00,2.523076923076923,2.4701244831085205,-2.0987247548452204,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cascalho_Rico,2023-12-31T00:00:00,2.4,1.7473771572113037,-27.19261844952901,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cassia,2023-12-31T00:00:00,1.6377649325626198,1.039982795715332,-36.499874002793234,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cataguases,2023-12-31T00:00:00,1.333333333333333,1.3487557172775269,1.1566787958145366,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Catas_Altas_da_Noruega,2023-12-31T00:00:00,1.1,1.0465587377548218,-4.858296567743483,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Catuji,2023-12-31T00:00:00,1.384615384615385,1.1030193567276,-20.33749090300668,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Caxambu,2023-12-31T00:00:00,1.316326530612245,1.0847601890563965,-17.59186160656833,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Chale,2023-12-31T00:00:00,1.3799999999999997,1.386029839515686,0.436944892441041,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Claraval,2023-12-31T00:00:00,1.8600214362272245,0.6793466806411743,-63.476405840831184,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Claudio,2023-12-31T00:00:00,2.398692810457516,1.334506273269653,-44.365269806469485,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Coimbra,2023-12-31T00:00:00,1.8000000000000005,2.119633197784424,17.757399876912416,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Conceicao_da_Aparecida,2023-12-31T00:00:00,1.679948420373952,1.4597505331039429,-13.107419525475295,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Conceicao_da_Barra_de_Minas,2023-12-31T00:00:00,1.680769230769231,1.1412837505340576,-32.09753429316821,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Conceicao_das_Pedras,2023-12-31T00:00:00,1.5598885793871868,1.6297738552093506,4.4801453607422825,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Conceicao_de_Ipanema,2023-12-31T00:00:00,1.5,1.4838855266571045,-1.074298222859701,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Conceicao_do_Rio_Verde,2023-12-31T00:00:00,1.44,1.399277925491333,-2.827921840879649,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Conceicao_dos_Ouros,2023-12-31T00:00:00,1.422222222222222,1.5137379169464111,6.434697285294545,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Congonhal,2023-12-31T00:00:00,1.2,1.1214264631271362,-6.54779473940531,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Congonhas_do_Norte,2023-12-31T00:00:00,1.111111111111111,0.6298243999481201,-43.315804004669175,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Conselheiro_Pena,2023-12-31T00:00:00,1.320048602673147,1.50885272026062,14.302815608844838,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Coqueiral,2023-12-31T00:00:00,1.32,0.9356729388237,-29.115686452750005,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cordislandia,2023-12-31T00:00:00,1.14,1.2852628231048584,12.742352903934956,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Coroaci,2023-12-31T00:00:00,2.4,1.9546222686767576,-18.557405471801754,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Coromandel,2023-12-31T00:00:00,2.0926575541308825,0.624164342880249,-70.17360333762419,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Corrego_Danta,2023-12-31T00:00:00,1.44,1.133328199386597,-21.29665282037523,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Corrego_Fundo,2023-12-31T00:00:00,1.320158102766798,0.693922758102417,-47.436389880266,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Corrego_Novo,2023-12-31T00:00:00,1.8000000000000005,1.2219719886779783,-32.11266729566787,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cristais,2023-12-31T00:00:00,1.5631111111111111,0.5796740651130676,-62.91536404593682,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cristina,2023-12-31T00:00:00,1.68,1.4776842594146729,-12.04260360626947,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cruzeiro_da_Fortaleza,2023-12-31T00:00:00,1.5,1.1570703983306885,-22.86197344462077,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cruzilia,2023-12-31T00:00:00,1.5,1.4799944162368774,-1.3337055842081704,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cuparaque,2023-12-31T00:00:00,1.318367346938776,0.9332635998725892,-29.2106557372185,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Datas,2023-12-31T00:00:00,0.6666666666666667,0.1854507029056549,-72.18239456415176,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Delfinopolis,2023-12-31T00:00:00,1.501818181818182,0.9198406338691713,-38.751531643093934,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Desterro_de_Entre_Rios,2023-12-31T00:00:00,1.375,1.4699450731277466,6.905096227472479,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Diamantina,2023-12-31T00:00:00,2.9651837524177957,3.0452444553375244,2.700025010404432,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Divinesia,2023-12-31T00:00:00,2.1,2.723921298980713,29.71053804670061,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Divino,2023-12-31T00:00:00,1.02,1.1192125082015991,9.726716490352851,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Divisa_Nova,2023-12-31T00:00:00,1.680092592592593,1.0850557088851929,-35.41691013524343,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Divisopolis,2023-12-31T00:00:00,1.616883116883117,1.0544686317443848,-34.783867755568174,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Dom_Cavati,2023-12-31T00:00:00,0.6000000000000001,0.5051078796386719,-15.815353393554698,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Dom_Vicoso,2023-12-31T00:00:00,1.32,1.4951950311660769,13.272350845914891,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Dores_do_Turvo,2023-12-31T00:00:00,1.5,1.118915557861328,-25.405629475911457,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Doresopolis,2023-12-31T00:00:00,1.501960784313725,1.1667687892913818,-22.316960504098574,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Durande,2023-12-31T00:00:00,1.3799999999999997,1.4715111255645752,6.631240982940256,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Eloi_Mendes,2023-12-31T00:00:00,1.577412806790921,0.7650009393692017,-51.502806616264586,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Entre_Folhas,2023-12-31T00:00:00,1.3210526315789468,1.7298052310943604,30.94143183582813,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Entre_Rios_de_Minas,2023-12-31T00:00:00,1.56,1.7563759088516235,12.58819928536048,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ervalia,2023-12-31T00:00:00,1.380044843049327,1.344030737876892,-2.6096329661910644,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Esmeraldas,2023-12-31T00:00:00,2.222222222222222,1.794616937637329,-19.24223780632018,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Espera_Feliz,2023-12-31T00:00:00,1.08,0.9414645433425904,-12.82735709790831,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Espirito_Santo_do_Dourado,2023-12-31T00:00:00,1.5,0.8894078731536865,-40.70614178975423,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Estrela_do_Indaia,2023-12-31T00:00:00,1.8000000000000005,1.6408225297927856,-8.8431927892897,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Estrela_do_Sul,2023-12-31T00:00:00,2.43015873015873,1.0181500911712646,-58.10355601320073,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Eugenopolis,2023-12-31T00:00:00,1.68,1.5136468410491943,-9.901973747071764,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Fama,2023-12-31T00:00:00,1.559677419354839,1.1596720218658447,-25.646674916564265,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Faria_Lemos,2023-12-31T00:00:00,1.380152671755725,1.0467040538787842,-24.160270432455345,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Felicio_dos_Santos,2023-12-31T00:00:00,3.542087542087541,2.3824286460876465,-32.73941940227841,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ferros,2023-12-31T00:00:00,1.17948717948718,1.2489266395568848,5.887258571127144,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Fervedouro,2023-12-31T00:00:00,1.2,1.569412112236023,30.78434268633525,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Formiga,2023-12-31T00:00:00,2.021543985637344,0.9953352808952332,-50.76360999479177,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Formoso,2023-12-31T00:00:00,3.3803921568627446,2.622343063354492,-22.42488617686826,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Fortaleza_de_Minas,2023-12-31T00:00:00,1.5,1.7997698783874512,19.98465855916341,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Franciscopolis,2023-12-31T00:00:00,1.2,0.8731105327606201,-27.24078893661499,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Frei_Gaspar,2023-12-31T00:00:00,1.2,0.9118648767471312,-24.011260271072384,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Grao_Mogol,2023-12-31T00:00:00,1.155555555555555,0.5187088251113892,-55.11173628843745,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Guape,2023-12-31T00:00:00,1.560674157303371,0.9632456302642822,-38.2801576000568,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Guaraciaba,2023-12-31T00:00:00,1.5,2.163748979568481,44.2499319712321,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Guaranesia,2023-12-31T00:00:00,1.1961439588688951,0.8565869927406311,-28.38763374680736,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Guarani,2023-12-31T00:00:00,0.9655172413793104,1.162451148033142,20.39672604628971,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Guarda-Mor,2023-12-31T00:00:00,1.7994350282485878,1.3982908725738523,-22.29278353357241,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Guaxupe,2023-12-31T00:00:00,1.2,0.7738983631134033,-35.50846974054972,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Guimarania,2023-12-31T00:00:00,1.7704600484261497,0.8431018590927124,-52.379503855950446,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Guiricema,2023-12-31T00:00:00,1.5,2.542483329772949,69.49888865152994,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Heliodora,2023-12-31T00:00:00,1.439872408293461,1.0532708168029783,-26.849711770550797,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Iapu,2023-12-31T00:00:00,1.559210526315789,1.3330144882202148,-14.507087675327965,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ibia,2023-12-31T00:00:00,1.668,0.8682499527931213,-47.94664551599992,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ibiraci,2023-12-31T00:00:00,1.804169884169884,0.7872268557548523,-56.36625671107114,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ibitiura_de_Minas,2023-12-31T00:00:00,1.150344827586207,1.128239393234253,-1.921635480235809,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ibituruna,2023-12-31T00:00:00,1.8000000000000005,1.1533774137496948,-35.92347701390585,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ijaci,2023-12-31T00:00:00,1.971428571428572,0.6212234497070312,-68.48866559457089,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ilicinea,2023-12-31T00:00:00,1.560032362459547,0.8360768556594849,-46.40644157270391,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Imbe_de_Minas,2023-12-31T00:00:00,1.3799999999999997,0.9478880167007446,-31.31246255791704,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Inconfidentes,2023-12-31T00:00:00,1.7401360544217692,0.8459286689758301,-51.38721096972362,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Indaiabira,2023-12-31T00:00:00,1.9320754716981128,1.6492254734039309,-14.6396971773356,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Indianopolis,2023-12-31T00:00:00,2.7000000000000006,1.38995361328125,-48.5202365451389,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ingai,2023-12-31T00:00:00,1.6197718631178712,0.9561312198638916,-40.97124159056258,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Inhapim,2023-12-31T00:00:00,2.7000000000000006,1.451927661895752,-46.22490141126846,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Irai_de_Minas,2023-12-31T00:00:00,2.18825561312608,1.300668478012085,-40.56140104427806,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Itabirinha,2023-12-31T00:00:00,1.027027027027027,0.7737619876861572,-24.66001698845311,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Itacambira,2023-12-31T00:00:00,0.75,0.487337589263916,-35.0216547648112,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Itaipe,2023-12-31T00:00:00,0.9598214285714286,0.851681649684906,-11.2666560328284,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Itajuba,2023-12-31T00:00:00,1.5862068965517242,1.9212422370910645,21.12179320791493,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Itamarandiba,2023-12-31T00:00:00,2.4,2.1026268005371094,-12.39054997762044,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Itamarati_de_Minas,2023-12-31T00:00:00,1.2,1.2646377086639404,5.38647572199504,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Itambacuri,2023-12-31T00:00:00,0.8987341772151899,0.69034743309021,-23.18669406461044,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Itamogi,2023-12-31T00:00:00,1.740011254924029,0.970897138118744,-44.20167482415886,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Itanhomi,2023-12-31T00:00:00,1.078787878787879,0.9479302763938904,-12.130058648880972,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Itapecerica,2023-12-31T00:00:00,0.9037974683544304,0.7979830503463745,-11.70775773478491,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ituiutaba,2023-12-31T00:00:00,1.0,1.3128256797790527,31.282567977905277,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Itumirim,2023-12-31T00:00:00,1.532033426183844,0.87166428565979,-43.10409480875189,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Itutinga,2023-12-31T00:00:00,1.5,1.0387659072875977,-30.74893951416016,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Jacui,2023-12-31T00:00:00,1.32,0.9955139756202698,-24.58227457422199,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Jacutinga,2023-12-31T00:00:00,1.160053262316911,1.0416479110717771,-10.206889208573854,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Jequeri,2023-12-31T00:00:00,1.5,2.007936954498291,33.862463633219406,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Jequitinhonha,2023-12-31T00:00:00,2.7000000000000006,2.361967086791992,-12.519737526222531,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Jesuania,2023-12-31T00:00:00,1.26,1.0972683429718018,-12.91521087525383,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Joao_Pinheiro,2023-12-31T00:00:00,3.3,2.0045006275177,-39.25755674188788,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Jose_Goncalves_de_Minas,2023-12-31T00:00:00,1.3210526315789468,1.2695753574371338,-3.8966860904161273,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Juiz_de_Fora,2023-12-31T00:00:00,0.7142857142857143,1.3335137367248535,86.69192314147949,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Juruaia,2023-12-31T00:00:00,1.5,1.3790045976638794,-8.066360155741375,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ladainha,2023-12-31T00:00:00,1.081818181818182,0.5226437449455261,-51.68839332436313,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Lagoa_Dourada,2023-12-31T00:00:00,1.8000000000000005,1.319095492362976,-26.716917090945785,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Lagoa_Formosa,2023-12-31T00:00:00,1.978723404255319,1.6608572006225586,-16.064205990042733,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Lagoa_Grande,2023-12-31T00:00:00,2.4,0.6436253190040588,-73.18227837483087,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Lajinha,2023-12-31T00:00:00,1.4399536768963517,1.3921656608581543,-3.318718984155014,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Lambari,2023-12-31T00:00:00,1.56,1.113139510154724,-28.64490319520999,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Lamim,2023-12-31T00:00:00,1.8000000000000005,2.409374713897705,33.854150772094705,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Lavras,2023-12-31T00:00:00,1.5,0.8983858227729797,-40.10761181513469,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Luisburgo,2023-12-31T00:00:00,1.44,1.4755253791809082,2.467040220896407,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Luminarias,2023-12-31T00:00:00,1.260224719101124,1.1190359592437744,-11.203459011505087,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Machado,2023-12-31T00:00:00,1.500560931145702,0.9826335906982422,-34.5155821198153,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Malacacheta,2023-12-31T00:00:00,1.619230769230769,1.7039883136749268,5.234432673510929,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Manhuacu,2023-12-31T00:00:00,1.2,1.6723552942276,39.36294118563335,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Manhumirim,2023-12-31T00:00:00,1.44,1.3260542154312134,-7.9129017061657345,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Mantena,2023-12-31T00:00:00,1.2,0.5791913270950317,-51.73405607541402,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Mar_de_Espanha,2023-12-31T00:00:00,1.5625,2.3106582164764404,47.88212585449219,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Maria_da_Fe,2023-12-31T00:00:00,1.422222222222222,1.38018000125885,-2.956093661487091,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Martins_Soares,2023-12-31T00:00:00,1.2,1.4157302379608154,17.977519830067955,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Mata_Verde,2023-12-31T00:00:00,1.739700374531835,1.5891392230987549,-8.654430017789531,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Matipo,2023-12-31T00:00:00,1.25990675990676,1.3774373531341553,9.32851517012999,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Matutina,2023-12-31T00:00:00,1.502024291497976,1.581735610961914,5.306926120644931,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Medeiros,2023-12-31T00:00:00,1.86,1.0534814596176147,-43.36121184851533,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Minas_Novas,2023-12-31T00:00:00,1.26,1.5397720336914062,22.204129658048117,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Miradouro,2023-12-31T00:00:00,1.140084388185654,0.9989374279975892,-12.380395841810277,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Mirai,2023-12-31T00:00:00,1.08,0.988014280796051,-8.517196222587874,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Moeda,2023-12-31T00:00:00,1.0,1.4333316087722778,43.33316087722778,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Monsenhor_Paulo,2023-12-31T00:00:00,1.389931972789116,1.0623157024383545,-23.57066941149272,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Monte_Alegre_de_Minas,2023-12-31T00:00:00,2.338983050847458,1.9263585805892944,-17.64119111973308,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Monte_Belo,2023-12-31T00:00:00,1.3799999999999997,0.8106384873390198,-41.25808062760725,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Monte_Carmelo,2023-12-31T00:00:00,2.4900284900284904,1.2858328819274902,-48.360716069044734,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Monte_Formoso,2023-12-31T00:00:00,0.6000000000000001,0.6598749160766602,9.979152679443343,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Monte_Santo_de_Minas,2023-12-31T00:00:00,1.620050377833753,0.8875170946121216,-45.21669777955527,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Monte_Siao,2023-12-31T00:00:00,1.5,0.9396969079971312,-37.35353946685791,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Muriae,2023-12-31T00:00:00,1.057297297297297,0.7005192041397095,-33.74434930171457,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Mutum,2023-12-31T00:00:00,1.019985196150999,1.4024909734725952,37.50111067935245,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Muzambinho,2023-12-31T00:00:00,1.68,1.0699729919433594,-36.3111314319429,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Natercia,2023-12-31T00:00:00,1.5,1.93299663066864,28.866442044576008,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Nazareno,2023-12-31T00:00:00,1.5599056603773582,1.1459511518478394,-26.537150229288788,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Nepomuceno,2023-12-31T00:00:00,1.650045578851413,0.7235146760940552,-56.15183693303252,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ninheira,2023-12-31T00:00:00,3.0,2.1503500938415527,-28.32166353861491,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Nova_Belem,2023-12-31T00:00:00,0.96,0.6130625605583191,-36.13931660850842,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Nova_Era,2023-12-31T00:00:00,2.636363636363636,1.356239676475525,-48.55642606472146,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Nova_Ponte,2023-12-31T00:00:00,2.6142857142857143,2.025336742401123,-22.528102749683818,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Nova_Resende,2023-12-31T00:00:00,1.56,1.4944473505020142,-4.202092916537557,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Novo_Cruzeiro,2023-12-31T00:00:00,1.209891435464415,1.178879737854004,-2.5631801913290944,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Novorizonte,2023-12-31T00:00:00,1.333333333333333,1.1456667184829712,-14.07499611377714,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Olimpio_Noronha,2023-12-31T00:00:00,1.2,1.3693583011627195,14.113191763559982,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Oliveira,2023-12-31T00:00:00,1.8240227434257288,1.0563877820968628,-42.08472531911293,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Orizania,2023-12-31T00:00:00,1.2,1.6137242317199707,34.477019309997566,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ouro_Fino,2023-12-31T00:00:00,1.68,0.9061533212661744,-46.06230230558487,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ouro_Verde_de_Minas,2023-12-31T00:00:00,2.5,1.8992775678634644,-24.028897285461422,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Padre_Paraiso,2023-12-31T00:00:00,0.7212121212121212,0.5606741309165955,-22.25946924265693,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Paracatu,2023-12-31T00:00:00,2.4,1.8641376495361328,-22.327597935994465,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Paraguacu,2023-12-31T00:00:00,1.298291457286432,0.927615225315094,-28.55107995134552,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Paraisopolis,2023-12-31T00:00:00,1.2,2.212470293045044,84.37252442042033,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Passa_Tempo,2023-12-31T00:00:00,1.625,1.3796347379684448,-15.099400740403397,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Passos,2023-12-31T00:00:00,1.829801324503311,1.197981595993042,-34.52941693993869,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Patis,2023-12-31T00:00:00,1.2,1.168081521987915,-2.659873167673743,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Patos_de_Minas,2023-12-31T00:00:00,1.782452316076294,1.9491204023361208,9.35049340487899,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Patrocinio,2023-12-31T00:00:00,2.4370275910039414,0.6188873648643494,-74.60482732534855,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Paula_Candido,2023-12-31T00:00:00,1.6197080291970802,1.8099358081817627,11.744572204101624,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pecanha,2023-12-31T00:00:00,2.30379746835443,1.961004614830017,-14.879470015620116,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pedra_Azul,2023-12-31T00:00:00,1.166666666666667,1.4936431646347046,28.026556968688933,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pedra_Bonita,2023-12-31T00:00:00,1.08,1.569678783416748,45.34062809414333,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pedra_Dourada,2023-12-31T00:00:00,1.2,1.200355887413025,0.0296572844187455,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pedra_do_Anta,2023-12-31T00:00:00,1.5,1.8651509284973145,24.343395233154297,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pedralva,2023-12-31T00:00:00,1.67998417721519,1.6958520412445068,0.94452461186986,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pedrinopolis,2023-12-31T00:00:00,2.187804878048781,1.0135763883590698,-53.67153631803585,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Perdizes,2023-12-31T00:00:00,2.106451612903226,0.8974653482437134,-57.394447480007486,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Perdoes,2023-12-31T00:00:00,1.6799401197604789,0.9668936729431152,-42.4447537403314,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Piedade_de_Caratinga,2023-12-31T00:00:00,2.4,1.1138900518417358,-53.58791450659434,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pimenta,2023-12-31T00:00:00,1.504186046511628,0.9364026188850404,-37.74688835489064,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Piracema,2023-12-31T00:00:00,1.2,0.9690993428230286,-19.241721431414284,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Piranga,2023-12-31T00:00:00,2.1,2.1883912086486816,4.209105173746741,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pirangucu,2023-12-31T00:00:00,1.333333333333333,1.3094091415405271,-1.7943143844604277,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Piranguinho,2023-12-31T00:00:00,1.460887949260042,1.4323959350585938,-1.950321666756151,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pirapora,2023-12-31T00:00:00,3.6000000000000005,3.039409875869751,-15.571947892506929,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Piumhi,2023-12-31T00:00:00,1.7399633363886338,1.0287652015686035,-40.87431728855572,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Poco_Fundo,2023-12-31T00:00:00,1.380160799652325,0.9892614483833312,-28.32273973927276,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pocos_de_Caldas,2023-12-31T00:00:00,1.5,1.2800620794296265,-14.662528038024902,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pocrane,2023-12-31T00:00:00,1.377952755905512,1.3933695554733276,1.1188191686357611,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ponte_Nova,2023-12-31T00:00:00,1.333333333333333,1.2046071290969849,-9.654465317726116,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ponto_dos_Volantes,2023-12-31T00:00:00,0.6000000000000001,0.5545651316642761,-7.572478055953994,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Porto_Firme,2023-12-31T00:00:00,1.200764818355641,1.465744972229004,22.067614725440887,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pote,2023-12-31T00:00:00,1.125,1.0542844533920288,-6.285826365152995,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pouso_Alegre,2023-12-31T00:00:00,1.566666666666667,1.416614294052124,-9.577811017949555,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pouso_Alto,2023-12-31T00:00:00,1.8000000000000005,1.430105209350586,-20.549710591634128,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pratapolis,2023-12-31T00:00:00,1.8011363636363642,0.8396955728530884,-53.37967797408722,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pratinha,2023-12-31T00:00:00,2.13,1.2606689929962158,-40.81366230064714,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Presidente_Bernardes,2023-12-31T00:00:00,1.320588235294118,1.492972731590271,13.053614418862356,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Presidente_Kubitschek,2023-12-31T00:00:00,0.8947368421052632,0.2944328784942627,-67.09279593299416,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Presidente_Olegario,2023-12-31T00:00:00,2.160074626865672,1.3519940376281738,-37.40984590009492,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Quartel_Geral,2023-12-31T00:00:00,3.0,2.5094029903411865,-16.353233655293785,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Raul_Soares,2023-12-31T00:00:00,1.5,1.046862244606018,-30.20918369293213,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Reduto,2023-12-31T00:00:00,0.9,1.5485179424285889,72.05754915873209,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ribeirao_Vermelho,2023-12-31T00:00:00,1.5,0.9816766381263732,-34.55489079157512,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Rio_Paranaiba,2023-12-31T00:00:00,1.8000000000000005,0.7763312458992004,-56.87048633893331,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Rio_Pardo_de_Minas,2023-12-31T00:00:00,2.568224299065421,2.187808036804199,-14.812423603329965,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Rio_Vermelho,2023-12-31T00:00:00,0.9,0.5814417600631714,-35.39535999298096,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ritapolis,2023-12-31T00:00:00,2.102222222222222,1.7016894817352295,-19.052825921685702,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Romaria,2023-12-31T00:00:00,2.131578947368421,1.504771709442139,-29.40577165580089,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Rosario_da_Limeira,2023-12-31T00:00:00,1.2,0.8775492310523987,-26.87089741230011,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sabinopolis,2023-12-31T00:00:00,1.2,1.1844555139541626,-1.2953738371531132,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sacramento,2023-12-31T00:00:00,1.75,0.857040286064148,-51.02626936776298,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santa_Barbara,2023-12-31T00:00:00,1.3,1.0924502611160278,-15.965364529536323,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santa_Barbara_do_Leste,2023-12-31T00:00:00,1.08,1.1053916215896606,2.3510760731167197,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santa_Barbara_do_Monte_Verde,2023-12-31T00:00:00,1.4,1.7579574584960938,25.56838989257813,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santa_Margarida,2023-12-31T00:00:00,1.32,1.6193069219589231,22.674766815069944,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santa_Maria_do_Suacui,2023-12-31T00:00:00,0.6666666666666667,0.894262969493866,34.13944542407988,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santa_Rita_de_Caldas,2023-12-31T00:00:00,1.68,1.8151185512542725,8.042770907992413,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santa_Rita_de_Minas,2023-12-31T00:00:00,1.019930675909879,1.089427471160889,6.81387440269033,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santa_Rita_do_Itueto,2023-12-31T00:00:00,1.2,1.5699089765548706,30.82574804623922,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santa_Rita_do_Sapucai,2023-12-31T00:00:00,1.3799999999999997,1.440183162689209,4.361098745594879,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santa_Rosa_da_Serra,2023-12-31T00:00:00,1.68,1.88195276260376,12.020997774033324,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santana_da_Vargem,2023-12-31T00:00:00,1.5593593593593589,0.8128181099891663,-47.87486892546043,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santana_do_Jacare,2023-12-31T00:00:00,0.9011235955056182,0.6673990488052368,-25.937013287199424,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santana_do_Manhuacu,2023-12-31T00:00:00,1.32,1.2936882972717283,-1.9933108127478445,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santo_Antonio_do_Amparo,2023-12-31T00:00:00,1.8000000000000005,0.8124397397041321,-54.864458905326,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santo_Antonio_do_Grama,2023-12-31T00:00:00,1.521739130434783,1.9710925817489624,29.52894108636036,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santo_Antonio_do_Retiro,2023-12-31T00:00:00,1.02,0.9445757269859314,-7.394536570006728,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Bento_Abade,2023-12-31T00:00:00,1.5,0.7010489702224731,-53.26340198516846,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Domingos_das_Dores,2023-12-31T00:00:00,1.296078431372549,1.0877469778060913,-16.073985070936985,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Domingos_do_Prata,2023-12-31T00:00:00,1.2,1.478419065475464,23.201588789621997,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Francisco_de_Paula,2023-12-31T00:00:00,1.56,1.3402405977249146,-14.08714117147984,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Francisco_do_Gloria,2023-12-31T00:00:00,1.08,0.8043275475502014,-25.52522707868506,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Geraldo,2023-12-31T00:00:00,1.5,1.5284682512283323,1.897883415222168,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Goncalo_do_Abaete,2023-12-31T00:00:00,1.619047619047619,1.1214876174926758,-30.731647154864145,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Goncalo_do_Rio_Preto,2023-12-31T00:00:00,2.868421052631579,0.4790414273738861,-83.2994731741214,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Goncalo_do_Sapucai,2023-12-31T00:00:00,1.2,1.077445149421692,-10.212904214859003,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Gotardo,2023-12-31T00:00:00,1.5,1.088285207748413,-27.44765281677246,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Joao_Batista_do_Gloria,2023-12-31T00:00:00,1.5232974910394272,1.1610732078552246,-23.77895882550412,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Joao_da_Mata,2023-12-31T00:00:00,1.08,1.4492149353027344,34.18656808358651,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Joao_del_Rei,2023-12-31T00:00:00,1.799568965517241,1.5447840690612793,-14.158106821025903,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Joao_do_Manhuacu,2023-12-31T00:00:00,1.2,1.3841314315795898,15.344285964965826,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Joao_do_Manteninha,2023-12-31T00:00:00,1.2,0.7898458242416382,-34.17951464653015,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Joao_do_Paraiso,2023-12-31T00:00:00,3.601190476190476,1.681699275970459,-53.30157382429138,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Jose_da_Barra,2023-12-31T00:00:00,2.2413698630136984,1.5027421712875366,-32.95429745508484,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Jose_do_Alegre,2023-12-31T00:00:00,1.592307692307692,1.7336173057556152,8.874516786584554,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Jose_do_Mantimento,2023-12-31T00:00:00,1.5,1.497202754020691,-0.1864830652872721,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Lourenco,2023-12-31T00:00:00,1.5,1.5008563995361328,0.0570933024088541,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Miguel_do_Anta,2023-12-31T00:00:00,1.5598870056497178,1.589369773864746,1.8900579406229636,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Pedro_da_Uniao,2023-12-31T00:00:00,1.5,1.2595807313919067,-16.02795124053955,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Roque_de_Minas,2023-12-31T00:00:00,1.8000000000000005,1.1214570999145508,-37.69682778252496,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Sebastiao_da_Bela_Vista,2023-12-31T00:00:00,1.5,1.564240574836731,4.2827049891153965,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Sebastiao_da_Vargem_Alegre,2023-12-31T00:00:00,1.5,0.8629032969474792,-42.47311353683472,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Sebastiao_do_Anta,2023-12-31T00:00:00,1.7998212689901698,1.5723919868469238,-12.636214832089982,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Sebastiao_do_Maranhao,2023-12-31T00:00:00,1.2,1.0326157808303833,-13.948684930801388,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Sebastiao_do_Paraiso,2023-12-31T00:00:00,1.440017746228926,0.9753323197364808,-32.26942360324024,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Tiago,2023-12-31T00:00:00,1.560526315789474,0.8943661451339722,-42.68817282446722,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Tomas_de_Aquino,2023-12-31T00:00:00,1.319968346082828,0.9848026037216188,-25.39195302340816,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Tome_das_Letras,2023-12-31T00:00:00,1.09812734082397,1.1260817050933838,2.545639583879085,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Senador_Firmino,2023-12-31T00:00:00,1.436170212765957,2.444007158279419,70.1753132431596,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Senador_Jose_Bento,2023-12-31T00:00:00,1.2,1.018138766288757,-15.155102809270222,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Senador_Modestino_Goncalves,2023-12-31T00:00:00,2.7000000000000006,2.226637125015259,-17.531958332768212,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Senhora_de_Oliveira,2023-12-31T00:00:00,1.2,1.6525572538375854,37.71310448646546,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Senhora_dos_Remedios,2023-12-31T00:00:00,1.5,1.538726806640625,2.581787109375,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sericita,2023-12-31T00:00:00,1.26,2.638876438140869,109.43463794768802,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Serra_do_Salitre,2023-12-31T00:00:00,1.489636363636364,0.9723109006881714,-34.72830521439106,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Serrania,2023-12-31T00:00:00,0.9,1.1587998867034912,28.755542967054577,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Setubinha,2023-12-31T00:00:00,1.2,0.9531363248825072,-20.57197292645772,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Silvianopolis,2023-12-31T00:00:00,1.13974358974359,0.8568446040153503,-24.821283337235865,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Simonesia,2023-12-31T00:00:00,1.5,1.5484931468963623,3.232876459757487,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Soledade_de_Minas,2023-12-31T00:00:00,1.5,0.93589186668396,-37.60720888773601,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Taiobeiras,2023-12-31T00:00:00,3.0,2.1177122592926025,-29.40959135691325,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Tapira,2023-12-31T00:00:00,1.92,1.063176155090332,-44.62624192237854,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Tapirai,2023-12-31T00:00:00,1.5579665220086798,1.42546546459198,-8.504743558023748,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Teixeiras,2023-12-31T00:00:00,1.5007092198581562,1.8382407426834104,22.49146725820457,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Teofilo_Otoni,2023-12-31T00:00:00,1.2,0.7984830737113953,-33.45974385738373,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Tiros,2023-12-31T00:00:00,2.382038834951457,1.157041072845459,-51.42643957485949,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Tocos_do_Moji,2023-12-31T00:00:00,1.5,1.6598646640777588,10.657644271850586,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Tombos,2023-12-31T00:00:00,1.32,1.0280030965805054,-22.1209775317799,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Tres_Coracoes,2023-12-31T00:00:00,1.44,0.8508331179618835,-40.91436680820253,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Tres_Pontas,2023-12-31T00:00:00,1.5900000000000003,0.6600884199142456,-58.48500503683991,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Tupaciguara,2023-12-31T00:00:00,2.622222222222222,1.8762937784194944,-28.446423704341296,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Turmalina,2023-12-31T00:00:00,1.360606060606061,1.0593868494033811,-22.13860572313681,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Turvolandia,2023-12-31T00:00:00,1.259748427672956,1.5613930225372314,23.94482804963544,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ubaporanga,2023-12-31T00:00:00,1.5,1.0861060619354248,-27.59292920430501,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Uberaba,2023-12-31T00:00:00,2.1200980392156863,1.435368299484253,-32.2970790532283,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Uberlandia,2023-12-31T00:00:00,1.8000000000000005,1.55574631690979,-13.569649060567231,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Unai,2023-12-31T00:00:00,2.520095187731359,2.305800437927246,-8.503438713242625,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Urucuia,2023-12-31T00:00:00,2.0994575045207946,1.3554611206054688,-35.437553859188235,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Vargem_Bonita,2023-12-31T00:00:00,1.487234042553192,1.200799822807312,-19.259525505087776,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Vargem_Grande_do_Rio_Pardo,2023-12-31T00:00:00,2.1,1.4465997219085691,-31.1142989567348,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Varginha,2023-12-31T00:00:00,1.679990280646337,0.7110475301742554,-57.675497390336304,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Varjao_de_Minas,2023-12-31T00:00:00,2.3892857142857142,2.263485908508301,-5.265163769458262,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Varzea_da_Palma,2023-12-31T00:00:00,3.3,1.4086273908615112,-57.31432148904511,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Vermelho_Novo,2023-12-31T00:00:00,1.5,0.8966348171234131,-40.22434552510579,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Vicosa,2023-12-31T00:00:00,1.5004329004329,1.4945260286331177,-0.393677837781223,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Vieiras,2023-12-31T00:00:00,1.5,1.0769524574279783,-28.203169504801437,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Virginia,2023-12-31T00:00:00,1.5,1.8230175971984863,21.53450647989909,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Virginopolis,2023-12-31T00:00:00,1.3258426966292132,1.2060869932174685,-9.032421698004493,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Visconde_do_Rio_Branco,2023-12-31T00:00:00,1.333333333333333,1.861584186553955,39.618813991546666,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Abadia_dos_Dourados,2024-12-31T00:00:00,2.6116071428571423,1.928374171257019,-26.16139925443208,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Abre_Campo,2024-12-31T00:00:00,1.32,1.3979711532592771,5.9069055499452485,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Acucena,2024-12-31T00:00:00,1.6666666666666672,1.097183108329773,-34.16901350021364,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Agua_Boa,2024-12-31T00:00:00,1.7064935064935067,1.1235549449920654,-34.16002224932342,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Aguanil,2024-12-31T00:00:00,2.025039123630673,1.0765554904937744,-46.83779301193803,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Aguas_Vermelhas,2024-12-31T00:00:00,3.0,3.7188024520874015,23.960081736246742,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Aimores,2024-12-31T00:00:00,0.9455882352941176,2.0206170082092285,113.68889044825434,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Aiuruoca,2024-12-31T00:00:00,1.8000000000000005,1.833174467086792,1.8430259492662069,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Albertina,2024-12-31T00:00:00,1.56,1.4682692289352417,-5.880177632356305,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Alfenas,2024-12-31T00:00:00,1.635197497066875,0.995194137096405,-39.13920863494911,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Almenara,2024-12-31T00:00:00,0.78,0.4248946905136108,-45.526321729024254,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Alpinopolis,2024-12-31T00:00:00,2.08,0.8727378845214844,-58.04144785954403,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Alterosa,2024-12-31T00:00:00,1.110028116213683,0.8691015839576721,-21.704543221645014,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Alto_Caparao,2024-12-31T00:00:00,1.14,1.2616806030273438,10.673737107661742,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Alto_Jequitiba,2024-12-31T00:00:00,1.02,1.104901671409607,8.323693275451658,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Alvarenga,2024-12-31T00:00:00,1.25,1.2432570457458496,-0.5394363403320312,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Amparo_do_Serra,2024-12-31T00:00:00,1.680555555555556,1.64470636844635,-2.133174770134567,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Andradas,2024-12-31T00:00:00,1.26,1.9895790815353396,57.90310170915392,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Andrelandia,2024-12-31T00:00:00,1.5,1.7689123153686523,17.927487691243492,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Angelandia,2024-12-31T00:00:00,1.870967741935484,2.2115721702575684,18.20471944480106,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Antonio_Dias,2024-12-31T00:00:00,1.5,1.489344358444214,-0.7103761037190754,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Antonio_Prado_de_Minas,2024-12-31T00:00:00,1.933333333333333,1.291454792022705,-33.20061420572213,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Araguari,2024-12-31T00:00:00,1.500037950664137,1.140145182609558,-23.992244189237848,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Araponga,2024-12-31T00:00:00,1.5,1.6472203731536863,9.814691543579102,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Arapua,2024-12-31T00:00:00,1.0805194805194802,0.4442103505134582,-58.8891863106535,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Araxa,2024-12-31T00:00:00,1.412283279459301,0.9417115449905396,-33.31992535158541,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Arceburgo,2024-12-31T00:00:00,1.7586206896551722,1.3827121257781982,-21.37519284790636,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Areado,2024-12-31T00:00:00,1.162105263157895,1.3257437944412231,14.081214195576244,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Aricanduva,2024-12-31T00:00:00,1.320245398773006,1.206479787826538,-8.617004918343067,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Astolfo_Dutra,2024-12-31T00:00:00,0.8749999999999999,0.9635046124458312,10.114812850952164,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ataleia,2024-12-31T00:00:00,0.7529411764705883,0.6922512650489807,-8.060378860682262,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Baependi,2024-12-31T00:00:00,1.439779005524862,1.7781040668487549,23.49840218711612,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Bambui,2024-12-31T00:00:00,1.8000000000000005,1.7225587368011477,-4.302292399936267,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Bandeira,2024-12-31T00:00:00,1.15,1.252507209777832,8.913670415463663,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Bandeira_do_Sul,2024-12-31T00:00:00,1.5,3.060632705688477,104.04218037923177,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Berilo,2024-12-31T00:00:00,1.681818181818182,1.608367919921875,-4.367312869510139,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Berizal,2024-12-31T00:00:00,3.5516129032258075,2.3729305267333984,-33.18724220823312,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Boa_Esperanca,2024-12-31T00:00:00,1.083893395133256,0.5141560435295105,-52.563965622624806,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Bocaiuva,2024-12-31T00:00:00,2.0989010989010994,3.4097087383270264,62.452091721339954,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Bom_Jesus_da_Penha,2024-12-31T00:00:00,1.56,1.5999767780303955,2.562613976307401,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Bom_Jesus_do_Amparo,2024-12-31T00:00:00,0.75,1.4476524591445925,93.02032788594563,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Bom_Jesus_do_Galho,2024-12-31T00:00:00,0.9,1.0843874216079712,20.48749128977457,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Bom_Sucesso,2024-12-31T00:00:00,1.6799426934097417,1.2761006355285645,-24.03903772821608,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Bonfinopolis_de_Minas,2024-12-31T00:00:00,2.1,2.902442216873169,38.21153413681756,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Borda_da_Mata,2024-12-31T00:00:00,1.5,1.6744439601898191,11.629597345987955,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Botelhos,2024-12-31T00:00:00,1.08,3.6831326484680176,241.03080078407567,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Botumirim,2024-12-31T00:00:00,0.7250000000000001,0.6575536727905273,-9.302941684065203,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Brazopolis,2024-12-31T00:00:00,1.501216545012166,1.540002703666687,2.5836484938424884,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Bueno_Brandao,2024-12-31T00:00:00,1.8000000000000005,2.9491636753082275,63.84242640601262,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Buritis,2024-12-31T00:00:00,2.69967707212056,2.7855329513549805,3.180227743571632,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Buritizeiro,2024-12-31T00:00:00,2.7000000000000006,2.9193990230560303,8.125889742815911,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cabo_Verde,2024-12-31T00:00:00,1.32,1.49993634223938,13.631541078740897,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cachoeira_de_Minas,2024-12-31T00:00:00,1.73984375,2.57676362991333,48.10316328195162,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Caete,2024-12-31T00:00:00,1.8000000000000005,1.426618576049805,-20.743412441677528,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Caiana,2024-12-31T00:00:00,1.14,1.029255509376526,-9.714429002059124,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cajuri,2024-12-31T00:00:00,1.32,1.5273716449737549,15.709973104072333,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Caldas,2024-12-31T00:00:00,1.68,1.615793228149414,-3.821831657772969,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Camacho,2024-12-31T00:00:00,1.5,1.9290529489517207,28.603529930114743,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cambuquira,2024-12-31T00:00:00,1.7400000000000002,2.1947944164276123,26.13761013951793,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Campanha,2024-12-31T00:00:00,1.5689448441247,1.5251210927963257,-2.7931989765276435,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Campestre,2024-12-31T00:00:00,1.320032051282051,1.31342613697052,-0.5004359026824432,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Campo_Belo,2024-12-31T00:00:00,1.2,1.510812282562256,25.901023546854663,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Campo_do_Meio,2024-12-31T00:00:00,1.372340425531915,0.5252484083175659,-61.72608497530915,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Campos_Altos,2024-12-31T00:00:00,1.5,4.023837089538574,168.25580596923828,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Campos_Gerais,2024-12-31T00:00:00,1.611315789473684,0.8591824769973755,-46.67820655577288,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cana_Verde,2024-12-31T00:00:00,1.2,0.7800289392471313,-34.99758839607239,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Canaa,2024-12-31T00:00:00,1.319791666666667,1.76551616191864,33.772337446084784,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Candeias,2024-12-31T00:00:00,1.14003294892916,0.3993364572525024,-64.97149861961432,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Caparao,2024-12-31T00:00:00,1.6799283154121862,1.3707343339920044,-18.40518899428861,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Capela_Nova,2024-12-31T00:00:00,2.101234567901236,2.072115421295166,-1.3858113249657098,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Capelinha,2024-12-31T00:00:00,1.62007678089009,1.6807351112365725,3.744163922475072,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Capetinga,2024-12-31T00:00:00,1.437691001697793,0.8682436943054199,-39.60846292561499,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Capitao_Eneas,2024-12-31T00:00:00,3.0,2.4472086429595947,-18.42637856801351,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Capitolio,2024-12-31T00:00:00,1.32,0.458879679441452,-65.23638792110212,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Caputira,2024-12-31T00:00:00,1.38008658008658,1.3762614727020264,-0.2771643054679723,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Carai,2024-12-31T00:00:00,1.2,1.2379465103149414,3.162209192911788,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Caranaiba,2024-12-31T00:00:00,1.5,2.444655179977417,62.97701199849447,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Carangola,2024-12-31T00:00:00,1.44,1.1081840991973877,-23.042770889070297,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Caratinga,2024-12-31T00:00:00,1.6200335289186922,1.5456223487854004,-4.593187659699756,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Careacu,2024-12-31T00:00:00,1.560169491525424,1.9147837162017824,22.729211576214155,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Carmo_da_Cachoeira,2024-12-31T00:00:00,1.44,0.9585763216018676,-33.432199888759186,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Carmo_da_Mata,2024-12-31T00:00:00,1.62,1.448878049850464,-10.563083342563964,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Carmo_de_Minas,2024-12-31T00:00:00,1.56,1.994953155517578,27.88161253317808,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Carmo_do_Paranaiba,2024-12-31T00:00:00,2.103206239168111,0.795555591583252,-62.17415216978811,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Carmo_do_Rio_Claro,2024-12-31T00:00:00,1.7634782608695652,1.125534176826477,-36.17533020954396,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Carmopolis_de_Minas,2024-12-31T00:00:00,1.98,1.697070837020874,-14.289351665612411,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Carrancas,2024-12-31T00:00:00,1.6428571428571432,1.6670386791229248,1.4719195987867038,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Carvalhopolis,2024-12-31T00:00:00,1.62,1.3254514932632446,-18.18200658868861,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Casa_Grande,2024-12-31T00:00:00,2.522388059701492,2.649505376815796,5.039562276129208,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cascalho_Rico,2024-12-31T00:00:00,1.8000000000000005,2.157824277877808,19.879126548767072,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cassia,2024-12-31T00:00:00,1.7162790697674415,0.9025429487228394,-47.41280922075597,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cataguases,2024-12-31T00:00:00,1.0,1.1715924739837646,17.159247398376465,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Catas_Altas_da_Noruega,2024-12-31T00:00:00,0.9,1.0457161664962769,16.19068516625298,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Catuji,2024-12-31T00:00:00,1.138461538461538,1.3224458694458008,16.160785829698767,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Caxambu,2024-12-31T00:00:00,1.795918367346939,1.2383311986923218,-31.04746734554118,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Chale,2024-12-31T00:00:00,1.320168067226891,1.4480774402618408,9.688870395390854,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Claraval,2024-12-31T00:00:00,1.92,0.3663403987884521,-80.91977089643478,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Claudio,2024-12-31T00:00:00,2.699367088607595,1.7858145236968994,-33.84321342459317,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Coimbra,2024-12-31T00:00:00,1.5012658227848097,1.9187151193618772,27.806487714661348,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Conceicao_da_Aparecida,2024-12-31T00:00:00,1.5,1.4780431985855105,-1.463786760965983,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Conceicao_da_Barra_de_Minas,2024-12-31T00:00:00,1.8000000000000005,1.5153114795684814,-15.816028912862151,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Conceicao_das_Pedras,2024-12-31T00:00:00,1.5598885793871868,1.599874496459961,2.5633828980581965,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Conceicao_de_Ipanema,2024-12-31T00:00:00,1.2901734104046243,1.526254653930664,18.298411796597165,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Conceicao_do_Rio_Verde,2024-12-31T00:00:00,1.5,1.712634801864624,14.175653457641602,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Conceicao_dos_Ouros,2024-12-31T00:00:00,1.8000000000000005,1.7445449829101562,-3.0808342827691115,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Congonhal,2024-12-31T00:00:00,1.8000000000000005,0.998396337032318,-44.53353683153789,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Congonhas_do_Norte,2024-12-31T00:00:00,1.2,0.7577383518218994,-36.85513734817505,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Conselheiro_Pena,2024-12-31T00:00:00,1.2,1.477651834487915,23.137652873992927,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Coqueiral,2024-12-31T00:00:00,0.9,0.6929183006286621,-23.009077707926437,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cordislandia,2024-12-31T00:00:00,1.439887640449438,0.9028209447860718,-37.29920867268015,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Coroaci,2024-12-31T00:00:00,2.1,1.896991491317749,-9.667071842011955,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Coromandel,2024-12-31T00:00:00,1.6144686299615878,0.7195256948471069,-55.43266177527239,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Corrego_Danta,2024-12-31T00:00:00,1.5,1.9860023260116575,32.40015506744385,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Corrego_Fundo,2024-12-31T00:00:00,1.501960784313725,0.2512219250202179,-83.27373606262256,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Corrego_Novo,2024-12-31T00:00:00,1.2,1.3047664165496826,8.730534712473556,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cristais,2024-12-31T00:00:00,1.439664804469274,0.5217649340629578,-63.75788777754388,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cristina,2024-12-31T00:00:00,1.619736842105263,1.7665023803710938,9.06107303672067,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cruzeiro_da_Fortaleza,2024-12-31T00:00:00,2.22,0.8829068541526794,-60.22942098411354,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cruzilia,2024-12-31T00:00:00,1.502793296089385,1.5923491716384888,5.9592943209254905,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Cuparaque,2024-12-31T00:00:00,1.020408163265306,0.994558811187744,-2.533236503601055,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Datas,2024-12-31T00:00:00,1.0,0.044680718332529,-95.5319281667471,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Delfinopolis,2024-12-31T00:00:00,1.5,0.6850531697273254,-54.32978868484497,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Desterro_de_Entre_Rios,2024-12-31T00:00:00,1.3780487804878048,2.1027703285217285,52.59041322016085,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Diamantina,2024-12-31T00:00:00,2.967637540453075,3.198396921157837,7.77586135635457,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Divinesia,2024-12-31T00:00:00,1.316666666666667,3.2135238647460938,144.06510365160193,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Divino,2024-12-31T00:00:00,1.2,1.2480109930038452,4.000916083653772,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Divisa_Nova,2024-12-31T00:00:00,1.679831932773109,1.8557343482971191,10.4714294383978,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Divisopolis,2024-12-31T00:00:00,1.4902200488997548,1.236117601394653,-17.051337330531016,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Dom_Cavati,2024-12-31T00:00:00,0.6000000000000001,0.5042769312858582,-15.953844785690318,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Dom_Vicoso,2024-12-31T00:00:00,1.2,1.620431423187256,35.035951932271324,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Dores_do_Turvo,2024-12-31T00:00:00,1.2,1.4483168125152588,20.693067709604904,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Doresopolis,2024-12-31T00:00:00,1.5615384615384622,1.0689576864242554,-31.544581657560027,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Durande,2024-12-31T00:00:00,1.380095693779904,1.4515440464019775,5.177057862298351,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Eloi_Mendes,2024-12-31T00:00:00,1.421623345558922,1.1538293361663818,-18.837198349978905,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Entre_Folhas,2024-12-31T00:00:00,1.2,1.437416434288025,19.78470285733541,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Entre_Rios_de_Minas,2024-12-31T00:00:00,1.88,1.7812496423721311,-5.25267859722705,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ervalia,2024-12-31T00:00:00,1.32,1.8843703269958496,42.75532780271587,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Esmeraldas,2024-12-31T00:00:00,3.0,2.1012625694274902,-29.957914352416992,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Espera_Feliz,2024-12-31T00:00:00,1.44,1.1938396692276,-17.09446741474999,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Espirito_Santo_do_Dourado,2024-12-31T00:00:00,1.4391752577319588,0.7156033515930176,-50.27684448100093,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Estrela_do_Indaia,2024-12-31T00:00:00,1.56,1.8356772661209104,17.671619623135292,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Estrela_do_Sul,2024-12-31T00:00:00,1.7099999999999995,1.11234450340271,-34.95061383609882,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Eugenopolis,2024-12-31T00:00:00,1.68,1.624985933303833,-3.274646827152793,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Fama,2024-12-31T00:00:00,1.679838709677419,1.5072901248931885,-10.271735243996442,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Faria_Lemos,2024-12-31T00:00:00,1.37956204379562,1.0986047983169556,-20.36568393152224,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Felicio_dos_Santos,2024-12-31T00:00:00,2.663299663299664,1.7680714130401611,-33.613500673460464,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ferros,2024-12-31T00:00:00,1.205128205128205,1.183144211769104,-1.8242037042658328,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Fervedouro,2024-12-31T00:00:00,1.56,1.3925352096557615,-10.734922457963997,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Formiga,2024-12-31T00:00:00,1.9475763016157988,1.622983455657959,-16.66650213850634,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Formoso,2024-12-31T00:00:00,3.6000000000000005,3.1216111183166504,-13.288580046759725,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Fortaleza_de_Minas,2024-12-31T00:00:00,1.5598425196850392,1.703907489776611,9.235866330958943,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Franciscopolis,2024-12-31T00:00:00,0.9,1.1111541986465454,23.46157762739393,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Frei_Gaspar,2024-12-31T00:00:00,1.2,1.2270686626434326,2.255721886952722,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Grao_Mogol,2024-12-31T00:00:00,2.0333333333333337,1.0719727277755735,-47.28002978152917,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Guape,2024-12-31T00:00:00,1.7459340659340663,0.760919451713562,-56.41762959092767,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Guaraciaba,2024-12-31T00:00:00,1.8000000000000005,1.8419923782348635,2.332909901936834,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Guaranesia,2024-12-31T00:00:00,1.205714285714286,0.890617311000824,-26.133635343533573,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Guarani,2024-12-31T00:00:00,0.9655172413793104,1.1616556644439695,20.314336674554,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Guarda-Mor,2024-12-31T00:00:00,1.740112994350282,1.5991549491882324,-8.100511036909994,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Guaxupe,2024-12-31T00:00:00,1.32,0.8632778525352478,-34.60016268672366,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Guimarania,2024-12-31T00:00:00,1.8219512195121947,1.2770729064941406,-29.90630633700164,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Guiricema,2024-12-31T00:00:00,1.56,2.0386884212493896,30.6851552082942,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Heliodora,2024-12-31T00:00:00,1.5601255886970171,1.0698065757751465,-31.42817581316478,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Iapu,2024-12-31T00:00:00,1.355263157894737,1.580111742019653,16.590769314071498,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ibia,2024-12-31T00:00:00,1.681621621621622,0.7384247779846191,-56.08852975662022,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ibiraci,2024-12-31T00:00:00,1.978101265822785,0.499069333076477,-74.77028392331114,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ibitiura_de_Minas,2024-12-31T00:00:00,1.360264900662252,0.8394700288772583,-38.2862831740672,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ibituruna,2024-12-31T00:00:00,1.8000000000000005,1.3835058212280271,-23.138565487331824,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ijaci,2024-12-31T00:00:00,2.19,0.6883248686790466,-68.56964069958691,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ilicinea,2024-12-31T00:00:00,1.5,0.5935535430908203,-60.42976379394531,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Imbe_de_Minas,2024-12-31T00:00:00,1.26,1.478682041168213,17.35571755303277,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Inconfidentes,2024-12-31T00:00:00,1.8000000000000005,2.9992074966430664,66.62263870239255,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Indaiabira,2024-12-31T00:00:00,2.511111111111111,1.6335697174072266,-34.94633868732284,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Indianopolis,2024-12-31T00:00:00,1.8000000000000005,1.1015838384628296,-38.80089786317614,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ingai,2024-12-31T00:00:00,1.621004566210046,2.1550443172454834,32.944987458242466,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Inhapim,2024-12-31T00:00:00,1.2,1.920479416847229,60.03995140393575,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Irai_de_Minas,2024-12-31T00:00:00,2.607944732297064,2.391982078552246,-8.280952087301285,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Itabirinha,2024-12-31T00:00:00,0.8918918918918919,0.8603466153144836,-3.536894646557894,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Itacambira,2024-12-31T00:00:00,0.5,0.6753569841384888,35.071396827697754,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Itaipe,2024-12-31T00:00:00,0.9,0.9877461194992064,9.749568833245169,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Itajuba,2024-12-31T00:00:00,1.068965517241379,1.7134053707122805,60.28630887308432,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Itamarandiba,2024-12-31T00:00:00,2.1352380952380954,2.007610321044922,-5.97721511609421,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Itamarati_de_Minas,2024-12-31T00:00:00,1.196969696969697,1.1676852703094482,-2.446547037438505,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Itambacuri,2024-12-31T00:00:00,1.084388185654009,0.7261717319488525,-33.03396868798523,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Itamogi,2024-12-31T00:00:00,1.44,1.5656321048736572,8.72445172733731,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Itanhomi,2024-12-31T00:00:00,1.02089552238806,0.9835590124130248,-3.657231240244668,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Itapecerica,2024-12-31T00:00:00,1.615189873417721,0.436573326587677,-72.97077366737736,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ituiutaba,2024-12-31T00:00:00,1.0,0.9633177518844604,-3.668224811553955,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Itumirim,2024-12-31T00:00:00,1.62116991643454,1.0348234176635742,-36.1681087729857,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Itutinga,2024-12-31T00:00:00,1.8000000000000005,1.5750354528427124,-12.498030397627105,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Jacui,2024-12-31T00:00:00,1.3799999999999997,1.1677546501159668,-15.380097817683543,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Jacutinga,2024-12-31T00:00:00,1.319874804381847,1.0825425386428833,-17.981422552430367,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Jequeri,2024-12-31T00:00:00,1.8000000000000005,1.643721342086792,-8.682147661844903,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Jequitinhonha,2024-12-31T00:00:00,2.4,2.391278982162476,-0.3633757432301802,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Jesuania,2024-12-31T00:00:00,1.5,1.7712723016738892,18.084820111592613,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Joao_Pinheiro,2024-12-31T00:00:00,3.0,2.4756476879119877,-17.478410402933754,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Jose_Goncalves_de_Minas,2024-12-31T00:00:00,1.5,1.4866015911102295,-0.8932272593180338,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Juiz_de_Fora,2024-12-31T00:00:00,1.166666666666667,0.945698618888855,-18.940118380955308,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Juruaia,2024-12-31T00:00:00,1.68,1.3378123044967651,-20.36831520852588,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ladainha,2024-12-31T00:00:00,1.12,0.7582935094833374,-32.29522236755917,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Lagoa_Dourada,2024-12-31T00:00:00,1.5,2.5562620162963867,70.41746775309244,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Lagoa_Formosa,2024-12-31T00:00:00,1.8142857142857145,1.812058687210083,-0.1227495238537043,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Lagoa_Grande,2024-12-31T00:00:00,2.4,1.0327517986297607,-56.9686750570933,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Lajinha,2024-12-31T00:00:00,1.564997053624043,1.42126202583313,-9.184364114812087,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Lambari,2024-12-31T00:00:00,1.56,2.3884334564208984,53.10470874492938,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Lamim,2024-12-31T00:00:00,1.777777777777778,1.9038357734680176,7.090762257575968,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Lavras,2024-12-31T00:00:00,1.55996015936255,0.8919349908828735,-42.823219841246015,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Luisburgo,2024-12-31T00:00:00,1.2,1.506248950958252,25.52074591318767,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Luminarias,2024-12-31T00:00:00,1.380229885057471,1.4104923009872437,2.192563445944553,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Machado,2024-12-31T00:00:00,1.3347736360118658,0.7577608823776245,-43.22925910930352,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Malacacheta,2024-12-31T00:00:00,1.5,1.5682494640350342,4.549964269002279,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Manhuacu,2024-12-31T00:00:00,1.5,1.251911997795105,-16.539200146993004,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Manhumirim,2024-12-31T00:00:00,1.56,1.3471052646636963,-13.647098418993831,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Mantena,2024-12-31T00:00:00,1.2,0.42510986328125,-64.57417805989584,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Mar_de_Espanha,2024-12-31T00:00:00,1.2625,1.8230338096618648,44.39871759697943,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Maria_da_Fe,2024-12-31T00:00:00,1.477777777777778,1.5436952114105225,4.460578215749619,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Martins_Soares,2024-12-31T00:00:00,1.2,1.3296984434127808,10.808203617731737,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Mata_Verde,2024-12-31T00:00:00,1.5,1.6779741048812866,11.86494032541911,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Matipo,2024-12-31T00:00:00,1.2,1.3104097843170166,9.200815359751388,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Matutina,2024-12-31T00:00:00,1.380566801619433,1.350050687789917,-2.2104047260675834,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Medeiros,2024-12-31T00:00:00,1.8600609756097564,2.34689998626709,26.173282330045133,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Minas_Novas,2024-12-31T00:00:00,1.6204545454545451,1.893014430999756,16.81996488638047,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Miradouro,2024-12-31T00:00:00,1.13996383363472,1.16484797000885,2.1828882320580507,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Mirai,2024-12-31T00:00:00,1.2,1.1587272882461548,-3.4393926461537645,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Moeda,2024-12-31T00:00:00,1.5,1.178717017173767,-21.418865521748863,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Monsenhor_Paulo,2024-12-31T00:00:00,1.5899728997289972,1.0325597524642944,-35.058028181468444,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Monte_Alegre_de_Minas,2024-12-31T00:00:00,2.378787878787879,2.575045347213745,8.25031395930393,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Monte_Belo,2024-12-31T00:00:00,1.5,1.1448894739151,-23.67403507232666,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Monte_Carmelo,2024-12-31T00:00:00,1.56,1.2652667760849,-18.893155379173084,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Monte_Formoso,2024-12-31T00:00:00,0.6800000000000002,0.7914155721664429,16.384642965653338,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Monte_Santo_de_Minas,2024-12-31T00:00:00,1.5,1.1941282749176023,-20.3914483388265,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Monte_Siao,2024-12-31T00:00:00,1.5,0.9501656889915466,-36.655620733896896,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Muriae,2024-12-31T00:00:00,1.170285714285714,1.0802582502365112,-7.692776469048085,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Mutum,2024-12-31T00:00:00,1.15997150997151,1.3108289241790771,13.00526891486088,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Muzambinho,2024-12-31T00:00:00,1.26,1.604917287826538,27.37438792274112,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Natercia,2024-12-31T00:00:00,1.8000000000000005,1.978570938110352,9.920607672797292,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Nazareno,2024-12-31T00:00:00,1.619811320754717,1.2628686428070068,-22.03606514994599,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Nepomuceno,2024-12-31T00:00:00,1.3800383877159308,0.5186012983322144,-62.42124110833328,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ninheira,2024-12-31T00:00:00,2.819758276405675,2.081418037414551,-26.184522452480607,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Nova_Belem,2024-12-31T00:00:00,0.9,0.8582063317298889,-4.6437409189012335,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Nova_Era,2024-12-31T00:00:00,1.5,1.6744704246520996,11.631361643473308,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Nova_Ponte,2024-12-31T00:00:00,2.306557377049181,2.723094940185547,18.0588424671772,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Nova_Resende,2024-12-31T00:00:00,1.32,2.088360071182251,58.20909630168567,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Novo_Cruzeiro,2024-12-31T00:00:00,1.7997542997542997,1.2393447160720823,-31.138116117223536,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Novorizonte,2024-12-31T00:00:00,1.333333333333333,1.3844209909439087,3.831574320793175,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Olimpio_Noronha,2024-12-31T00:00:00,1.5,1.670783519744873,11.385567982991535,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Oliveira,2024-12-31T00:00:00,1.8240227434257288,2.0546908378601074,12.646119422894744,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Orizania,2024-12-31T00:00:00,1.5,1.4209833145141602,-5.267779032389322,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ouro_Fino,2024-12-31T00:00:00,1.5,1.0579538345336914,-29.46974436442057,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ouro_Verde_de_Minas,2024-12-31T00:00:00,2.5,2.133753061294556,-14.649877548217772,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Padre_Paraiso,2024-12-31T00:00:00,0.7212121212121212,0.6398112177848816,-11.286679886970196,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Paracatu,2024-12-31T00:00:00,2.7003236245954687,2.174365997314453,-19.477577520354007,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Paraguacu,2024-12-31T00:00:00,1.323316582914573,1.0105921030044556,-23.631871915437596,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Paraisopolis,2024-12-31T00:00:00,1.5066666666666668,2.081800937652588,38.17262860526024,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Passa_Tempo,2024-12-31T00:00:00,1.5,1.912251710891724,27.48344739278157,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Passos,2024-12-31T00:00:00,1.95459940652819,0.9546067714691162,-51.1610016722192,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Patis,2024-12-31T00:00:00,0.9,2.1149821281433105,134.9980142381456,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Patos_de_Minas,2024-12-31T00:00:00,1.6624523160762943,1.8650346994400024,12.185756030695746,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Patrocinio,2024-12-31T00:00:00,1.4995330375904743,1.2219510078430176,-18.51123134929321,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Paula_Candido,2024-12-31T00:00:00,1.31970802919708,1.7231955528259275,30.57399930152221,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pecanha,2024-12-31T00:00:00,1.8855421686746991,2.168211936950684,14.991431799940386,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pedra_Azul,2024-12-31T00:00:00,0.9,1.3092840909957886,45.47601011064317,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pedra_Bonita,2024-12-31T00:00:00,1.2,1.4440901279449463,20.340843995412197,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pedra_Dourada,2024-12-31T00:00:00,1.2800000000000002,1.2109249830245972,-5.396485701203364,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pedra_do_Anta,2024-12-31T00:00:00,1.379166666666667,1.571600317955017,13.952893144774617,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pedralva,2024-12-31T00:00:00,1.5600790513833993,1.7514123916625977,12.264336227676004,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pedrinopolis,2024-12-31T00:00:00,1.8511627906976744,2.2465410232543945,21.35837185921982,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Perdizes,2024-12-31T00:00:00,1.142806076854334,3.561617612838745,211.655466747463,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Perdoes,2024-12-31T00:00:00,1.6799401197604789,0.9036824107170104,-46.207462987082245,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Piedade_de_Caratinga,2024-12-31T00:00:00,1.68,1.961708903312683,16.76838710194543,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pimenta,2024-12-31T00:00:00,1.715219421101774,0.4804939329624176,-71.98644517132557,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Piracema,2024-12-31T00:00:00,0.8,1.2869162559509275,60.86453199386595,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Piranga,2024-12-31T00:00:00,1.8000000000000005,2.0885820388793945,16.03233549329968,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pirangucu,2024-12-31T00:00:00,1.333333333333333,1.289039969444275,-3.322002291679361,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Piranguinho,2024-12-31T00:00:00,1.6807610993657498,1.4892266988754272,-11.395694519738694,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pirapora,2024-12-31T00:00:00,2.7000000000000006,3.321467876434326,23.017328756826867,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Piumhi,2024-12-31T00:00:00,1.3800316957210783,0.7561278343200684,-45.2093863739133,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Poco_Fundo,2024-12-31T00:00:00,1.380192991366176,1.1403615474700928,-17.376660032064603,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pocos_de_Caldas,2024-12-31T00:00:00,1.7400000000000002,1.3735108375549316,-21.06259554282003,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pocrane,2024-12-31T00:00:00,1.7968750000000002,1.4267444610595703,-20.598569123641315,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ponte_Nova,2024-12-31T00:00:00,2.0,1.1639761924743652,-41.80119037628173,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ponto_dos_Volantes,2024-12-31T00:00:00,0.5,0.6023826599121094,20.476531982421875,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Porto_Firme,2024-12-31T00:00:00,1.3810526315789473,1.3286904096603394,-3.7914718614845695,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pote,2024-12-31T00:00:00,1.125,1.085823655128479,-3.482341766357422,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pouso_Alegre,2024-12-31T00:00:00,1.7878787878787883,1.7083287239074707,-4.449410357717762,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pouso_Alto,2024-12-31T00:00:00,1.53,1.707690954208374,11.61378785675647,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pratapolis,2024-12-31T00:00:00,1.1988636363636362,0.5700386762619019,-52.451750226495385,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Pratinha,2024-12-31T00:00:00,1.849285714285714,2.2341766357421875,20.81295056157061,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Presidente_Bernardes,2024-12-31T00:00:00,1.110144927536232,1.48884916305542,34.11304471386939,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Presidente_Kubitschek,2024-12-31T00:00:00,0.7368421052631579,0.5665454268455505,-23.11169207096099,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Presidente_Olegario,2024-12-31T00:00:00,1.9199630314232905,1.6834372282028198,-12.31928945241884,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Quartel_Geral,2024-12-31T00:00:00,3.0,1.7033014297485352,-43.22328567504883,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Raul_Soares,2024-12-31T00:00:00,1.5,1.122414231300354,-25.1723845799764,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Reduto,2024-12-31T00:00:00,1.2,1.262610673904419,5.217556158701583,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ribeirao_Vermelho,2024-12-31T00:00:00,1.43859649122807,0.8192269802093506,-43.053734302520745,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Rio_Paranaiba,2024-12-31T00:00:00,1.680014776505357,0.4332328140735626,-74.21255931005906,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Rio_Pardo_de_Minas,2024-12-31T00:00:00,3.064285714285715,2.4352357387542725,-20.52843742993052,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Rio_Vermelho,2024-12-31T00:00:00,0.9230769230769232,0.7174227237701416,-22.27920492490133,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ritapolis,2024-12-31T00:00:00,1.8000000000000005,1.937471628189087,7.6373126771714785,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Romaria,2024-12-31T00:00:00,2.052631578947369,1.92285680770874,-6.322360650087042,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Rosario_da_Limeira,2024-12-31T00:00:00,1.259493670886076,1.1669883728027344,-7.344641757370843,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sabinopolis,2024-12-31T00:00:00,1.2,1.1020445823669434,-8.162951469421383,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sacramento,2024-12-31T00:00:00,1.737021276595745,2.471966505050659,42.31066356857053,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santa_Barbara,2024-12-31T00:00:00,1.333333333333333,1.2060387134552002,-9.547096490859966,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santa_Barbara_do_Leste,2024-12-31T00:00:00,1.4101226993865028,1.365581512451172,-3.158674557519662,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santa_Barbara_do_Monte_Verde,2024-12-31T00:00:00,1.3,1.3714720010757446,5.497846236595737,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santa_Margarida,2024-12-31T00:00:00,1.5,1.312382698059082,-12.507820129394531,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santa_Maria_do_Suacui,2024-12-31T00:00:00,1.333333333333333,0.9148656725883484,-31.385074555873853,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santa_Rita_de_Caldas,2024-12-31T00:00:00,1.8000000000000005,1.8338247537612915,1.8791529867384016,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santa_Rita_de_Minas,2024-12-31T00:00:00,1.200173310225303,1.1347854137420654,-5.44820451564304,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santa_Rita_do_Itueto,2024-12-31T00:00:00,1.365238095238095,1.4245598316192627,4.345156832942182,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santa_Rita_do_Sapucai,2024-12-31T00:00:00,1.5,1.8633111715316768,24.22074476877848,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santa_Rosa_da_Serra,2024-12-31T00:00:00,1.92,1.9715431928634644,2.6845412949721057,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santana_da_Vargem,2024-12-31T00:00:00,1.44,0.6593026518821716,-54.21509361929363,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santana_do_Jacare,2024-12-31T00:00:00,1.2,0.416444718837738,-65.2962734301885,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santana_do_Manhuacu,2024-12-31T00:00:00,1.08,1.3215585947036743,22.366536546636503,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santo_Antonio_do_Amparo,2024-12-31T00:00:00,1.68,1.0972561836242676,-34.68713192712693,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santo_Antonio_do_Grama,2024-12-31T00:00:00,1.565217391304348,1.5154378414154053,-3.180360131793556,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Santo_Antonio_do_Retiro,2024-12-31T00:00:00,1.9666666666666672,0.7587218284606934,-61.420923976574926,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Bento_Abade,2024-12-31T00:00:00,1.5,3.4669580459594727,131.13053639729816,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Domingos_das_Dores,2024-12-31T00:00:00,1.41,1.254676342010498,-11.015862268759012,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Domingos_do_Prata,2024-12-31T00:00:00,1.05,1.1661016941070557,11.057304200671965,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Francisco_de_Paula,2024-12-31T00:00:00,1.62,1.5313565731048584,-5.471816475008748,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Francisco_do_Gloria,2024-12-31T00:00:00,1.25,1.2674903869628906,1.39923095703125,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Geraldo,2024-12-31T00:00:00,1.3189189189189188,1.6203505992889404,22.85445117559591,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Goncalo_do_Abaete,2024-12-31T00:00:00,1.5,1.2257230281829834,-18.285131454467773,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Goncalo_do_Rio_Preto,2024-12-31T00:00:00,2.5238095238095246,3.090522289276123,22.454656744902948,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Goncalo_do_Sapucai,2024-12-31T00:00:00,1.5,0.6295617818832397,-58.02921454111735,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Gotardo,2024-12-31T00:00:00,1.668148148148148,0.7465232610702515,-55.24838355040677,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Joao_Batista_do_Gloria,2024-12-31T00:00:00,1.548387096774194,0.939978837966919,-39.29303338130317,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Joao_da_Mata,2024-12-31T00:00:00,1.32,1.1252895593643188,-14.750790957248578,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Joao_del_Rei,2024-12-31T00:00:00,1.80168776371308,1.95263671875,8.37819727019909,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Joao_do_Manhuacu,2024-12-31T00:00:00,1.32,1.2196025848388672,-7.605864784934309,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Joao_do_Manteninha,2024-12-31T00:00:00,0.9,0.6299565434455872,-30.00482850604587,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Joao_do_Paraiso,2024-12-31T00:00:00,3.5396226415094336,2.2453763484954834,-36.56452746787813,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Jose_da_Barra,2024-12-31T00:00:00,1.709523809523809,1.8976490497589111,11.004540515145251,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Jose_do_Alegre,2024-12-31T00:00:00,1.8000000000000005,1.7215189933776855,-4.360055923461928,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Jose_do_Mantimento,2024-12-31T00:00:00,1.44,1.5152580738067627,5.226255125469636,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Lourenco,2024-12-31T00:00:00,1.3799999999999997,1.4056072235107422,1.855595906575545,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Miguel_do_Anta,2024-12-31T00:00:00,1.55974025974026,1.5461032390594482,-0.8743135657139985,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Pedro_da_Uniao,2024-12-31T00:00:00,2.04,1.233284831047058,-39.54486122318343,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Roque_de_Minas,2024-12-31T00:00:00,1.58,1.4795172214508057,-6.359669528430026,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Sebastiao_da_Bela_Vista,2024-12-31T00:00:00,1.44,1.5341033935546875,6.534957885742192,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Sebastiao_da_Vargem_Alegre,2024-12-31T00:00:00,1.2800000000000002,1.3485623598098757,5.356434360146502,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Sebastiao_do_Anta,2024-12-31T00:00:00,1.8000000000000005,1.7364221811294556,-3.532101048363593,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Sebastiao_do_Maranhao,2024-12-31T00:00:00,1.380952380952381,1.16099750995636,-15.927766520401526,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Sebastiao_do_Paraiso,2024-12-31T00:00:00,1.26,1.088974952697754,-13.573416452559217,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Tiago,2024-12-31T00:00:00,1.621052631578947,1.7031522989273071,5.064589868892342,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Tomas_de_Aquino,2024-12-31T00:00:00,1.619975932611312,0.9506362676620485,-41.317877103910114,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sao_Tome_das_Letras,2024-12-31T00:00:00,2.1,1.4539551734924316,-30.764039357503258,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Senador_Firmino,2024-12-31T00:00:00,1.804347826086957,1.7131222486495972,-5.055875376046447,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Senador_Jose_Bento,2024-12-31T00:00:00,0.9,1.200885772705078,33.431752522786454,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Senador_Modestino_Goncalves,2024-12-31T00:00:00,2.706666666666667,2.7084801197052,0.0669994964975319,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Senhora_de_Oliveira,2024-12-31T00:00:00,1.8000000000000005,1.6349239349365234,-9.170892503526488,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Senhora_dos_Remedios,2024-12-31T00:00:00,1.8000000000000005,1.6222667694091797,-9.874068366156695,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Sericita,2024-12-31T00:00:00,1.3799999999999997,1.7122275829315186,24.07446253126949,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Serra_do_Salitre,2024-12-31T00:00:00,1.5168750000000002,1.0627927780151367,-29.93537516175449,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Serrania,2024-12-31T00:00:00,1.32,0.954155445098877,-27.71549658341841,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Setubinha,2024-12-31T00:00:00,1.020238095238095,1.1349077224731443,11.239496718487944,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Silvianopolis,2024-12-31T00:00:00,1.56025641025641,0.9747849106788636,-37.5240566697195,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Simonesia,2024-12-31T00:00:00,1.2,1.4542701244354248,21.189177036285407,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Soledade_de_Minas,2024-12-31T00:00:00,1.5,1.1795014142990112,-21.36657238006592,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Taiobeiras,2024-12-31T00:00:00,3.1206349206349207,2.933283805847168,-6.0036216844498576,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Tapira,2024-12-31T00:00:00,1.98,1.5768930912017822,-20.358934787788765,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Tapirai,2024-12-31T00:00:00,1.9163050216986977,1.7520971298217771,-8.568985105062207,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Teixeiras,2024-12-31T00:00:00,1.5,1.6911911964416504,12.746079762776692,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Teofilo_Otoni,2024-12-31T00:00:00,1.05,0.9197824001312256,-12.40167617797852,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Tiros,2024-12-31T00:00:00,1.95,1.6757826805114746,-14.062426640437186,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Tocos_do_Moji,2024-12-31T00:00:00,1.5,2.0217201709747314,34.78134473164876,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Tombos,2024-12-31T00:00:00,1.5,1.130650281906128,-24.62331453959147,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Tres_Coracoes,2024-12-31T00:00:00,1.56,1.370457649230957,-12.15015069032327,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Tres_Pontas,2024-12-31T00:00:00,1.387228956803825,0.5936359167098999,-57.2070699794476,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Tupaciguara,2024-12-31T00:00:00,2.8219895287958106,2.1495842933654785,-23.827346932688958,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Turmalina,2024-12-31T00:00:00,1.8507692307692305,1.343861103057861,-27.3890509569734,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Turvolandia,2024-12-31T00:00:00,1.44,1.2754433155059814,-11.42754753430684,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Ubaporanga,2024-12-31T00:00:00,1.440056417489422,1.4614129066467283,1.4830314214035625,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Uberaba,2024-12-31T00:00:00,2.102941176470588,1.8923054933547971,-10.016242274037593,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Uberlandia,2024-12-31T00:00:00,1.919565217391304,1.2178877592086792,-36.553978568970265,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Unai,2024-12-31T00:00:00,2.2801061007957566,2.536806583404541,11.258269188402943,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Urucuia,2024-12-31T00:00:00,1.920433996383363,1.96887731552124,2.522519348704908,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Vargem_Bonita,2024-12-31T00:00:00,2.187804878048781,0.8957614898681641,-59.0566097161709,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Vargem_Grande_do_Rio_Pardo,2024-12-31T00:00:00,1.8000000000000005,1.6977274417877195,-5.68180878957114,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Varginha,2024-12-31T00:00:00,1.3799999999999997,0.6005829572677612,-56.47949585016222,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Varjao_de_Minas,2024-12-31T00:00:00,2.6876337184424486,2.392392635345459,-10.985168145162625,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Varzea_da_Palma,2024-12-31T00:00:00,3.0,3.0984246730804443,3.280822436014811,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Vermelho_Novo,2024-12-31T00:00:00,1.8000000000000005,1.3692576885223389,-23.93012841542563,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Vicosa,2024-12-31T00:00:00,1.32,1.6881884336471558,27.89306315508755,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Vieiras,2024-12-31T00:00:00,1.44,1.4070903062820437,-2.285395397080312,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Virginia,2024-12-31T00:00:00,1.6599999999999997,1.7045634984970093,2.684548102229493,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Virginopolis,2024-12-31T00:00:00,1.325,1.2457507848739624,-5.981072839700947,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2024,Visconde_do_Rio_Branco,2024-12-31T00:00:00,1.333333333333333,1.407131910324097,5.534893274307275,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:13:55
V38_2025,Abadia_dos_Dourados,2024-12-31T00:00:00,2.6116071428571423,2.0756685733795166,-20.521408472305673,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Abre_Campo,2024-12-31T00:00:00,1.32,1.3806641101837158,4.59576592300877,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Acucena,2024-12-31T00:00:00,1.6666666666666672,1.1578123569488525,-30.531258583068873,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Agua_Boa,2024-12-31T00:00:00,1.7064935064935067,1.1666882038116455,-31.632426412864014,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Aguanil,2024-12-31T00:00:00,2.025039123630673,1.8841197490692139,-6.958847012733561,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Aguas_Vermelhas,2024-12-31T00:00:00,3.0,3.3442296981811523,11.474323272705078,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Aimores,2024-12-31T00:00:00,0.9455882352941176,1.724412441253662,82.36399067690363,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Aiuruoca,2024-12-31T00:00:00,1.8000000000000003,1.8156940937042236,0.8718940946790759,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Albertina,2024-12-31T00:00:00,1.56,1.572102665901184,0.7758119167425659,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Alfenas,2024-12-31T00:00:00,1.635197497066875,1.741976261138916,6.530022475179588,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Almenara,2024-12-31T00:00:00,0.78,0.8139995336532593,4.358914570930673,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Alpinopolis,2024-12-31T00:00:00,2.08,2.1489005088806152,3.3125244654141905,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Alterosa,2024-12-31T00:00:00,1.110028116213683,1.2706966400146484,14.474275151606744,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Alto_Caparao,2024-12-31T00:00:00,1.14,1.3414226770401,17.668655880710546,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Alto_Jequitiba,2024-12-31T00:00:00,1.02,1.0364545583724976,1.6131919973036806,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Alvarenga,2024-12-31T00:00:00,1.25,1.1767278909683228,-5.86176872253418,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Amparo_do_Serra,2024-12-31T00:00:00,1.680555555555556,1.4518535137176514,-13.608716539114985,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Andradas,2024-12-31T00:00:00,1.26,1.2490872144699097,-0.8660940896897096,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Andrelandia,2024-12-31T00:00:00,1.5,1.8162944316864014,21.086295445760094,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Angelandia,2024-12-31T00:00:00,1.870967741935484,2.0330452919006348,8.662765601585646,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Antonio_Dias,2024-12-31T00:00:00,1.5,1.3287616968154907,-11.415886878967285,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Antonio_Prado_de_Minas,2024-12-31T00:00:00,1.933333333333333,1.4542157649993896,-24.781943189686725,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Araguari,2024-12-31T00:00:00,1.500037950664137,2.5388474464416504,69.25221427348447,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Araponga,2024-12-31T00:00:00,1.5,1.5012918710708618,0.08612473805745444,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Arapua,2024-12-31T00:00:00,1.0805194805194802,1.2929564714431763,19.660634977313222,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Araxa,2024-12-31T00:00:00,1.412283279459301,1.4384233951568604,1.8509116462504056,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Arceburgo,2024-12-31T00:00:00,1.7586206896551722,1.837837815284729,4.504503222072842,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Areado,2024-12-31T00:00:00,1.162105263157895,1.6201934814453125,39.418823131616534,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Aricanduva,2024-12-31T00:00:00,1.320245398773006,1.167146921157837,-11.596213685535583,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Astolfo_Dutra,2024-12-31T00:00:00,0.8749999999999999,1.0922629833221436,24.830055236816424,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ataleia,2024-12-31T00:00:00,0.7529411764705883,0.8991928100585938,19.424045085906965,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Baependi,2024-12-31T00:00:00,1.439779005524862,1.715029239654541,19.117533529344545,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Bambui,2024-12-31T00:00:00,1.8000000000000003,1.6434929370880127,-8.694836828443753,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Bandeira,2024-12-31T00:00:00,1.15,1.0816004276275635,-5.947788901950995,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Bandeira_do_Sul,2024-12-31T00:00:00,1.5,1.8752299547195435,25.01533031463623,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Berilo,2024-12-31T00:00:00,1.6818181818181819,1.4563610553741455,-13.405558869645407,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Berizal,2024-12-31T00:00:00,3.5516129032258075,2.4362380504608154,-31.404741540158714,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Boa_Esperanca,2024-12-31T00:00:00,1.083893395133256,1.3502975702285767,24.578448055084632,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Bocaiuva,2024-12-31T00:00:00,2.0989010989010994,2.40240216255188,14.459998320534561,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Bom_Jesus_da_Penha,2024-12-31T00:00:00,1.56,1.8714423179626465,19.96425115145169,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Bom_Jesus_do_Amparo,2024-12-31T00:00:00,0.75,1.463226556777954,95.09687423706055,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Bom_Jesus_do_Galho,2024-12-31T00:00:00,0.9,1.212494134902954,34.721570544772675,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Bom_Sucesso,2024-12-31T00:00:00,1.6799426934097417,1.5299935340881348,-8.925849667958524,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Bonfinopolis_de_Minas,2024-12-31T00:00:00,2.1,2.8549511432647705,35.95005444117954,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Borda_da_Mata,2024-12-31T00:00:00,1.5,1.756713628768921,17.114241917928062,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Botelhos,2024-12-31T00:00:00,1.08,1.8773239850997925,73.82629491664744,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Botumirim,2024-12-31T00:00:00,0.7250000000000001,0.7055994868278503,-2.6759328513309995,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Brazopolis,2024-12-31T00:00:00,1.501216545012166,1.470853328704834,-2.022574052238806,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Bueno_Brandao,2024-12-31T00:00:00,1.8000000000000003,1.8829939365386963,4.6107742521497785,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Buritis,2024-12-31T00:00:00,2.69967707212056,2.871913433074951,6.3798875329597005,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Buritizeiro,2024-12-31T00:00:00,2.7000000000000006,2.7347702980041504,1.2877888149685097,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cabo_Verde,2024-12-31T00:00:00,1.32,2.099517345428467,59.05434435064142,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cachoeira_de_Minas,2024-12-31T00:00:00,1.73984375,1.924370527267456,10.605939600464476,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Caete,2024-12-31T00:00:00,1.8000000000000003,1.3133606910705566,-27.035517162746864,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Caiana,2024-12-31T00:00:00,1.14,1.0793598890304565,-5.319307979784506,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cajuri,2024-12-31T00:00:00,1.32,1.4680383205413818,11.215024283438012,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Caldas,2024-12-31T00:00:00,1.68,1.067799687385559,-36.440494798478625,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Camacho,2024-12-31T00:00:00,1.5,1.6096470355987549,7.309802373250325,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cambuquira,2024-12-31T00:00:00,1.7400000000000002,1.8368816375732422,5.567910205358734,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Campanha,2024-12-31T00:00:00,1.5689448441247,1.5681178569793701,-0.05270976531946121,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Campestre,2024-12-31T00:00:00,1.320032051282051,1.561256766319275,18.274155904240356,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Campo_Belo,2024-12-31T00:00:00,1.2,1.475952386856079,22.9960322380066,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Campo_do_Meio,2024-12-31T00:00:00,1.372340425531915,1.2816944122314453,-6.6052133722822814,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Campos_Altos,2024-12-31T00:00:00,1.5,1.8716493844985962,24.776625633239746,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Campos_Gerais,2024-12-31T00:00:00,1.611315789473684,1.4354209899902344,-10.916221428010923,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cana_Verde,2024-12-31T00:00:00,1.2,1.298330545425415,8.194212118784591,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Canaa,2024-12-31T00:00:00,1.319791666666667,1.6692297458648682,26.476760539090222,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Candeias,2024-12-31T00:00:00,1.14003294892916,1.240471601486206,8.810153482966314,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Caparao,2024-12-31T00:00:00,1.6799283154121862,1.3486926555633545,-19.7172496474982,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Capela_Nova,2024-12-31T00:00:00,2.1012345679012356,1.8381242752075195,-12.52170018107579,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Capelinha,2024-12-31T00:00:00,1.62007678089009,1.5693620443344116,-3.130390926769229,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Capetinga,2024-12-31T00:00:00,1.437691001697793,1.6350188255310059,13.725329267567584,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Capitao_Eneas,2024-12-31T00:00:00,3.0,1.9843966960906982,-33.85344346364339,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Capitolio,2024-12-31T00:00:00,1.32,1.4468787908554077,9.612029610258155,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Caputira,2024-12-31T00:00:00,1.38008658008658,1.3512808084487915,-2.087243804369244,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Carai,2024-12-31T00:00:00,1.2,1.4079374074935913,17.328117291132614,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Caranaiba,2024-12-31T00:00:00,1.5,1.8404171466827393,22.694476445515953,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Carangola,2024-12-31T00:00:00,1.44,1.1036546230316162,-23.35731784502665,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Caratinga,2024-12-31T00:00:00,1.6200335289186922,1.51912260055542,-6.228940732518439,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Careacu,2024-12-31T00:00:00,1.560169491525424,1.4557452201843262,-6.6931363488590705,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Carmo_da_Cachoeira,2024-12-31T00:00:00,1.44,1.6916627883911133,17.47658252716065,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Carmo_da_Mata,2024-12-31T00:00:00,1.62,1.2713812589645386,-21.51967537255935,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Carmo_de_Minas,2024-12-31T00:00:00,1.56,1.7555489540100098,12.535189359616005,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Carmo_do_Paranaiba,2024-12-31T00:00:00,2.103206239168111,2.040149211883545,-2.998138086044621,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Carmo_do_Rio_Claro,2024-12-31T00:00:00,1.7634782608695652,1.796957015991211,1.898450117844805,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Carmopolis_de_Minas,2024-12-31T00:00:00,1.9799999999999998,1.65180242061615,-16.575635322416662,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Carrancas,2024-12-31T00:00:00,1.6428571428571432,1.6093569993972778,-2.0391391671222414,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Carvalhopolis,2024-12-31T00:00:00,1.62,1.4317374229431152,-11.621146731906473,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Casa_Grande,2024-12-31T00:00:00,2.522388059701492,2.0222573280334473,-19.82766806021243,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cascalho_Rico,2024-12-31T00:00:00,1.8000000000000003,2.2571749687194824,25.39860937330456,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cassia,2024-12-31T00:00:00,1.7162790697674417,1.7786657810211182,3.63499808117627,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cataguases,2024-12-31T00:00:00,1.0,1.350307583808899,35.03075838088989,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Catas_Altas_da_Noruega,2024-12-31T00:00:00,0.9,0.9731029272079468,8.122547467549639,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Catuji,2024-12-31T00:00:00,1.138461538461538,1.239891767501831,8.909412010296018,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Caxambu,2024-12-31T00:00:00,1.795918367346939,1.337109923362732,-25.547288358211528,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Chale,2024-12-31T00:00:00,1.320168067226891,1.408409833908081,6.684131276296385,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Claraval,2024-12-31T00:00:00,1.92,2.0760087966918945,8.125458161036178,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Claudio,2024-12-31T00:00:00,2.699367088607595,1.8749195337295532,-30.542254084579273,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Coimbra,2024-12-31T00:00:00,1.5012658227848097,1.8096176385879517,20.53945484692093,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Conceicao_da_Aparecida,2024-12-31T00:00:00,1.5,1.9135969877243042,27.573132514953613,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Conceicao_da_Barra_de_Minas,2024-12-31T00:00:00,1.8000000000000003,1.8761340379714966,4.229668776194239,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Conceicao_das_Pedras,2024-12-31T00:00:00,1.5598885793871868,1.5930376052856445,2.125089338847556,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Conceicao_de_Ipanema,2024-12-31T00:00:00,1.2901734104046243,1.4505014419555664,12.426859076305101,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Conceicao_do_Rio_Verde,2024-12-31T00:00:00,1.5,1.4972987174987793,-0.1800855000813802,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Conceicao_dos_Ouros,2024-12-31T00:00:00,1.8000000000000003,1.416548252105713,-21.302874883015964,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Congonhal,2024-12-31T00:00:00,1.8000000000000003,1.484107494354248,-17.549583646986232,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Congonhas_do_Norte,2024-12-31T00:00:00,1.2,0.9394363164901733,-21.713640292485554,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Conselheiro_Pena,2024-12-31T00:00:00,1.2,1.5594991445541382,29.958262046178184,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Coqueiral,2024-12-31T00:00:00,0.9,1.4542006254196167,61.5778472688463,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cordislandia,2024-12-31T00:00:00,1.439887640449438,1.1379914283752441,-20.9666507019924,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Coroaci,2024-12-31T00:00:00,2.1,1.94070303440094,-7.585569790431436,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Coromandel,2024-12-31T00:00:00,1.6144686299615878,1.8744373321533203,16.102431311899682,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Corrego_Danta,2024-12-31T00:00:00,1.5,1.6854323148727417,12.362154324849445,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Corrego_Fundo,2024-12-31T00:00:00,1.501960784313725,1.0113956928253174,-32.661644472465795,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Corrego_Novo,2024-12-31T00:00:00,1.2,1.4250380992889404,18.75317494074504,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cristais,2024-12-31T00:00:00,1.439664804469274,1.5573835372924805,8.176815357141626,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cristina,2024-12-31T00:00:00,1.619736842105263,1.9639337062835693,21.250171955768717,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cruzeiro_da_Fortaleza,2024-12-31T00:00:00,2.2199999999999998,1.6936309337615967,-23.71031829902717,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cruzilia,2024-12-31T00:00:00,1.502793296089385,1.5597023963928223,3.786888087106046,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cuparaque,2024-12-31T00:00:00,1.020408163265306,1.0517371892929077,3.070244550704976,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Datas,2024-12-31T00:00:00,1.0,0.22095008194446564,-77.90499180555344,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Delfinopolis,2024-12-31T00:00:00,1.5,1.444603443145752,-3.693103790283203,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Desterro_de_Entre_Rios,2024-12-31T00:00:00,1.3780487804878048,1.3200281858444214,-4.21034403606853,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Diamantina,2024-12-31T00:00:00,2.967637540453075,2.478271007537842,-16.490104544253768,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Divinesia,2024-12-31T00:00:00,1.3166666666666673,2.080669403076172,58.02552428426614,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Divino,2024-12-31T00:00:00,1.2,1.2250518798828125,2.0876566569010455,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Divisa_Nova,2024-12-31T00:00:00,1.679831932773109,1.839996576309204,9.53456357218375,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Divisopolis,2024-12-31T00:00:00,1.4902200488997548,1.296429991722107,-13.004123607162924,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Dom_Cavati,2024-12-31T00:00:00,0.6000000000000001,0.5219601988792419,-13.006633520126357,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Dom_Vicoso,2024-12-31T00:00:00,1.2,1.5438486337661743,28.654052813847862,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Dores_do_Turvo,2024-12-31T00:00:00,1.2,1.4445017576217651,20.37514646848043,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Doresopolis,2024-12-31T00:00:00,1.5615384615384622,1.6198149919509888,3.7319945584376604,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Durande,2024-12-31T00:00:00,1.380095693779904,1.376517653465271,-0.2592603056990386,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Eloi_Mendes,2024-12-31T00:00:00,1.421623345558922,1.5864970684051514,11.597567200995002,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Entre_Folhas,2024-12-31T00:00:00,1.2,1.2849830389022827,7.081919908523564,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Entre_Rios_de_Minas,2024-12-31T00:00:00,1.88,1.8275829553604126,-2.788140672318473,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ervalia,2024-12-31T00:00:00,1.32,1.6946899890899658,28.385605234088313,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Esmeraldas,2024-12-31T00:00:00,3.0,2.132371425628662,-28.920952479044598,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Espera_Feliz,2024-12-31T00:00:00,1.44,1.2620904445648193,-12.354830238554209,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Espirito_Santo_do_Dourado,2024-12-31T00:00:00,1.4391752577319588,1.4165124893188477,-1.5747052550657428,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Estrela_do_Indaia,2024-12-31T00:00:00,1.56,1.8067543506622314,15.817586580912268,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Estrela_do_Sul,2024-12-31T00:00:00,1.7099999999999997,1.9014837741851807,11.197881531297131,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Eugenopolis,2024-12-31T00:00:00,1.68,1.7242215871810913,2.63223733220782,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Fama,2024-12-31T00:00:00,1.679838709677419,1.6641364097595215,-0.9347504511854497,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Faria_Lemos,2024-12-31T00:00:00,1.37956204379562,1.1649657487869263,-15.555392812799496,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Felicio_dos_Santos,2024-12-31T00:00:00,2.663299663299664,2.0973100662231445,-21.251442519813683,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ferros,2024-12-31T00:00:00,1.205128205128205,1.058022379875183,-12.206653584825228,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Fervedouro,2024-12-31T00:00:00,1.56,1.3301280736923218,-14.73537989151784,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Formiga,2024-12-31T00:00:00,1.9475763016157988,1.6338260173797607,-16.109781371632852,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Formoso,2024-12-31T00:00:00,3.6000000000000005,3.109537124633789,-13.62396876017254,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Fortaleza_de_Minas,2024-12-31T00:00:00,1.5598425196850392,1.5629632472991943,0.20006683846426326,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Franciscopolis,2024-12-31T00:00:00,0.9,1.2541674375534058,39.35193750593397,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Frei_Gaspar,2024-12-31T00:00:00,1.2,1.172482967376709,-2.2930860519409144,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Grao_Mogol,2024-12-31T00:00:00,2.0333333333333337,0.990675687789917,-51.27824486279098,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Guape,2024-12-31T00:00:00,1.7459340659340663,1.3736295700073242,-21.324086813528147,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Guaraciaba,2024-12-31T00:00:00,1.8000000000000003,1.6175962686538696,-10.13354063034059,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Guaranesia,2024-12-31T00:00:00,1.205714285714286,1.305710792541504,8.293549144437504,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Guarani,2024-12-31T00:00:00,0.9655172413793104,1.2604800462722778,30.549719078200198,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Guarda-Mor,2024-12-31T00:00:00,1.740112994350282,1.7566709518432617,0.9515449598238351,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Guaxupe,2024-12-31T00:00:00,1.32,1.4485610723495483,9.73947517799608,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Guimarania,2024-12-31T00:00:00,1.8219512195121947,1.8301961421966553,0.4525325703653037,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Guiricema,2024-12-31T00:00:00,1.56,1.8965470790863037,21.573530710660492,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Heliodora,2024-12-31T00:00:00,1.5601255886970171,1.5846211910247803,1.5701045162794456,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Iapu,2024-12-31T00:00:00,1.355263157894737,1.5388667583465576,13.5474501304256,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ibia,2024-12-31T00:00:00,1.681621621621622,1.6129167079925537,-4.0856345295331495,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ibiraci,2024-12-31T00:00:00,1.978101265822785,1.4477214813232422,-26.81256989535028,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ibitiura_de_Minas,2024-12-31T00:00:00,1.360264900662252,0.9965292811393738,-26.740057715654626,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ibituruna,2024-12-31T00:00:00,1.8000000000000003,1.6346522569656372,-9.18598572413128,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ijaci,2024-12-31T00:00:00,2.19,1.694329023361206,-22.63337792871205,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ilicinea,2024-12-31T00:00:00,1.5,1.3973770141601562,-6.841532389322917,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Imbe_de_Minas,2024-12-31T00:00:00,1.26,1.3803215026855469,9.549325609964036,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Inconfidentes,2024-12-31T00:00:00,1.8000000000000003,2.657245397567749,47.62474430931937,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Indaiabira,2024-12-31T00:00:00,2.511111111111111,2.6498401165008545,5.524606409326065,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Indianopolis,2024-12-31T00:00:00,1.8000000000000003,2.3328473567962646,29.602630933125795,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ingai,2024-12-31T00:00:00,1.621004566210046,1.6350884437561035,0.8688363894610083,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Inhapim,2024-12-31T00:00:00,1.2,1.9511017799377441,62.591814994812026,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Irai_de_Minas,2024-12-31T00:00:00,2.6079447322970637,2.4497878551483154,-6.064425951597699,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Itabirinha,2024-12-31T00:00:00,0.8918918918918919,0.8840680122375488,-0.8772228703354338,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Itacambira,2024-12-31T00:00:00,0.5,0.6741136908531189,34.82273817062378,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Itaipe,2024-12-31T00:00:00,0.9,0.9667037725448608,7.411530282762313,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Itajuba,2024-12-31T00:00:00,1.068965517241379,1.5636932849884033,46.28098472472164,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Itamarandiba,2024-12-31T00:00:00,2.1352380952380954,1.9373098611831665,-9.269609534240647,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Itamarati_de_Minas,2024-12-31T00:00:00,1.196969696969697,1.2062433958053589,0.7747647128527638,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Itambacuri,2024-12-31T00:00:00,1.084388185654009,0.9974435567855835,-8.017850989033784,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Itamogi,2024-12-31T00:00:00,1.44,2.001044511795044,38.96142443021139,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Itanhomi,2024-12-31T00:00:00,1.02089552238806,1.3205475807189941,29.351882906685056,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Itapecerica,2024-12-31T00:00:00,1.615189873417721,0.852749764919281,-47.20436408415108,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ituiutaba,2024-12-31T00:00:00,1.0,0.9464643001556396,-5.353569984436035,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Itumirim,2024-12-31T00:00:00,1.62116991643454,1.552025318145752,-4.265104945992247,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Itutinga,2024-12-31T00:00:00,1.8000000000000003,1.711026668548584,-4.942962858412015,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Jacui,2024-12-31T00:00:00,1.3799999999999997,1.5457916259765625,12.013885940330644,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Jacutinga,2024-12-31T00:00:00,1.319874804381847,1.4675798416137695,11.190836944652425,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Jequeri,2024-12-31T00:00:00,1.8000000000000003,1.5508865118026733,-13.839638233184829,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Jequitinhonha,2024-12-31T00:00:00,2.4,2.4038326740264893,0.15969475110372278,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Jesuania,2024-12-31T00:00:00,1.5,1.4460296630859375,-3.5980224609375,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Joao_Pinheiro,2024-12-31T00:00:00,3.0,2.5991830825805664,-13.36056391398112,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Jose_Goncalves_de_Minas,2024-12-31T00:00:00,1.5,1.3975729942321777,-6.828467051188151,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Juiz_de_Fora,2024-12-31T00:00:00,1.166666666666667,0.9018023014068604,-22.70265987941199,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Juruaia,2024-12-31T00:00:00,1.68,1.6270368099212646,-3.152570838019958,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ladainha,2024-12-31T00:00:00,1.12,1.1124647855758667,-0.6727870021547684,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Lagoa_Dourada,2024-12-31T00:00:00,1.5,2.2754218578338623,51.694790522257485,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Lagoa_Formosa,2024-12-31T00:00:00,1.8142857142857145,2.078979253768921,14.589407688050745,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Lagoa_Grande,2024-12-31T00:00:00,2.4,1.21699059009552,-49.29205874602,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Lajinha,2024-12-31T00:00:00,1.564997053624043,1.39858078956604,-10.633647115988811,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Lambari,2024-12-31T00:00:00,1.56,1.578861951828003,1.2090994761540306,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Lamim,2024-12-31T00:00:00,1.7777777777777781,1.8164927959442139,2.17771977186201,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Lavras,2024-12-31T00:00:00,1.55996015936255,1.413746953010559,-9.372880805605856,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Luisburgo,2024-12-31T00:00:00,1.2,1.425185203552246,18.765433629353844,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Luminarias,2024-12-31T00:00:00,1.380229885057471,1.4269349575042725,3.3838618444967743,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Machado,2024-12-31T00:00:00,1.3347736360118658,1.195967435836792,-10.399231482411441,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Malacacheta,2024-12-31T00:00:00,1.5,1.6818360090255737,12.122400601704914,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Manhuacu,2024-12-31T00:00:00,1.5,1.196138858795166,-20.2574094136556,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Manhumirim,2024-12-31T00:00:00,1.56,1.3419742584228516,-13.976009075458236,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Mantena,2024-12-31T00:00:00,1.2,0.6804448962211609,-43.29625864823659,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Mar_de_Espanha,2024-12-31T00:00:00,1.2625,1.748454213142395,38.49142282316001,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Maria_da_Fe,2024-12-31T00:00:00,1.477777777777778,1.4533685445785522,-1.6517526225040033,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Martins_Soares,2024-12-31T00:00:00,1.2,1.3076667785644531,8.972231547037765,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Mata_Verde,2024-12-31T00:00:00,1.5,1.517882227897644,1.192148526509603,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Matipo,2024-12-31T00:00:00,1.2,1.320618987083435,10.051582256952926,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Matutina,2024-12-31T00:00:00,1.380566801619433,1.8092097043991089,31.048327562046907,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Medeiros,2024-12-31T00:00:00,1.8600609756097564,1.942049503326416,4.407840860689126,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Minas_Novas,2024-12-31T00:00:00,1.6204545454545451,1.3961758613586426,-13.84047980395472,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Miradouro,2024-12-31T00:00:00,1.13996383363472,1.2056001424789429,5.757753615300643,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Mirai,2024-12-31T00:00:00,1.2,1.2485463619232178,4.045530160268152,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Moeda,2024-12-31T00:00:00,1.5,1.1098995208740234,-26.006698608398438,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Monsenhor_Paulo,2024-12-31T00:00:00,1.5899728997289972,1.6410670280456543,3.2135219616237345,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Monte_Alegre_de_Minas,2024-12-31T00:00:00,2.378787878787879,2.3518333435058594,-1.133120591473432,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Monte_Belo,2024-12-31T00:00:00,1.5,1.7100770473480225,14.005136489868164,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Monte_Carmelo,2024-12-31T00:00:00,1.56,2.2397818565368652,43.57576003441444,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Monte_Formoso,2024-12-31T00:00:00,0.6800000000000002,0.8098726272583008,19.098915773279497,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Monte_Santo_de_Minas,2024-12-31T00:00:00,1.5,1.8523032665252686,23.486884435017906,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Monte_Siao,2024-12-31T00:00:00,1.5,1.7081636190414429,13.877574602762857,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Muriae,2024-12-31T00:00:00,1.170285714285714,1.3992284536361694,19.56297821598131,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Mutum,2024-12-31T00:00:00,1.15997150997151,1.3659645318984985,17.758455285858524,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Muzambinho,2024-12-31T00:00:00,1.26,1.8171794414520264,44.220590591430664,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Natercia,2024-12-31T00:00:00,1.8000000000000003,1.527808427810669,-15.121754010518403,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Nazareno,2024-12-31T00:00:00,1.619811320754717,1.7636712789535522,8.881278723981682,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Nepomuceno,2024-12-31T00:00:00,1.3800383877159308,1.5280542373657227,10.725487853621916,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ninheira,2024-12-31T00:00:00,2.819758276405675,3.1439836025238037,11.498337599753988,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Nova_Belem,2024-12-31T00:00:00,0.9,0.9126203656196594,1.4022628466288223,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Nova_Era,2024-12-31T00:00:00,1.5,1.707855463027954,13.857030868530273,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Nova_Ponte,2024-12-31T00:00:00,2.306557377049181,2.4628827571868896,6.777432969722977,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Nova_Resende,2024-12-31T00:00:00,1.32,2.350137233734131,78.04069952531295,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Novo_Cruzeiro,2024-12-31T00:00:00,1.7997542997542997,1.195230484008789,-33.58924136633759,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Novorizonte,2024-12-31T00:00:00,1.333333333333333,1.309668779373169,-1.7748415470123073,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Olimpio_Noronha,2024-12-31T00:00:00,1.5,1.3560346364974976,-9.597690900166828,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Oliveira,2024-12-31T00:00:00,1.8240227434257288,1.6468865871429443,-9.711290986980895,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Orizania,2024-12-31T00:00:00,1.5,1.3202528953552246,-11.983140309651692,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ouro_Fino,2024-12-31T00:00:00,1.5,2.037710189819336,35.847345987955734,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ouro_Verde_de_Minas,2024-12-31T00:00:00,2.5,1.8542766571044922,-25.828933715820312,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Padre_Paraiso,2024-12-31T00:00:00,0.7212121212121212,0.674877405166626,-6.424561468493034,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Paracatu,2024-12-31T00:00:00,2.7003236245954687,2.443659782409668,-9.504928959181742,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Paraguacu,2024-12-31T00:00:00,1.323316582914573,1.253354549407959,-5.2868704594122375,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Paraisopolis,2024-12-31T00:00:00,1.5066666666666668,1.4496530294418335,-3.784090966249999,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Passa_Tempo,2024-12-31T00:00:00,1.5,1.516218662261963,1.081244150797526,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Passos,2024-12-31T00:00:00,1.95459940652819,1.9265832901000977,-1.433343135914242,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Patis,2024-12-31T00:00:00,0.9,2.3246383666992188,158.29315185546875,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Patos_de_Minas,2024-12-31T00:00:00,1.6624523160762943,1.8241957426071167,9.729206965320236,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Patrocinio,2024-12-31T00:00:00,1.4995330375904743,1.5984342098236084,6.59546470493598,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Paula_Candido,2024-12-31T00:00:00,1.31970802919708,1.6166937351226807,22.50389475210581,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pecanha,2024-12-31T00:00:00,1.8855421686746991,2.0211172103881836,7.190241828894061,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pedra_Azul,2024-12-31T00:00:00,0.9,1.1963659524917603,32.929550276862244,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pedra_Bonita,2024-12-31T00:00:00,1.2,1.337013840675354,11.417820056279504,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pedra_Dourada,2024-12-31T00:00:00,1.2800000000000002,1.245073676109314,-2.728619053959865,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pedra_do_Anta,2024-12-31T00:00:00,1.379166666666667,1.4856064319610596,7.717686909563199,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pedralva,2024-12-31T00:00:00,1.5600790513833993,1.7203172445297241,10.271158567524747,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pedrinopolis,2024-12-31T00:00:00,1.8511627906976742,2.3369693756103516,26.243320541765236,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Perdizes,2024-12-31T00:00:00,1.142806076854334,2.0600757598876953,80.26468371241253,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Perdoes,2024-12-31T00:00:00,1.6799401197604789,1.5539271831512451,-7.501037395737671,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Piedade_de_Caratinga,2024-12-31T00:00:00,1.68,2.0115551948547363,19.73542826516288,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pimenta,2024-12-31T00:00:00,1.715219421101774,1.271706461906433,-25.857505677638,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Piracema,2024-12-31T00:00:00,0.8,1.096752643585205,37.09408044815063,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Piranga,2024-12-31T00:00:00,1.8000000000000003,2.0583295822143555,14.351643456353063,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pirangucu,2024-12-31T00:00:00,1.333333333333333,1.2915599346160889,-3.1330049037933136,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Piranguinho,2024-12-31T00:00:00,1.6807610993657498,1.4676324129104614,-12.68048662809452,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pirapora,2024-12-31T00:00:00,2.7000000000000006,3.0890865325927734,14.410612318250843,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Piumhi,2024-12-31T00:00:00,1.3800316957210783,1.521512746810913,10.252014611585404,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Poco_Fundo,2024-12-31T00:00:00,1.380192991366176,1.2759453058242798,-7.553123816308266,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pocos_de_Caldas,2024-12-31T00:00:00,1.7400000000000002,1.3203679323196411,-24.11678549887121,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pocrane,2024-12-31T00:00:00,1.7968750000000002,1.3058340549468994,-27.32749607252039,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ponte_Nova,2024-12-31T00:00:00,1.9999999999999996,1.177000641822815,-41.14996790885924,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ponto_dos_Volantes,2024-12-31T00:00:00,0.5,0.6139261722564697,22.785234451293945,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Porto_Firme,2024-12-31T00:00:00,1.3810526315789473,1.2574259042739868,-8.95163040699028,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pote,2024-12-31T00:00:00,1.125,0.915395200252533,-18.631537755330406,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pouso_Alegre,2024-12-31T00:00:00,1.7878787878787883,1.6824030876159668,-5.89948831978493,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pouso_Alto,2024-12-31T00:00:00,1.53,1.6599912643432617,8.496161068187039,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pratapolis,2024-12-31T00:00:00,1.1988636363636362,1.9570088386535645,63.23865194456274,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pratinha,2024-12-31T00:00:00,1.849285714285714,1.9488680362701416,5.384907330173762,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Presidente_Bernardes,2024-12-31T00:00:00,1.110144927536232,1.4264014959335327,28.487863210722903,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Presidente_Kubitschek,2024-12-31T00:00:00,0.7368421052631579,0.7660849094390869,3.968666281018944,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Presidente_Olegario,2024-12-31T00:00:00,1.9199630314232903,1.9409929513931274,1.0953294217465972,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Quartel_Geral,2024-12-31T00:00:00,3.0,3.0666871070861816,2.2229035695393877,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Raul_Soares,2024-12-31T00:00:00,1.5,1.176797866821289,-21.546808878580727,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Reduto,2024-12-31T00:00:00,1.2,1.1214399337768555,-6.546672185262041,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ribeirao_Vermelho,2024-12-31T00:00:00,1.43859649122807,1.5284273624420166,6.244341047798729,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Rio_Paranaiba,2024-12-31T00:00:00,1.680014776505357,1.9105503559112549,13.722235222563995,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Rio_Pardo_de_Minas,2024-12-31T00:00:00,3.064285714285715,2.686830520629883,-12.31788510764953,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Rio_Vermelho,2024-12-31T00:00:00,0.9230769230769231,0.8203600645065308,-11.127659678459173,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ritapolis,2024-12-31T00:00:00,1.8000000000000003,1.9862892627716064,10.349403487311452,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Romaria,2024-12-31T00:00:00,2.052631578947369,2.1944074630737305,6.907030252309915,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Rosario_da_Limeira,2024-12-31T00:00:00,1.259493670886076,1.2873203754425049,2.2093564421687253,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sabinopolis,2024-12-31T00:00:00,1.2,1.1091349124908447,-7.572090625762937,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sacramento,2024-12-31T00:00:00,1.7370212765957447,1.8229482173919678,4.946798404486141,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santa_Barbara,2024-12-31T00:00:00,1.333333333333333,1.2235983610153198,-8.230122923850992,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santa_Barbara_do_Leste,2024-12-31T00:00:00,1.4101226993865028,1.3718305826187134,-2.715516655710106,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santa_Barbara_do_Monte_Verde,2024-12-31T00:00:00,1.3,1.3035739660263062,0.2749204635620083,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santa_Margarida,2024-12-31T00:00:00,1.5,1.2801710367202759,-14.655264218648275,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santa_Maria_do_Suacui,2024-12-31T00:00:00,1.333333333333333,0.8275842070579529,-37.93118447065352,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santa_Rita_de_Caldas,2024-12-31T00:00:00,1.8000000000000003,1.6690912246704102,-7.272709740532783,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santa_Rita_de_Minas,2024-12-31T00:00:00,1.200173310225303,1.2434171438217163,3.6031324166253467,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santa_Rita_do_Itueto,2024-12-31T00:00:00,1.365238095238095,1.427335262298584,4.548449627730278,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santa_Rita_do_Sapucai,2024-12-31T00:00:00,1.5,1.6445069313049316,9.633795420328777,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santa_Rosa_da_Serra,2024-12-31T00:00:00,1.92,1.8422235250473022,-4.050858070453005,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santana_da_Vargem,2024-12-31T00:00:00,1.44,1.350581407546997,-6.209624475902978,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santana_do_Jacare,2024-12-31T00:00:00,1.2,1.2082716226577759,0.6893018881479936,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santana_do_Manhuacu,2024-12-31T00:00:00,1.08,1.368541955947876,26.716847772951468,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santo_Antonio_do_Amparo,2024-12-31T00:00:00,1.68,1.4740179777145386,-12.260834659848891,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santo_Antonio_do_Grama,2024-12-31T00:00:00,1.565217391304348,1.4734646081924438,-5.861983365482758,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santo_Antonio_do_Retiro,2024-12-31T00:00:00,1.9666666666666672,1.0041228532791138,-48.94290576546881,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Bento_Abade,2024-12-31T00:00:00,1.5,1.9816091060638428,32.10727373758952,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Domingos_das_Dores,2024-12-31T00:00:00,1.4100000000000001,1.3168126344680786,-6.609033016448334,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Domingos_do_Prata,2024-12-31T00:00:00,1.05,1.0381393432617188,-1.12958635602679,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Francisco_de_Paula,2024-12-31T00:00:00,1.62,1.4988987445831299,-7.475386136843841,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Francisco_do_Gloria,2024-12-31T00:00:00,1.25,1.2677416801452637,1.4193344116210938,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Geraldo,2024-12-31T00:00:00,1.3189189189189188,1.567360758781433,18.836778842034903,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Goncalo_do_Abaete,2024-12-31T00:00:00,1.5,1.7265273332595825,15.101822217305502,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Goncalo_do_Rio_Preto,2024-12-31T00:00:00,2.5238095238095246,2.497323989868164,-1.0494268165444742,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Goncalo_do_Sapucai,2024-12-31T00:00:00,1.5,1.164228081703186,-22.384794553120933,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Gotardo,2024-12-31T00:00:00,1.668148148148148,1.4608349800109863,-12.42774320538047,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Joao_Batista_do_Gloria,2024-12-31T00:00:00,1.548387096774194,1.5097041130065918,-2.4982760349909716,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Joao_da_Mata,2024-12-31T00:00:00,1.32,1.1116292476654053,-15.785663055651119,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Joao_del_Rei,2024-12-31T00:00:00,1.8016877637130797,2.050534725189209,13.811880531579076,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Joao_do_Manhuacu,2024-12-31T00:00:00,1.32,1.1990857124328613,-9.160173300540812,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Joao_do_Manteninha,2024-12-31T00:00:00,0.9,0.8123234510421753,-9.741838773091636,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Joao_do_Paraiso,2024-12-31T00:00:00,3.5396226415094336,2.693657875061035,-23.899857474288446,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Jose_da_Barra,2024-12-31T00:00:00,1.709523809523809,2.208524227142334,29.189439470721528,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Jose_do_Alegre,2024-12-31T00:00:00,1.8000000000000003,1.6040914058685303,-10.883810785081664,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Jose_do_Mantimento,2024-12-31T00:00:00,1.44,1.5351014137268066,6.604264842139354,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Lourenco,2024-12-31T00:00:00,1.3799999999999997,1.6787986755371094,21.652077937471724,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Miguel_do_Anta,2024-12-31T00:00:00,1.55974025974026,1.5128055810928345,-3.009134267986488,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Pedro_da_Uniao,2024-12-31T00:00:00,2.04,1.7380781173706055,-14.800092285754635,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Roque_de_Minas,2024-12-31T00:00:00,1.58,1.6122796535491943,2.0430160474173586,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Sebastiao_da_Bela_Vista,2024-12-31T00:00:00,1.44,1.531010389328003,6.320165925555762,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Sebastiao_da_Vargem_Alegre,2024-12-31T00:00:00,1.2800000000000002,1.4549710750579834,13.669615238904932,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Sebastiao_do_Anta,2024-12-31T00:00:00,1.8000000000000003,1.7341028451919556,-3.660953044891372,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Sebastiao_do_Maranhao,2024-12-31T00:00:00,1.380952380952381,1.0327259302139282,-25.216398156922438,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Sebastiao_do_Paraiso,2024-12-31T00:00:00,1.26,1.682115077972412,33.50119666447715,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Tiago,2024-12-31T00:00:00,1.621052631578947,1.50051748752594,-7.435609535737455,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Tomas_de_Aquino,2024-12-31T00:00:00,1.619975932611312,1.6420694589614868,1.3638181842961934,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Tome_das_Letras,2024-12-31T00:00:00,2.1,1.2962790727615356,-38.272425106593545,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Senador_Firmino,2024-12-31T00:00:00,1.804347826086957,1.472809076309204,-18.37443673467064,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Senador_Jose_Bento,2024-12-31T00:00:00,0.9,1.3623944520950317,51.37716134389241,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Senador_Modestino_Goncalves,2024-12-31T00:00:00,2.706666666666667,2.423497200012207,-10.461926107923397,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Senhora_de_Oliveira,2024-12-31T00:00:00,1.8000000000000003,1.3470876216888428,-25.1617987950643,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Senhora_dos_Remedios,2024-12-31T00:00:00,1.8000000000000003,1.5659650564193726,-13.00194131003487,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sericita,2024-12-31T00:00:00,1.3799999999999997,1.4865761995315552,7.72291300953301,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Serra_do_Salitre,2024-12-31T00:00:00,1.5168750000000002,1.8586186170578003,22.52945147476226,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Serrania,2024-12-31T00:00:00,1.32,1.0429636240005493,-20.98760424238263,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Setubinha,2024-12-31T00:00:00,1.020238095238095,1.103485345840454,8.159590490779662,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Silvianopolis,2024-12-31T00:00:00,1.56025641025641,1.3890498876571655,-10.972973510880093,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Simonesia,2024-12-31T00:00:00,1.2,1.3851852416992188,15.4321034749349,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Soledade_de_Minas,2024-12-31T00:00:00,1.5,1.742227554321289,16.148503621419273,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Taiobeiras,2024-12-31T00:00:00,3.1206349206349207,2.8989815711975098,-7.102828593365659,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Tapira,2024-12-31T00:00:00,1.9799999999999998,1.7878084182739258,-9.70664554172091,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Tapirai,2024-12-31T00:00:00,1.9163050216986979,1.692265510559082,-11.691223923267565,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Teixeiras,2024-12-31T00:00:00,1.5,1.5208230018615723,1.3882001241048179,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Teofilo_Otoni,2024-12-31T00:00:00,1.05,1.0069950819015503,-4.095706485566643,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Tiros,2024-12-31T00:00:00,1.9499999999999997,1.6868736743927002,-13.49365772345126,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Tocos_do_Moji,2024-12-31T00:00:00,1.5,1.7601327896118164,17.342185974121094,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Tombos,2024-12-31T00:00:00,1.5,1.2548446655273438,-16.34368896484375,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Tres_Coracoes,2024-12-31T00:00:00,1.56,1.9612447023391724,25.720814252511044,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Tres_Pontas,2024-12-31T00:00:00,1.387228956803825,1.643237829208374,18.45469496213469,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Tupaciguara,2024-12-31T00:00:00,2.8219895287958106,2.4994020462036133,-11.431207639166919,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Turmalina,2024-12-31T00:00:00,1.8507692307692305,1.3912519216537476,-24.828449785957105,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Turvolandia,2024-12-31T00:00:00,1.44,1.3646125793457031,-5.23523754543728,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ubaporanga,2024-12-31T00:00:00,1.440056417489422,1.4969117641448975,3.9481332790139225,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Uberaba,2024-12-31T00:00:00,2.102941176470588,2.618105411529541,24.497320268537635,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Uberlandia,2024-12-31T00:00:00,1.9195652173913038,1.8666428327560425,-2.75699852007024,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Unai,2024-12-31T00:00:00,2.2801061007957566,2.5216100215911865,10.591784334559918,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Urucuia,2024-12-31T00:00:00,1.920433996383363,2.088035821914673,8.727289031903425,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Vargem_Bonita,2024-12-31T00:00:00,2.1878048780487815,1.4424588680267334,-34.06821227525525,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Vargem_Grande_do_Rio_Pardo,2024-12-31T00:00:00,1.8000000000000003,1.8360731601715088,2.0040644539726955,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Varginha,2024-12-31T00:00:00,1.3799999999999997,1.703333854675293,23.429989469224157,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Varjao_de_Minas,2024-12-31T00:00:00,2.6876337184424486,2.4196643829345703,-9.970455931888415,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Varzea_da_Palma,2024-12-31T00:00:00,3.0,2.8335604667663574,-5.54798444112142,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Vermelho_Novo,2024-12-31T00:00:00,1.8000000000000003,1.288078784942627,-28.4400675031874,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Vicosa,2024-12-31T00:00:00,1.32,1.6079518795013428,21.814536325859297,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Vieiras,2024-12-31T00:00:00,1.44,1.4618995189666748,1.5207999282413096,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Virginia,2024-12-31T00:00:00,1.6599999999999997,1.6118414402008057,-2.9011180601924123,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Virginopolis,2024-12-31T00:00:00,1.325,1.4152642488479614,6.81239613946879,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Visconde_do_Rio_Branco,2024-12-31T00:00:00,1.333333333333333,1.0836284160614014,-18.72786879539488,validacao,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Abadia_dos_Dourados,2025-12-31T00:00:00,0.0,2.3010683059692383,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Abre_Campo,2025-12-31T00:00:00,0.0,1.6655938625335693,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Acucena,2025-12-31T00:00:00,0.0,1.9295850992202759,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Agua_Boa,2025-12-31T00:00:00,0.0,1.4850027561187744,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Aguanil,2025-12-31T00:00:00,0.0,1.9527863264083862,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Aguas_Vermelhas,2025-12-31T00:00:00,0.0,3.7948219776153564,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Aimores,2025-12-31T00:00:00,0.0,1.8406223058700562,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Aiuruoca,2025-12-31T00:00:00,0.0,1.7536697387695312,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Albertina,2025-12-31T00:00:00,0.0,1.4836357831954956,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Alfenas,2025-12-31T00:00:00,0.0,1.7091255187988281,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Almenara,2025-12-31T00:00:00,0.0,0.7808427214622498,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Alpinopolis,2025-12-31T00:00:00,0.0,2.23603892326355,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Alterosa,2025-12-31T00:00:00,0.0,1.1881413459777832,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Alto_Caparao,2025-12-31T00:00:00,0.0,1.3875702619552612,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Alto_Jequitiba,2025-12-31T00:00:00,0.0,1.357365608215332,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Alvarenga,2025-12-31T00:00:00,0.0,1.607150912284851,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Amparo_do_Serra,2025-12-31T00:00:00,0.0,1.564880609512329,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Andradas,2025-12-31T00:00:00,0.0,1.2462137937545776,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Andrelandia,2025-12-31T00:00:00,0.0,1.6521239280700684,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Angelandia,2025-12-31T00:00:00,0.0,1.8607690334320068,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Antonio_Dias,2025-12-31T00:00:00,0.0,1.527984619140625,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Antonio_Prado_de_Minas,2025-12-31T00:00:00,0.0,1.3922542333602905,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Araguari,2025-12-31T00:00:00,0.0,1.895439863204956,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Araponga,2025-12-31T00:00:00,0.0,1.5408108234405518,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Arapua,2025-12-31T00:00:00,0.0,1.0042674541473389,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Araxa,2025-12-31T00:00:00,0.0,1.280750036239624,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Arceburgo,2025-12-31T00:00:00,0.0,1.2152233123779297,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Areado,2025-12-31T00:00:00,0.0,1.338379144668579,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Aricanduva,2025-12-31T00:00:00,0.0,1.2778875827789307,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Astolfo_Dutra,2025-12-31T00:00:00,0.0,0.33923113346099854,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ataleia,2025-12-31T00:00:00,0.0,0.9831169843673706,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Baependi,2025-12-31T00:00:00,0.0,1.6689344644546509,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Bambui,2025-12-31T00:00:00,0.0,1.6871662139892578,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Bandeira,2025-12-31T00:00:00,0.0,1.537888526916504,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Bandeira_do_Sul,2025-12-31T00:00:00,0.0,1.2479826211929321,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Berilo,2025-12-31T00:00:00,0.0,1.516015648841858,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Berizal,2025-12-31T00:00:00,0.0,5.986603736877441,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Boa_Esperanca,2025-12-31T00:00:00,0.0,1.0917673110961914,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Bocaiuva,2025-12-31T00:00:00,0.0,2.2517528533935547,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Bom_Jesus_da_Penha,2025-12-31T00:00:00,0.0,1.5749855041503906,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Bom_Jesus_do_Amparo,2025-12-31T00:00:00,0.0,1.1665512323379517,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Bom_Jesus_do_Galho,2025-12-31T00:00:00,0.0,1.5763272047042847,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Bom_Sucesso,2025-12-31T00:00:00,0.0,1.5896384716033936,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Bonfinopolis_de_Minas,2025-12-31T00:00:00,0.0,2.4723143577575684,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Borda_da_Mata,2025-12-31T00:00:00,0.0,1.3529109954833984,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Botelhos,2025-12-31T00:00:00,0.0,0.8674359321594238,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Botumirim,2025-12-31T00:00:00,0.0,0.8037216067314148,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Brazopolis,2025-12-31T00:00:00,0.0,1.4280147552490234,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Bueno_Brandao,2025-12-31T00:00:00,0.0,1.6145576238632202,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Buritis,2025-12-31T00:00:00,0.0,3.1123085021972656,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Buritizeiro,2025-12-31T00:00:00,0.0,2.9651787281036377,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cabo_Verde,2025-12-31T00:00:00,0.0,1.4644193649291992,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cachoeira_de_Minas,2025-12-31T00:00:00,0.0,1.7813408374786377,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Caete,2025-12-31T00:00:00,0.0,1.3667491674423218,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Caiana,2025-12-31T00:00:00,0.0,1.2593419551849365,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cajuri,2025-12-31T00:00:00,0.0,1.5523985624313354,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Caldas,2025-12-31T00:00:00,0.0,1.3809797763824463,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Camacho,2025-12-31T00:00:00,0.0,1.6352002620697021,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cambuquira,2025-12-31T00:00:00,0.0,1.6963717937469482,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Campanha,2025-12-31T00:00:00,0.0,1.5505189895629883,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Campestre,2025-12-31T00:00:00,0.0,1.2286841869354248,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Campo_Belo,2025-12-31T00:00:00,0.0,1.489322543144226,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Campo_do_Meio,2025-12-31T00:00:00,0.0,1.061463475227356,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Campos_Altos,2025-12-31T00:00:00,0.0,1.610276699066162,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Campos_Gerais,2025-12-31T00:00:00,0.0,1.4183285236358643,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cana_Verde,2025-12-31T00:00:00,0.0,1.3381462097167969,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Canaa,2025-12-31T00:00:00,0.0,1.7093899250030518,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Candeias,2025-12-31T00:00:00,0.0,1.6020865440368652,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Caparao,2025-12-31T00:00:00,0.0,1.521180510520935,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Capela_Nova,2025-12-31T00:00:00,0.0,1.8935959339141846,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Capelinha,2025-12-31T00:00:00,0.0,1.592337727546692,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Capetinga,2025-12-31T00:00:00,0.0,1.7775583267211914,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Capitao_Eneas,2025-12-31T00:00:00,0.0,2.1647512912750244,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Capitolio,2025-12-31T00:00:00,0.0,1.6755664348602295,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Caputira,2025-12-31T00:00:00,0.0,1.765514850616455,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Carai,2025-12-31T00:00:00,0.0,1.579723834991455,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Caranaiba,2025-12-31T00:00:00,0.0,1.5114316940307617,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Carangola,2025-12-31T00:00:00,0.0,1.4531333446502686,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Caratinga,2025-12-31T00:00:00,0.0,1.7434301376342773,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Careacu,2025-12-31T00:00:00,0.0,1.4869298934936523,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Carmo_da_Cachoeira,2025-12-31T00:00:00,0.0,1.3996412754058838,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Carmo_da_Mata,2025-12-31T00:00:00,0.0,1.3298285007476807,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Carmo_de_Minas,2025-12-31T00:00:00,0.0,1.869107723236084,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Carmo_do_Paranaiba,2025-12-31T00:00:00,0.0,1.7564589977264404,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Carmo_do_Rio_Claro,2025-12-31T00:00:00,0.0,2.136960744857788,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Carmopolis_de_Minas,2025-12-31T00:00:00,0.0,1.7043466567993164,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Carrancas,2025-12-31T00:00:00,0.0,1.4630059003829956,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Carvalhopolis,2025-12-31T00:00:00,0.0,1.5731455087661743,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Casa_Grande,2025-12-31T00:00:00,0.0,2.1753807067871094,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cascalho_Rico,2025-12-31T00:00:00,0.0,2.261512279510498,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cassia,2025-12-31T00:00:00,0.0,1.8262336254119873,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cataguases,2025-12-31T00:00:00,0.0,0.8158737421035767,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Catas_Altas_da_Noruega,2025-12-31T00:00:00,0.0,0.9696069955825806,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Catuji,2025-12-31T00:00:00,0.0,1.3475311994552612,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Caxambu,2025-12-31T00:00:00,0.0,1.655871868133545,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Chale,2025-12-31T00:00:00,0.0,1.7611424922943115,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Claraval,2025-12-31T00:00:00,0.0,1.9001373052597046,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Claudio,2025-12-31T00:00:00,0.0,2.344533920288086,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Coimbra,2025-12-31T00:00:00,0.0,1.7574455738067627,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Conceicao_da_Aparecida,2025-12-31T00:00:00,0.0,1.6606051921844482,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Conceicao_da_Barra_de_Minas,2025-12-31T00:00:00,0.0,1.4863407611846924,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Conceicao_das_Pedras,2025-12-31T00:00:00,0.0,1.5646233558654785,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Conceicao_de_Ipanema,2025-12-31T00:00:00,0.0,1.6079373359680176,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Conceicao_do_Rio_Verde,2025-12-31T00:00:00,0.0,1.543613314628601,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Conceicao_dos_Ouros,2025-12-31T00:00:00,0.0,1.4960885047912598,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Congonhal,2025-12-31T00:00:00,0.0,1.8101449012756348,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Congonhas_do_Norte,2025-12-31T00:00:00,0.0,1.266434669494629,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Conselheiro_Pena,2025-12-31T00:00:00,0.0,1.7766581773757935,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Coqueiral,2025-12-31T00:00:00,0.0,1.1296278238296509,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cordislandia,2025-12-31T00:00:00,0.0,1.4752140045166016,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Coroaci,2025-12-31T00:00:00,0.0,2.5587477684020996,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Coromandel,2025-12-31T00:00:00,0.0,1.6293805837631226,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Corrego_Danta,2025-12-31T00:00:00,0.0,1.6307125091552734,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Corrego_Fundo,2025-12-31T00:00:00,0.0,1.557145357131958,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Corrego_Novo,2025-12-31T00:00:00,0.0,1.7957499027252197,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cristais,2025-12-31T00:00:00,0.0,1.7754809856414795,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cristina,2025-12-31T00:00:00,0.0,2.2386183738708496,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cruzeiro_da_Fortaleza,2025-12-31T00:00:00,0.0,1.6321849822998047,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cruzilia,2025-12-31T00:00:00,0.0,1.6106445789337158,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Cuparaque,2025-12-31T00:00:00,0.0,1.2007683515548706,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Datas,2025-12-31T00:00:00,0.0,0.43181630969047546,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Delfinopolis,2025-12-31T00:00:00,0.0,1.482040286064148,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Desterro_de_Entre_Rios,2025-12-31T00:00:00,0.0,1.413435697555542,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Diamantina,2025-12-31T00:00:00,0.0,2.455155372619629,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Divinesia,2025-12-31T00:00:00,0.0,1.5023577213287354,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Divino,2025-12-31T00:00:00,0.0,1.5218080282211304,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Divisa_Nova,2025-12-31T00:00:00,0.0,1.4862034320831299,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Divisopolis,2025-12-31T00:00:00,0.0,1.8312149047851562,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Dom_Cavati,2025-12-31T00:00:00,0.0,0.6403641700744629,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Dom_Vicoso,2025-12-31T00:00:00,0.0,1.5042825937271118,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Dores_do_Turvo,2025-12-31T00:00:00,0.0,1.3075364828109741,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Doresopolis,2025-12-31T00:00:00,0.0,1.6950228214263916,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Durande,2025-12-31T00:00:00,0.0,2.364645481109619,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Eloi_Mendes,2025-12-31T00:00:00,0.0,1.400869369506836,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Entre_Folhas,2025-12-31T00:00:00,0.0,1.2740554809570312,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Entre_Rios_de_Minas,2025-12-31T00:00:00,0.0,1.7004188299179077,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ervalia,2025-12-31T00:00:00,0.0,1.582132339477539,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Esmeraldas,2025-12-31T00:00:00,0.0,2.1283602714538574,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Espera_Feliz,2025-12-31T00:00:00,0.0,1.593367099761963,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Espirito_Santo_do_Dourado,2025-12-31T00:00:00,0.0,1.365699052810669,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Estrela_do_Indaia,2025-12-31T00:00:00,0.0,1.625542163848877,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Estrela_do_Sul,2025-12-31T00:00:00,0.0,1.5867815017700195,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Eugenopolis,2025-12-31T00:00:00,0.0,1.5527526140213013,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Fama,2025-12-31T00:00:00,0.0,1.5671544075012207,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Faria_Lemos,2025-12-31T00:00:00,0.0,1.3488984107971191,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Felicio_dos_Santos,2025-12-31T00:00:00,0.0,4.412513256072998,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ferros,2025-12-31T00:00:00,0.0,1.1185879707336426,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Fervedouro,2025-12-31T00:00:00,0.0,1.841245174407959,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Formiga,2025-12-31T00:00:00,0.0,1.6673965454101562,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Formoso,2025-12-31T00:00:00,0.0,3.2770261764526367,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Fortaleza_de_Minas,2025-12-31T00:00:00,0.0,1.4687960147857666,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Franciscopolis,2025-12-31T00:00:00,0.0,1.4259096384048462,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Frei_Gaspar,2025-12-31T00:00:00,0.0,1.176272988319397,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Grao_Mogol,2025-12-31T00:00:00,0.0,1.1317051649093628,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Guape,2025-12-31T00:00:00,0.0,1.6675196886062622,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Guaraciaba,2025-12-31T00:00:00,0.0,1.3490378856658936,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Guaranesia,2025-12-31T00:00:00,0.0,1.1327345371246338,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Guarani,2025-12-31T00:00:00,0.0,0.819476306438446,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Guarda-Mor,2025-12-31T00:00:00,0.0,1.763771414756775,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Guaxupe,2025-12-31T00:00:00,0.0,1.1711777448654175,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Guimarania,2025-12-31T00:00:00,0.0,1.7211452722549438,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Guiricema,2025-12-31T00:00:00,0.0,1.5479276180267334,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Heliodora,2025-12-31T00:00:00,0.0,1.746816873550415,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Iapu,2025-12-31T00:00:00,0.0,1.6526991128921509,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ibia,2025-12-31T00:00:00,0.0,1.3670014142990112,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ibiraci,2025-12-31T00:00:00,0.0,2.1223154067993164,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ibitiura_de_Minas,2025-12-31T00:00:00,0.0,1.1185003519058228,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ibituruna,2025-12-31T00:00:00,0.0,1.587397575378418,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ijaci,2025-12-31T00:00:00,0.0,1.5963425636291504,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ilicinea,2025-12-31T00:00:00,0.0,1.6159663200378418,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Imbe_de_Minas,2025-12-31T00:00:00,0.0,1.5558884143829346,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Inconfidentes,2025-12-31T00:00:00,0.0,1.6401787996292114,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Indaiabira,2025-12-31T00:00:00,0.0,3.426461696624756,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Indianopolis,2025-12-31T00:00:00,0.0,1.888566255569458,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ingai,2025-12-31T00:00:00,0.0,1.5165669918060303,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Inhapim,2025-12-31T00:00:00,0.0,2.4301583766937256,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Irai_de_Minas,2025-12-31T00:00:00,0.0,3.0007572174072266,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Itabirinha,2025-12-31T00:00:00,0.0,1.03949773311615,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Itacambira,2025-12-31T00:00:00,0.0,0.6218816041946411,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Itaipe,2025-12-31T00:00:00,0.0,0.9992709159851074,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Itajuba,2025-12-31T00:00:00,0.0,1.2185626029968262,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Itamarandiba,2025-12-31T00:00:00,0.0,2.111659526824951,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Itamarati_de_Minas,2025-12-31T00:00:00,0.0,1.0460954904556274,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Itambacuri,2025-12-31T00:00:00,0.0,1.0463594198226929,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Itamogi,2025-12-31T00:00:00,0.0,1.5077263116836548,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Itanhomi,2025-12-31T00:00:00,0.0,1.3000175952911377,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Itapecerica,2025-12-31T00:00:00,0.0,1.347316026687622,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ituiutaba,2025-12-31T00:00:00,0.0,0.7198972105979919,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Itumirim,2025-12-31T00:00:00,0.0,1.4515787363052368,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Itutinga,2025-12-31T00:00:00,0.0,1.5797703266143799,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Jacui,2025-12-31T00:00:00,0.0,1.295244574546814,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Jacutinga,2025-12-31T00:00:00,0.0,1.2994256019592285,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Jequeri,2025-12-31T00:00:00,0.0,1.8229429721832275,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Jequitinhonha,2025-12-31T00:00:00,0.0,2.454721450805664,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Jesuania,2025-12-31T00:00:00,0.0,1.5572326183319092,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Joao_Pinheiro,2025-12-31T00:00:00,0.0,2.6522443294525146,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Jose_Goncalves_de_Minas,2025-12-31T00:00:00,0.0,1.6422929763793945,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Juiz_de_Fora,2025-12-31T00:00:00,0.0,0.9738583564758301,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Juruaia,2025-12-31T00:00:00,0.0,1.5438423156738281,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ladainha,2025-12-31T00:00:00,0.0,1.2767257690429688,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Lagoa_Dourada,2025-12-31T00:00:00,0.0,1.5000324249267578,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Lagoa_Formosa,2025-12-31T00:00:00,0.0,1.9026230573654175,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Lagoa_Grande,2025-12-31T00:00:00,0.0,1.545582890510559,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Lajinha,2025-12-31T00:00:00,0.0,2.026979923248291,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Lambari,2025-12-31T00:00:00,0.0,1.6749106645584106,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Lamim,2025-12-31T00:00:00,0.0,1.4874439239501953,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Lavras,2025-12-31T00:00:00,0.0,1.476083517074585,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Luisburgo,2025-12-31T00:00:00,0.0,1.3976800441741943,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Luminarias,2025-12-31T00:00:00,0.0,1.3257827758789062,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Machado,2025-12-31T00:00:00,0.0,1.3759753704071045,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Malacacheta,2025-12-31T00:00:00,0.0,1.8239576816558838,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Manhuacu,2025-12-31T00:00:00,0.0,1.703201174736023,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Manhumirim,2025-12-31T00:00:00,0.0,1.6053156852722168,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Mantena,2025-12-31T00:00:00,0.0,1.4758737087249756,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Mar_de_Espanha,2025-12-31T00:00:00,0.0,1.3207043409347534,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Maria_da_Fe,2025-12-31T00:00:00,0.0,1.6218159198760986,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Martins_Soares,2025-12-31T00:00:00,0.0,1.8220710754394531,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Mata_Verde,2025-12-31T00:00:00,0.0,2.0035934448242188,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Matipo,2025-12-31T00:00:00,0.0,1.6104507446289062,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Matutina,2025-12-31T00:00:00,0.0,1.591970443725586,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Medeiros,2025-12-31T00:00:00,0.0,1.754319429397583,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Minas_Novas,2025-12-31T00:00:00,0.0,1.8178025484085083,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Miradouro,2025-12-31T00:00:00,0.0,1.1336153745651245,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Mirai,2025-12-31T00:00:00,0.0,1.0012975931167603,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Moeda,2025-12-31T00:00:00,0.0,1.2727704048156738,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Monsenhor_Paulo,2025-12-31T00:00:00,0.0,1.6699351072311401,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Monte_Alegre_de_Minas,2025-12-31T00:00:00,0.0,2.171057939529419,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Monte_Belo,2025-12-31T00:00:00,0.0,1.3274750709533691,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Monte_Carmelo,2025-12-31T00:00:00,0.0,2.1226134300231934,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Monte_Formoso,2025-12-31T00:00:00,0.0,0.7873421311378479,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Monte_Santo_de_Minas,2025-12-31T00:00:00,0.0,1.4011714458465576,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Monte_Siao,2025-12-31T00:00:00,0.0,1.4637707471847534,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Muriae,2025-12-31T00:00:00,0.0,1.0825401544570923,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Mutum,2025-12-31T00:00:00,0.0,1.4281210899353027,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Muzambinho,2025-12-31T00:00:00,0.0,1.3251562118530273,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Natercia,2025-12-31T00:00:00,0.0,1.5718729496002197,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Nazareno,2025-12-31T00:00:00,0.0,1.315166711807251,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Nepomuceno,2025-12-31T00:00:00,0.0,1.3569483757019043,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ninheira,2025-12-31T00:00:00,0.0,3.69793963432312,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Nova_Belem,2025-12-31T00:00:00,0.0,1.1100889444351196,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Nova_Era,2025-12-31T00:00:00,0.0,1.7113391160964966,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Nova_Ponte,2025-12-31T00:00:00,0.0,2.137526512145996,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Nova_Resende,2025-12-31T00:00:00,0.0,1.4296765327453613,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Novo_Cruzeiro,2025-12-31T00:00:00,0.0,1.3815722465515137,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Novorizonte,2025-12-31T00:00:00,0.0,1.4230903387069702,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Olimpio_Noronha,2025-12-31T00:00:00,0.0,1.4304509162902832,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Oliveira,2025-12-31T00:00:00,0.0,1.7205899953842163,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Orizania,2025-12-31T00:00:00,0.0,1.585845947265625,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ouro_Fino,2025-12-31T00:00:00,0.0,1.4911530017852783,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ouro_Verde_de_Minas,2025-12-31T00:00:00,0.0,2.023582696914673,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Padre_Paraiso,2025-12-31T00:00:00,0.0,0.7124961614608765,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Paracatu,2025-12-31T00:00:00,0.0,2.4097046852111816,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Paraguacu,2025-12-31T00:00:00,0.0,1.4465733766555786,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Paraisopolis,2025-12-31T00:00:00,0.0,1.4244219064712524,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Passa_Tempo,2025-12-31T00:00:00,0.0,1.5307440757751465,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Passos,2025-12-31T00:00:00,0.0,1.6036922931671143,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Patis,2025-12-31T00:00:00,0.0,1.3047566413879395,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Patos_de_Minas,2025-12-31T00:00:00,0.0,1.8380472660064697,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Patrocinio,2025-12-31T00:00:00,0.0,1.3473167419433594,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Paula_Candido,2025-12-31T00:00:00,0.0,1.4807960987091064,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pecanha,2025-12-31T00:00:00,0.0,2.5676376819610596,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pedra_Azul,2025-12-31T00:00:00,0.0,1.4586732387542725,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pedra_Bonita,2025-12-31T00:00:00,0.0,1.5436550378799438,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pedra_Dourada,2025-12-31T00:00:00,0.0,1.312173843383789,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pedra_do_Anta,2025-12-31T00:00:00,0.0,1.5748121738433838,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pedralva,2025-12-31T00:00:00,0.0,1.6277844905853271,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pedrinopolis,2025-12-31T00:00:00,0.0,2.150078296661377,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Perdizes,2025-12-31T00:00:00,0.0,1.7509568929672241,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Perdoes,2025-12-31T00:00:00,0.0,1.6579997539520264,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Piedade_de_Caratinga,2025-12-31T00:00:00,0.0,2.3133180141448975,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pimenta,2025-12-31T00:00:00,0.0,1.7274541854858398,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Piracema,2025-12-31T00:00:00,0.0,0.947127103805542,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Piranga,2025-12-31T00:00:00,0.0,1.7226738929748535,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pirangucu,2025-12-31T00:00:00,0.0,1.2917649745941162,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Piranguinho,2025-12-31T00:00:00,0.0,1.4732825756072998,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pirapora,2025-12-31T00:00:00,0.0,3.316178560256958,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Piumhi,2025-12-31T00:00:00,0.0,1.5819714069366455,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Poco_Fundo,2025-12-31T00:00:00,0.0,1.4138336181640625,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pocos_de_Caldas,2025-12-31T00:00:00,0.0,1.0728445053100586,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pocrane,2025-12-31T00:00:00,0.0,1.5448360443115234,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ponte_Nova,2025-12-31T00:00:00,0.0,1.4958975315093994,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ponto_dos_Volantes,2025-12-31T00:00:00,0.0,0.5825430154800415,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Porto_Firme,2025-12-31T00:00:00,0.0,1.2490758895874023,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pote,2025-12-31T00:00:00,0.0,0.9756540060043335,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pouso_Alegre,2025-12-31T00:00:00,0.0,1.6820523738861084,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pouso_Alto,2025-12-31T00:00:00,0.0,1.747568130493164,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pratapolis,2025-12-31T00:00:00,0.0,1.9246385097503662,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Pratinha,2025-12-31T00:00:00,0.0,1.7630361318588257,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Presidente_Bernardes,2025-12-31T00:00:00,0.0,1.2165569067001343,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Presidente_Kubitschek,2025-12-31T00:00:00,0.0,0.7397153377532959,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Presidente_Olegario,2025-12-31T00:00:00,0.0,1.7576419115066528,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Quartel_Geral,2025-12-31T00:00:00,0.0,2.98065447807312,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Raul_Soares,2025-12-31T00:00:00,0.0,1.705652117729187,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Reduto,2025-12-31T00:00:00,0.0,1.858236312866211,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ribeirao_Vermelho,2025-12-31T00:00:00,0.0,1.463039755821228,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Rio_Paranaiba,2025-12-31T00:00:00,0.0,1.3570550680160522,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Rio_Pardo_de_Minas,2025-12-31T00:00:00,0.0,3.492609739303589,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Rio_Vermelho,2025-12-31T00:00:00,0.0,0.8118492364883423,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ritapolis,2025-12-31T00:00:00,0.0,1.8159881830215454,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Romaria,2025-12-31T00:00:00,0.0,2.2027862071990967,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Rosario_da_Limeira,2025-12-31T00:00:00,0.0,1.2893240451812744,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sabinopolis,2025-12-31T00:00:00,0.0,1.152267336845398,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sacramento,2025-12-31T00:00:00,0.0,1.4454625844955444,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santa_Barbara,2025-12-31T00:00:00,0.0,1.1490789651870728,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santa_Barbara_do_Leste,2025-12-31T00:00:00,0.0,1.6274917125701904,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santa_Barbara_do_Monte_Verde,2025-12-31T00:00:00,0.0,1.1213716268539429,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santa_Margarida,2025-12-31T00:00:00,0.0,1.659772515296936,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santa_Maria_do_Suacui,2025-12-31T00:00:00,0.0,1.0623258352279663,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santa_Rita_de_Caldas,2025-12-31T00:00:00,0.0,1.7137970924377441,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santa_Rita_de_Minas,2025-12-31T00:00:00,0.0,1.4888384342193604,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santa_Rita_do_Itueto,2025-12-31T00:00:00,0.0,1.3353614807128906,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santa_Rita_do_Sapucai,2025-12-31T00:00:00,0.0,1.7185345888137817,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santa_Rosa_da_Serra,2025-12-31T00:00:00,0.0,1.7215945720672607,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santana_da_Vargem,2025-12-31T00:00:00,0.0,1.3073675632476807,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santana_do_Jacare,2025-12-31T00:00:00,0.0,1.2923082113265991,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santana_do_Manhuacu,2025-12-31T00:00:00,0.0,1.7167404890060425,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santo_Antonio_do_Amparo,2025-12-31T00:00:00,0.0,1.5555245876312256,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santo_Antonio_do_Grama,2025-12-31T00:00:00,0.0,1.6447937488555908,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Santo_Antonio_do_Retiro,2025-12-31T00:00:00,0.0,1.4901374578475952,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Bento_Abade,2025-12-31T00:00:00,0.0,1.5161290168762207,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Domingos_das_Dores,2025-12-31T00:00:00,0.0,1.5185999870300293,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Domingos_do_Prata,2025-12-31T00:00:00,0.0,1.0963362455368042,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Francisco_de_Paula,2025-12-31T00:00:00,0.0,1.5722641944885254,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Francisco_do_Gloria,2025-12-31T00:00:00,0.0,1.3613020181655884,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Geraldo,2025-12-31T00:00:00,0.0,1.3986103534698486,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Goncalo_do_Abaete,2025-12-31T00:00:00,0.0,1.294715404510498,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Goncalo_do_Rio_Preto,2025-12-31T00:00:00,0.0,2.7351861000061035,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Goncalo_do_Sapucai,2025-12-31T00:00:00,0.0,1.5365667343139648,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Gotardo,2025-12-31T00:00:00,0.0,1.3823882341384888,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Joao_Batista_do_Gloria,2025-12-31T00:00:00,0.0,1.430954933166504,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Joao_da_Mata,2025-12-31T00:00:00,0.0,1.1625615358352661,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Joao_del_Rei,2025-12-31T00:00:00,0.0,1.6839451789855957,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Joao_do_Manhuacu,2025-12-31T00:00:00,0.0,1.6092214584350586,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Joao_do_Manteninha,2025-12-31T00:00:00,0.0,1.395477294921875,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Joao_do_Paraiso,2025-12-31T00:00:00,0.0,4.724332809448242,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Jose_da_Barra,2025-12-31T00:00:00,0.0,2.04836106300354,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Jose_do_Alegre,2025-12-31T00:00:00,0.0,1.5749421119689941,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Jose_do_Mantimento,2025-12-31T00:00:00,0.0,1.8004207611083984,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Lourenco,2025-12-31T00:00:00,0.0,2.5378565788269043,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Miguel_do_Anta,2025-12-31T00:00:00,0.0,1.5927364826202393,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Pedro_da_Uniao,2025-12-31T00:00:00,0.0,1.5831966400146484,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Roque_de_Minas,2025-12-31T00:00:00,0.0,1.6279276609420776,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Sebastiao_da_Bela_Vista,2025-12-31T00:00:00,0.0,1.5251193046569824,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Sebastiao_da_Vargem_Alegre,2025-12-31T00:00:00,0.0,1.289090633392334,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Sebastiao_do_Anta,2025-12-31T00:00:00,0.0,1.9710150957107544,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Sebastiao_do_Maranhao,2025-12-31T00:00:00,0.0,1.0959653854370117,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Sebastiao_do_Paraiso,2025-12-31T00:00:00,0.0,1.3175508975982666,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Tiago,2025-12-31T00:00:00,0.0,1.4511181116104126,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Tomas_de_Aquino,2025-12-31T00:00:00,0.0,1.5083242654800415,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sao_Tome_das_Letras,2025-12-31T00:00:00,0.0,2.0729353427886963,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Senador_Firmino,2025-12-31T00:00:00,0.0,1.398680567741394,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Senador_Jose_Bento,2025-12-31T00:00:00,0.0,1.1037828922271729,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Senador_Modestino_Goncalves,2025-12-31T00:00:00,0.0,3.4568865299224854,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Senhora_de_Oliveira,2025-12-31T00:00:00,0.0,1.2517426013946533,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Senhora_dos_Remedios,2025-12-31T00:00:00,0.0,1.640761137008667,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Sericita,2025-12-31T00:00:00,0.0,2.16278076171875,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Serra_do_Salitre,2025-12-31T00:00:00,0.0,1.5311931371688843,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Serrania,2025-12-31T00:00:00,0.0,1.2646276950836182,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Setubinha,2025-12-31T00:00:00,0.0,1.058264136314392,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Silvianopolis,2025-12-31T00:00:00,0.0,1.483588695526123,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Simonesia,2025-12-31T00:00:00,0.0,2.326964855194092,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Soledade_de_Minas,2025-12-31T00:00:00,0.0,2.088977575302124,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Taiobeiras,2025-12-31T00:00:00,0.0,3.487426280975342,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Tapira,2025-12-31T00:00:00,0.0,1.7445780038833618,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Tapirai,2025-12-31T00:00:00,0.0,1.7215619087219238,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Teixeiras,2025-12-31T00:00:00,0.0,1.5385725498199463,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Teofilo_Otoni,2025-12-31T00:00:00,0.0,1.1192185878753662,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Tiros,2025-12-31T00:00:00,0.0,1.6680467128753662,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Tocos_do_Moji,2025-12-31T00:00:00,0.0,1.4326446056365967,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Tombos,2025-12-31T00:00:00,0.0,1.190578818321228,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Tres_Coracoes,2025-12-31T00:00:00,0.0,1.5402569770812988,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Tres_Pontas,2025-12-31T00:00:00,0.0,1.33225417137146,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Tupaciguara,2025-12-31T00:00:00,0.0,1.946883201599121,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Turmalina,2025-12-31T00:00:00,0.0,1.5735708475112915,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Turvolandia,2025-12-31T00:00:00,0.0,1.523424506187439,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Ubaporanga,2025-12-31T00:00:00,0.0,1.6122779846191406,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Uberaba,2025-12-31T00:00:00,0.0,2.213899612426758,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Uberlandia,2025-12-31T00:00:00,0.0,1.7769381999969482,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Unai,2025-12-31T00:00:00,0.0,2.456753969192505,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Urucuia,2025-12-31T00:00:00,0.0,1.9578778743743896,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Vargem_Bonita,2025-12-31T00:00:00,0.0,1.662156581878662,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Vargem_Grande_do_Rio_Pardo,2025-12-31T00:00:00,0.0,2.2517824172973633,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Varginha,2025-12-31T00:00:00,0.0,1.3287317752838135,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Varjao_de_Minas,2025-12-31T00:00:00,0.0,2.2993173599243164,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Varzea_da_Palma,2025-12-31T00:00:00,0.0,2.6450579166412354,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Vermelho_Novo,2025-12-31T00:00:00,0.0,2.013258934020996,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Vicosa,2025-12-31T00:00:00,0.0,1.6588630676269531,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Vieiras,2025-12-31T00:00:00,0.0,1.561140775680542,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Virginia,2025-12-31T00:00:00,0.0,1.5939329862594604,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Virginopolis,2025-12-31T00:00:00,0.0,1.5504217147827148,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
V38_2025,Visconde_do_Rio_Branco,2025-12-31T00:00:00,0.0,1.026964545249939,0.0,teste,V38,LSTM,"./Treinos/Altitude_Dataset_Unico/Modelos/V38_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V38.
    Estou usando o dataset V38, cada ano tem um dataset e o cluster se tornou variavel categorica (com dummy).

    O modelo foi treinado com as seguintes configurações:
    input_size: 6

    encoder_n_layers = 4
    learning_rate: 0.0010330837083315822
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-18T00:14:31
